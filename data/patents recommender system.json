[{"id": "20110208426", "patent_code": "10288433", "patent_name": "Map-matching for low-sampling-rate GPS trajectories", "year": "2019", "inventor_and_country_data": " Inventors: \nZheng; Yu (Beijing, CN), Lou; Yin (Shanghai, CN), Zhang; Chengyang (Beijing, CN), Xie; Xing (Beijing, CN)  ", "description": "<BR><BR>BACKGROUND\nThere has been an increased use of handheld or dashboard-mounted travel guidance systems, for example, Global Positioning System (GPS)-embedded personal digital assistants (PDAs) and smart phones.  In addition, there has been an increase in\napplications such as route planners, hot route finders, traffic flow analyzers, and geographical social network applications that use GPS data to achieve a better quality of service.\nTypically, a GPS trajectory consists of a sequence of positions with latitude, longitude, instant speed, direction and timestamp information.  However, this data can often be incorrect as a result of measurement errors caused by the limitations\nof typical GPS devices, as well as sampling errors caused by the sampling rate.  Therefore, an observed GPS position often needs to be aligned with a road network on a digital map.  This process is referred to as map-matching.  The difficulty of\nmap-matching can greatly differ depending on GPS accuracy and the sampling frequency, for example, map-matching is easier with data that is gathered frequently, and with a high degree of accuracy, than with data that is inaccurate or that is gathered\nless frequently.\nExisting map-matching approaches generally employ an algorithm that maps sampled positions from a GPS trajectory onto vector road segments on a map.  Such an approach typically considers sampled positions on a GPS trajectory while overlooking\nthe speed and temporal data that may also be found in the GPS trajectory.  These map-matching algorithms are typically most accurate when using data gathered at a high sampling rate.  As sampling frequency decreases, measurement errors typically\nincrease.  However, while a high sampling rate results in increased accuracy, it also carries a greater computational cost.\nMap-matching for low-sampling-rate GPS data is challenging because, as the sampling rate decreases, the interval between two neighboring positions in a trajectory increases, and less information is available to deduce the precise location of an\nobject.  A more effective approach for map-matching for low-sampling rate GPS trajectories utilizes temporal and speed data from the GPS trajectory to augment the spatial data.\n<BR><BR>SUMMARY\nThis summary is provided to introduce a selection of concepts in a simplified form that are further described below in the Detailed Description.  This summary is not intended to identify key features or essential features of the claimed subject\nmatter, nor is it intended to be used as an aid in determining the scope of the claimed subject matter.\nIn view of the above, this disclosure describes an exemplary method, user-interface, and computer-readable media for implementing map-matching for low-sampling rate GPS trajectories.\nIn an exemplary implementation, a mapping module receives a GPS trajectory that represents a path traveled by a user.  For example, as the user is driving through town, a GPS device automatically records data at regular, predetermined time\nintervals.  The GPS trajectory includes spatial data (e.g., one or more sampling points, latitude, longitude, and direction) and temporal data (e.g., speed and timestamp).  A set of one or more candidate projection points surrounding each of the one or\nmore sampling points of the trajectory is retrieved from a road network database, and one or more candidate road segments upon which the candidate projection points lie are determined.  Spatial and temporal analyses are performed on the retrieved set of\none or more candidate projection points.  A candidate graph is constructed based upon the results of the spatial analysis and the temporal analysis, and the candidate graph is evaluated to determine the set of candidate projection points that best\nmatches the one or more sampling points received from the user.\nMap-matching that is performed based on the GPS trajectory may also be used to calculate a recommended route based on user-submitted data that identifies additional locations to which the user would like to travel.  For example, a user interface\nmay be provided through which a user submits one or more locations to which the user would like to travel.  Those points are appended to the existing GPS trajectory, and the mapping module calculates a route to the user-submitted locations based, at\nleast in part, on the previously collected GPS trajectory.  The calculated route is then presented to the user. <BR><BR>BRIEF DESCRIPTION OF THE DRAWINGS\nThe detailed description is described with reference to the accompanying figures.  In the figures, the left-most digit of a reference number identifies the figure in which the reference number first appears.  The use of the same reference\nnumbers in different figures indicates similar or identical items.\nFIG. 1 is a schematic of an illustrative architecture of a map-matching framework.\nFIG. 2 is a block diagram of an exemplary computing device within the map-matching framework of FIG. 1.\nFIG. 3 is a block diagram of an exemplary server within the map-matching framework of FIG. 1.\nFIG. 4 is a flow chart of an exemplary map-matching process for determining a best-match trajectory.\nFIG. 5 is an illustration of exemplary sampling points mapped to sets of candidate projection points along mapped road segments.\nFIG. 6 is an illustrative shortest path computation.\nFIG. 7 is a further illustration of the spatial-temporal analysis of FIG. 4.\nFIG. 8 is an illustrative candidate graph within the map-matching framework of FIG. 1.\nFIG. 9 is an illustrative local spatial-temporal matching strategy.\nFIG. 10 is an illustrative process flow of the map-matching framework of FIG. 1.\nFIG. 11 is an illustrative example of the map-matching framework of FIG. 1.\n<BR><BR>DETAILED DESCRIPTION\nMap-matching for low-sampling rate global positioning system (GPS) trajectories is described.  More specifically, an exemplary map-matching algorithm utilizes both a spatial analysis and a temporal analysis to analyze a submitted set of sampling\npoints to determine a best match trajectory, or route, which is presented to the user.\nFIG. 1 is a block diagram of an exemplary environment 100, which is used for map-matching for a low-sampling rate GPS on a computing device.  The environment 100 includes an exemplary computing device 102, which may take a variety of forms\nincluding, but not limited to, a portable handheld computing device (e.g., a personal digital assistant, a smart phone, a cellular phone), a laptop computer, a desktop computer, a media player, a digital camcorder, an audio recorder, a camera, or any\nother device capable of connecting to one or more network(s) 104 to log or to record daily activities for a user 106 (i.e., creating a location history).  The computing device 102, which connects to one or more network(s) 104, is often associated with a\nuser 106.  For example, the user 106 often carries their computing device 102 when travelling outside the home.\nThe network(s) 104 represent any type of communications network(s), including, but not limited to, wire-based networks (e.g., cable), wireless networks (e.g., cellular, satellite), cellular telecommunications network(s), and IP-based\ntelecommunications network(s) (e.g., Voice over Internet Protocol networks).  The network(s) 104 may also include traditional landline or a public switched telephone network (PSTN), or combinations of the foregoing (e.g., Unlicensed Mobile Access or UMA\nnetworks, circuit-switched telephone networks or IP-based packet-switch networks).\nThe computing device 102 accesses a global positioning system (GPS) that conveniently logs navigation and positioning information as the device moves with the user 106.  In an exemplary implementation, a GPS 108 in the computing device 102\nstarts recording location data upon detecting a satellite signal.  For example, a GPS receiver collects the location data, p.sub.1, p.sub.2, and p.sub.3 along a GPS trajectory 110 based on pre-determined rate.  In the exemplary implementation, the GPS\n108 in the computing device 102 uses a low sampling rate to minimize computations and network bandwidth usage.  For example, the GPS 108 may record data every 2 minutes, every 5 minutes, or the like.  The GPS 108 continues to collect the location data as\nlong as there is a satellite signal detected on the network 104.\nThe user 106 enters a starting location and a desired destination through a user interface of the computing device 102.  The user-submitted starting location and desired destination, along with the data collected by the GPS 108, is sent over\nnetwork 104 to servers 112.  Exemplary servers 112 include a map-matching module 114 that analyzes the data collected by the GPS to determine a preferred route, for example, the shortest and most direct route from the starting location to the\nuser-submitted desired destination.  The map-matching module 114 determines the preferred route by preparing candidate projection points, performing spatial and temporal analysis, and matching the results.  The determined route is then stored and/or\npresented visually to the user.  Alternatively, the data collected by the GPS may be used to determine a route consisting entirely of highways, a route consisting entirely of service roads, or the like.  The map-matching module 114 provides the result\nback to the user via the computing device 102 through a network service provider, a context-aware computing service, email, text message, a pop up, and the like.\nFIG. 2 illustrates an exemplary computing device 102.  The computing device 102 includes, without limitation, a processor 202, a memory 204, and one or more communication interfaces 206.  An operating system 208, a user interface (UI) module\n210, a global positioning system (GPS) 108, and content storage 212 are maintained in memory 204 and executed on processor 202.\nWhen executed on the processor 202, the operating system 208 and UI module 210 collectively facilitate presentation of a user interface on a display of the computing device 102.  GPS 108 may be implemented as a component of a web browser or a\nsearch engine, or may be implemented as an application in the computing device 102.  As described above, the GPS 108 collects location data (e.g., GPS trajectories) over time as the computing device physically moves from one location to another.  Content\nstorage 212 provides local storage of sampling points and/or data received from map-matching module 114.  For example, the sampling points and/or data received from the map-matching module may be stored in GPS log 214.\nThe communication interfaces 204 may include, without limitation, a wide area network (WAN) interface, a local area network interface (e.g., WiFi), a personal area network (e.g., Bluetooth) interface, and/or any other suitable communication\ninterfaces to allow the computing device 102 to communicate over the network(s) 104.\nThe computing device 102, as described above, may be implemented in various types of system or networks.  For example, the computing device may be a part of, without limitation, a client-server system, a peer-to-peer computer network, a\ndistributed network, an enterprise architecture, a local area network, a wide area network, a virtual private network, a storage area network, and the like.\nFIG. 3 illustrates an exemplary server within the map-matching framework of FIG. 1.  The illustrated exemplary server 112 includes, without limitation, processor 302, memory 304, removable storage 306 and/or non-removable storage 308,\ncommunication interface(s) 314, and content storage 316.\nAn operating system 310, and a map-matching module 114 are maintained in the memory 304 and executed on the processor 302.  In an exemplary implementation, the map-matching module 114 includes a road network database 312 that includes, without\nlimitation information pertaining to at least geographical locations within roadway system(s).  For example, road network database 312 may contain a mapping system of the roadways of the greater Seattle area including, service roads, highways, and any\nother roads available to the user 106.  Map-matching module 114 may also include databases of other types of information, including for example, rivers, railways, airports, restaurants, hotels, etc.\nCommunication interfaces 314, allow the processor 302 to communicate with the computing device 102, other network servers, network storage, and/or other devices over the network(s) 104, and content storage 316.  Content storage 316 may store the\nGPS data collected by the GPS 108 and sent to the server 112.  For example, the GPS data may be stored in GPS log 318.  Although not shown in FIG. 3, the server 112 may also include one or more known input device(s), such as a keyboard, a mouse, a pen, a\nvoice input device, a touch input device, and an output device such as a display, speaker, printer, or the like.\nAny memory described herein may include volatile memory (such as RAM), nonvolatile memory, removable memory, and/or non-removable memory, implemented in any method or technology for storage of information, such as, computer-readable\ninstructions, data structures, applications, program modules, emails, and/or other content.  Also, any of the processors described herein may include onboard memory in addition to or instead of the memory shown in the figures.  The memory may include\nstorage media such as, but not limited to, random access memory (RAM), read only memory (ROM), flash memory, optical storage, magnetic disk storage or other storage devices, or any other medium which can be used to store the desired information and which\ncan be accessed by the respective systems and devices.\nFIG. 4 illustrates a process 400 for determining a best-match trajectory within the map-matching framework of FIG. 1.  The map-matching framework of FIG. 1 enables the analysis of the data collected by the computing device to determine a\npreferred route from the starting location to the user desired destination.\nThe process 400 includes, without limitation, preparation of candidate projection points 402, spatial and temporal analyses 404, and result matching, storage, and visualization 406.\nTo prepare the candidate projection points, the map-matching module obtains data from GPS logs 408(1), 408(2), .  . . , 408(N) and the road network database 312.  A candidate computation 410 is then performed, the results of which are used to\ndetermine candidate sets 412.  GPS logs 408 may correspond, for example, to GPS log 214 or GPS log 318 shown in FIG. 2 and FIG. 3, respectively.\nSpatial and temporal analyses 404 are then performed.  For example, a spatial analysis 414 and a temporal analysis 416 are performed on the candidate sets 412, resulting in a candidate graph 418.\nThe process concludes with result matching, storage, and visualization 406.  For example, a best path search 420 is performed on the candidate graph 418 to determine a matching result 422.  The matching result, or the preferred route, is\npresented to the user via a user interface 424.\nSpecific portions of process 400 are described below in greater detail with reference to FIG. 5-FIG. 9.  However, it is to be appreciated that the description is not necessarily limited to the specific features or methods described.\nFIG. 5 illustrates an exemplary candidate computation 410 portion of the process describe above with reference to FIG. 4.  Referring back to FIG. 1 and FIG. 4, in an exemplary implementation, as the user 106 travels along the trajectory 110, raw\nGPS trajectory data, or sampling points, are automatically collected by computing device 102 and communicated to the map-matching module 114.  The sampling points are taken at a low frequency, such as every 2 to 5 minutes, and are stored in GPS logs 408. As described above, GPS logs 408 may correspond to the GPS log 214 in the computing device 102 and/or the GPS log 318 in the server 112.  Map-matching module 114 accesses the sampling points stored in the GPS log 408 to determine the best trajectory or\nroute to get the user 106 from an identified starting location to a desired destination by first determining a set of candidate projection points corresponding to the sampling points stored in the GPS log 408.  To determine the set of candidate\nprojection points, map-matching module 114 utilizes a road network database 312 which, as discussed above, includes possible candidate road segments, or routes, available to the user 106.  Using the information from the road network database 312 and GPS\nlog 408, map-matching module 114 performs a candidate computation 404, an example of which is shown in FIG. 5.\nExemplary candidate computation 410 is determined by plotting one or more sampling points, p.sub.i, along a determined candidate road segment.  For each sampling point p.sub.i, a circle 502 encompasses a set of candidate road segments supplied\nby road network database 312 within a given radius.  In the example illustrated in FIG. 5, three sampling points are shown (i.e., p.sub.i-1, p.sub.i, and p.sub.i+1).  Focusing first on sampling point p.sub.i-1, two candidate road segments (i.e.,\nr.sub.i-1.sup.1 and r.sub.i-1.sup.2) lie within the circle 502(1) of p.sub.i-1, indicating that the sampled point p.sub.i+1 may correspond to a point on either road segment r.sub.i-1.sup.1 or road segment r.sub.i-1.sup.2.  Utilizing this data, the\nmap-matching module 114 determines at least one set of candidate projection points that lie along the candidate road segments r.sub.i-1.sup.1 and r.sub.i-1.sup.2.  For example, as further shown in FIG. 5, the map-matching module 114 determines candidate\nprojection points c.sub.i-1.sup.1 and c.sub.i-1.sup.2, corresponding to sampling point p.sub.i-1.\nSimilarly, the map-matching module 114 also identifies candidate projection points c.sub.i.sup.1 and c.sub.i.sup.2 along candidate road segments r.sub.i.sup.1 and r.sub.i.sup.2, respectively, within the circle 502(2) encompassing sampling point\np.sub.i; and identifies candidate projection points c.sub.i+1.sup.1 and c.sub.i+1.sup.2 corresponding to sampling point p.sub.i+1, where sampling point p.sub.i+1 is encompassed by circle 502(3).\nThe result of the candidate computation 410 is, for each sampling point, a set of candidate projection points.  Referring to the example shown in FIG. 5, the candidate computation 410 results in set {c.sub.i-1.sup.1,c.sub.i-1.sup.2},\ncorresponding to sampling point p.sub.i-1; set {c.sub.i.sup.1,c.sub.i.sup.2} corresponding to sampling point p.sub.i; and set {c.sub.i+1.sup.1,c.sub.i+1.sup.2} corresponding to sampling point p.sub.i+1.\nIn an exemplary implementation, one or more indexing techniques may be used to expedite the generation of a set of candidate projection points.  For example, indexing techniques that may be used include, without limitation, a space-partition\nbased indexing method, such as the grid-based spatial index and the quad tree indexing structure, or a data driven indexing structure such as an R-tree indexing structure.\nAfter determining the set of candidate projection points, as described above, the map-matching algorithm performs a spatial analysis 414 and a temporal analysis 416 to identify a particular candidate projection point within each set of candidate\nprojection points that best matches the corresponding sampling point.\nExemplary spatial analysis 414 utilizes geometric and topological information from the road network database 312 to evaluate each of the determined candidate projection points.  In one implementation, spatial analysis 414 includes two\ncomponents, an observation probability component and a transmission probability component.\nThe observation probability component represents the likelihood that a trajectory, or route, supplied from the map-matching module 114 to the user 106 is the best route based upon the distance between two candidate points, such as candidate\npoints c.sub.i.sup.1 and c.sub.i.sup.2.  However, because no additional information is taken into account the result typically includes an error.\nThe error in the observation probability is calculated as a normal distribution N (.mu., .sigma..sup.2) using the distance between sampling point p.sub.i and candidate point c.sub.i.sup.j.  The normal distribution demonstrates how likely the\ntrajectory supplied from the map-matching module 114 would have been if the user 106 had actually been on a road with a location c.sub.i.sup.j and without considering any previous points.  Accordingly, the observation probability is calculated according\nto:\n.function..times..pi..times..sigma..times.e.mu..times..sigma..times..time- s. ##EQU00001##\nwhere x is the distance between the sampling point p.sub.i and its corresponding candidate point c.sub.i.sup.j, represented as x.sub.i.sup.j=dist(c.sub.i.sup.j, p.sub.i).  In one implementation, a zero-mean normal distribution with a standard\ndeviation of about 66 feet (or about 20 meters) may be used.  Alternatively, any normal distribution with a suitable standard deviation may be used.\nIt is assumed that a typical user 106 would desire the shortest and most direct route to a destination.  Therefore, in one implementation, Equation (1) corresponds to a shortest path computation.  A variety of shortest path algorithms may be\nused to compute the shortest path.\nFIG. 6 illustrates an exemplary shortest path computation utilizing a Dijkstra's shortest path algorithm.  Steps 602, 604, 606, 608, 610, and 612, illustrate typical steps of a Dijkstra's computation.  An example Dijkstra's algorithm is:\nTABLE-US-00001 1.  INITIALIZE SINGLE-SOURCE (G, s) 2.  S .rarw.  { } // S will ultimately contains vertices of final shortest-path weights from s 3.  Initialize priority queue Q i.e., Q .rarw.  V[G] 4.  while priority queue Q is not empty do 5. \nu.rarw.  EXTRACT_MIN(Q) // Pull out new vertex 6.  S.rarw.  S .orgate.  {u} // Perform relaxation for each vertex v adjacent to u 7.  for each vertex v in Adj[u] do 8.  Relax (u,v,w)\nwhere G represents a candidate graph, s represents a source vertex or source sampling point, Q is a set of candidate projection points, and a vertex represents sampling points other than the source sampling point.  A tree T is built that spans\nall reachable vertices from a point S. Vertices are added to the tree T in order of the distance between the source sampling point and the remaining sampling points.  For example, a first distance S, then a vertex closest to S, and so on.\nAs described above, an exemplary spatial analysis 414 has an observation probability component and a transmission probability component.  The example Dijkstra's algorithm described above results in an observation probability.\nThe transmission probability for candidate points c.sub.i-1.sup.t to c.sub.i.sup.s for two neighboring sampling points p.sub.i-1 and p.sub.i respectively, is the likelihood that the \"true\" path from p.sub.i-1 and p.sub.i follows the shortest\npath from c.sub.i-1.sup.t to c.sub.i.sup.s.  Such a true path is represented by:\n.function..fwdarw..fwdarw..fwdarw..times..times.  ##EQU00002## where d.sub.i-1.fwdarw.1=dist(p.sub.i, p.sub.i-1) is the Euclidean distance between p.sub.i and p.sub.i-1, and w.sub.(i-1,t).fwdarw.(l,s) is the length of the shortest path from\nc.sub.i-1.sup.t to c.sub.i.sup.s.\nThe product of the observation probability and the transmission probability reflect the likelihood that the user 106 will move from c.sub.i-1.sup.t to c.sub.i.sup.s.  Combining the observation probability and the transmission probability, an\nexemplary spatial analysis function is: F.sub.s(c.sub.i-1.sup.t.fwdarw.c.sub.i.sup.s)=N(c.sub.i.sup.s)*V(c.su- b.i-1.sup.t.fwdarw.c.sub.i.sup.s),2.ltoreq.i.ltoreq.n Equation (3) where c.sub.i-1.sup.t and c.sub.i.sup.s may be any two candidate points for\ntwo neighboring sampling points p.sub.i-1 and p.sub.i.  The spatial analysis 414 for a candidate p.sub.i will differ depending upon the previous candidate point.\nAs previously discussed, map-matching based on spatial analysis alone, typically leads to poor accuracy when determining a best trajectory or route.  For example, as illustrated in FIG. 7, a bold line 702 represents a highway, and a thin line\n704 represents a service road.  Just looking at sampling point p.sub.i, it is difficult to determine from which road sampling point p.sub.i was most likely sampled.  In this example, although p.sub.i appears closer to the service road 704, the\nneighboring point's p.sub.i-1 and p.sub.i+1 are closer to the highway, which may suggest that p.sub.i was more likely sampled from a location on the highway than a location on the service road.  This example illustrates the potential for errors when\nperforming map-matching based solely on spatial analysis.\nAnalyzing speed information in addition to the location information can increase the accuracy of the map-matching.  In the example shown in FIG. 7, because the service road 704 and highway 702 are located in close proximity to one another,\nwhether p.sub.i is on the highway or the service road, the candidate points c.sub.i.sup.1 and c.sub.i.sup.2 have similar spatial measurements.  However, if the average speed of the user 106 is calculated over a time interval .DELTA.t, a speed indicting a\nhighway or a service road may be determined, enabling a more accurate result when determining the best trajectory or route for the user.  For example, if a typical service road has a speed limit of 30 miles per hour (mph), and over the time interval, an\naverage speed of 65 (mph) is calculated, then it would be more reasonable to map sampling point p.sub.i to the candidate projection point c.sub.i.sup.2 on the highway.\nTherefore, an exemplary temporal analysis 416 is based upon an average speed between two candidate points c.sub.i-1.sup.t and c.sub.i.sup.s corresponding to two neighboring sampling points, p.sub.i-1 and p.sub.i, respectively.  The average speed\n.nu..sub.(i-1,t).fwdarw.(i,s) is calculated using the formula:\n.fwdarw..times..times..DELTA..times..times..fwdarw..times..times.  ##EQU00003## where l.sub.u=e'.sub.u*l is the length of road segment e'.sub.u, and .DELTA.t.sub.i-1.fwdarw.i=p.sub.i*t-p.sub.i-1*t is the time interval between the two sampling\npoints p.sub.i and p.sub.i-1.  In an exemplary implementation, each road segment e'.sub.u is also associated with a typical speed value e'.sub.u*.nu., and a cosine distance may be used to measure the similarity between the actual average speed from\nc.sub.i-1.sup.t to c.sub.i.sup.s and the speed constraints (e.g., known speed limits) of the path.  Alternatively, any suitable measurement may be used to determine the similarity.  Considering a vector k with elements of the same value\n.nu..sub.(i-1,t).fwdarw.(i,s) and the vector (e'.sub.1.nu., e'.sub.21.nu., .  . . , e'.sub.k.nu.).sup.T, an exemplary temporal analysis function is calculated as:\n.function..fwdarw..times..times.'.times..fwdarw..times..times.'.times..ti- mes..times..fwdarw..times..times.  ##EQU00004##\nCombining Equation (3) and Equation (5), as set forth above, the spatial-temporal (ST) function for c.sub.i-1.sup.t.fwdarw.c.sub.i.sup.s is: F(c.sub.i-1.sup.t.fwdarw.c.sub.i.sup.s)=F.sub.s(c.sub.i-1.sup.t.fwdar-\nw.c.sub.i.sup.s)*F.sub.t(c.sub.i-1.sup.t.fwdarw.c.sub.i.sup.s),2.ltoreq.i.- ltoreq.n Equation (6)\nReferring back to the process illustrated in FIG. 4, a candidate graph 418 is created using candidate projection points determined during the spatial analysis 414 and the temporal analysis 416 calculations.  The candidate graph 418 illustrates\nthe possible trajectories or routes available to the user 106 and is used to perform a best path search 420.\nFIG. 8 illustrates an exemplary best path search 420.  For example, FIG. 8 illustrates an exemplary candidate graph G'.sub.T(P'.sub.T, E'.sub.T) for a trajectory T:p.sub.1.fwdarw.p.sub.2.fwdarw.p.sub.n, where V'.sub.T is a set of candidate\npoints corresponding to each of a set of received sampling points, and E'.sub.T is a set of edges representing the shortest paths between any two neighboring candidate points.\nThe candidate path search 420 may include c.sub.1.sup.s1.fwdarw.c.sub.2.sup.s2.fwdarw.  . . . c.sub.n.sup.sn, for example, 802.fwdarw.804.fwdarw.806.\nTo determine which candidate path sequence is a best match trajectory or route 422 corresponding to the sample points input by the user 106 or collected by the GPS 108, a score for each of the candidate path sequences is calculated.  For\nexample, scores for candidate path sequences 808(1) and 808(2) may be calculated and compared to determine which of the two candidate path sequences has the highest score, and is therefore the best match for the sampling points along the trajectory.  In\nan exemplary implementation, the score for such a candidate sequence path is given by: F(P.sub.c)=.SIGMA..sub.i=2.sup.nF(c.sub.i-1.sup.s.sup.i-1.fwdar- w.c.sub.i.sup.s.sup.i) Equation (7)\nThe best-match path P for a trajectory T may be selected using: P=arg max.sub.P.sub.cF(P.sub.c),.A-inverted.P.sub.c G'.sub.T(V'.sub.T,E'.sub.T) Equation (8)\nAlgorithm 1, set forth below, outlines an exemplary algorithm for a spatial and temporal analysis 404 using the map-matching module 114.  Algorithm 1 includes the terms and equations described above in FIGS. 1-7 and Equations 1-6.  According to\nAlgorithm 1, a set of candidate points for each sampling point along a Trajectory T (for example, the sampling points found in the GPS logs 408) is calculated.  A candidate graph is constructed based upon the spatial and temporal analyses, followed by a\nreport identifying the path sequence P with the highest ST-function value from G'.sub.T.  The result is sent to Algorithm 2.\nTABLE-US-00002 Algorithm 1 Map-Matching Algorithm Input: Road Network G, a list of GPS points p.sub.1, p.sub.2,...,p.sub.n Output: The matched sequence c.sub.1,j1, c.sub.2,j2,...,c.sub.n,jn 1: Initialize tList as an empty list; // a list of sets\nof candidates 2: for I = 1 to n do 3: s = GetCandidates(pi, G, r); // candidates within radius r 4: tList.add(s); 5: G' = ConstructGraph(tList); // constructs graph G' 6: RETURN FindMatchedSequence (G')\nAlgorithm 2, set forth below, outlines an exemplary algorithm for result matching, storage and visualization 406 based upon the results of Algorithm 1.  Algorithm 2 determines the trajectory or route most likely to correspond to the received\nsampling points.\nTABLE-US-00003 Algorithm 2 FindMatchedSequence Input: Candidate graph G' Output: The matched sequence c.sub.1,j1, c.sub.2,j2,...,c.sub.n,jn 1: Let f[ ] denote the highest score found so far; 2: Let pre[ ] denote the parent of current candidate;\n3: for each c.sub.l,s do 4: f[c.sub.l,s] = F.sub.s(c.sub.l,s); 5: for i = 2 to n do 6: for each c.sub.l,s do 7: max = -.infin.; 8: for each c.sub.i-l,t do 9: alt = f [c.sub.i-l,t] + F.sub.s(c.sub.l,s) * F.sub.t (P.sub.ci-l,t to cl,s); 10: if (alt&gt;max)\nthen 11: max = alt; 12: pre[c.sub.l,s] = c.sub.i-l,t; 13: f[c.sub.l,s] = max; 14: Initialize rList as an empty list; 15: p = maxarg.sub.cn,s(f[c.sub.n,s]); 16: for I = n downto 1 do 17: rList.add(p); 18: p = pre[p]; 19: return rList.reverse90;\nThe exemplary ST-matching strategy represented by Algorithm 1 and Algorithm 2 is based upon a global algorithm, meaning the best path sequence is computed based upon an overall score for the entire trajectory of the candidate path sequence. \nHowever, if a trajectory has too many sampling points (i.e., n is very large) map-matching module 114 may use a local algorithm, based on a subset of the sampling points, to determine a matching result 422.\nFIG. 9 illustrates an exemplary best path search 420 using a local algorithm.  As illustrated in FIG. 9, each partial candidate graph 902 and 904 is constructed from a trajectory T. A best matching sequence is determined for each partial\ncandidate graph similar to the global algorithm approach set forth above.  The process is repeated for each partial candidate graph to determine a matching result 422.\nFIG. 10 illustrates an exemplary method outlining the map-matching procedure set forth above.  At block 1002, a set of sampling points are collected by GPS 108 on computing device 102.  The sampling points are communicated from the computing\ndevice 102 to the map-matching module 114 over network 104.  At block 1004 map-matching module 114 generates a set of candidate projection points corresponding to each sampling point.  For example, a for every p.sub.1, a set of candidate points may\ninclude c.sub.1.sup.1, c.sub.1.sup.2, and c.sub.1.sup.3.  Using these candidate points, map-matching module 114 may access a road network database at block 1006 to determine one or more corresponding road segments.  At block 1008, map-matching module 114\nmay perform a spatial analysis and a temporal analysis using the set of candidate points.  For example, an observation measurement, a transmission measurement, and a temporal measurement are illustrated in Tables 1 and 2, respectively, shown in FIG. 11.\nAt block 1010 a candidate graph may be constructed.  For example, a candidate graph 1106, may be created corresponding to those measurements set forth in Tables 1 and 2, 1102 and 1104 of FIG. 11.  At block 1012 map--matching module may determine\na best match trajectory for the sampling points input by GPS 108.  For example, map-matching module 114 may use Algorithms 1 and 2, described above, to ascertain which candidate point has the highest overall score, and therefore is the best match to the\nsampling points.  For example, Table 3, 1108, illustrated in FIG. 11, shows c.sub.3.sup.2 having the highest overall score for candidate graph 1106.  Therefore, c.sub.3.sup.2 may be chosen as the matching result for p.sub.3, and therefore, the best match\ntrajectory is most likely c.sub.1.sup.1.fwdarw.c.sub.2.sup.2.fwdarw.c.sub.3.sup.2.  Conclusion\nAlthough map-matching for low-sampling rate GPS trajectories has been described in language specific to structural features and/or methods, it is to be understood that the subject of the appended claims are not necessarily limited to the\nspecific features or methods described.  Rather, the specific features and methods are disclosed as exemplary implementations.", "application_number": "12712857", "abstract": " This disclosure describes a map-matching module that supports a Global\n     Positioning System (GPS) and provides a user with a best match trajectory\n     corresponding to GPS sampling points taken at a low sampling rate. The\n     best match trajectory is based upon a spatial-temporal analysis.\n", "citations": ["5428546", "5802492", "5845227", "5904727", "6023241", "6091359", "6091956", "6122628", "6128279", "6219662", "6243647", "6317684", "6317686", "6351775", "6356838", "6385539", "6411897", "6424370", "6427122", "6430547", "6446121", "6493650", "6496814", "6513026", "6516272", "6553310", "6584401", "6606643", "6611881", "6615130", "6618507", "6625319", "6724733", "6732120", "6785704", "6816779", "38724", "6904160", "6919842", "6925447", "6965827", "6970884", "6981055", "7003555", "7013290", "7013517", "7031517", "7062562", "7111061", "7136932", "7152118", "7155456", "7171415", "7194552", "7197500", "7203693", "7219067", "7228359", "7233861", "7239962", "7281199", "7284051", "7349768", "7366726", "7389283", "7395250", "7428551", "7437239", "7437372", "7447588", "7479897", "7493294", "7519690", "7548936", "7561959", "7574508", "7584159", "7584301", "7603233", "7610151", "7660441", "7685422", "7706964", "7707314", "7710984", "7739040", "7801842", "7840407", "7860891", "7904530", "7920965", "7930427", "7948400", "7982635", "7984006", "7991879", "8060462", "8117138", "8135505", "8190649", "8219112", "8275649", "8458298", "8562439", "8577380", "9009177", "20010029425", "20020032689", "20020038360", "20020044690", "20020052873", "20020062193", "20020077749", "20020128768", "20030053424", "20030063133", "20030069893", "20030069968", "20030139898", "20030140040", "20030195810", "20030212689", "20030217070", "20030229697", "20040039798", "20040064338", "20040073640", "20040117358", "20040196161", "20040198386", "20040217884", "20040220965", "20040264465", "20050004830", "20050004903", "20050031296", "20050075116", "20050075119", "20050075782", "20050075784", "20050080554", "20050108261", "20050131889", "20050198286", "20050203927", "20050225678", "20050231394", "20050265317", "20050278371", "20060020597", "20060036630", "20060042483", "20060075139", "20060085177", "20060085419", "20060090122", "20060095540", "20060101377", "20060129675", "20060143442", "20060149464", "20060155464", "20060156209", "20060161560", "20060164238", "20060173838", "20060178807", "20060190602", "20060200539", "20060212217", "20060224303", "20060224773", "20060247844", "20060251292", "20060265125", "20060266830", "20070005419", "20070006098", "20070016663", "20070038362", "20070041393", "20070064633", "20070064715", "20070088974", "20070100776", "20070118668", "20070127833", "20070168208", "20070203638", "20070226004", "20080004789", "20080004793", "20080016051", "20080016233", "20080052303", "20080059576", "20080071465", "20080076451", "20080086574", "20080098313", "20080201074", "20080201102", "20080214157", "20080215237", "20080228396", "20080228783", "20080235383", "20080268876", "20080270019", "20080312822", "20080319648", "20080319660", "20080319974", "20090005987", "20090019181", "20090063646", "20090070035", "20090083128", "20090083237", "20090100018", "20090138188", "20090164516", "20090213844", "20090216435", "20090216704", "20090222581", "20090228198", "20090239552", "20090282122", "20090326802", "20100004997", "20100010991", "20100027527", "20100070171", "20100076968", "20100082611", "20100111372", "20100153292", "20100279616", "20100312461", "20110022299", "20110029224", "20110130947", "20110173015", "20110176000", "20110184949", "20110191011", "20110191284", "20110208419", "20110280453", "20110282798", "20110302209", "20120030029", "20120030064", "20120150425", "20120256770", "20130166188", "20140088791", "20150117713", "20150186389", "20160232179", "20170131110"], "related": []}, {"id": "20130138743", "patent_code": "10367898", "patent_name": "Interest profiles for audio and/or video streams", "year": "2019", "inventor_and_country_data": " Inventors: \nAmento; Brian (Morris Plains, NJ), Harrison; Christopher (Mount Kisco, NY), Stead; Larry (Upper Montclair, NJ)  ", "description": "<BR><BR>FIELD OF THE DISCLOSURE\nThe present disclosure is generally related to methods and systems for determining user interest in audio and/or video streams.\n<BR><BR>BACKGROUND\nA large quantity of streaming media items, such as audio items and video items, are available to users through cable television, Internet Protocol television (IPTV), internet radio and other distribution systems.  Recommendation systems have\nbeen proposed to help users find and play those items that may be of interest to them, and to filter out items that may not be of interest to them.  For television programming, some recommendation systems cluster people based on what shows they enjoy. \nHowever, different people may enjoy the same show for different reasons.  For example, a first group of people may like a television show such as \"Law & Order\" because of its being an investigative drama, and a second group of people may like the same\ntelevision show because of its being a court drama.  Using a current voting system for television programming, both the first group and the second group would indicate that they enjoy this television show.  However, current recommendation systems may use\nthis information to make an ill-advised recommendation of other court dramas to the first group, and/or other investigative dramas to the second group. <BR><BR>BRIEF DESCRIPTION OF THE DRAWINGS\nFIG. 1 is a block diagram of an embodiment of a system for determining and using a user interest profile;\nFIG. 2 is a flow chart of an embodiment of a method of determining a user interest profile;\nFIG. 3 is an example of a user interest profile;\nFIG. 4 is a flow chart of an embodiment of a method of recommending a streaming media item to a user based on a user interest profile;\nFIGS. 5(A-D) show examples of three aggregate user interest profiles of three groups of users toward the same program, and a user interest profile of the user toward the same program;\nFIG. 6 is a flow chart of an embodiment of a method of determining a contention point in a streaming media item;\nFIGS. 7(A-C) show examples of two interest profiles for the same streaming media item, and an example of an interest difference profile formed by calculating a difference between the two interest profiles;\nFIG. 8 is a flow chart of an embodiment of a method of creating a streaming media item based on a plurality of interest profiles;\nFIGS. 9(A-D) show examples of aggregate interest profiles of a group toward three programs, and an example of a combined streaming media item that combines the high-interest portions into a continuous high-interest program; and\nFIG. 10 is a block diagram of an illustrative embodiment of a computer system.\n<BR><BR>DETAILED DESCRIPTION\nDisclosed herein are embodiments of methods and systems that provide a profile of portion-varying and/or time-varying ratings throughout an entire stream of content.  The in-stream ratings can be used during playback to concentrate on the best\nportions of the stream or to segment the stream and to keep only those segments having high quality ratings.  Storage space can be saved by storing higher-quality segments and not storing lower-quality segments.  More powerful recommendation systems can\nbe created using the profile in contrast to using an overall enjoyment rating for each streaming media item.\nFIG. 1 is a block diagram of an embodiment of a system for determining and using the user interest profile, and FIG. 2 is a flow chart of an embodiment of a method of determining a user interest profile.  As indicated by block 10, the method\ncomprises playing a streaming media item A 12 to a user 14.  Examples of any of the herein-disclosed streaming media items, including the streaming media item A 12, include but are not limited to video items such as movies, documentaries and television\nprograms, and audio items such as songs and radio programs.  The video items and audio items may be recorded or live.  A media player 16 may be used to play the streaming media item A 12 to the user 14.  Examples of the media player 16 include but are\nnot limited to a computer, a wireless telephone, a digital audio player, a set-top box, a television, a radio, or an alternative device operable to play audio and/or video received as packets.  The streaming media item A 12 may be either\nfully-downloaded, progressively-downloaded, or otherwise streamed to the site of the user 14 while the media player 16 plays the streaming media item A 12.  In an embodiment, an IPTV service provider provides the streaming media item A 12 to the user 14.\nAs indicated by block 20, the method comprises receiving an input from the user 14 while the user is watching and/or listening to a currently-playing portion of the streaming media item A 12.  The input indicates a rating, by the user 14, of the\ncurrently-playing portion of the streaming media item A 12.  The input may be received by a user input device 22.  In an embodiment, the user input device 22 comprises a positive rating button 24 and a negative rating button 26.  The user 14 indicates a\npositive rating of the currently-playing portion of the streaming media item A 12 by pushing or otherwise selecting the positive rating button 24.  The user 14 indicates a negative rating of the currently-playing portion of the streaming media item A 12\nby pushing or otherwise selecting the negative rating button 26.  Different levels of positive and negative ratings can be indicated by repeated selections of the positive rating button 24 and the negative rating button 26, respectively.  The positive\nrating button 24 and negative rating button 26 may be metaphors for more complex adjective pairs such as exciting/slow, interesting/boring, well-done/cheesy, and unexpected/predictable.  To mitigate any bias of the user 14, no additional meaning beyond\npositive/negative is supplied to the user 14.\nAs indicated by block 30, the method comprises storing data 32 representative of the input from the user 14.  The data 32 may associate a first value, which indicates the particular portion of the streaming media item A 12 for which the rating\nwas inputted, with a second value which indicates the rating (e.g. positive or negative) inputted by the user 14.  The first value may indicate the particular portion by a time value.  For example, the first value may indicate that the rating was\ninputted at a time position of 2 minutes, 52 seconds from the beginning of the streaming media item A 12.  Alternatively, the first value may indicate the particular position by a frame value.  For example, the first value may indicate that the rating\nwas inputted while the Nth frame of the streaming media item A 12 was being displayed.\nThe acts indicated by blocks 20 and 30 are repeated one or more times as the user 14 watches and/or listens to the streaming media item A 12.  As the acts are repeated, the data 32 is collected in the memory 34 over a course (which may be entire\ncourse) of the streaming media item A 12.  The collected data 32 indicates a plurality of ratings inputted by the user 14 for a plurality of respective portions of the streaming media item A 12.  Each of the plurality of ratings is inputted by the user\nduring playback of its respective portion of the streaming media item A 12.  The user 14 decides how many and/or which respective portions of the streaming media item A 12 to express the ratings.  The collection of data 32 can be viewed as representing\nindividual votes regarding the quality of the streaming media item A 12, the votes being temporally synchronized to a stream of the streaming media item A 12.  The data 32 can be stored either at a premise of the user 14, or at a site of a media service\nprovider (e.g. an IPTV service provider), or at a site of a third-party advertiser.\nAs indicated by block 40, the method comprises determining a user interest profile 42 based on the data 32.  The user interest profile 42 indicates a portion-varying level of user interest of the user 14 toward the streaming media item A 12. \nThe user interest profile 42 may span the entire course of the streaming media item A 12.  The user interest profile 42 may be determined by an interest profile generator 44.  The interest profile generator 44 can be located either at a premise of the\nuser 14, or at a site of a media service provider (e.g. an IPTV service provider), or at a site of a third-party advertiser.\nMany different approaches can be used to create the user interest profile 42 based on the data 32.  In an embodiment, when the streaming media item A 12 first begins, the user interest profile 42 indicates an interest level of the user 14 that\nis neither positive nor negative (e.g. a nominal or average level).  The interest level is increased for a section of the streaming media item A 12 for which the positive rating button 24 was pressed or otherwise selected.  The interest level is\ndecreased for a section of the streaming media item A 12 for which the negative rating button 26 was pressed or otherwise selected.  Repeated button presses in one direction will accumulate to further increase or decrease the interest level in the user\ninterest profile 42.\nThe user 14 may be likely to indicate his/her interest level at noteworthy points in the streaming media item A 12, but thereafter may be unlikely to adjust his/her interest level back to an average state.  To handle this scenario, the user\ninterest profile 42 is generated to have an interest level that responds to the user-inputted ratings as described above, but returns toward the nominal level over periods of inactivity (e.g. periods for which no user-inputted ratings are received).  The\nreturn toward the nominal level can be a linear decay, an exponential decay, or according to another decay function.\nIn an embodiment, the user interest profile 42 is generated using curve fitting and/or interpolation to fit a smooth and/or continuous curve over the data 32.\nThe method of collecting user interest data tied to particular portions of a media stream gives finer-grained ratings data compared with existing recommender systems.  This user interest data can be used for applications such as social\nrecommendation applications, contention point applications, and social highlighting applications.  Embodiments of social recommendation applications are subsequently described with reference to FIGS. 4 and 5.  Embodiments of contention point applications\nare subsequently described with reference to FIGS. 6 and 7.  Embodiments of social highlighting applications are subsequently described with reference to FIGS. 8 and 9.  The user interest data may be used internally by a media service provider, such as\nan IPTV service provider, to provide these and other applications.  Alternatively, some applications may be provided by a third-party advertiser.  The third-party advertiser may receive user interest data and/or interest profiles either from a plurality\nof users including the user 14, or from the media service provider (e.g. the IPTV service provider) that serves the plurality of users including the user 14.  The third-party advertiser may target an advertisement (e.g. recommend a media content item) to\nthe user 14 based on the received data and/or received interest profiles.\nFIG. 3 is an example of the user interest profile 42.  The user interest profile 42 indicates an interest level versus time over the course of the streaming media item A 12.  The user interest profile 42 is generated based on positive\nindications (indicated by the circles containing a plus sign) and negative indications (indicated by circles containing a minus sign) inputted by the user 14.  The times associated with the positive indications and the negative indications are indicated\nby the time axis.  The resulting user interest profile 42 may indicate a high interest portion 56 and a low interest portion 58 of the streaming media item A 12.\nFIG. 4 is a flow chart of an embodiment of a method of recommending a streaming media item B 70 to the user 14 based on the user interest profile 42.  As indicated by block 72, the method comprises determining a plurality of user interest\nprofiles 74 for a plurality of users.  Each of the user interest profiles 74 indicates a respective portion-varying level of interest of a respective one of the users toward the streaming media item A 12.\nAs indicated by block 76, the method comprises determining a group of the users whose aggregate user interest profile for the streaming media item A 12 is similar to the user interest profile 42.  The aggregate user interest profile is a user\ninterest profile formed by aggregating the interest data collected for all of the users in the group.  In an embodiment, an aggregation of collected rating data for a number of users is processed by the interest profile generator 44 (e.g. as if for a\nsingle user) but divided by the number of users to form the aggregate user interest profile.  In another embodiment, the aggregate user interest profile is generated by processing a number of user interest profile curves.\nAs indicated by block 82, the method comprises determining that streaming media item B 70 is positively rated by the group of users whose aggregate user interest profile is similar to the user interest profile 42.  The aggregate user interest\nprofile may be deemed to be similar to the user interest profile 42 based on a high degree of correlation between their two respective functions of time.  The streaming media item B 70 may be determined to be positively rated based on other user interest\nprofiles 80 of other users toward the streaming media item B 70.\nAs indicated by block 86, the method comprises recommending the streaming media item B 70 to the user 14 based on said determining in block 82.  This act can be performed by a recommender system 88, which sends a recommendation message 90 for\nthe streaming media item B 70 to the user 14.  The recommender system 88 can be located either at a premise of the user 14, or at a site of a media service provider (e.g. an IPTV service provider), or at a site of a third-party advertiser.  Thus, the act\nof recommending may be performed by the IPTV service provider, or the advertiser who is advertising the streaming media item B 70, or another entity.\nIn an embodiment, the recommendation message 90 is sent to the user 14 via an Internet Protocol (IP) network such as an IPTV network provided by an IPTV service.  Based on the recommendation message 90, a recommendation of the streaming media\nitem B 70 is displayed by a visual display device and/or an audio output device.  In an embodiment, the recommendation message 90 comprises an advertisement for the streaming media item B 70.  In response to the recommendation message 90, the user 14 may\norder or otherwise select the streaming media item B 70, and thereafter play the streaming media item B 70 using the media player 16.  An IPTV service provider may provide the streaming media item B 70 to the user 14.\nFIGS. 5(A-C) show examples of three aggregate user interest profiles 100, 102 and 104 of three groups X, Y and Z of users toward the same program (or alternative streaming media item).  As a user watches the program for the first time, interest\ndata is collected.  When the program is complete, an analysis can be performed to see if a group of users had similar characteristics.  FIG. 5D shows a user interest profile 106 of the user 14 toward the same program.  The user interest profile 106 is\ncompared to the three aggregate user interest profiles 100, 102 and 104 to determine a best fit.  In this example, the user interest profile 106 is most similar to the aggregate user interest profile 102 for group Y. The recommender system searches for\nanother program that is highly rated by the users in group Y, and recommends the other program to the user 14.\nThe aforementioned approach can be applied either to a single program or to multiple programs.  If a group has similar interest profiles for many programs, it is likely that they enjoy similar shows for similar reasons.\nFIG. 6 is a flow chart of an embodiment of a method of determining a contention point in a streaming media item.  A contention point is a portion of the streaming media item at which a significant level of disagreement is exhibited in the\ninterest level of different users.  In an embodiment, the different users are within the same group.  The users can be automatically placed in the group based on collected interest data, or can choose to join the group.  Examples of groups that users\njoin include a group of friends, a group of family members and a group of co-workers.\nAs indicated by block 110, the method comprises determining a portion of the streaming media item for which the group has expressed disagreement in interest.  This act may comprise determining an interest difference profile based on a difference\nbetween two interest profiles for the streaming media item.  In an embodiment, the interest different profile is determined by subtracting a first interest profile from a second interest profile for the streaming media item.  This act may further\ncomprise determining that the interest difference profile is beyond a predetermined agreement threshold for a portion of the streaming media item.  If a difference level for a section of the streaming media item is above a predetermined agreement\nthreshold, that section of streaming media item is considered a contention point at which disagreement in interest has been expressed.\nAs indicated by block 112, the method comprises indicating the portion to a user.  The portion may be indicated to the user either while he/she is watching/listening to the streaming media item, or after he/she has watched/listened to the\nstreaming media item, or before he/she has watched/listened to the streaming media item.  For example, the portion can be indicated to the user 14 via the media player 16.  Indicating the contention point to users promotes a collaborative and interactive\nviewing experience for television and other stream-based media.  For example, the indication of the contention point may promote discussion of the streaming media item to be generated within the group.\nThe contention point may be determined by a contention point detector 114.  The contention point detector 114 may generate a message 116 to indicate the contention point to the user 14.\nFor example, the contention point detector 114 may detect one or more contention points in streaming media item B 70 based on the other user interest profiles 80.  The message 116 may indicate, to the user 14, the one or more contention points\nin the streaming media item B 70.  The message 116 may be communicated to the media player 16 either before, during, or after the streaming media item B 70 has been communicated to the media player 16.\nFIGS. 7(A-B) show examples of two interest profiles 120 and 122 for the same streaming media item.  FIG. 7C shows an example of an interest difference profile 124 formed by calculating a difference between the interest profiles 120 and 122.  An\nagreement threshold 126 is used to determine if any contention points exist in the interest difference profile 124.  In this example, a portion 130 of the streaming media item has an associated interest difference that exceeds the agreement threshold\n126, and is thus considered to be a contention point.\nFIG. 8 is a flow chart of an embodiment of a method of creating a streaming media item based on a plurality of interest profiles.\nAs indicated by block 140, the method comprises determining one or more aggregate interest profiles for a respective one or more streaming media items.  Each of the aggregate interest profiles indicates a portion-varying level of interest of\nmembers of a group toward its respective streaming media item.  Each of the group interest profiles is based on a plurality of ratings inputted by the group members for a plurality of respective portions of its respective streaming media item.\nAs indicated by block 142, the method comprises determining a plurality of high-interest portions of the one or more streaming media items based on the aggregate interest profiles.  A portion is deemed to be of high-interest if either a spike or\na sustained plateau of high aggregate interest (e.g. aggregate interest above a threshold) is identified therefore.  This may occur, for example, when an exciting play occurs during a sporting event or when a particularly interesting or relevant story\nairs on a news program.\nAs indicated by block 144, the method comprises extracting the high-interest portions from the one or more streaming media items and creating a combined streaming media item that combines the high-interest portions.  The combined streaming media\nitem is a synthesized high-interest program comprising a succession of the extracted high-interest portions.\nAs indicated by block 146, the method comprises providing the combined streaming media item to a user.  The combined streaming media item can be provided to the user because the user has manually selected the group, or because the system has\nautomatically determined that the user has like interests with people in the group.\nIn an embodiment, the one or more streaming media items are limited by at least one criterion selected or otherwise inputted by the user.  For example, one or more streaming media items may be limited to a plurality of streaming media items in a\nparticular genre (e.g. all sporting events) selected by the user, and/or a plurality of streaming media items in a particular time period (e.g. everything within the last hour or the current day) selected by the user.  Alternatively, the one or more\nstreaming media items may be limited to a single program (e.g. a single football game) selected by the user.  As another alternative, the one or more streaming media items may comprise all available programming.\nThis method empowers users to act collectively to filter streaming media and to remix streams by their ratings.\nFIGS. 9(A-C) show examples of aggregate interest profiles 160, 162 and 166 of a group toward three programs.  The three programs can originate from one or more sources.  The aggregate interest profile 160 exhibits a high-interest portion 170. \nThe aggregate interest profile 162 exhibits two high-interest portions 172 and 174.  The aggregate interest profile 166 exhibits a high-interest portion 176.  FIG. 9D shows an example of a combined streaming media item that combines the high-interest\nportions 170, 172, 174 and 176 into a continuous high-interest program.\nThe herein-disclosed streaming media items can be stored in a variety of ways.  For example, any of the herein-disclosed streaming media items can be either stored locally to the user 14 (e.g. on a digital video recorder of the user 14), stored\non a central server in a network that serves media content to the user 14, or distributed through a peer-to-peer network that serves media content to the user 14.  Various distribution mechanisms can be used to distribute streaming media items in packets\nto users.\nReferring to FIG. 10, an illustrative embodiment of a computer system is shown and is designated 400.  The computer system 400 can include a set of instructions that can be executed to cause the computer system 400 to perform any one or more of\nthe methods or computer based functions disclosed herein.  The computer system 400 may operate as a standalone device or may be connected, e.g., using a network, to other computer systems or peripheral devices.\nIn a networked deployment, the computer system may operate in the capacity of a server or as a client user computer in a server-client user network environment, or as a peer computer system in a peer-to-peer (or distributed) network environment. The computer system 400 can also be implemented as or incorporated into various devices, such as a personal computer (PC), a tablet PC, a set-top box (STB), a personal digital assistant (PDA), a mobile device, a palmtop computer, a laptop computer, a\ndesktop computer, a communications device, a wireless telephone, a land-line telephone, a control system, a camera, a scanner, a facsimile machine, a printer, a pager, a personal trusted device, a web appliance, a network router, switch or bridge, or any\nother machine capable of executing a set of instructions (sequential or otherwise) that specify actions to be taken by that machine.  In a particular embodiment, the computer system 400 can be implemented using electronic devices that provide voice,\nvideo or data communication.  Further, while a single computer system 400 is illustrated, the term \"system\" shall also be taken to include any collection of systems or sub-systems that individually or jointly execute a set, or multiple sets, of\ninstructions to perform one or more computer functions.\nAs illustrated in FIG. 10, the computer system 400 may include a processor 402, e.g., a central processing unit (CPU), a graphics processing unit (GPU), or both.  Moreover, the computer system 400 can include a main memory 404 and a static\nmemory 406 that can communicate with each other via a bus 408.  As shown, the computer system 400 may further include a video display unit 410, such as a liquid crystal display (LCD), an organic light emitting diode (OLED), a flat panel display, a solid\nstate display, or a cathode ray tube (CRT).  Additionally, the computer system 400 may include an input device 412, such as a keyboard, and a cursor control device 414, such as a mouse.  The computer system 400 can also include a disk drive unit 416, a\nsignal generation device 418, such as a speaker or remote control, and a network interface device 420.\nIn a particular embodiment, as depicted in FIG. 10, the disk drive unit 416 may include a computer-readable medium 422 in which one or more sets of instructions 424, e.g. software, can be embedded.  Further, the instructions 424 may embody one\nor more of the methods or logic as described herein.  In a particular embodiment, the instructions 424 may reside completely, or at least partially, within the main memory 404, the static memory 406, and/or within the processor 402 during execution by\nthe computer system 400.  The main memory 404 and the processor 402 also may include computer-readable media.\nIn an alternative embodiment, dedicated hardware implementations, such as application specific integrated circuits, programmable logic arrays and other hardware devices, can be constructed to implement one or more of the methods described\nherein.  Applications that may include the apparatus and systems of various embodiments can broadly include a variety of electronic and computer systems.  One or more embodiments described herein may implement functions using two or more specific\ninterconnected hardware modules or devices with related control and data signals that can be communicated between and through the modules, or as portions of an application-specific integrated circuit.  Accordingly, the present system encompasses\nsoftware, firmware, and hardware implementations.\nIn accordance with various embodiments of the present disclosure, the methods described herein may be implemented by software programs executable by a computer system.  Further, in an exemplary, non-limited embodiment, implementations can\ninclude distributed processing, component/object distributed processing, and parallel processing.  Alternatively, virtual computer system processing can be constructed to implement one or more of the methods or functionality as described herein.\nThe present disclosure contemplates a computer-readable medium that includes instructions 424 so that a device connected to a network 426 can communicate voice, video or data over the network 426.  Further, the instructions 424 may be\ntransmitted or received over the network 426 via the network interface device 420.\nWhile the computer-readable medium is shown to be a single medium, the term \"computer-readable medium\" includes a single medium or multiple media, such as a centralized or distributed database, and/or associated caches and servers that store one\nor more sets of instructions.  The term \"computer-readable medium\" shall also include any medium that is capable of storing or encoding a set of instructions for execution by a processor or that cause a computer system to perform any one or more of the\nmethods or operations disclosed herein.\nIn a particular non-limiting, exemplary embodiment, the computer-readable medium can include a solid-state memory such as a memory card or other package that houses one or more non-volatile read-only memories.  Further, the computer-readable\nmedium can be a random access memory or other volatile re-writable memory.  Additionally, the computer-readable medium can include a magneto-optical or optical medium, such as a disk or tapes or other storage device.  A digital file attachment to an\ne-mail or other self-contained information archive or set of archives may be considered a distribution medium that is equivalent to a tangible storage medium.  Accordingly, the disclosure is considered to include any one or more of a computer-readable\nmedium or a distribution medium and other equivalents and successor media, in which data or instructions may be stored.\nAlthough the present specification describes components and functions that may be implemented in particular embodiments with reference to particular standards and protocols, the disclosed embodiments are not limited to such standards and\nprotocols.  For example, standards for Internet and other packet switched network transmission (e.g., TCP/IP, UDP/IP, HTML, HTTP) represent examples of the state of the art.  Such standards are periodically superseded by faster or more efficient\nequivalents having essentially the same functions.  Accordingly, replacement standards and protocols having the same or similar functions as those disclosed herein are considered equivalents thereof.\nThe illustrations of the embodiments described herein are intended to provide a general understanding of the structure of the various embodiments.  The illustrations are not intended to serve as a complete description of all of the elements and\nfeatures of apparatus and systems that utilize the structures or methods described herein.  Many other embodiments may be apparent to those of skill in the art upon reviewing the disclosure.  Other embodiments may be utilized and derived from the\ndisclosure, such that structural and logical substitutions and changes may be made without departing from the scope of the disclosure.  Additionally, the illustrations are merely representational and may not be drawn to scale.  Certain proportions within\nthe illustrations may be exaggerated, while other proportions may be reduced.  Accordingly, the disclosure and the figures are to be regarded as illustrative rather than restrictive.\nOne or more embodiments of the disclosure may be referred to herein, individually and/or collectively, by the term in \"invention\" merely for convenience and without intending to voluntarily limit the scope of this application to any particular\ninvention or inventive concept.  Moreover, although specific embodiments have been illustrated and described herein, it should be appreciated that any subsequent arrangement designed to achieve the same or similar purpose may be substituted for the\nspecific embodiments shown.  This disclosure is intended to cover any and all subsequent adaptations or variations of various embodiments.  Combinations of the above embodiments, and other embodiments not specifically described herein, will be apparent\nto those of skill in the art upon reviewing the description.\nThe Abstract of the Disclosure is provided with the understanding that it will not be used to interpret or limit the scope or meaning of the claims.  In addition, in the foregoing Detailed Description, various features may be grouped together or\ndescribed in a single embodiment for the purpose of streamlining the disclosure.  This disclosure is not to be interpreted as reflecting an intention that the claimed embodiments require more features than are expressly recited in each claim.  Rather, as\nthe following claims reflect, inventive subject matter may be directed to less than all of the features of any of the disclosed embodiments.  Thus, the following claims are incorporated into the Detailed Description, with each claim standing on its own\nas defining separately claimed subject matter.\nThe above-disclosed subject matter is to be considered illustrative, and not restrictive, and the appended claims are intended to cover all such modifications, enhancements, and other embodiments, which fall within the scope of the disclosure. \nThus, to the maximum extent allowed by law, the scope of the disclosure is to be determined by the broadest permissible interpretation of the following claims and their equivalents, and shall not be restricted or limited by the foregoing detailed\ndescription.", "application_number": "13751722", "abstract": " A method includes determining, at a processor, a difference between a\n     first user interest profile of a first user and a second user interest\n     profile of a second user. The difference is associated with a portion of\n     a first streaming media item. The method further includes transmitting,\n     to a device associated with a third user interest profile of a third\n     user, a first indication associated with the first streaming media item\n     based on the difference. The first user, the second user, and the third\n     user are distinct users.\n", "citations": ["4870579", "4996642", "5223924", "5754939", "5790426", "5884282", "5983214", "6029195", "6064980", "6438579", "6567797", "6782550", "6792412", "6912521", "7031931", "7051352", "7075000", "7343417", "7403910", "7643422", "7756879", "7827055", "7858010", "7865478", "7899700", "7908183", "7937725", "7945475", "7958010", "7970922", "8005776", "8099315", "8396951", "8422490", "8478880", "8490123", "20020010759", "20020059094", "20020069218", "20020097265", "20020111912", "20020162107", "20020178057", "20020193066", "20020194586", "20020199194", "20030014407", "20030066068", "20030088480", "20030093790", "20030105870", "20030191826", "20030234805", "20040003392", "20040032486", "20040064526", "20040210491", "20050022239", "20050096997", "20050131918", "20050144632", "20050149974", "20060020614", "20060041548", "20060150216", "20060195790", "20060259355", "20060288041", "20070011039", "20070078876", "20070136753", "20070157221", "20080082394", "20080126109", "20080319833", "20090077052", "20110173194", "20120089437"], "related": ["13326909", "11810395"]}, {"id": "20140143087", "patent_code": "10373229", "patent_name": "In-app recommendation system and user terminal", "year": "2019", "inventor_and_country_data": " Inventors: \nAhn; Heejung (Yongin-si, KR), Roh; Suerynn (Seoul, KR), Lee; Jihong (Seoul, KR), Im; Hyuckjin (Seongnam-si, KR), Jang; Jaeseok (Seoul, KR)  ", "description": "<BR><BR>CROSS-REFERENCE TO RELATED PATENT APPLICATION\nThis application is a National Stage of International Application No. PCT/KR2011/005135 filed on Jul.  13, 2011, and claims the benefit of Korean Patent Application No. 10-2011-0059262 filed on Jun.  17, 2011, in the Korean Intellectual Property\nOffice, the disclosures of which are incorporated herein in their entirety by reference.\n<BR><BR>BACKGROUND OF THE INVENTION\n1.  Field of the Invention\nThe exemplary embodiments relate to an in-app recommending system and a user terminal.\n2.  Description of the Related Art\nSmartphones that have been actively developed and released provide various applications.  Also, various multimedia content and applications may be purchased through an online market such as an app store.\nHowever, in the related art, when a user finds interesting multimedia content while watching a TV or while Web surfing, the user needs to directly connect to an online market, search for the multimedia content, and subsequently purchase it,\ncausing inconvenience.\nAlso, the user may download the purchased content to his or her phone, but a function allowing for the user to present content to a different user, in particular, a friend, or to download content to another of his or her terminals is not\nprovided.\nFurther, a function allowing the user to share multimedia content with a different user, while executing the multimedia content, has not been proposed yet.\nThe above information disclosed in this Background section is only for enhancement of understanding of the background of the invention and therefore it may contain information that does not form the prior art that is already known in this\ncountry to a person of ordinary skill in the art.\n<BR><BR>SUMMARY OF THE INVENTION\nThe exemplary embodiments have been made in an effort to provide an in-app recommending system and a user terminal that provide an in-app service allowing for recommending a customized application and allowing for users to present, recommend,\nand share an application through an in-app module.\nAn exemplary embodiment provides an in-app recommending system.  The in-app recommending system includes: an in-app module interworking unit configured to periodically collect state information of a particular application having an in-app module\nfrom a user terminal in which the in-app module is installed, the in-app module being an application in the form of a component which can be inserted into a plurality of unspecified applications to provide a common service; a user analyzing unit\nconfigured to generate recommendation information of multimedia content on the basis of the state information of the particular application, the multimedia content including an application and digital content; and a transmission unit configured to\npush-transmit the recommendation information to the in-app module of the user terminal.\nAnother exemplary embodiment provides a user terminal.  The user terminal includes: an in-app module configured as an application in the form of a component which can be inserted into a plurality of unspecified applications to provide a common\nservice, installed in a particular application installed in the user terminal, configured to periodically transmit state information of the particular application to an in-app recommending system, receive multimedia content recommendation information\ngenerated by the in-app recommending system, and transmit, when user confirmation with respect to the multimedia content recommendation information is input, the user confirmation to the in-app recommending system; and a download unit configured to\ndownload multimedia content included in the recommendation information from the in-app recommending system.\nAccording to an exemplary embodiment, since an in-app service is implemented in the form of a component and inserted in a plurality of unspecified applications, a customized recommended service can be easily provided in any environment.\n<BR><BR>BRIEF DESCRIPTION OF THE DRAWINGS\nThe above and other features and aspects of the present invention will become more apparent by describing in detail exemplary embodiments thereof with reference to the attached drawings in which:\nFIG. 1 is a view illustrating a configuration of an in-app service network according to an exemplary embodiment;\nFIG. 2 is a block diagram illustrating a configuration of a user terminal according to an exemplary embodiment;\nFIG. 3 is a functional block diagram of an in-app module according to an exemplary embodiment.\nFIG. 4 is a block diagram illustrating a configuration of an in-app recommending system according to an exemplary embodiment.\nFIG. 5 is a flowchart illustrating a process of an in-app recommending method according to an exemplary embodiment;\nFIG. 6 is a flowchart illustrating a process of an in-app recommending method according to another exemplary embodiment;\nFIG. 7 is a flowchart illustrating a process of an in-app recommending method according to another exemplary embodiment;\nFIG. 8 is a flowchart illustrating a purchase process according to an exemplary embodiment;\nFIG. 9 is a flowchart illustrating an in-app presenting method according to an exemplary embodiment;\nFIG. 10 is a flowchart illustrating an in-app sharing method according to an exemplary embodiment; and\nFIG. 11 is a schematic view of an in-app recommending system according to another exemplary embodiment.\n<BR><BR>DETAILED DESCRIPTION OF THE INVENTION\nIn the following detailed description, only certain exemplary embodiments have been shown and described, simply by way of illustration.  As those skilled in the art would realize, the described exemplary embodiments may be modified in various\ndifferent ways, all without departing from the spirit or scope of the present invention.  Accordingly, the drawings and description are to be regarded as illustrative in nature and not restrictive.  Like reference numerals designate like elements\nthroughout the specification.\nThroughout the specification, unless explicitly described to the contrary, the word \"comprise\" and variations such as \"comprises\" or \"comprising\" will be understood to imply the inclusion of stated elements but not the exclusion of any other\nelements.\nIn addition, the terms such as\"-er\", \"-or\", and \"module\" described in the specification mean units for processing at least one function and operation and can be implemented by hardware components or software components and combinations thereof.\nHereinafter, an in-app recommending system and a user terminal according to an exemplary embodiment will be described in detail.\nFirst, in-app refers to an application in the form of a component which can be inserted into a plurality of unspecified applications to provide a common service.\nHere, an application may be a web application accessed by a uniform resource locator (URL) of a web page and executed on the web, or may be a native application downloaded to a terminal and executed in the terminal.\nFIG. 1 is a view illustrating a configuration of an in-app service network according to an exemplary embodiment.\nReferring to FIGS. 1 and 2, the in-app service network includes a user terminal 100 and an in-app recommending system 200.  The user terminal 100 and the in-app recommending system 200 are connected via a network 300.\nThe network 300 provides an access path allowing the user terminal 100 to access the in-app system 200.  When the user terminal 100 is a wired terminal, the network 300 may be a wired communication network such as the Internet, and when the user\nterminal 100 is a mobile terminal, the network 300 may be a wireless communication network such as a mobile communication network.\nThe user terminal 100 may include any terminal which may access the network 300 to transmit and receive data and store and execute digital content.  The user terminal 100 may include any terminal which includes an in-app module 101 installed\ntherein and is able to access the network 300.\nThe in-app recommending system 200 interworks or communicates with the in-app module 101 installed in the user terminal 100 to generate customized recommended information on the basis of state information of a particular application, e.g., a\nfirst application, having the in-app module 101 installed therein, and provides the same.\nThe recommended information includes a recommended application and recommended digital content.\nDetailed configurations of the user terminal 100 and the in-app recommending system 200 will now be described.\nFIG. 2 is a block diagram illustrating a configuration of a user terminal according to an exemplary embodiment.\nReferring to FIG. 2, the user terminal 100 includes the in-app module 101, a download unit 103, a display unit 105, an input unit 107, a communication unit 109, and a controller 111.\nThe in-app module 101 is illustrated as a separate component, but is a component installed in a particular application.  In this case, the in-app module 101 is provided in the form of an open API to application developers so as to be installed.\nThe in-app module 101 refers to an application in the form of a component which can be inserted into a plurality of unspecified applications to provide a common service.  The in-app module 101 periodically transmits state information of a\nparticular application in which the in-app module 101 is installed, to the in-app recommending system 200.  On the basis of state information from the in-app recommending system 200, the in-app module 101 receives multimedia content recommendation\ninformation generated by the in-app recommending system 200, and when user confirmation with respect to the multimedia content recommendation information is received, the in-app module 101 transmits the user confirmation.  In an exemplary embodiment,\nmultimedia content is defined as including an application and digital content.\nWhile a particular application is being executed, the in-app module 101 outputs a recommended item, a gift item, and a share item of the particular application to a screen, and when one of the items is selected, the in-app module 101 transmits a\nrequest for the corresponding item of the particular application to the in-app recommending system 200.\nIn a case in which the particular application provides a social service, when a particular friend, i.e., a first friend, is selected from a friend list of a subscriber of the user terminal, the in-app module 101 transmits information regarding a\nterminal of the particular friend and the request for the corresponding item.\nThe download unit 103 downloads multimedia content included in the recommended information from the in-app recommending system 200.\nThe display unit 105 outputs various types of information according to an operation of the user terminal 100 to the screen.\nThe input unit 107 is a means for allowing the user to input information or select information displayed on the display unit 130.\nThe communication unit 109 is connected to the network 200 to provide a path for transmitting and receiving data.\nThe controller 111 is to a component which performs a general operation of the user terminal 100 according to an operating system of the user terminal 100, and is connected to the in-app module 101, the download unit 103, the display unit 105,\nthe input unit 107, and the communication unit 109 to control associated operations between the respective components.\nFIG. 3 is a functional block diagram of the in-app module according to an exemplary embodiment.\nReferring to FIG. 3, the in-app module 101 includes a `TALK` function, a `push` function, a `download and streaming` function, a `control` function, and an `in-app market`.\nHere, the `TALK` function provides a communication function between user terminals 100 having the in-app module 101 installed therein.  According to the function, an environment in which a counterpart terminal having the in-app module 101 is\nregistered by using an ID or a phone number may be provided.\nThe `push` function pushes multimedia content stored in the user terminal 100 having the in-app module 101 installed therein to a different user terminal 100 having an in-app module 101 installed therein.\nThe `download and streaming` function may download and stream multimedia content from the in-app recommending system 200.\nThe `control` function controls an in-app service of the in-app module 120, and it may confirm authority to execute multimedia content.\nThe `in-app market` function may be connected to the in-app recommending system 200 to provide an interface environment allowing for purchasing multimedia content.\nFIG. 4 is a block diagram illustrating a configuration of the in-app recommending system according to an exemplary embodiment.\nReferring to FIG. 4, the in-app recommending system 200 includes an in-app module interworking unit 201, e.g, in-app module interworker, a user analyzing unit 203, e.g., a user analyzer, a purchase history managing unit 205, e.g., a purchase\nhistory manager, a terminal managing unit 207, e.g., a terminal manager, a settling unit 209, e.g., a settler, a resource managing unit 211, e.g., a resource manager, a transmission unit 213, e.g., a transmitter, and a download and streaming unit 215,\ne.g., a downloader and streamer.\nThe in-app module interworking unit 201 periodically collects state information of a particular application including the in-app module 101 installed therein from the in-app module 101.\nThe user analyzing unit 203 generates information regarding recommendation of multimedia content on the basis of the state information of the particular application.  The multimedia content includes an application and digital content.\nThe recommendation information is generated in consideration of purchase history of the subscriber of the user terminal.\nThe user analyzing unit 203 selects a subscriber preference terminal on the basis of the purchase history among terminals owned by the subscriber of the user terminal 100, and generates recommendation information that may be used by the\nsubscriber preference terminal.\nThe user analyzing unit 203 also transmits a user interface page configured to select a terminal to the user terminal 100.  Information regarding a terminal selected by the user is received from the user terminal 100.  Recommendation information\nexecutable in the terminal selected by the user is generated.\nAlso, the user analyzing unit 203 pushes a recommendation message including the recommendation information to the user terminal 100, and when a confirmation request is received from the user terminal, the user analyzing unit 203 requests\ntransmission of recommendation content.\nThe recommendation message includes an experience version download item for downloading multimedia content to use it free of charge, e.g., a trial version or a free version, and a paid version download item for purchasing multimedia content to\nuse it.\nThus, when the user selects the experience version download item and a confirmation request is received, the user analyzing unit 203 transmits experience version multimedia content to the user terminal.  In a case in which the user selects a\npaid version download item and a confirmation request is received, when purchasing of multimedia content is completed, the user analyzing unit 203 may request transmission of multimedia content to the user terminal.\nThe experience version multimedia content includes multimedia content having limited usage term or a portion of multimedia content.\nAlso, when the recommendation request is received, the user analyzing unit 203 checks purchase history of a counterpart terminal as a recommendation target to determine whether a particular application having an in-app module of a user terminal\ninstalled therein has been purchased.  When the particular application has not been purchased, the user analyzing unit 203 transmits a terminal selection user interface page including a terminal list of a subscriber of a counterpart terminal to the\ncounterpart terminal to generate a particular application as a recommendation application such that it may be executed in a terminal selected by the counterpart subscriber.\nWhen a present request is received, the user analyzing unit 203 checks terminal information and purchase history of the subscriber of the counterpart terminal as a present request target to determine whether a particular application having the\nin-app module 101 installed therein has been purchased.  In a case in which the particular application has not been purchased, the user analyzing unit 203 determines whether the particular application is executable in the counterpart terminal.  When the\nparticular application is executable, the user analyzing unit 203 requests to push and transmit the paid particular application to the counterpart terminal.\nWhen a share request is received, the user analyzing unit 203 checks terminal information and purchase history of the subscriber of the counterpart terminal as a share request target to determine whether a particular application having the\nin-app module 101 installed therein has been purchased.  In a case in which the particular application has not been purchased, the user analyzing unit 203 determines whether the particular application is executable in the counterpart terminal.  When the\nparticular application is executable, the user analyzing unit 203 push-transmits a message recommending an experience version of the particular application to the counterpart terminal, and when acceptance of the experience version recommendation is\nreceived from the counterpart terminal, the user analyzing unit 203 provides the particular application of the experience version to the counterpart terminal.\nThe purchase history managing unit 205 manages purchase history of multimedia content by subscribers.\nThe terminal managing unit 207 manages a terminal list including terminals owned by each subscriber, and searches terminal information of the subscriber of the user terminal 100.\nWhen paid version confirmation is received from the user terminal, the settling unit 209 checks whether integrated payment resource information of the subscriber of the user terminal exists.  When integrated payment resource information exists,\nthe settling unit 209 pays for the recommendation multimedia content by using the integrated payment resource information.  When integrated payment resource information does not exist, the settling unit 209 receives payment information, registers it as\nintegrated payment resource information, and pays for it.\nThe resource managing unit 211 manages integrated payment resource information by subscribers, and provides the same to the settling unit 209.\nThe transmission unit 213 push-transmits the recommendation information generated by the user analyzing unit 203 to the in-app module 101.\nThe download and streaming unit 215 transmits multimedia content, namely, a recommendation app, a present app, a share app, and the like, requested by the user terminal 100, to the user terminal 100.\nVarious exemplary embodiments of the in-app recommending method will be described on the basis of the foregoing contents.  The in-app recommending method will be described in association with the configurations of FIGS. 1 through 4, and the same\nreference numerals are used for the same components.\nFIG. 5 is a flowchart illustrating a process of an in-app recommending method according to an exemplary embodiment.\nReferring to FIG. 5, the in-app module 101 is executed in the user terminal 100 (S101).  When a period arrives (S103), the in-app module 101 transmits state information of a particular application having the in-app module 101 installed therein\n(S105).  The state information may include purchase information of the particular application, purchase history of the subscriber through the particular application, and the like.\nThen, the in-app module interworking unit 201 of the in-app recommending system 200 receives the state information and delivers the same to the purchase history managing unit 205 (S107).  The purchase history managing unit 205 then updates the\nreceived state information in a purchase history DB (not shown) of each subscriber (S109).\nThereafter, the in-app module interworking unit 201 transmits personal connection information of the in-app module 101 to the user analyzing unit 203 (S111).\nSubsequently, the user analyzing unit 203 requests purchase history from the purchase history managing unit 205 (S113) and receives the same (S115).  The user analyzing unit 203 generates a customized recommendation app and recommendation\ncontent (S117).\nAlso, the user analyzing unit 203 requests the terminal managing unit 207 to search terminal information of the subscriber of the user terminal and receives the same (S119 and S121).  The user analyzing unit 203 selects a preference terminal of\nthe subscriber of the user terminal on the basis of the purchase history received in operation S115 (S123), and generates a recommendation app or recommendation content that may be executable in the preference terminal (S125).  The purchase history\nincludes purchase details through a terminal owned by the subscriber.\nThen, the user analyzing unit 203 requests the transmission unit 213 to push the information including information regarding the generated recommendation app (S127).  The transmission unit 213 transmits requested recommendation information to\nthe user terminal 100 (S129).  The recommendation information may be implemented as a message.  The recommendation message may be implemented as \"Recommendation app arrived.fwdarw.paid version download.fwdarw.`experience version download`\".\nThe user terminal 100 then returns the transmission result (S131).\nIn this case, the transmission unit 213 checks failure on the basis of the transmission result (S133), and in case of failure, the transmission unit 213 generates a retransmission list for retransmission afterwards (S135).\nThereafter, when downloading of recommendation information is selected (S137), the user terminal 100 transmits user selected information to the download and streaming unit 215 (S139) to receive content included in the recommendation information,\nnamely, a recommended app or content (S141).\nWhen the user terminal 100 returns the transmission result (S143), a transmission complete message is received (S145, S147).\nFIG. 6 is a flowchart illustrating a process of an in-app recommending method according to another exemplary embodiment.\nReferring to FIG. 6, the in-app module 101 is executed in the user terminal 100 (S201).  When a period arrives (S203), the in-app module 101 transmits state information of a particular application having the in-app module 101 installed therein\n(S205).\nThen, the in-app module interworking unit 201 of the in-app recommending system 200 receives the state information and delivers the same to the purchase history managing unit 205 (S207).  The purchase history managing unit 205 then updates the\nreceived state information in a purchase history DB (not shown) of each subscriber (S209).\nThereafter, the in-app module interworking unit 201 transmits personal connection information of the in-app module 101 to the user analyzing unit 203 (S211).\nThe user analyzing unit 203 then requests purchase history from the purchase history managing unit 205 (S213) and receives the same (S215).  The user analyzing unit 203 generates a customized recommendation app and recommendation content (S217).\nThe user analyzing unit 203 requests the terminal managing unit 207 to search terminal information of the subscriber of the user terminal and receives the same (S219 and S221).  The user analyzing unit 203 requests the in-app module interworking\nunit 201 to select a terminal (S223).\nThe in-app module interworking unit 201 transmits a user interface (UI) allowing for selecting a terminal to the user terminal 100 (S225).  Here, although not shown, the in-app module interworking unit 201 interworks with a UI server that\nprovides a UI page and receives information selected by the user from the UI page.\nIn this case, the UI page may be implemented as \"Please select terminal for receiving recommendation app based on social used by Mr. or Miss OOO.fwdarw.mobile phone.fwdarw.pad\".\nWhen the user selects a terminal (S227), the user terminal 100 transmits terminal selection information to the in-app module interworking unit 201 (S229).  Then, the in-app module interworking unit 201 delivers the terminal selection information\nto the user analyzing unit 203 (S231).\nThe user analyzing unit 203 generates recommendation app or recommendation content executable in the user selected terminal (S233).\nThe user analyzing unit 203 then requests the transmission unit 213 to push information including information regarding the generated recommendation app (S235).  The transmission unit 213 transmits the requested recommendation information to the\nuser terminal 100 (S237).  The user terminal 100 returns the transmission result (S239).\nHere, the transmission unit 213 checks failure on the basis of the transmission result (S241), and in case of failure, the transmission unit 213 generates a retransmission list for retransmission afterwards (S243).\nThereafter, when downloading of recommendation information is selected (S245), the user terminal 100 transmits user selected information to the download and streaming unit 215 (S247) to receive content included in the recommendation information,\nnamely, a recommended app or content (S249).\nWhen the user terminal 100 returns the transmission result (S251), a transmission complete message is received (S253, S255).\nFIG. 7 is a flowchart illustrating a process of an in-app recommending method according to another exemplary embodiment.\nReferring to FIG. 7, when the recommendation requester terminal 100 selects a recommendation item in a state in which the user executes the particular application (S301), the recommendation requester terminal 100 transmits a recommendation\nrequest to the in-app module interworking unit 201 (S303).\nThen, the in-app module interworking unit 201 transmits personal connection information of the in-app module 101 to the user analyzing unit 203 (S305).\nThe user analyzing unit 203 requests purchase history from the purchase history managing unit 205 (S307) and receives the same (S309).\nHere, the user analyzing unit 203 determines whether there is purchase history (S311), and when purchase history exists, the user analyzing unit 203 transmits purchase history presence notification to the user terminal 100 (S313).  Meanwhile,\nwhen purchase history does not exist, the user analyzing unit 203 requests the terminal managing unit 207 to search terminal information of the user terminal subscriber and receives (S315, S317).\nThe user analyzing unit 203 requests the in-app module interworking unit 201 to select a terminal (S319).\nThe in-app module interworking unit 201 transmits a user interface (UI) for selecting a terminal to the user terminal 100 (S321).\nWhen the user selects a terminal (S323), the user terminal 100 transmits terminal selection information to the in-app module interworking unit 201 (S325).  Then, the in-app module interworking unit 201 delivers the terminal selection information\nto the user analyzing unit 203 (S327).\nThe user analyzing unit 203 generates a recommendation app or recommendation content executable in the user selected terminal (S329).\nThe user analyzing unit 203 requests the transmission unit 213 to push the information including information of the generated recommendation app (S331).  The transmission unit 213 transmits the requested recommendation information to the user\nterminal 100 (S333).  The user terminal 100 returns the transmission result (S335).\nAt this time, the transmission unit 213 checks failures on the basis of the transmission result (S337).  In case of failure, the transmission unit 213 generates a retransmission list for retransmission afterwards (S339).\nThereafter, when downloading of the recommendation information is selected, the user terminal 100 transmits the user selection information to the download and streaming unit 215 (S343) to receive content included in the recommendation\ninformation, i.e., a recommendation app or content (S345).\nWhen the user terminal 100 returns the transmission result (S347), a transmission complete message is received (S349, S351).\nFIG. 8 is a flowchart illustrating a purchase process according to an exemplary embodiment.  The process of FIG. 8 may be performed in all the processes of FIGS. 5 through 10.\nReferring to FIG. 8, when the user selects paid version download (S401), the user terminal 100 transmits user selection information to the in-app module interworking unit 201 (S403).\nThe in-app module interworking unit 201 requests payment from the settling unit 209 (S409).\nThe settling unit 209 requests purchase history from the purchase history managing unit 205 (S407) and receives the same (S409).\nThe settling unit 209 determines whether there is purchase history (S411), and when purchase history exists, the settling unit 209 requests transmission of a recommendation app of paid version from the download and streaming unit 215 (S413). \nThen, the download and streaming unit 215 transmits the recommendation app to the user terminal 100 (S415).\nMeanwhile, when purchase history does not exist, the settling unit 209 requests the resource managing unit 211 to check integrated payment resource information (S417).  Here, the integrated payment resource information is defined as payment\ninformation registered to be paid in a terminal in which the in-app module 101 is installed, regardless of the type of terminal.\nThe resource managing unit 211 determines whether a payment resource exists (S419).  When the payment resource does not exist, the resource managing unit 211 requests payment information registration from the user terminal 100 to perform\nregistration (S421, S423).\nWhen payment resource exists or after registration is performed, the resource managing unit 211 provides the payment resource information requested in operation S417 to the settling unit 209 (S425).  The payment resource information includes\ninformation required for payment such as mobile payment, credit card payment, or the like.\nThe settling unit 209 then transmits a charging page including charging information of the recommendation app to the user terminal 100 (S427).  When the user agrees with the charging page, the settling unit 209 receives user selection\ninformation (S329).\nThen, the settling unit 209 performs the charging and payment process (S431), and transmits payment results to the user terminal 100 (S433).  The settling unit 209 requests transmission of the recommendation app from the download and streaming\nunit 215 (S435).  The settling unit 209 transmits purchase history of the recommendation app to the purchase history managing unit 205 (S437).\nFIG. 9 is a flowchart illustrating an in-app presenting method according to an exemplary embodiment.\nReferring to FIG. 9, when the user selects a receiver (S501) and requests a present, the user terminal 100 transmits the present request to the in-app module interworking unit 201 (S503).  In this case, when a present item is selected in a state\nin which a particular application is executed, the in-app module 101 may request presenting of the particular application.\nThe in-app module interworking unit 201 then transmits personal connection information to the user analyzing unit 203 (S505).\nThe user analyzing unit 203 requests the terminal managing unit 207 to search terminal information (S507) and receives terminal information of a present counterpart (S509).\nIn this case, the user analyzing unit 203 determines whether the user requested app is executable in the counterpart terminal (S511).  When the counterpart terminal cannot support the user requested app, the user analyzing unit 203 transmits a\nsupport unavailability notification to the present requester terminal 100 (S513).  For example, the user analyzing unit 203 may transmit a message \"Receiver terminal does not support corresponding app\".\nMeanwhile, when the counterpart terminal supports the user requested app, the user analyzing unit 203 requests purchase history from the purchase history managing unit 205 to receive it (S515, S517).  The present counterpart also includes the\nin-app module 101, and uploads state information of a particular application having the in-app module 101 installed therein to the purchase history managing unit 205 periodically.\nMeanwhile, the user analyzing unit 203 determines whether purchase history exists (S519).  When purchase history exists, the user analyzing unit 203 transmits a notification indicating that the counterpart terminal has purchase history to the\npresent requester terminal 100 (S521).  For example, the user analyzing unit 203 may transmit a message \"Receiver has already purchased the corresponding app\".\nMeanwhile, in a case in which purchase history does not exist, the user analyzing unit 203 requests purchase from the settling unit 209 (S523) to allow for performing the process of FIG. 8, and here, corresponding operations are omitted.\nThereafter, when purchase is completed (S525), the user analyzing unit 203 requests transmission of a recommendation app from the download and streaming unit 216 (S527).  Then, the download and streaming unit 215 transmits the recommendation app\nto the present counterpart terminal 100 (S529).\nThe user terminal 100 then returns the transmission result (S531) and receives a transmission complete message (S533, S535).\nFIG. 10 is a flowchart illustrating an in-app sharing method according to an exemplary embodiment.\nReferring to FIG. 10, when the user selects a receiver and requests sharing, the user terminal 100 transmits the share request to the in-app module interworking unit 201 (S601).  In this case, when a share item is selected in a state in which a\nparticular application is executed, the in-app module 101 may request sharing of the particular application.\nThen, the in-app module interworking unit 201 transmits personal connection information to the user analyzing unit 203 (S603).\nThe user analyzing unit 203 then requests purchase history from the purchase history managing unit 205 to receive it (S605, S607).  The share counterpart also includes the in-app module 101, and periodically uploads state information of a\nparticular application having the in-app module 101 installed therein to the purchase history managing unit 205.\nMeanwhile, the user analyzing unit 203 determines whether purchase history exists (S609).  When purchase history exists, the user analyzing unit 203 transmits a notification indicating that the counterpart terminal has purchase history to the\nshare requester terminal 100 (S611).  For example, the user analyzing unit 203 may transmit a message \"Receiver has already purchased the corresponding app\".\nMeanwhile, when there is no purchase history, the user analyzing unit 203 requests the terminal managing unit 207 to search terminal information and receives terminal information of the share counterpart (S615).\nIn this case, the user analyzing unit 203 determines whether the app requested by the user to share is executable in the counterpart terminal (S617).  When the counterpart terminal cannot support the user requested app, the user analyzing unit\n203 transmits a support unavailability notification to the share requester terminal 100 (S619).  For example, the user analyzing unit 203 may transmit a message \"Share target terminal does not support corresponding app\".\nWhen the counterpart terminal supports the user requested app, the user analyzing unit 203 requests the transmission unit 213 to push recommendation information including information regarding an app requested to be shared (S621).  The\ntransmission unit 213 transmits the requested recommendation information to the share target terminal 100 (S623).  Then, the share target terminal 100 returns the transmission result (S625).\nIn this case, the transmission unit 213 checks failure on the basis of the transmission result (S627), and in case of failure, the transmission unit 213 generates a retransmission list for retransmission afterwards (S629).\nThereafter, when the user selects downloading of the experience version of the recommendation information (S631), the share target terminal 100 transmits user selection information to the download and streaming unit 215 (S633) to receive share\napp (S635).\nWhen the share target terminal 100 returns the transmission result (S637), it receives a transmission complete message (S639, S641).\nFIG. 11 is a schematic view of an in-app recommending system according to another exemplary embodiment.\nAt least some functions of the in-app recommending system 200 according to an exemplary embodiment may be implemented as hardware or software combined with hardware.\nAn exemplary embodiment in which the in-app recommending system 200 is combined to a computer system will be described in detail with reference to FIG. 11.\nFIG. 11 is a schematic view of an in-app recommending system according to another exemplary embodiment.  The in-app recommending system may be used to perform at least some of the functions of the in-app module interworking unit 201, the user\nanalyzing unit 203, the purchase history managing unit 205, the terminal managing unit 207, the settling unit 209, the resource managing unit 211, the transmission unit 213, and the download and streaming unit 215 as described above with reference to\nFIG. 4.\nReferring to FIG. 11, the in-app recommending system 400 includes a processor 401, a memory 403, at least one storage device 405, an input/output (I/O) interface 407, and a network interface 409.\nThe processor 401 may be implemented as a central processing unit (CPU), a chip set, a microprocessor, or the like, and the memory 403 may be implemented as a medium such as a random access memory (RAM) such as a dynamic RAM (DRAM), a rambus\nDRAM, a synchronous DRAM (SDRAM), a static RAM (SRAM), or the like.\nThe storage device 405 may be implemented as a permanent or volatile storage device such as a hard disk, a compact disk read only memory (CD-ROM), a CD rewritable (CD-RW), a digital video disk (DVD)-ROM, a flash memory, or various types of RAM.\nThe I/O interface 407 allows the processor 401 and/or memory 403 to access the storage device 405, and the network interface 409 allows the processor 401 and/or the memory 403 to access the network 300.\nIn this case, the processor 401 may load a program command for implementing at least some of the functions of the in-app module interworking unit 201, the user analyzing unit 203, the purchase history managing unit 205, the terminal managing\nunit 207, the settling unit 209, the resource managing unit 211, the transmission unit 213, and the download and streaming unit 215 to the memory 403, and provide control to perform the operations as described above with reference to FIG. 3.\nAlso, the storage device 405 may interwork with the processor 401 to perform a function.\nThe processor 401, the memory 403, the storage device 405, the I/O interface unit 407, and the network interface 409 illustrated in FIG. 10 may be implemented in a single computer or may be implemented in a plurality of computers in a\ndistributed fashion.\nWhile this invention has been described in connection with what is presently considered to be practical exemplary embodiments, it is to be understood that the invention is not limited to the disclosed exemplary embodiments, but, on the contrary,\nis intended to cover various modifications and equivalent arrangements included within the spirit and scope of the appended claims.", "application_number": "14126617", "abstract": " An in-app recommending system is provided. The in-app recommending system\n     includes an in-app module interworking unit configured to periodically\n     collect state information of a particular application having an in-app\n     module from a user terminal in which the in-app module is installed, the\n     in-app module being an application in the form of a component which can\n     be inserted into a plurality of unspecified applications to provide a\n     common service, a user analyzing unit configured to generate\n     recommendation information of multimedia content on the basis of the\n     state information of the particular application, the multimedia content\n     including an application and digital content, and a transmission unit\n     configured to push-transmit the recommendation information to the in-app\n     module of the user terminal.\n", "citations": ["20060217111", "20090163183"], "related": []}, {"id": "20150169783", "patent_code": "10289746", "patent_name": "Tag aggregator", "year": "2019", "inventor_and_country_data": " Inventors: \nWatson; Ben (Carp, CA)  ", "description": "<BR><BR>BACKGROUND\n1.  Technical Field\nThis disclosure relates to managing the content of a web site.  More specifically, this disclosure relates to managing tags implemented for management of third party reporting services on a web site.\n2.  Background\nA tag is generally a piece of data representative of other information.  For example, referring to an advertisement on a web page, the link within an advertisement may be referred to as a tag or the data representative while the data, once the\nlink is selected, is the other information represented by the tag.  Tags represent a wide area of data and data types such as a web link, a media file or an image.  A collection of data for a specific topic may be represented by a tag.  When a tag on a\nweb page is clicked, other content may appear.  For example, a web page hosted on a web server that supports tagging may include the tags United States news, United Kingdom news, France news, politics, and law.  Someone viewing that webpage can easily\ntell the web page relates to news and politics in several countries by viewing the tags.  The tags are usually displayed as a listing on the web page where each tag that is displayed is a web link.  Once the link is activated, all of the web pages that\nuse the tag activated may be displayed.  Thus, in the example above, a user can easily find all of the pages that relate to news in the United States.\nLinks on a web site may also have tags that are seemingly unrelated to the link.  For example, if a user clicks to purchase ski equipment from a web site, an advertisement for ski vacations may be displayed.  Similarly, links or advertisements\nof a retailer with a web site may be tagged so that once a user accesses the web site or certain products on the retailer's web site, pop up advertisements of other businesses offering related services may appear.  Alternatively, search result listings\nmay have tags associated with them.  Tags can refer to any information that is or becomes associated with a search or search results.  Tags may also be generated by search engine optimization tools or search engine optimization agencies.  Tags may be\nattributed to a web page search.  Traffic may be driven to a website in exchange for a share of the revenue.  The host that is driving the traffic may have a tag on the web page.  A tag can also store user preferences and other related information. \nThus, tags can be used in countless ways within web sites.\nTags are becoming increasingly popular in website design.  Tags have many purposes.  One purpose is to manage traffic to and from a website.  In general, web pages include at least one tag and as many as ten or more.  A web page that includes\nadvertising includes additional tags, including a set of tags for the content of the web page and additional tags related to the advertising on the web page.  Advertisements may include tags of a specific content, specific to an advertisement campaign or\nspecific to a domain.  Tags may be used to track people or track traffic to the website.  A tag may be based on a user's behavior so it may include personalization settings.  As web sites become more and more complex, sometimes having hundreds or\nthousands of links within a single web site, the number of tags on the page also increases and the management of the tags becomes more and more complex.\nTags are provided to a web browser on a personal computer with the rest of the information on a web page requested by the browser.  Once a web page is loaded on a web browser, every tag on the website must retrieve its URL successfully in order\nfor the web page to complete loading.  Thus, web pages are taking longer and longer to load.  If the network connection isn't optimized, it can take even more time for a web page to load.  Tags may store a number of preferences in a cookie on a local\ncomputing system.  If the temporary internet folder of the computing system is not cleaned regularly, there may be tens of thousands of files to look through.  Furthermore, the temporary folder may be searched for additional values about the user or the\nuser's preferences.  For each tag on the web page, these values are then sent to the resulting domain.  Once each domain sends a confirmation back to the tag, the web page will be loaded.  Often, web pages with multiple tags can take a lot of time to\nload properly.  Additionally, if a user has certain internet security settings in place, the web page may not load at all because the security settings will detect the web page traffic as a cross domain call.\nUnfortunately, managing tags and keeping track of all of a web site's tags is currently a manual process and can be extremely burdensome.  In a typical environment, in order to implement a new tag, an email or other communication is sent to the\ndeveloper or group of developers by the person or entity interested in adding the new tag.  The email may include the requirements for the new tag.  The developer or group of developers then proceeds with building the tag based on the requirements given\nin the email.\nPopular commercial web content management systems include BroadVision, provided by BroadVision, Inc., Redwood City, Calif., and Vignette, offered by Vignette Corp., Austin, Tex.  Popular open source web content management systems include Drupal,\nand Joomla, both distributed under the General Public License (GPL) and maintained by a community of users and developers.  None of the current web content management systems currently has a standard facility for managing tags on a page, developers often\nhardcode tags into the templates of a website or into the content of a website.  This leads to an additional problem of effectively keeping track of all of the tags and their sources.  A given website may have several tags that are unsourced. \nDetermining the source of the unsourced tags can be a website administrator's nightmare.  A web developer or administrator cannot simply remove the tag without first determining the source and why the tag was placed on the site.  That information may not\nbe readily available.\nAnother issue with tagging relates to reporting.  Several reports are usually generated.  For example, the search engine optimizer may have a report, the web site may have a traffic report, the advertisement server may also generate a report and\neach network where an advertisement is running may also generate a report.  These reports usually come in various formats.  Furthermore, such reports typically include inconsistent data.  For example, a traffic report may state a web site was called 50\ntimes while the report for a web site where the tag is hosted may state the call was made 100 times.\nAdditionally, most advertisement networks are plagued with what is known as piggyback pixels.  Thus, if a call is made to a domain, the domain may make a call to another domain and so on until a successful call is reported back.  If any of these\ncalls fails, the web page will fail.  Therefore, a need exists for an efficient way to manage tags and report tag usage.\n<BR><BR>BRIEF SUMMARY\nBy way of introduction, the embodiments described below include methods and systems for managing tags implemented for the management of third party reporting services on a web site.\nIn a first aspect, a system for managing tags on a web page is disclosed.  Generally, the system includes a tag service running on a tag server.  Generally, a tag on a web page is called.  The tag service responds to the call and determines and\nexecutes specific instructions from the tag.  The information from the tag is then divided into one or more asynchronous calls.\nIn a second aspect, a system for managing tags on a web page is disclosed.  The system includes a primary tag module and a secondary tag module in communication with the primary tag module.  The secondary tag module is able to request the\naddition of a secondary tag to the primary tag module.  The primary tag module is able to create the secondary tag requested.\nIn a third aspect, a method for managing tags on a web page is disclosed.  First, a user interface is presented in response to a user request.  Next, a user requests the addition of a primary tag.  The primary tag is created.  Next, a user\nrequests the addition of one or more secondary tags.  Finally, the secondary tags are aggregated.\nOther systems, methods, features and advantages will be, or will become, apparent to one with skill in the art upon examination of the following figures and detailed description.  It is intended that all such additional systems, methods,\nfeatures and advantages be included within this description, be within the scope of the invention, and be protected by the following claims. <BR><BR>BRIEF DESCRIPTION OF THE DRAWINGS\nThe tag and beacon aggregator may be better understood with reference to the following drawings and description.  The components in the figures are not necessarily to scale, emphasis instead being placed upon illustrating the principles of the\ninvention.  Moreover, in the figures, like referenced numerals designate corresponding parts throughout the different views.\nFIG. 1 is a high level view of exemplary system architecture,\nFIG. 2 is a detailed view of the modules of a portion of the system architecture;\nFIG. 3 illustrates the process of implementing primary and secondary tags;\nFIG. 4 illustrates a detailed process overview of the current system.\nFIG. 5 illustrates prior art implementation of tags and tag reporting; and\nFIG. 6 illustrates the new implementation of tags and tag reporting.\n<BR><BR>DETAILED DESCRIPTION OF THE DRAWINGS AND THE PRESENTLY PREFERRED EMBODIMENTS\nReference will now be made to the accompanying drawings, which form a part hereof, and which show, by way of illustration, specific exemplary embodiments.  The principles described herein may, however, be embodied in many different forms, and\nthis specification should not be construed to limit the claims.  Rather, these embodiments are provided so that the disclosure will be thorough and complete to those skilled in the art.\nThe internet is becoming the primary means for businesses to target potential customers and sell products or services.  The internet is also widely used for a multitude of other reasons such as performing research, keeping up with current\nevents, and travel guides amongst other things.  Social networking web sites and resources may be used to connect members having a common interest or to communicate with friends and family.  Most people have used or are using the internet for one reason\nor another.  Thus, the internet provides an ideal forum for advertising of products and services.\nAs used herein, the term Taggregator refers to all of the components and tools relating to the Tag and Beacon aggregator.\nFIG. 1 provides a simplified view of a network environment 100.  The components of FIG. 1 represent the many elements that can make up the tag management environment.  The environment 100 in the exemplary embodiment of FIG. 1 includes an ad\nserver 108, a portal server 110, a third party server 118, a tag server 106, web/content server 120 and user devices 102, 104.  The tag server 106 includes a tag service 112, a tag database 122, a user interface module 114 and a reporting module 116. \nThe tag server 106 may be a dedicated server for tagging or a server that includes additional functions outside of tagging.\nIn FIG. 1, the environment 100 includes the ad server 108, which may provide a platform for selection, optimization, and/or distribution of advertisements.  Advertisements may be provided by a portal server 110 and/or a third-party server 118. \nIn FIG. 1, clients are represented by user devices 102, 104.  The user devices 102, 104 are depicted as conventional personal computers.  However, any suitable user device may be used, such as a wireless or wire line telephone, a cellular telephone, a\npersonal digital assistant, etc. The user devices 102 and 104 are examples of devices used by users who will be managing tags on their website or websites.\nPortal server 110, third-party server 118, ad server 108, web/content server 120, tag server 106, and user devices 102 and 104 each represent computing devices of various kinds.  Such computing devices may generally include any device that is\nconfigured to perform computations and that is capable of sending and receiving data communications by way of one or more wired and/or wireless communication interfaces.  Such devices may be configured to communicate in accordance with any of a variety\nof network protocols, including but not limited to protocols within the Transmission Control Protocol/Internet Protocol (TCP/IP) protocol suite.  For example, user device 104 may be configured to execute a browser application that employs hypertext\ntransfer protocol (HTTP) to request information, such as a web page, from a web server.  The illustrated computing devices communicate using a network 150.  The network 150 may include any suitable communication network including wire line and wireless\nnetworks and may include sub-networks such as local area networks or wide area networks.\nA tag server 106 can represent several servers or other devices.  The tag server 106 includes a tag service 112, a user interface module 114, and a reporting module 116.  The tag service 112 may keep track of and manage tags.  When a link on a\nweb page is clicked, the tag service 112 begins executing.  The tag service 112 may wait for a tag to be called, collect the information from that tag, and break the information up into the appropriate asynchronous calls that it's going to make and send\nit to each of the partners or other services that need to be called in order to generate reports.  This process is completed latently.  Thus, websites can perform at optimum speeds while the tag service 112, also referred as the Taggregator service 112,\nworks in the background and separately from a web page loading by informing other services for tagging purposes versus page load purposes.  Currently, these separate entities are tied together such that each entity may avoid taking full responsibility if\na problem should occur.\nThe tag service 112 may record each activity related to tagging in a tag database 122.  In an alternate embodiment, the tag database 122 may comprise several databases.  The user interface module 114 includes the software that may provide a\nfront end to users and may incorporate tools for users to view and manage their tags.  Referring briefly to FIG. 2, a system user 260 using user device 102 may add and remove tags based on new specifications or change tags if the recording provider is\nchanged through a common user interface 270.  The common user interface 270 may be a secured web page that requires a user id and password to ensure that access is only available to legitimate users of the system.  Alternatively, the common user\ninterface 270 may be client side software in a client server network that is not implemented on the Internet but rests on local system devices or an Intranet.  Furthermore, a common user interface 270 may include both a means to access from the Internet,\nan Intranet, and client side software application.  One purpose to implement multiple configurations may be for added security purposes.  For example, the Internet accessible front end may only provide a means to view the current tag information but not\nto change configuration settings.  The client side front end, whether it is implemented as a web page or other client side software, may be referred to as Taggregator.  In addition to providing a single point of management for tags, a common user\ninterface 270 provides a user friendly medium for users who are not technical experts in web content management.  In one embodiment, the common user interface 270 may have the ability to retrieve all of the tags for a given URL.  Thus, a user 102 may\ninput a URL within the common user interface 270 and retrieve all of the tags within the URL.  In one embodiment, the retrieval may alert the user 102 with an analysis of the degree of complexity of the tags within the URL.  For example, a green\nindicator may show that everything is working and the tags are properly linked.  A yellow indicator may show that there are some issues with the tags and a red indicator may reveal that a large number of tag issues are present.  The common user interface\n270 may also have a means to make recommendations regarding which tags should be aggregated.\nA reporting module 116 (FIG. 1) may be used to create, manage, and update reports.  A reporting module 116 may be integrated with a tag database 122 or may be a separate module that is able to communicate and with and retrieve data from the tag\ndatabase 122.  The reporting module 116 may include reporting software (not shown) that can automatically create reports based on the data captured by the tag service 112.  Since the tag server 106 is in communication with many other types of servers,\nsuch as ad server 108, the reporting module 116 can provide various types of reports based on aggregated data collected by other components in network 150.  Such reports will be useful to both online service providers and companies who provide online\nadvertisements.  Alternatively, a reporting module 116 may not be implemented.  The Tag service 112 might simply inform other reporting services that are not part of the Tag and Beacon aggregator, but are instead parts of other standard suite software.\nSome or all of ad server 108, portal server 110, and third-party server 112 may be in communication with each other by way of network 150.  The ad server 108 and portal server 110 may each represent multiple linked computing devices, and\nmultiple third-party servers.  For example, third-party server 118 may be included in environment 100.  Network 150 may be regarded as a public or private network connection or any combination of these, and may include, for example, a DMZ (demilitarized\nzone), a virtual private network or an encryption or other security mechanism employed over the public Internet.\nUser devices 102 and 104 are represented by user-interactive devices that typically run browser applications, and the like, to display requested pages received over a network that include advertisements.  User devices 102 and 104 may view and\nmanage their tags through a web browser.\nNot all of the depicted components in FIG. 1 may be required, however, and some embodiments of the invention may include additional components not shown in FIG. 1.  Variations in the arrangement and the type of components may be made without\ndeparting from the spirit or scope of the claims as set forth herein.  Additional, different or fewer components may be provided.\nFIG. 2 is a detailed view of the modules of a portion of the system architecture.  The tag server 106 includes a primary tag module 210, a secondary tag module 220, and additional tag modules 230 for subsequent tags, a user interface module 240,\nand a reporting module 250.  Also illustrated in FIG. 2 are a user device 102 where a common user interface 270 may be viewed and a system user 260.\nThe primary tag module 210 includes software that is configured to allow defining a primary tag.  A primary tag replaces all of the tags in a web site.  The primary tag may span one pixel on a web page.  Defining the primary tag may include\ndefining the settings for the primary tags, who has access to the primary tag, who can change it, what the name of the primary tag will be, etc. Once the primary tag is defined, all of the secondary tags must be defined.\nThe secondary tag module 220 includes software with the ability to define the secondary tags.  All of the tags that were previously individually defined on the web site are now defined as secondary tags with a link to the primary tag.  A beacon\nmay be defined as the business idea or implementation of some type of technology that provides the capacity to either navigate somewhere or not from within a web page or web application and a tag is how a beacon is implemented.  Typically, beacons are\nimplemented by several tags.  With the current invention, there is a single beacon implemented by a single tag with multiple variables assigned to that beacon to perform the same functions as multiple beacons would have previously made.\nCustom variables may also be set so that if certain conditions are met, other tags may be called off.  An initial report or a tag analysis report may be run initially to retrieve all of the secondary tags, configuration settings and conditional\nsettings currently implemented on the website so that the transitioning process to the primary tag method is simplified.  Once a system user 102 has made all of the changes discussed using the common user interface 270, these settings can be saved with\nan option to replace all of the tags on the web page with code that is generated from the back end of the common user interface 270.  The system user 260 must then implement the changes on the website.  When a new tag is implemented, the system user 260\ncan use the common user interface 260 to implement the new tag by creating an additional secondary tag using the Taggregator software.\nThe additional tag modules 230 for subsequent tags include software with the ability to define the subsequent tags.  Subsequent tags may be the same as secondary tags, but they may be placed in a different order.  A secondary tag is conjoined to\nthe primary tag, and all tags after the secondary would also be conjoined, and therefore by nature be subsequent to the secondary tag.  Subsequent tags may represent a plurality of tags, each added separately, each unique, and each with its own set of\nrequirements and values.\nIn many cases within the industry, internet traffic reports have one set of data regarding the number of tags that were called while business partners have another set of data regarding the number of tags that were called.  This current\ndiscrepancy can easily be rectified with reporting features of the Taggregator software.  The reporting module 250 may include the software and programming that is able to define and run real time reports of the secondary tags 220.  A system user 260 may\nuse the common user interface 270 to retrieve a master report that is an aggregate report of the number of times a primary tag was called and the number of successful calls the primary tag made through each of the secondary tags.  This provides an audit\ntag for the system user 260 to review.  The system user 260 can compare the master report with the reports from partners and other sources to ensure the number of calls made and the system user 260 is paying for are accurate.  The master report may\nreport the number of times a certain domain was called and thus the system user 260 should only have to pay for that number of hits.  Thus, it is no longer a question as to whether or not the webpage was actually loaded.  Now, the question may be whether\nor not the service was called from a third party.\nA reporting module 250 may also include sophisticated software that can customize reports for advertisers or other partners or affiliates.  For example, one affiliate program may require generating a report every Friday.  All of the calls to\nthat affiliate may be stored until Friday and the aggregate report can automatically be sent to the affiliate every Friday.  This provides an additional layer of network and server efficiently.\nFIG. 3 is flow diagram illustrating the process of implementing primary and secondary tags.  Operation begins at block 310.  At block 320, a user interface is presented.  Next, at block 330, a request is received to implement a primary tag and\nthe primary tag is implemented upon receipt.  Next, at block 340, secondary tags are received and implemented.  At block 330, the secondary tags are aggregated by adding the necessary tag information options and configuration data from the secondary tag\nto the primary tag configuration.  This configuration remains on the server and is not integrated into the tag so that future edits can be done without changing the implementation code for the tag.\nFIG. 4 illustrates a detailed process overview of the current system.  At step 410 a user signs up for the Taggregator service.  The user may do this through a login procedure or an alternate means.  The user then defines primary tags at step\n420 such as the domain name and other variables such as the campaign type associated with a primary tag at step 420.  If the user is only in charge of managing one website, only one primary tag may be created.  A campaign type may be related to an\nadvertisement campaign such as a multi-site campaign or a Smart Ad campaign, or a new promotion.  Another variable may be used for revenue tracking and sharing among multiple entities.  Furthermore, the primary tag definition may be used for funneling\nacross multiple campaigns.\nNext, at step 430, the user defines secondary tags using existing tag definitions.  The existing tag definitions may be found as part of the master report previously discussed or any other method that may be in place to determine all of the tags\non a given website.  Secondary tags may be in place for functions such as website reporting including for example website traffic reporting, campaign reporting, advertisement reporting tags for publishers, advertising reporting tags for advertisement\ndelivery systems, tags associated with affiliate programs, revenue tracking or tags used for any other additional purpose.\nNext, at step 440, the user confirms and saves the new tag.  Taggregator receives the instruction to save the tag and complies or aggregates the new tag.  The Taggregator client side software, web page or other tool may respond with the tag or\nbeacon code necessary to implement the new tags on the user's website.  The user can then replace the existing code on the website with the new code created by the Taggregator system.  Finally, at step 450, the new primary tag is added to the website.  A\nuser can now access the Taggregator system and review reports related to tags.\nFIG. 5 illustrates prior art implementation of tags and tag reporting.  FIG. 5 includes a web page 510, a reporting module 550, a campaign module 560, a partner module 570 and multiple reports 580.  Web page 510 may include tag1 520, tag2 530,\nand tag3 540.  In FIG. 5, each call to tag1 520, tag2 530, and tag3 540 is implemented synchronously.  That is, every call must be validated and thus wait for a response of success.  In prior art systems, a call to a tag such as tag1 520 is not enough. \nA successful response must be returned for the web page to be loaded.\nIn one implementation on the tag server 106 (FIG. 1) side, all of the tags on the website are generated as one primary tag.  That primary tag calls the Taggregator service 112 in real time.  The Taggregator service 112 then makes latent calls to\nevery partner of the primary website in order for the partner's current internal reporting to continue to exist.  A latent call, as used here, refers to a waiting period between the time the call is first made and the time execution of the call begins. \nAt the same time, an aggregate report may be made for all of the calls that were made on behalf of the service.\nFIG. 6 illustrates the new implementation of tags and tag reporting.  FIG. 6 includes a web page 605 having TagA 610, the Taggregator service 615 including tags Tag1 620, Tag2 630 and Tag3 640, Aggregate reporting module 680 coupled with the\nTaggregator service 615, a reporting module 650, a campaign module 660, and a partner module 670 and existing reports 690.  In FIG. 6, there is one real-time call with multiple latent informs.\nIn this example, campaign is intended to represent a temporary event with unique reporting requirements and tracking configuration.  A campaign, such as a limited time advertising campaign, or a temporary or seasonal promotion, could have its\ntracking requirements facilities by aggregating the tags required, and these could be removed once the campaign is complete.\nWhile various embodiments of the invention have been described, it will be apparent to those of ordinary skill in the art that many more embodiments and implementations are possible within the scope of the invention.  Accordingly, the invention\nis not to be restricted except in light of the attached claims and their equivalents.", "application_number": "14635601", "abstract": " A system for managing tags on a web page is disclosed. Tags are managed\n     by implementing primary and secondary tags. The secondary tags are\n     aggregated to provide network and tag management efficiency.\n", "citations": ["6112240", "6169997", "6438592", "7168063", "7248603", "7280558", "7454434", "8239491", "8244584", "8560398", "20030084048", "20030187976", "20040255006", "20050044139", "20050092823", "20060026064", "20060179133", "20060242574", "20060248207", "20070016575", "20070043583", "20070124430", "20070226077", "20070233715", "20070273518", "20080034279", "20080040313", "20080040473", "20080046458", "20080071929", "20080072145", "20080086496", "20080091797", "20080092044", "20080104194", "20080114573", "20080114875", "20080201645", "20080244051", "20080320498", "20090006442", "20090024982", "20090063447", "20090119572", "20090182727"], "related": ["13362777", "11960619"]}, {"id": "20150227531", "patent_code": "10318572", "patent_name": "Structured labeling to facilitate concept evolution in machine learning", "year": "2019", "inventor_and_country_data": " Inventors: \nKulesza; Todd (Corvallis, OR), Charles; Denis (Redmond, WA), Caruana; Rich (Woodinville, WA), Amershi; Saleema Amin (Seattle, WA), Fisher; Danyel Aharon (Seattle, WA)  ", "description": "<BR><BR>BACKGROUND\nConventional labeling technology allows users to label content.  The labels are used by a computer to differentiate among different types of content.  The labeling technology may assign content to different groups.  However, users may label\ncontent differently at different times, and different users may label data differently.  This uncertainty in label application may impact labeling consistency and label quality.\nFor instance, conventional spam filters employ labeling technology to identify spam messages.  The performance of the conventional spam filters depend directly on label quality and label consistency.  Spam filters may be trained from a large\ncorpus of content (e.g. emails or web pages) labeled as spam or not spam.  Poorly trained spam filters may admit unwanted spam or, worse yet, incorrectly classify important content as spam.\nImprovements in label quality or label consistency may yield superior performance in spam filtering, product recommendation, prioritization, etc. Label quality is affected by factors such as the labeler's expertise or familiarity with the\nconcept or data, the labeler's judgment ability and attentiveness during labeling, and the ambiguity and changing distribution of the content.  The label quality may be particularly important in situations where data quantity is limited (e.g., when\nlabels are expensive to obtain or when individuals are labeling data for their own purposes).\nTo improve label quality and consistency, label noise and concept drift should be managed.  The label noise may be identified when several different labels are applied to the same content.  Concept drift may be identified by when quickly\nchanging content requires several different labels.  The label noise and concept drift are managed by technologies that provide set-based label judgments and temporally applied labels (e.g., by discarding or weighting information according to a moving\nwindow that changes as the underlying content changes.)\n<BR><BR>SUMMARY\nEmbodiments of the invention relate to systems, methods, and computer-readable media for, among other things, generating a graphical user interface that structures labeling of multimedia content.  The structured labeling of multimedia content\nvia the graphical user interface may permit concept evolution as labels, categories, or user-supplied tags are applied to the multimedia content.  The structured labeling allows the user to categorize multimedia content with an existing schema (e.g.,\n`YES`, `NO`, `COULD BE`, etc.) The structured labeling graphical user interface may, in at least one embodiment, allow a labeler to postpone labeling decisions.\nIn one embodiment, a structured labeling graphical user interface having several portions is generated by a computer.  A first portion of the structured labeling graphical user interface is configured to display multimedia content.  A second\nportion of the structured labeling graphical user interface is configured to assign the multimedia content to one of at least two categories.  In turn, a user provides input to the graphical user interface.  The user input may associate multimedia\ncontent displayed in the first portion with one of the at least two categories in the second portion of the graphical user interface.  In an alternative embodiment, the user input may associate multimedia content displayed in the first portion with at\nleast one group of the at least two categories.  In certain embodiments, the user input may be, among other things, menu selections or drag-and-drop commands.  For instance, hovering over the multimedia content with a selector, clicking on the multimedia\ncontent, dragging the multimedia content to one of the at least two categories, and dropping the multimedia content.\nIn some embodiments, the structured labeling graphical user interface is updated with summaries.  The summaries are generated for the multimedia content associated with one or more groups.  The groups may have, in one embodiment, user-supplied\ntags.  In other embodiments, the summaries are generated for groups without user-supplied tags.  Additionally, the structured labeling graphical user interface may provide recommendation for removing or adding multimedia content to the groups.\nThe user-supplied tags may correspond to the grouped multimedia content in at least one category.  The user-supplied tags may receive user input that further define a concept corresponding to the multimedia content associated with one of the at\nleast two categories or the user-supplied tags.\nThis Summary is provided to introduce a selection of concepts in a simplified form that are further described below in the Detailed Description.  This Summary is not intended to identify key features or essential features of the claimed subject\nmatter, nor is it intended to be used as an aid in determining the scope of the claimed subject matter. <BR><BR>BRIEF DESCRIPTION OF THE DRAWINGS\nThe embodiments of the invention are described in detail below with reference to the attached drawing figures, wherein:\nFIG. 1 is a block diagram illustrating an exemplary computing environment suitable for implementing embodiments of the invention;\nFIG. 2 is a network diagram illustrating a network environment suitable for implementing embodiments of the invention;\nFIG. 3 is a logic diagram illustrating a computer-implemented method of multimedia content labeling, in accordance with embodiments of the invention;\nFIG. 4 is another logic diagram illustrating a computer-implemented method of generating a structured labeling graphical user interface, in accordance with embodiments of the invention;\nFIG. 5 is a screen shot illustrating an exemplary graphical user for structured labeling, in accordance with embodiments of the invention;\nFIG. 6 is a screen shot illustrating another exemplary graphical user for assisted structured labeling, in accordance with embodiments of the invention; and\nFIG. 7 is a screen shot illustrating an exemplary user-supplied tag with visual representations for associated multimedia content, in accordance with embodiments of the invention.\n<BR><BR>DETAILED DESCRIPTION\nThe subject matter of this patent is described with specificity herein to meet statutory requirements.  However, the description itself is not intended to necessarily limit the scope of the claims.  Rather, the claimed subject matter might be\nembodied in other ways to include different steps or combinations of steps similar to the ones described in this document, in conjunction with other present or future technologies.  Although the terms \"step,\" \"block,\" or \"component,\" etc., might be used\nherein to connote different components of methods or systems employed, the terms should not be interpreted as implying any particular order among or between various steps herein disclosed unless and except when the order of individual steps is explicitly\ndescribed.\nAs utilized herein, \"concept evolution\" refers to defining and refining a target concept by a labeler such that different labels are applied to similar items due to changes in the labeler's notion of the underlying concept over time.  That is,\nsimilar items may be labeled differently not because the user perceives the items to be different from one another, but because their understanding of which items match their concept has evolved since labeling the earlier items.  Noting this evolution\nmay reduce inconsistency in labeling similar items when concept evolution is properly considered during label assignment.\nAs utilized herein, \"category\" is selected from a high level schema that includes at least two labels.  In one embodiment, the labels may be \"YES,\" \"NO,\" and \"COULD BE,\" which are predefined.\nAs utilized herein, \"groups\" are collection of multimedia content that are associated with a category.  Each category may have one or more groups in some embodiments.  The groups are malleable.  A group may be moved between categories.  The\ngroups may be merged, deleted, or edited.\nAs utilized herein, \"user-supplied tags\" are descriptions selected or defined by a labeler.  These tags, in one embodiment, are temporary and modifiable.  In at least one embodiment, the tags are applied to groups of multimedia content within at\nleast one category.  The tags, in additional embodiments, are displayed within at least two predefined categories selected from `YES,` `NO,` or `COULD BE.` The tags could create a hierarchy within the predefined categories.  In other words, tags may be\nnested (e.g. tag \"B\" may be nested in tag \"1\").\nEmbodiments of the invention are directed to, among other things, multimedia content labeling.  A server is configured to provide a prompt for a concept in a graphical user interface.  The graphical user interface includes at least two\ncategories for the prompt and one or more user-supplied tags for groups within each of the two categories.  The server renders the multimedia content for display to a user in a portion of the graphical user interface.  In turn, user input in the at least\ntwo categories or corresponding user-supplied tags is received.  The user input, in an embodiment of the invention, may associate one of the at least two categories with the rendered multimedia content.  The rendered multimedia content may be added to\none or more groups corresponding to the at least two categories.  Additionally, the user input may describe the grouped multimedia content with user-supplied tags.  The server may store the user input, categories, and association between the multimedia\ncontent and the categories, groups, or user-supplied tags in a database.\nThe structured labeling graphical user interface assists labelers as they define and refine concepts for multimedia content.  This structured labeling graphical user interface allows people to organize their concept definition by grouping and\ntagging data (e.g., `YES, `NO`, and `COULD BE`).  The labeler's interaction with the structured labeling graphical user interface is logged to gain insights into grouping multimedia content.  Based on the logged data, the server may identify\ngroup-specific features, generate one or more recommendations for grouping multimedia content, and assign weights to group structures.  The structured labels may be utilized to build machine learners or evaluate algorithms.\nHaving briefly described an overview of embodiments of the invention, an exemplary operating environment in which embodiments of the invention may be implemented is described below to provide a general context for various aspects of these\nembodiments.\nFIG. 1 is a block diagram illustrating an exemplary computing environment suitable for implementing embodiments of the invention.  Referring to the figures in general and initially to FIG. 1 in particular and computing device 100.  The computing\ndevice 100 is but one example of a suitable computing environment and is not intended to suggest any limitation as to the scope of use or functionality of embodiments of the invention.  Neither should the computing device 100 be interpreted as having any\ndependency or requirement relating to any one component, or combination of components, illustrated.\nThe embodiments of the invention may be described in the general context of computer code or machine-useable instructions, including computer-executable instructions.  These instructions may include program components being executed by a\ncomputer or other machine (e.g., a personal data assistant or other handheld device).  Generally, program components, including routines, programs, applications objects, components, data structures, and the like, refer to code that performs particular\ntasks or implements particular abstract data types.  Embodiments of the invention may be practiced in a variety of system configurations, including handheld devices, tablet computers, gaming devices, consumer electronics, general-purpose computers,\nspecialty computing devices, etc. Embodiments of the invention may also be practiced in distributed computing environments, where tasks are performed by remote-processing devices that are linked through a communications network.\nAs one skilled in the art will appreciate, the computing device 100 may include hardware, firmware, software, or a combination of hardware and software.  The hardware includes processors and memories configured to execute instructions stored in\nthe memories.  The logic associated with the instructions may be implemented, in whole or in part, directly in hardware logic.  For example, and without limitation, illustrative types of hardware logic include field programmable gate array (FPGA),\napplication-specific integrated circuit (ASIC), system-on-a-chip (SOC), or complex programmable logic devices (CPLDs).  The hardware logic allows a device to generate a structured labeling graphical user interface for a user.  The device is configured to\nreceive user input at the graphical user interface and to log the user interaction with the graphical user interface.  The device may recommend groupings or summaries based on the user interaction that associated multimedia content rendered in the\ngraphical user interface with one or more categories.  The device may, in an embodiment, display statistics associated with groupings and categories in the graphical user interface.\nWith continued reference to FIG. 1, computing device 100 includes a bus 110 that directly or indirectly couples the following devices: memory 112, one or more processors 114, one or more presentation components 116, input/output (I/O) ports 118,\nI/O components 120, and an illustrative power supply 122.  Bus 110 represents what may be one or more busses (such as an address bus, data bus, or combination thereof).  Although the various blocks of FIG. 1 are shown with lines for the sake of clarity,\nin reality, delineating various components is not so clear and, metaphorically, the lines would more accurately be grey and fuzzy.  For example, one may consider a presentation component, such as a display device, to be an I/O component.  Also,\nprocessors have memory.  The inventors hereof recognize that such is the nature of the art and reiterate that the diagram of FIG. 1 is merely illustrative of an exemplary computing device that can be used in connection with one or more embodiments of the\ninvention.  Distinction is not made between such categories as \"workstation,\" \"server,\" \"laptop,\" \"handheld device,\" etc., as all are contemplated within the scope of FIG. 1 and refers to \"computer\" or \"computing device.\"\nComputing device 100 typically includes a variety of computer-readable media.  Computer-readable media can be any available media that is accessible by computing device 100 and includes both volatile and nonvolatile media, removable and\nnon-removable media.  Computer-readable media may comprise computer storage media and communication media.\nComputer storage media includes volatile and nonvolatile, removable and non-removable media implemented in any method or technology for storage of information such as computer-readable instructions, data structures, program modules or other\ndata.  Computer storage media includes, but is not limited to, Random Access Memory (RAM), Read Only Memory (ROM), Electronically Erasable Programmable Read Only Memory (EEPROM), flash memory or other memory technology, CD-ROM, digital versatile disks\n(DVD) or other holographic memory, magnetic cassettes, magnetic tape, magnetic disk storage or other magnetic storage devices, or any other medium that can be used to encode desired data and that can be accessed by the computing device 100.  In an\nembodiment, the computer storage media can be selected from tangible computer storage media like flash memory.  These memory technologies can store data momentarily, temporarily, or permanently.  Computer storage does not include and excludes\ncommunication media.\nOn the other hand, communication media typically embodies computer-readable instructions, data structures, program modules or other data in a modulated data signal such as a carrier wave or other transport mechanism and includes any information\ndelivery media.  The term \"modulated data signal\" means a signal that has one or more of its characteristics set or changed in such a manner as to encode information in the signal.  By way of example, and not limitation, communication media includes\nwired media, such as a wired network or direct-wired connection, and wireless media such as acoustic, RF, infrared and other wireless media.\nMemory 112 includes computer-storage media in the form of volatile and/or nonvolatile memory.  The memory may be removable, nonremovable, or a combination thereof.  Exemplary hardware devices include solid-state memory, hard drives, optical-disc\ndrives, etc. Computing device 100 includes one or more processors that read data from various entities such as memory 112 or I/O components 120.  Presentation component(s) 116 present data indications to a user or other device.  Exemplary presentation\ncomponents 116 include a display device, speaker, printing component, vibrating component, etc. I/O ports 118 allow computing device 100 to be logically coupled to other devices including I/O components 120, some of which may be built in. Illustrative\nI/O components include a microphone, joystick, game pad, satellite dish, scanner, printer, wireless device, a controller (such as a stylus, keyboard, and mouse) or a natural user interface (NUI), etc.\nThe NUI processes gestures (e.g., hand, face, body, etc.), voice, or other physiological inputs generated by a user.  These inputs may be interpreted as terms for user-supplied tags, requests for associating multimedia content with categories,\nor requests for modifying groups having the multimedia content.  The input of the NUI may be transmitted to the appropriate network elements for further processing.  The NUI implements any combination of speech recognition, touch and stylus recognition,\nfacial recognition, biometric recognition, gesture recognition both on screen and adjacent to the screen, air gestures, head and eye tracking, and touch recognition associated with displays on the computing device 100.  The computing device 100 may be\nequipped with depth cameras, such as stereoscopic camera systems, infrared camera systems, RGB camera systems, and combinations of these, for gesture detection and recognition.  Additionally, the computing device 100 may be equipped with accelerometers\nor gyroscopes that enable detection of motion.  The output of the accelerometers or gyroscopes is provided to the display of the computing device 100 to render immersive augmented reality or virtual reality.\nAs previously mentioned, embodiments of the invention are generally directed to systems, methods, and computer-readable storage media for, among other things, generating a structured labeling graphical user interface configured to render\nmultimedia content and associate the multimedia content with categories.  At least a portion of the graphical user interface provides user-supplied tags that may be associated with the rendered multimedia content.  The user-supplied tags may describe\ngroups of multimedia content within the categories of the structured labeling graphical user interface.  In some embodiments, the groups may be nested within each other.  Accordingly, Group A may be nested in Group 1.  This nesting may create a hierarchy\nfor organizing the labeled multimedia content.\nVarious aspects of the technology described herein are generally employed in computer systems, computer-implemented methods, and computer-readable storage media for, among other things, associating the multimedia content with user-supplied tags\nand categories in a structured labeling graphical use interface.  In one embodiment, a server executes suggestion components that detect associations between the user-supplied tags and the grouped multimedia content and provide grouping suggestions for\nuncategorized multimedia content or suggestions for modifying groups of categorized multimedia content.  The server may display the suggestions to the user, who may decide to accept the suggestions or to decline the suggestions.  The server may log user\ninteraction with the structured labeling graphical user interface to gather metrics (e.g., dwell time, click frequency, revision per group, revision per user-supplied tag, and number of multimedia content per group, etc.) for storage in a data store.\nIn one embodiment, a computer system is configured to label multimedia content.  The computer system includes, among other components, a grouping and tagging component and a summary generation component.  The grouping and tagging component\nreceives the user input, associates multimedia content with one or more categories or user-supplied tags based on the user input, and updates the user-supplied tags from terms provided in the user input.  The summary generation component provides\nsummaries for the multimedia content associated with the groups, one or more categories, or user-supplied tags.  The summaries may be used by the user to modify the user-supplied tags or the groups having the multimedia content.  The user may associate\nuncategorized multimedia content with the groups, categories, or the user-supplied tags based on the generated summaries.\nFIG. 2 is a network diagram illustrating a network environment suitable for implementing embodiments of the invention.  The computing system 200 may include client device 210, server 220, data store 230, and network 240.  The network 240 may\ncommunicatively connect the client device 210, server 220, and data store 230.  It should be understood that any number of client computing devices 210, servers 220 and data stores 230 may be employed in the computing system 200 within the scope of\nembodiments of the invention.  Each may comprise a single device/interface or multiple devices/interfaces cooperating in a distributed environment.  For instance, the server 220 may comprise multiple devices and/or modules arranged in a distributed\nenvironment that collectively provide the functionality of the server 220 described herein.  Additionally, other components/modules not shown also may be included within the computing system 200.\nIn some embodiments, one or more of the illustrated components/modules may be implemented as stand-alone applications.  In other embodiments, one or more of the illustrated components/modules may be implemented via the client device 210, as an\nInternet-based service, or as a module inside the server 220.  It will be understood by those of ordinary skill in the art that the components/modules illustrated in FIG. 2 are exemplary in nature and in number and should not be construed as limiting. \nAny number of components/modules may be employed to achieve the desired functionality within the scope of embodiments hereof.  Further, components/modules may be located on any number of search engines or user computing devices.  By way of example only,\nthe server 220 might be provided as a single server (as shown), a cluster of servers, or a computing device remote from one or more of the remaining components.\nThe client device 210 may be used to input one or more user-supplied tags and to associate multimedia content with categories or grouped multimedia content with user-supplied tags via a structured labeling graphical user interface.  The client\ndevice 210 may communicate the user input received at the structured labeling graphical user interface to the server 220.  In an embodiment, the client device 210 may include any type of computing device, such as the computing device 100 described with\nreference to FIG. 1, for example.\nGenerally, the client device 210 includes a display 211 and a browser 212.  The display 211 is configured to present various content including, without limitation, a structured labeling graphical user interface having, among other things, a\nfirst portion for rendering multimedia content and a second portion for categories and user-supplied tags that may be associated with the multimedia content as described herein.  The structured labeling graphical user interface is designed to increase\nlabel consistency by assisting users by explicitly surfacing and recalling labeling decisions.  Further, the structured labeling graphical user interface enables users to create, delete, split, and merge groups.  This allows users to frequently refine\ntheir concept definition as they observe additional portions of multimedia content or other types of multimedia content.  The graphical user interface, in certain embodiments, may provide assisted structured labeling.  The assisted structured labeling is\npresented to the user as visual aids with a configurable level of automation to further assist users as they label multimedia content and while their understanding of the concept or multimedia content evolves.\nThe structured labeling graphical use interface, in one embodiment, may display one multimedia content at a time.  In other embodiments, the graphical user interface may display several multimedia content at the same time.  The graphical user\ninterface may also prompt users to categorize the multimedia content into one of three high-level categories: `YES`, `NO`, or `COULD BE` for a current concept prompt (e.g. \"CARS\").  For instance the prompt may be \"WHETHER THE CURRENT MULTIMEDIA CONTENT\nIS AN EXAMPLE OF CONCEPT X.\" In addition, participants could create via the structured labeling graphical user interface user-supplied tags for groups within the categories.  For a `COULD BE` category the user may create a user-supplied tag as a reminder\nof the group of multimedia content that is associated with the current user-supplied tag.  The user-supplied tag may include a description.  In some embodiments, the user-supplied tag lacks a description and may be user a placeholder to display one or\nmore suggestions generated by the summary generation component 224.  The structured labeling graphical user interface organizes the multimedia content with mutually exclusive categories such as `YES`, `NO`, and `COULD BE`) and provides grouping and\ntagging of the multimedia content within the categories.  The users may drag multimedia content from a rendering portion of the structured labeling graphical user interface to a labeling area.  The user may drop the multimedia content over an existing\nuser-supplied tag or over a category to create or update groupings of the multimedia content.  The user may drop the multimedia content over a visual indicator to create a new user-supplied tag.  In embodiments, the display 220 is further configured to\nenable touch or gesture inputs from a user or provide a NUI.\nThe browser 212 is configured to render multimedia content, for instance, web pages, video files, audio files, etc., in association with the display 211 of the client computing device 210.  The browser 212 is further configured to receive user\ninput for refining or defining the user-supplied tags, updating groupings of the multimedia content (generally inputted via a graphical user interface or NUI) and to receive multimedia content for presentation on the display 211, for instance, from the\ndata store 230.  The browser 212 may be any suitable type of web browser such as INTERNET EXPLORER.RTM., FIREFOX.RTM., CHROME.RTM., SAFARI.RTM., or other type of software configured to enable structured labeling of multimedia content as described herein. It should be noted that the functionality described herein as being performed by the browser 212 may be performed by any other application capable of rendering multimedia content.  Any and all such variations, and any combination thereof, are\ncontemplated to be within the scope of embodiments of the invention.\nThe server 220 is configured to receive user input from the client devices 210, provide group suggestions or summaries to assist the user, and log user interaction with a structured labeling graphical user interface transmitted to the client\ndevice 210.  The server may implement any combination of the following components to process the user input: a grouping and tagging component 221, a logging component 222, a suggestion component 223, a summary generation component 224, and a display\ncomponent 225.  In one embodiment, the components of the server 220 may be executed locally by the client device 210 to process the multimedia content stored in the data store 230.\nThe grouping and tagging component 221, in one embodiment, receives user input from the client device 210.  The user input may associate multimedia content rendered in the structured labeling interface with one or more categories.  The one or\nmore categories may be predefined in at least one embodiment.  In other embodiments, the one or more categories may be configured based on user input in the graphical user interface.  The user input, in some embodiments, includes user-supplied tags\nhaving terms that describe multimedia content grouped within a category.  The grouping and tagging component 221 may group the multimedia content within categories based on the user input.  The user-supplied tags, in at least one embodiment, are rendered\nwith visual representation of the grouped multimedia content within the categories in the structured labeling graphical user interface.  The terms received from the user are displayed in the user-supplied tags and a visual indicator representing\nmultimedia content associated with the user-supplied tag may be updated to reflect an association between the grouped or rendered multimedia content and the user-supplied tag.  In other embodiments, the user-supplied tags may be selected in the graphical\nuser interface.  For instance, a user may right-click on the multimedia content to select terms that describe the concept corresponding to the multimedia content.  In additional embodiments, the grouping and tagging component 221 may receive user input\nthat drags the user-supplied tags or categories over or near the multimedia content and drops the user-supplied tags or categories onto the multimedia content to add the multimedia content to the group having the user-supplied tag or category.\nIn certain embodiments, the logging component 222 receives the user inputs and logs the user inputs and other metadata associated with the structured labeling graphical user interface in the data store 230.  The logging component 222 may log the\nnumber of multimedia content associated with the categories.  In one embodiment, the logging component 222 may log the number of multimedia content associated with each group, including groups with user-supplied tags in the data store 230.  The data\nstore 230 may store the associations between the multimedia content and the categories and user-supplied tags.  The data store 230 may receive log data from the logging component 222.  The log data may include, among other things, the number of revisions\nto the groups, the length of time that transpired before a user associated multimedia content with a category or user-supplied tag, whether the user-supplied tag is completed by the user, whether the user-supplied tag is complete based on a summary\nprovided by the summary generation component, the number of revisions to the user-supplied tags, and the length of time it takes to classify all multimedia content stored in the data store 230.  The structured labeling graphical user interface allows the\nuser to preform edits by moving user-supplied tags between categories (e.g., preserving any accompanying tags and associated multimedia content), merging user-supplied tags, or moving individual multimedia content between user-supplied tags.\nThe suggestion component 223 receives the log data and generates suggestions for grouping multimedia content.  The suggestion component 223, in one embodiment, provides suggestions for grouping multimedia content.  For instance, the suggestion\ncomponent may provide suggestions for modifying the groups of multimedia content that are associated with the categories or the user-supplied tags.  Additionally, the suggestion component 223 may provide suggestions for associating the uncategorized\nmultimedia content with the categories or the groups having the user-supplied tags.\nIn certain embodiments, the suggestions from the suggestion component 223 are computed based on similarity between an uncategorized multimedia content and a group of multimedia content associated with the categories or the user-supplied tags. \nThe group of multimedia content that is most similar to the uncategorized multimedia content is suggested as a potential association for the uncategorized multimedia content.  The suggestion component 223 computes item-to-group similarity as the\nsimilarity between the uncategorized multimedia content item and the most similar multimedia content in the group of the multimedia content of each user-supplied tag or category.  For instance, the suggestion component 223 may compute similarity between\nthe uncategorized multimedia content and all multimedia content associated with each of each group of multimedia content with a user-supplied tag or category.  In turn, the suggestion component 223 selects the `shortest-link` as the similarity value. \nThe suggestion component 223 computes item-to-item similarity via the cosine similarity metric.  In other embodiments, a term frequency-inverse document frequency (TF-IDF) may be used to calculate similarity.  The recommendations for grouping may be\ndisplayed on the structured labeling graphical user interface as a `wiggle` animation on the group to draw the user's attention or a static indicator visible within the recommended group.  In some embodiments, the suggestion component 223 may generate a\nsimilarity window.  The suggestion component 223 may select the most similar unlabeled multimedia content to the multimedia currently being labeled.  The similar multimedia content, for display in the similarity window, may be identified using the same\nitem-to-item similarity measure used to make group recommendations.\nThe summary generation component 224, in some embodiments, receives groups of multimedia content associated with each of the user-supplied tags.  In an alternate embodiment, the summary generation component 224 may receive multimedia content\ncorresponding to each category or one or more groups within each category.  The summary generation component 224 generates summaries that may be included near the user-supplied tags.  The groups may have, in one embodiment, user-supplied tags.  In other\nembodiments, the summaries are generated for groups without user-supplied tags.\nThe summary generation component 224 may identify terms from the multimedia content associated with the user-supplied tags.  The terms selected are best able to summarize the set of multimedia content associated with the user-supplied tag.  The\nsummary generation component 224 may analyze the document structure (e.g., heading, titles, metadata, and file type) to summarize the multimedia content.  In one embodiment, two bag-of-words algorithms are executed to create textual summaries. \nInitially, the summary generation component 224 considers the content of multimedia content associated with each user-supplied tag as a bag-of-words (i.e., the set of words from all the multimedia content associated with the user-supplied tag).  In turn,\nthe summary generation component 224 selects the most frequently occurring words from the bag, with frequency computed via the common term frequency inverse document frequency (TF-IDF).  In an alternate embodiment, the summary generation component 224\naccesses query logs of a search engine (not shown).  The search terms associated with the multimedia content are extracted from the search log.  The search terms include phrases that searchers used to locate that multimedia content via the search engine. Because these phrases are typically short and targeted, the summary generation component 224 may return the selected query terms as summaries.  In one embodiment, the search query phrases with the highest TF-IDFs are displayed as summaries.  These\nsummaries may display the most prominent search terms used to find the web pages within each group and are updated in real-time as multimedia content changes.\nIn optional embodiments, the display component 225 is executed by the server 220 to render the user experiences for providing (i) entry of user input and (ii) viewing of multimedia content and associations between categories or user-supplied\ntags and the multimedia content.  The display component 225 provides both user input entry and grouping of multimedia content user experiences.  The viewing experiences on the structured labeling graphical user interface include providing visual\nrepresentations of the multimedia content associated with the categories and user-supplied tags.\nThe display component 225 provides term highlighting as visual cues for suggested groupings of multimedia content in the graphical user interface.  The visual cues may include icons such as \"*\" to assist users that are associating the multimedia\ncontent with the categories or user-supplied tags.  The \"*\" may be rendered proximate to the suggested category or user-supplied tag for the multimedia content currently being considered by the user.\nThe data store 230 is accessed by the server 220 to select multimedia content for labeling.  The data store 230, in turn, stores search logs and log data from the user interaction with the structured labeling graphical user interface.  The data\nstore 230 may be a relational database that includes an index to content, including image, audio, video, text, webpages, etc. The data store 230 may also include a log that tracks statistics (e.g., decision time, click rate, term frequency, revision\nfrequency, etc.) for each of the associated multimedia content, categories, and user-supplied tags.  These statistics are sent to the suggestion component 223 (for creating group suggestions) or to the summary generation component 224 (for ranking of the\nsummaries).  The stored structure (e.g., categories and user-supplied tags) for each multimedia content may be shareable with other labelers that are considering labels for similar multimedia content or the same multimedia content.  Thus, other labelers\nmay have insight into how others have labeled the multimedia content.\nThe network 240 communicatively connects the search engine 220 and client device 210.  The network 240 may include, without limitation, one or more local area networks (LANs) and/or wide area networks (WANs).  Such networking environments are\ncommonplace in offices, enterprise-wide computer networks, intranets and the Internet.  Accordingly, the network 240 is not further described herein.\nThe exemplary computing system 200 in which embodiments of the invention are employed is described above.  Generally, the computing system 200 illustrates an environment in which group suggestions are provided to assist labelers as they\nassociate multimedia content with user-supplied tags and categories.  As will be described in further detail below, embodiments of the invention provide methods and graphical user interface elements for structured labeling of multimedia content.  It\nshould be understood that this and other arrangements described herein are set forth only as examples.  Other arrangements and elements (e.g., machines, interfaces, functions, orders, and groupings of functions, etc.) can be used in addition to or\ninstead of those shown, and some elements may be omitted altogether.  Further, many of the elements described herein are functional components that may be implemented as discrete or distributed components or in conjunction with other components, and in\nany suitable combination and location.  Various functions described herein as being performed by one or more entities may be carried out by hardware, firmware, and/or software.  For instance, various functions may be carried out by a processor executing\ninstructions stored in memory.\nAccordingly, the structured labeling graphical user interface associates labels with multimedia content.  Moreover, the structured labeling graphical user interface may provide assistance to labelers.  The assisted structured labeling graphical\nuser interface generates automated visual cues and recommendations that are explicitly surfaced to assist in recall of labeling decisions.\nFIG. 3 is a logic diagram illustrating a computer-implemented method 300 of multimedia content labeling, in accordance with embodiments of the invention.  The method initializes in step 310 on a server.  The multimedia content may include a\ncollection of webpages, audio files, or video files.\nIn step 312, the server, optionally, provides a prompt for a concept in a graphical user interface.  The graphical user interface, in one embodiment, includes at least two categories for the prompt.  One or more user-supplied tags for groups\nwithin each of the two categories may be received via the graphical user interface.  The graphical user interface may provide a viewable region in the graphical user interface with multimedia content similar to multimedia content associated with the at\nleast two categories.  In one embodiment, the at least two categories are selected from `YES`, `NO`, and `COULD BE`.\nIn turn, the server, in step 314, renders multimedia content for display to a user in a portion of the graphical user interface.  The graphical user interface receives, in step 316, user input in the at least two categories to associate the\nmultimedia content in the graphical user interface with one of the two categories.  Additionally, the user input may correspond to user-supplied tags that describe the concept of multimedia content grouped within the at least two categories.  The\nuser-supplied tags are assigned to one or more groups of multimedia content.  In some embodiments, the groups may be subgroups of a group.  All groups are associated with at least on the at least two categories.  In one embodiment, the user input is\ndragging and dropping a visual representation of the multimedia content onto or near one of the at least two categories or a group having the user-supplied tags.  In certain embodiments, the user input may include removing, combining, or adding\nuser-supplied tags to the graphical user interface.  In other embodiments, the user input may include removing, combining, or adding groups to the graphical user interface.\nThe server associates one of the at least two categories or the groups having the user-supplied tags with the rendered multimedia content.  The server may update the graphical user interface with visual indicators.  The visual indicators may\nrepresent a number of multimedia content associated with the groups of the at least two categories.  These visual indicators may be displayed proximate to the at least two categories.  In other embodiments, the visual indicators may be thumbnails of the\nmultimedia content or icons associated with a file format of the multimedia content.  In another embodiment, the visual indicators are numerical values.  In yet another embodiment, the visual indicator reveals previews of additional content for the\nmultimedia content in response to a hover command over the visual indicator.\nThe server, in step 318, stores the user input, categories, and association between the multimedia content and the categories or user-supplied tags in a database.  The database may store a user interaction log.  In one embodiment, the database\nstores a number of multimedia content associated with the at least two categories, and a number of multimedia content associated with each group having the user-supplied tags.  The database may also store an amount of time that occurs between each input\nevent received from the user.  This database may also store a number of revisions made to user-supplied tags or a number of move, combine, add, or delete inputs received for each of the at least two categories.\nIn step 320, the server determines whether uncategorized multimedia content still exist.  If uncategorized multimedia content exist, the server returns to step 314.  If uncategorized multimedia content does not exist, the server continues to\nstep 322.  The method terminates in step 322.\nAccordingly, the server provides a structure for hierarchically organizing and grouping multimedia content based on categories or user-supplied tags.  The structured graphical user interface may provide improvements in label consistency by\nassisting labeler's to explicitly surface and recall their labeling decisions.  The structured graphical user interface provides the user-supplied tags that receive metadata to aid in organization and recall.  In turn, the structured graphical user\ninterface may provide automated summaries of group multimedia content, suggestions for altering groups, and interactive revisions to group categories and user-supplied tags (e.g., moving groups within a category, adding and deleting user-supplied tags,\nmerging and splitting user-supplied tags, adding or removing multimedia content within user-supplied tags, or revising user-supplied tags).\nIn additional embodiments of the invention, the structured graphical user interface may provide assistance during labeling.  The structured graphical user interface renders various visual aids and some automation to assist labelers.  For\ninstance, visual aids may include, among other things, providing category recommendations (to improve label consistency or to reduce effort in tagging), providing tagging recommendations (to reduce effort in tagging), summarizing items within a\nuser-supplied tags (to aid in recall of group contents), and rendering similar items or the number of similar items to the item being organized (to aid in structuring decisions).\nFIG. 4 is another logic diagram illustrating a computer-implemented method 400 of generating a structured labeling graphical user interface label acquisition, in accordance with embodiments of the invention.  The method initializes in step 410\nwhen loaded into memory by the server.  In step 412, the server generates a graphical user interface with at least two portions.  The first portion displays multimedia content.  The second portion assigns the multimedia content to at least two\ncategories.  The server, in certain embodiments, may generate a third portion of the graphical user interface having uncategorized multimedia content that are similar to each other.  The server may determine similarity based on term frequency within the\nmultimedia content.\nThe server, in step 414, receives user input for associating multimedia content displayed in the first portion with at least one of two categories in the second portion of the graphical user interface.  In some embodiments, the multimedia\ncontent is associated with at least one group of the at least two categories.  In one embodiment, the user input is a gesture.  In another embodiment, the user input is a voice command.\nIn turn, the server may, in step 416, generate assistance for the labeler.  The assistance may include summaries.  The summaries may correspond to multimedia content associated with the at least two categories.  The summaries generated by the\nserver may be based on multimedia content associated with at least one group within one of the at least two categories.  Alternatively, the server may generate summaries for multimedia content associated with user-supplied tags that correspond to groups\nwithin each of the at least two categories.  These generated summaries may be rendered in a visual representation of the user-supplied tags, in some embodiments of the invention.\nThe user-supplied tags may receive input that further describe a concept corresponding to the multimedia content grouped within one of the at least two categories or having the user-supplied tags.  The graphical user interface is updated to\nreflect, among other things, the association between the selected one of the at least two categories and the multimedia content.\nIn step 420, the server determines whether uncategorized multimedia content exist.  If uncategorized multimedia content exist, the server returns to step 414.  If uncategorized multimedia content does not exist, the server continues to step 422. The method terminates in step 422.\nThus, the graphical user interface is updated to provide assistance via visual aids.  These visual aids may include, among other things, providing category recommendations, providing tagging recommendations, summarizing multimedia content within\na group of multimedia content having the user-supplied tags, and rendering similar multimedia content or the number of similar multimedia content to the multimedia content being organized.\nIn one embodiment, the structured labeling graphical user interface may include several portions.  For instance, an exemplary structured labeling graphical user interface may be configured with a prompt portion, multimedia content portion, and\ncategory portion.  The structured labeling graphical user interface may provide assistance to the user when the associated multimedia content rendered in the multimedia content portion is assigned to categories or groups of multimedia content having\nuser-supplied tags rendered in the category portion.\nFIG. 5 is a screen shot illustrating an exemplary graphical user 500 for structured labeling in accordance with embodiments of the invention.  The structured labeling graphical user interface 500 may include a prompt portion 510, multimedia\ncontent portion 515, and category portion 520, 530, or 540.\nThe prompt portion 510 may provide a prompt for a concept under consideration by the labeler.  For instance, the prompt may be about \"COOKING.\" In turn, the labeler may review multimedia content and assign the multimedia content to at least one\ncategory.  The prompt portion 510 may be updated with a new concept after all the multimedia content is classified.\nThe multimedia content portion 515 may render the multimedia content.  In one embodiment, the multimedia content is rendered individually (e.g. \"one at a time\").  The labeler may decide to associate the multimedia content with at least one\ncategory 520, 530, or 540.  The category 520, 530, or 540 may be predefined in an embodiment.  In other embodiments, the category is alterable and may be selected based on user input.\nThe category portion 520, 530, or 540, in an embodiment, provides three categories: \"YES\" 520, \"COULD BE\" 530, and \"NO\" 540.  The categories may each have user-supplied tags.  For instance, category 520 may have two user-supplied tags (e.g.\n\"SOFTWARE\" 521 and RECIPE LINKS 522).  Category 530 may have two user-supplied tags of which one is blank (e.g. NULL 531 and CAETERING 532).  Category 540 may have zero user-supplied tags.  The multimedia content may be associated with the categories\n520, 530, or 540 or the groups having the user-supplied tags 521, 522, 531, 532.\nIn another embodiment, the structured labeling graphical user interface may include several visual indictors that provide assistance to the labeler.  For instance, an exemplary structured labeling graphical user interface may be configured with\na similar window visual indicator, summary visual indicator, and suggestion visual indicator.  The visual indicators of the structured labeling graphical user may provide additional assistance to the user when associating multimedia content rendered in\nthe multimedia content portion with categories or with groups having the user-supplied tags of the category portion.\nFIG. 6 is a screen shot illustrating another exemplary graphical user 600 for assisted structured labeling in accordance with embodiments of the invention.  The structured labeling graphical user interface 600 may provide visual indicators that\ninclude a similarity window visual indicator 610, a suggestion visual indicator 620, and a summaries visual indicator 630.\nThe similarity window visual indicator 610 may display multimedia content that is similar to the multimedia content that is currently being categorized.  In some embodiments, the similarity window visual indicator 610 may include thumbnails of\nthe multimedia content that is currently being categorized and other multimedia content that is similar to it.  In one embodiment, the other multimedia content that is identified as similar consist of uncategorized multimedia content.\nThe suggestion visual indicator 620 may provide a recommendation of which category to associate the currently being categorized multimedia content.  The suggestion visual indicator 620 may include, among other things, a star.  In other\nembodiments, the suggestion visual indicator 620 may be an animation that shows the multimedia content transitioning from the multimedia content portion of the graphical user interface 600 to the appropriate location in the category portion of the\ngraphical user interface 600.\nThe summaries visual indicator 630 may include at least one or more terms that are generated to summarize multimedia content associated with the groups of multimedia content having user-supplied tags or the categories.  The summaries visual\nindicator 630 may be highlighted in the graphical user interface.  The highlighting may include font formatting (e.g., bold, italics, or color) or font animation (e.g. blinking, growing, shirking, etc.)\nAccordingly, these visual indicators rendered in the structured labeling graphical user interface are provided to improve user performance while labeling multimedia content.  The structured labeling graphical user interface updates the visual\nindicators as the user associates multimedia content with the categories of groups having user-supplied tags.  The server logs the interaction of the user with structured labeling graphical use interface to determine whether user performance is improved\nwith the use of the visual aids.\nIn at least one embodiment, the structured labeling graphical user interface may render statistics associated with the multimedia content.  For instance, the statistics may include the number of multimedia content associated each of the\ncategories or the groups with the user-supplied tags.  The statistics may be visualized as a number or an icon representing the multimedia content.\nFIG. 7 is a screen shot illustrating an exemplary user-supplied tag 710 and 720 with visual representations for associated multimedia content in accordance with embodiments of the invention.  The structured labeling graphical user interface may\nhave a portion 700 for displaying statistics.  The statistics may be rendered in the user-supplied tags 710 or 720 or categories.  The statistics may include a numerical summary of the number of multimedia content associated with the group having the\nuser-supplied tags 710 or 720.  For instance, user-supplied tag 710 is associated with a group of 12 multimedia content and user-supplied tag 720 is associated with a group of 11 multimedia content.  The statistics, in certain embodiments, may be\nrendered as icons representing each multimedia content.  The icons may include squares or a graphic representing the file type associated with each of the multimedia content associated with the user-supplied tag or categories.\nAdditional information about the structured labeling graphical user interface may be found in the paper published by the inventors.  Kulesza et. al., \"Structured Labeling to Facilitate Concept Evolution in Machine Learning\" CHI 2014 Association\nfor Computing Machine, which is hereby incorporated by reference in its entirety.\nWith the benefit of the structured labeling graphical user interface a user may structure subcomponents of a concept in an open-ended manner.  For instance, a user could structure the concept \"AUTOS\" into subcomponents like \"CARS,\" \"TRUCKS,\"\n\"ADVERTISEMENTS,\" \"REVIEWS,\" etc. Regardless of the subcomponent defined by the user, the structured labeling graphical user interface provides assistance to ensure that the user consistently organizes items into the defined subcomponents.\nIn summary, embodiments of the invention provide for automated or semi-automated grouping of data (to reduce user effort and errors).  A server may generate structured labeling graphical user interfaces to assist labelers as they assign labels\nto multimedia content.  The structured labeling graphical user interfaces may facilitate concept evolution.  The server may provide a prompt for a concept in a graphical user interface.  The graphical user interface may include at least two categories\nfor the prompt and one or more user-supplied tags for groups of multimedia content within each of the two categories.  The server, in turn, renders multimedia content for display to a user in a portion of the graphical user interface.  The server may\nreceive user input in the at least two categories or groups corresponding to the user-supplied tags.  The server may associate the multimedia content with the at least two categories and the user-supplied tags.\nIn at least one embodiment, a database associated with the server may store log data that includes, among other things, user input, categories, and association between the multimedia content and the categories.  The database provides a mechanism\nfor labelers to gather statistics about the labeling tasks, speed or number of multimedia content associated with each label.  The database may also allow labelers to share structured labeling data for multimedia content.  The labelers may share the\nstructured labeling data as concept definitions to other users: These definitions may be used as guidelines for other labelers (e.g., as guidelines that teach by showing examples).  In alternate embodiments, sharing structured labeling data may enable\nmultiple users to collectively define concepts and associate the multimedia content with the concepts.  The database may provide corporate memory (i.e., allowing new users to continue labeling--assigning multimedia content to categories--where previous\nusers left off).\nThe embodiments of the invention have been described in relation to particular embodiments, which are intended in all respects to be illustrative rather than restrictive.  Alternative embodiments will become apparent to those of ordinary skill\nin the art to which the embodiments of invention pertains without departing from its scope.  From the foregoing, it will be seen that this invention is one well adapted to attain all the ends and objects set forth above, together with other advantages\nwhich are obvious and inherent to the system and method.  It will be understood that certain features and subcombinations are of utility and may be employed without reference to other features and subcombinations.  This is contemplated by and is within\nthe scope of the claims.", "application_number": "14176990", "abstract": " A system, method, and media are provided for generating a structured\n     labeling graphical user interface. The user interface receives user input\n     that associates multimedia content with categories. The user input may\n     include user-supplied tags that further define the category for the\n     multimedia content. The user-supplied tags are rendered proximate to the\n     categories. In turn, a database logs user events to store, among other\n     things, the categories, the user-supplied tags, time associated with\n     completing the user-supplied tags, and time for associating multimedia\n     content with the categories or tags.\n", "citations": ["5239596", "5418942", "6266649", "6581068", "6847972", "6940509", "7062561", "7421441", "7725414", "7793212", "8001003", "8086549", "8126912", "8190604", "8201073", "8370357", "8433993", "8566329", "8732175", "8819024", "8909950", "8996350", "9471671", "20020069192", "20030033370", "20030050805", "20030050923", "20030060284", "20030206203", "20030210278", "20030212585", "20030217335", "20030227487", "20040111432", "20040125405", "20040205482", "20050010589", "20050097008", "20050216457", "20050256866", "20050289163", "20060041548", "20060173985", "20060242554", "20060282776", "20070038938", "20070055655", "20070067293", "20070083894", "20070118802", "20070127834", "20070136267", "20070219945", "20070255742", "20080034329", "20080082298", "20080082941", "20080086484", "20080086755", "20080120501", "20080172413", "20080189336", "20080201314", "20080228928", "20080235289", "20080281764", "20080281810", "20080288596", "20090006335", "20090132459", "20090193096", "20090217149", "20090222551", "20090240674", "20090240683", "20090240692", "20090265631", "20090319518", "20090327243", "20100125576", "20100169243", "20100191582", "20100274667", "20100318846", "20110010364", "20110061068", "20110131299", "20110161814", "20110173141", "20110225162", "20110238495", "20110302163", "20120030161", "20120066233", "20120158638", "20120158935", "20120210247", "20120233567", "20120254804", "20120272171", "20120287152", "20120303637", "20130060785", "20130066864", "20130097172", "20130124963", "20130151940", "20130198609", "20130212060", "20130311485", "20130339362", "20130342566", "20140006930", "20140031086", "20140040232", "20140082525", "20140164507"], "related": []}, {"id": "20150256517", "patent_code": "10362001", "patent_name": "Method and apparatus for providing secure communications based on trust\n     evaluations in a distributed manner", "year": "2019", "inventor_and_country_data": " Inventors: \nYan; Zheng (Espoo, FI)  ", "description": "<BR><BR>RELATED APPLICATION\nThis application was originally filed as Patent Cooperation Treaty Application No. PCT/CN2012/083081 filed Oct.  17, 2012.\n<BR><BR>FIELD OF THE INVENTION\nThe present invention generally relates to communications.  More specifically, the invention relates to providing secure communications based on trust evaluations in a distributed manner, for example in a pervasive social networking.\n<BR><BR>BACKGROUND\nThe modern communications era has brought about a tremendous expansion of communication networks.  Communication service providers (e.g., wireless, cellular, internet, etc.) and device manufacturers are continually challenged to deliver value\nand convenience to consumers by, for example, providing compelling network services, applications and contents.  One area of interest has been the development of social networking services and other services for making connections and communicating data,\ncontents or resources among users.  One exemplary service is that user equipments such as personal mobile devices (e.g., smart phones) can be self-organized and communicate with each other for social activities, for example by forming a multi-hop radio\nnetwork, and maintaining connectivity in a decentralized manner.  Such kind of social networking based on mobile devices that supports instant and pervasive social activities can be called as pervasive social networking (PSN).\nIt is crucial to ensure the security of the communication, for example to avoid malicious eavesdropping.  However, it is difficult to provide a secure communication in a distributed manner, in which situations there is no centralized server, for\nexample in a distributed communication network.  Moreover, in some situations (e.g., disasters, military activities), it is hard to connect to a centralized server.  Thus, a secure communication and access control solution based on a traditional\ncentralized server may not be applicable for the distributed communication in some situations.  Thus, service providers and device manufacturers face significant technical challenges to provide secure communications in a distributed manner.\n<BR><BR>SOME EXAMPLE EMBODIMENTS\nTo overcome limitations in the prior art described above, and to overcome other limitations that will be apparent upon reading and understanding the present specification, the disclosure provides an approach for providing a secure communication\nbased on trust evaluations in a distributed manner (i.e. without any support of a centralized server).\nAccording to one embodiment, a method comprises sending data to a plurality of devices, the data being encrypted with a communication key.  The method further comprises encrypting the communication key with public attribute keys associated with\nattributes, for example according to an attribute-based encryption (ABE) scheme, wherein the attributes comprising at least one trust level related attribute representing an access condition for the data based on a trust level.  The method further\ncomprises evaluating a trust level of each device of the plurality of devices, to identify eligible devices of the plurality of devices whose trust levels satisfy the access condition.  The method further comprises sending the encrypted communication key\nto the plurality of devices; and sending secret attribute keys associated with the attributes to each device of the eligible devices for decrypting the encrypted communication key, the secret attribute keys being personalized for the each device of the\neligible devices.\nIn an exemplary embodiment, the method can further comprise re-evaluating the trust level of the eligible devices after sending the secret attribute keys to re-identify eligible devices whose re-evaluated trust levels satisfy the access\ncondition; and when a device of the eligible devices becomes ineligible, updating the communication key to a new communication key, and sending the new communication key encrypted with the public attribute keys to the re-identified eligible devices.\nIn an exemplary embodiment, the method can further comprise setting the access condition for the data.\nIn an exemplary embodiment, the method can further comprise informing an access policy of the data to the eligible devices, wherein the access policy indicates a corresponding access condition to be used for a particular access context, wherein\nthe secret attribute keys can be generated based on the identity of the each device of the eligible devices and the at least one trust level related attribute representing the corresponding access condition indicated by the access policy.\nIn an exemplary embodiment, the method can further comprise using the communication key to decrypt data received from some devices.\nIn some exemplary embodiments, the sending of at least one of the encrypted communication key and the secret attribute keys can be performed in response to a request from at least one device of the plurality of devices.  In some exemplary\nembodiments, the trust level related attribute can indicate a pre-determined threshold of trust level, and a device whose trust level meets the pre-determined threshold of trust level can be identified as an eligible device.  In some exemplary\nembodiments, the trust level of the each device of the plurality of devices can be evaluated based on social networking activities related to the each device.\nIn some exemplary embodiments, the communication key is a symmetric key.\nIn some exemplary embodiments, the encrypted data are broadcasted or multicast to the plurality of devices.  In some exemplary embodiments, the encrypted communication key is multicast to the eligible devices together with the secret attribute\nkeys.\nAccording to another embodiment, an apparatus comprising at least one processor, and at least one memory including computer program code, the at least one memory and the computer program code configured to, with the at least one processor,\ncause, at least in part, the apparatus to send data to a plurality of devices, the data being encrypted with a communication key.  The apparatus is further caused to encrypt the communication key with public attribute keys associated with attributes,\ne.g., according to an attribute-based encryption (ABE) scheme.  The attributes can comprise at least one trust level related attribute representing an access condition for the data based on a trust level.  The apparatus is further caused to evaluate a\ntrust level of each device of the plurality of devices, to identify eligible devices of the plurality of devices whose trust levels satisfy the access condition.  The apparatus is further caused to send the encrypted communication key to the plurality of\ndevices.  The apparatus is further caused to send secret attribute keys associated with the attributes to each device of the eligible devices for decrypt the encrypted communication key, wherein the secret attribute keys being personalized for the each\ndevice of the eligible devices.\nAccording to another embodiment, a computer-readable storage medium carrying one or more sequences of one or more instructions which, when executed by one or more processors, cause, at least in part, an apparatus to send data to a plurality of\ndevices, the data being encrypted with a communication key.  The apparatus is further caused to encrypt the communication key with public attribute keys associated with attributes, e.g., according to an attribute-based encryption (ABE) scheme.  The\nattributes can comprise at least one trust level related attribute representing an access condition for the data based on a trust level.  The apparatus is further caused to evaluate a trust level of each device of the plurality of devices, to identify\neligible devices of the plurality of devices whose trust levels satisfy the access condition.  The apparatus is further caused to send the encrypted communication key to the plurality of devices.  The apparatus is further caused to send secret attribute\nkeys associated with the attributes to each device of the eligible devices for decrypting the encrypted communication key, wherein the secret attribute keys being personalized for the each device of the eligible devices.\nAccording to another embodiment, an apparatus comprises means for sending data to a plurality of devices, the data being encrypted with a communication key.  The apparatus also comprises means for encrypting the communication key with public\nattribute keys associated with attributes, e.g., according to an attribute-based encryption (ABE) scheme, wherein the attributes comprising at least one trust level related attribute representing an access condition for the data based on a trust level. \nThe apparatus also comprises means for evaluating a trust level of each device of the plurality of devices, to identify eligible devices of the plurality of devices whose trust levels satisfy the access condition.  The apparatus also comprises means for\nsending the encrypted communication key to the plurality of devices; and means for sending secret attribute keys associated with the attributes to each device of the eligible devices for decrypting the encrypted communication key, the secret attribute\nkeys being personalized for the each device of the eligible devices.\nThrough various embodiments, communications can be controlled automatically in a secure and efficient way.  Meanwhile, each communication device can control its data communications with a personalized access policy.  In this regard, a local\ntrust level can be used to control access of data in the communications based on distributed trust evaluation.  Any device can select other devices with, for example at least a minimum level of local trust, for secure communications.  On the other hand,\nthe devices with a lower trust level cannot access its communication data.  The secure communications can be provided in a flexible way based on a distributed trust evaluation by issuing a communication key using a trust controlled attribute-based\nencryption.\nStill other aspects, features, and advantages of the invention are readily apparent from the following detailed description, simply by illustrating a number of particular embodiments and implementations, including the best mode contemplated for\ncarrying out the invention.  The invention is also capable of other and different embodiments, and its several details can be modified in various obvious respects, all without departing from the spirit and scope of the invention.  Accordingly, the\ndrawings and description are to be regarded as illustrative in nature, and not as restrictive. <BR><BR>BRIEF DESCRIPTION OF THE DRAWINGS\nThe embodiments of the invention are illustrated by way of example, and not by way of limitation, in the figures of the accompanying drawings:\nFIG. 1 is a diagram of a system capable of providing secure a communication based on trust evaluations in a distributed manner according to an embodiment;\nFIG. 2 is a diagram of the components of user equipment capable of providing a secure communication based on trust evaluations in a distributed manner, according to one embodiment\nFIG. 3 is a flowchart of a overall system process for providing a secure communication based on trust evaluations in a distributed manner according to an embodiment;\nFIG. 4 is a flowchart of a process for providing a secure communication based on trust evaluations in a distributed manner, according to one embodiment; and\nFIG. 5 is a simplified block diagram of various devices that are suitable for use in practicing various exemplary embodiments of the present invention.\n<BR><BR>DESCRIPTION OF SOME EMBODIMENTS\nExamples of a method, apparatus, and computer program for providing secure communications based on a trust level in a distributed manner are disclosed.  In the following description, for the purposes of explanation, numerous specific details are\nset forth in order to provide a thorough understanding of the embodiments of the invention.  It is apparent, however, to one skilled in the art that the embodiments of the invention may be practiced without these specific details or with an equivalent\narrangement.  In other instances, well-known structures and devices are shown in block diagram form in order to avoid unnecessarily obscuring the embodiments of the invention.  Like reference numerals refer to like elements throughout.  The terms \"data\",\n\"content\", \"information\", and similar terms may be used interchangeably, according to some example embodiments of the present invention, to refer to data capable of being transmitted, received, operated on, and/or stored.\nVarious exemplary embodiments of the present invention are directed to the generation, distributing, and utilization of security keys in a distributed manner for providing a secure communication.  The communication may be implemented in, for\nexample, a pervasive social networking (PSN), in which personal mobile devices (e.g., smart phones) can be self-organized and communicate with each other for social activities by forming a multi-hop radio network and maintaining connectivity in a\ndecentralized manner.  For example, a user may want to query people in vicinity using his/her mobile device about which shop is on sale, which movie is recommended to see, or which mobile application should be installed for tagging the locations of\nphotos.  Then, some people in vicinity may respond these queries by providing their recommendations via the PSN.  In another example, users may also chat with people nearby via the PSN with regard to sharing a taxi ride, or sharing the cost of a series\nof movie tickets, or the like.  Moreover, they may seek services or aids from strangers in vicinity through the PSN.  In another example, people who are strangers but regularly in the same public places may want to make an instant appointment for a\nface-to-face meeting.  This kind of social networking is very valuable for the mobile users, especially when fixed networks (e.g., Internet) or cellular networks are temporarily unavailable or costly to access.\nThe communication networks such as mobile ad hoc network (MANET), Bluetooth network, Wireless Local Area Network (WLAN), cellular network, and the like has a good prospect of becoming a practical platform for such distributed communications. \nFor example, nowadays, a mobile ad hoc network (MANET) has become a practical platform for pervasive social networking and computing, playing as a valuable extension and complement of traditional Internet social networks.  Several research groups in the\nacademia have focused on social activities based on the mobile ad hoc network (MANET).  For example, Stanford MobiSocial Group has developed Junction, which is a mobile ad hoc and multiparty platform for MANET applications (which can be retrieved from\nhttp://openjunction.org/).  SyNRG in Duke University has developed Micro-blog (which can be retrieved from http://synrg.ee.duke.edu/microblog.html), which can help users to post micro-blogs tagged by locations.  ETHz Systems Group has introduced AdSocial\n(which can be retrieved from http://www.iks.inf.ethz.ch/publications/files/mobicom08_demo.pdf), which can provide a pervasive social communication platform.  Floating content concept was analyzed based on a theoretical framework to study the fundamental\nquantities of an ephemeral content sharing service in opportunistic networking, such as a node encounter rate, mean contact times as a function of location, achievable transmission rates and transmission ranges.  In a proposed floating content system,\ncontent is only shared within an anchor zone in a best-effort manner, i.e., copies are kept available within that zone while they are deleted outside the anchor zone.\nIn industry, quite a number of companies, such as Microsoft, Nokia and Intel have conducted researches in the area of PSN.  For example, Microsoft Research Asia developed an EZSetup system in order to make a mobile user find services provided by\nhis/her neighbors (retrieved from http://research.microsoft.com/en-us/groups/wn/mssn.aspx).  The Nokia Instant Community (NIC) (https://lausanne.nokiaresearch.com/nic/) developed by the Nokia Research Center provides an instant social networking platform\nto allow people in vicinity to communicate, get to know, and share information and data with each other.  Similarly, the Intel Berkeley Lab ran a project named Familiar Stranger based on mobile devices to extend our feelings and relationships with\nstrangers that we regularly observe but do not interact with in public places (which can be retrieved from http://www.paulos.net/research/intel/familiarstranger/index.htm).  However, none of them pursue how to make use of the trust established in social\nnetworking for providing a secure communication in a distributed manner.\nTrust plays an important role in the pervasive social networking, such as for reciprocal activities among nearby strangers.  It helps people overcome perceptions of uncertainty and risk and engages in \"trust-related behaviors\".  During the\ninstant social activities, users are not necessarily acquaintances but more likely to be strangers.  Therefore, the users need to balance between the benefits received in such reciprocal activities and the risks related to communications with strangers. \nIn this context, it is important to figure out how much users should trust with each other in order to make decisions.  Herein, a trust level can be used as a measure to assess the level of belief and dependence that one entity (such as a user, a mobile\ndevice, a communication node, and the like) put into another entity.  The trust level can be derived from direct or indirect knowledge/experience on earlier interactions of entities.\nFor communications in PSN, especially crucial communications, it is important to set up a secure communication channel among trustworthy users in order to avoid malicious eavesdropping.  In the previous work, some centralized solutions are\nproposed to control data access for a secure communication based on general trust levels generated by a centralized trusted server, and some hybrid solutions are proposed to control data access for secure communications based on general trust level\nand/or local trust level.  However, these centralized and hybrid solutions may be not suitable for providing a secure communication in a distributed manner, such as in PSN, because they rely on a centralized trusted server to generate and to issue data\naccess keys.  Thus they may be not able to support the situations that the centralized trusted server is not available or trusted at all.  For example, in the case of an urgent disaster and military activities, these centralized and hybrid solutions may\nbe impractical due to unavailability of a centralized trusted server.  Another weakness of these solutions is that the server may be the target of Denial of Service (DoS)/Distributed DoS (DDoS) attacks or other kinds of attack.  Once the server is broken\nor down, the reliability of the whole system could be greatly influenced.  Although it is possible to setup a backup server, the connection availability would still be a problem in some practical situations.  In practice, a fully trusted server is hard\nto achieve, the internal attackers inside the server may intrude the system.  Meanwhile, communications between communication nodes and a centralized server would introduce extra cost.\nFurthermore, due to the dynamic characteristic of a PSN topology and the frequent changes of each user's trust level, for securing PSN communications, the decryption key need to be frequently changed and distributed to each eligible user.  This\nintroduces a heavy traffic and processing load, which may cause a serious performance bottleneck.\nNowadays, trust, security and privacy aspects in pervasive social networking have not been seriously considered in most existing work in industry.  For example, the traditional centralized social networking systems (e.g., facebook) have not\ntaken user privacy and security into concern.  They cannot satisfy instant social networking demands, especially when users do not have an internet connection, but with a location proximity.  As such, issues on a trust management for security assurance\nand privacy enhancement need to be serious researched, in order to deploy a practical pervasive social networking system that can be easily accepted by mobile users.  A number of crucial issues with regard to trust, security and privacy should be solved\ntowards a trustworthy pervasive social networking.  However, most existing work don't consider how to control data access of secure communications based on trust, especially in instant and distributed social networking scenarios.\nGenerally, an access control of communication data applies data encryptions, so that the encrypted data can only be decrypted by users with permissions.  The ideal approach is to encrypt each data once, and distribute appropriate keys to users\nonce, so that each user can only decrypt his authorized data.  Previous work seldom controlled access to communication data based on the level of trust although trust is a crucial factor that should be considered in the process of authorizing data\naccess.  As mentioned already, in PSN, due to the frequently user changes and trust level changes, the decryption key needs to be frequently changed in order to achieve expected security level.  As such, a pure symmetric key based encryption is not\nsuitable for a PSN scenario, because the key is hard to be managed in a distributed way.  It is complicated to control an access of communications data based on a trust level and other policies.  Meanwhile, a public key based encryption is also not\nsuitable for the PSN scenario, especially community-based instant social activities, when a number of users join together for communicating.  This is because this encryption scheme is not efficient for multicasting/broadcasting data to a group of users. \nData should be encrypted by the data owner for each target receiver.\nThere is another difficulty faced by the control of the security of a social communication regarding a user revocation.  The user revocation means that the data owner withdraws access rights from users, for example, who no longer belong to a\ngroup or due to other reasons, e.g., the user is not trustworthy enough.  Since the revoked users still retain the decryption keys issued earlier, and thus can still decrypt the encrypted data.  As such, the data owner may need to encrypt its data with\nnew keys, so that the revoked users cannot decrypt the recent data any more using their old keys, and redistribute the new keys to the remaining authorized users, so that they can still access the data.  Obviously, the key re-generation and management\nwill introduce an extra computing load and make the system complicated.\nAccording to various exemplary embodiments, an efficient and secure communication can be provided based on a trust level in a distributed manner by applying an encryption theory for encrypting and decrypting based on attributes, for example,\naccording to an Attribute-based encryption (ABE) scheme.  The attribute-based encryption (ABE) is a newly developed cryptographic technique.  According to the ABE scheme, users are identified by a set of attributes rather than an exact identity.  Each\ndata is encrypted with an attribute-based access condition constructing an access policy of the data, such that only users whose attributes satisfy the access condition can decrypt the data.  For example, for data D, encrypted with the access condition\nA1 or A2, either users with attributes satisfying A1 or users with attributes satisfying A2, can decrypt D. Recently ABE is widely applied in secure data storage for cloud computing.  But none of existing work proposes providing secure communications\nbased on the trust level in a distributed manner, such as in pervasive social networking.\nIn various embodiments, a new approach is provided to securely access communication data in pervasive social networking purely based on trust levels which are locally evaluated by PSN nodes in a distributed manner (i.e. without any support of a\ncentralized server).  Based on the distributed trust evaluation, the various embodiments can support a secure communication in distributed manner by issuing a data encryption key using a trust controlled attribute-based encryption.  In an exemplary\nembodiment, each node in a PSN can generate a key (hereinafter called as a communication key) for the data encryption of its communication with other nodes, so that only those eligible nodes (e.g. the users permitted to have a corresponding decryption\nkey) can decrypt the encrypted communication data.  For example, the communication key used for the communication of a user u can be denoted as S_u, and similarly the communication key used for the communication of a user u' can be denoted as S_u'. In\nsome exemplary embodiments, the communication key can be a symmetric key.  The communication data can be of any type, such as message, instant message, media content (e.g., images, video, audio, etc.), file, stream, and the like.  Meanwhile, each node in\na PSN can further generate an encryption public key, and secret keys personalized for each of other nodes, based on the locally evaluated trust level for encrypting and decrypting the communication key respectively.  Then, it issues the personalized\nsecret keys to those eligible nodes that satisfy the conditions for access of its communication data.  For example, a condition is that a locally evaluated trust level of an eligible node (e.g. trust level of a user of the eligible node) should be\ngreater than a threshold.  The communication key encrypted by the encryption public key can be broadcast/multicast to the other nodes, for example together with the communication data that are encrypted by the communication key.  Alternatively, the\nencrypted communication key can be multicast merely to the eligible nodes together with the personalized secret keys.  As such, the communication data can only be decrypted by the eligible nodes that are authorized to decrypt the encrypted communication\nkey.  Then, the malicious eavesdropping can be avoided for the communications between the node and the eligible nodes.\nIn case that some eligible nodes need to be revoked, for example when the local trust levels of these nodes have a big change and do not satisfy the conditions for access the communication data, the node can regenerate a new communication key\nand then encrypt the new communication key with the encryption public key.  Then, the communication data of the node will be encrypted with the new communication key.  Meanwhile, the newly encrypted communication key is multicast to the current eligible\nnodes, for example whose current trust levels are above a threshold.  As a result, the revoked nodes cannot access the communication data with their old communication keys and personalized secret keys any more.\nFIG. 1 is a diagram of a system capable of providing a secure communication based on trust evaluations in a distributed manner according to an embodiment.  As shown in FIG. 1, the system 100 comprises communication nodes 101 that can be\nself-organized and communicate with each other by forming a distributed communication network 103, for example a multi-hop radio network, and maintaining connectivity in a decentralized manner.  The communication nodes 101 can be any type of user\nequipment, network node, server, and other communication devices applicable to communication in a distributed communication.  For example, the communication nodes 101 can be user equipments, such as mobile terminal, fixed terminal, or portable terminal\nincluding a mobile handset, station, unit, device, multimedia computer, multimedia tablet, Internet node, communicator, desktop computer, laptop computer, Personal Digital Assistants (PDAs), or any combination thereof.  It is also contemplated that the\ncommunication nodes 101 can support any type of interface to the user (such as \"wearable\" circuitry, etc.).\nThe distributed communication system may be applied for pervasive social networking (PSN).  For example, several PSN nodes 101a-101x may be utilized to perform social networking activities for communicating with each other.  By way of example,\ncommunications of the PSN can be supported by one or more networking means such as MANET, Bluetooth, WLAN and the like.  It is contemplated that the proposed method also may be applied to any other suitable scenarios where a secure communication in a\ndistributed manner (without any support of a centralized service) may be needed.\nThe solutions according to the exemplary embodiments can provide a secure and flexible access control of PSN data, by using a local trust level based on distributed node trust evaluation.  In this regard, a local trust value means that the trust\nlevel is generated locally at each PSN node without any support of a centralized service.  For example, each PSN node (such as 101a, 101b, 101c, .  . . , 101x) can perform various social activities and networking with other PSN nodes, such as making a\nremote call to other PSN nodes, accessing internet to talk to other PSN nodes, sending short messages to other PSN nodes, and conducting instant social activities based on the communication network 103.  As such, each PSN node can evaluate the local\ntrust value of any of the other PSN nodes locally, for example based on the accumulated behavior data of the various social activities, and other local information.\nThere are various solutions for generating/evaluating a trust value/level of each node.  In an embodiment, the trust levels can be evaluated automatically by a PSN node (such as 101a, 101b, 101c, .  . . , 101x) based on mobile social networking\nactivities.  Alternatively or additionally, the trust levels can be entered by the user.  In an embodiment, a PSN node can evaluate the trust levels not only based on the mobile social networking activities accumulated by itself, but also based on\nrelated information obtained from other PSN nodes, such as trust levels evaluated by the other PSN nodes.  In some embodiments, a PSN node (e.g. 101x) may be configured to implement a trust evaluation algorithm, which may evaluate a trust level of\nanother PSN node (e.g. 101a), by using the identities of node 101x and the node 101a and the behavior data of various PSN activities of the PSN node 101a.  The identity of a PSN node can be unique to the particular PSN node, such as the telephone number\nof the user of the node, universal resource identifier, and the like.  In an embodiment, the trust level can be normalized into a range of (0, 1).  However, it is contemplated that the trust level needs not to be normalized, or can be normalized to any\nrange.\nBased on the local trust evaluation, each PSN node can set data communication control based on trust levels, contexts and other limitations, such as a time period, a group of eligible user identities, etc. In a certain example, the PSN node 101x\ncan set an access policy for the chat of taxi ride sharing as that, if the chat occurs in the office of the user of the PSN node 101x, an eligible PSN node's trust level should be greater than 4, while if the chat occurs in a street, an eligible PSN\nnode's trust level should be greater than 8.  It is contemplated that the access policy can be set in any ways, to satisfy various necessities of the PSN communications.  Based on the access policy, each PSN node can encrypt the communication key to be\nused for securing its communications, for example according to an ABE scheme by taking a trust level as an attribute of an access policy.  In the certain example, for ensuring their chatting being accessed by a number of trustworthy nodes, the\ncommunication of the chatting can be encrypted with a symmetric key by the PSN node 101x.  Meanwhile, the node 101x can send to the other nodes the encrypted symmetric key, which is encrypted according to an ABE scheme by taking a threshold of trust\nlevel as an attribute of an access condition.  Furthermore, the decryption keys for the symmetric key are issued only to the nodes having a sufficient trust level locally evaluated by the node 101x, e.g. a trust level greater than or equal to the\nthreshold of trust level.\nIn an exemplary embodiment, the PSN 101x may be configured to implement an initiation algorithm using an identity of the PSN node 101x to generate a public key (denoted as PK_u) of its user (denoted as u) and a secret key (denoted as SK_u) of\nits users.  For example, a public key and a secret key of a user u' of another PSN node can denoted as PK_u' and SK_u'. The PK_u, SK_u, (or PK_u', SK_u') can be generated during a system setup procedure of a PSN node.  As noted previously, the identity\nof the PSN node 101x can be a pseudonym of the node 101x, a telephone number of user u, a universal resource identifier of the user u or the node 101x, or the other kind of identity which is unique for the PSN node 101x, for example globally or in the\nPSN.  The binding of the keys SK_u and PK_u of a node to a unique identity of the node can facilitate the verification of the node's attributes.  In some exemplary embodiment, a PK_u can simply be the unique identity of the node or a part of the unique\nidentity.\nEvery node can maintain a PK_u and a SK_u. A PK_u of a node can be used by another node (e.g. a peer PSN node) to generate secret keys personalized for the node.  A SK_u of a node can be used by itself in the decryption operation related to the\nPK_u. For example, a public key PK_u' of a PSN node (e.g. 101a) can be used by its peer PSN node (e.g. 101x) to generate a secret attribute key personalized for the node 101a, and then a secret key SK_u' of the PSN node 101a can be used for the\ndecryption of a cipher-key (e.g. an encrypted communication key) in connection with the secret attribute keys personalized for the PSN node 101a.  The personalized secret attribute keys can be issued to the PSN node 101a by the peer PSN node 101x.  In\nthis regard, the peer node 101x may be configured to generate the secret attribute keys personalized for each eligible node u' by using its secret key SK_u, and the public key PK_u' of each eligible node.\nIn an exemplary embodiment, the personalized secret attribute keys can be issued to respective eligible nodes based on trust levels of the respective nodes.  Furthermore, a local trust level can also be utilized as an attribute to generate a\npublic attribute key, for representing an access condition for the communication data based on a trust level (e.g. a threshold of trust level).  For example, in a scenario, a PSN node would like to allow only other PSN nodes with local trust level over 4\nto access its communication data.  Then, the PSN node can encrypt its communication data with an access condition S1: lt&gt;=4, wherein lt is used to represent the local trust level evaluated by the node for the other nodes.\nAccording to an ABE scheme, each attribute is associated with an access condition, and an access policy is a set of access conditions, for example required for different communication contexts.  An access policy can be described in a Disjunctive\nNormal Form (DNF).  For example, an access policy (denoted as AA) in DNF can be written as:\n.times.  .di-elect cons..times.  ##EQU00001## where S.sub.j denotes the j-th access condition in an access policy, and n is the total number of S (n=1, 2, 3, .  . . ). A denotes an attribute that occurs in the j-th conjunction of AA.  S can be a\nset of attributes, and S1, S2, .  . . , Sn, are not pairwise disjoint.\nFor example, a threshold of local trust level 4 can be set as an attribute to indicate an access condition: lt&gt;=4, which means that only those nodes with a trust level greater or equal to 4 can access the communication data.  An access\ncondition S1 can comprise only one attribute (the local trust level).  It is contemplated that the access condition S1 can further comprise any other attributes regarding limitations to access of the communication data, such as valid time period, valid\nlocation, and the like.  An access policy can comprise one or more access conditions associated with different context.  For example, in the previous certain example about a PSN chatting for taxi ride sharing, the access policy can comprise another\naccess condition S2, which may limits that only those nodes with a trust level over or equal to 8 can access the communication data by an attribute: lt&gt;=8.\nIn order to control access to the communication data according to an access policy, public attribute keys associated respective attributes can be used to encrypt the communication key.  In an exemplary embodiment, a node may be configured to\nperform a local-trust-public-key-creation algorithm for using the attribute regarding a local trust level (also called a trust level related attribute, and denoted as LT) and its secret key of user SK_u to generate a public attribute key (denoted as\nPK_LT).  For example, the public attribute key can be generated whenever the PSN node 101x would like to control the access to its communication data (e.g. PSN chatting messages).  The local-trust-public-key-creation algorithm can check the access policy\nfor the communication data.  When there is a trust level related attribute, a public attribute key PK_LT can be generated based on LT.  When there is no such an attribute, there is no public attribute key of the attribute LT generated.  For example, the\noutput of the algorithm for PK_LT is NULL.\nThen, the PSN node 101x may be configured to perform a encryption key algorithm for using the public attribute keys (such as PK_LT) associated with attributes (such as LT) of an access condition indicated by the access policy, to encrypt the\ncommunication key.  In an example, the encryption key algorithm can take as input the communication key S_u, an access policy AA, and the public attribute key PK_LT corresponding to the trust level related attribute occurring in an access condition S\nindicated by the policy AA, and then output the encrypted communication key, a cipher-key CK.  In some exemplary embodiments, the encryption key algorithm may iterate over all j=1, .  . . , n, to generate for each conjunction Sj a random value R_j and\nconstructs CK_j corresponding to each Sj.  For example, the cipher-key CK can be obtained as a tuple CK:=&lt;CK_1, CK_2, .  . . , CK_n&gt;.  As such, the PSN node 101x can protect its PSN communication key S_u according to an ABE mechanism.  In some\nexemplary embodiments, the access policy AA can be set by the PSN node 101x, and informed to the other nodes (e.g. a PSN node 101a, 101b, 101c, .  . . ). In some exemplary embodiments, the access policy AA can be a default policy, which may be commonly\nknown by all nodes in the PSN.\nFurther, the PSN node 101x can protect its communication data with the PSN communication key S_u. In this regard, the PSN node 101x may be configured to perform a data encryption algorithm for using the PSN communication key S_u, an access\npolicy AA regarding the local trust level, and the communication data (such as PSN chatting messages, denoted as M) to generate the encrypted communication data, such as a ciphertext CT.\nIn some exemplary embodiments, to access the communication data of the PSN node 101x, the other nodes (such as the PSN nodes 101a, 101b, 101c, .  . . ) can request at least one of the encrypted communication key CK and the personalized secret\nattribute keys.  For example, the PSN node 101a may request the encrypted communication key CK and the secret attribute keys personalized for itself from the PSN node 101x.  The request may occur when the PSN node 101a decides to communicate with the PSN\nnode 101x, for example after receiving the encrypted communication data broadcasted from the PSN node 101x.  In some exemplary embodiment, the PSN node 101a can evaluate a local trust level of the PSN node 101x, in a similar way as discussed above with\nrespect to the PSN node 101x.  Then, the PSN node 101a can check whether the PSN node 101x is trustworthy to communicate with based on the evaluated local trust level.  In some other exemplary embodiments, at least one of the encrypted communication key\nand the personalized secret attribute keys can be issued by the PSN node 101x in an unsolicited manner.\nThen the encrypted communication key of the PSN node 101x can be decrypted by the PSN node 101a with the personalized secret attribute keys for the PSN node 101a.  Each of the secret attribute keys corresponds to respective public attribute\nkeys, and is personalized to each node.  To prevent collusion, each node will get a different secret attribute key that only itself can use.  For example, a secret attribute key of a trust level related attribute LT, issued for a use u' (e.g. of the PSN\nnode 101a) by a user u (e.g. of the PSN node 101x) can be denoted as SK_(LT,u,u').  As such, a node 101a can obtain a set of secret keys (i.e., the key SK_u' and all keys SK_(TL,u,u')), which can be called as its key ring.\nBefore issuing the encrypted communication key and the personalized secret attribute keys, a node can check whether the local trust level of the peer node with a public key PK_u' (and/or a unique ID u') can satisfy the access condition with\nregard to the trust level related attribute LT (e.g., LT&gt;=4).  When the trust level of the peer node satisfies the access condition, this peer node u' can be identified as an eligible node, and a personalized secret attribute key (such as SK_(LT, u,\nu')) corresponding to the attribute can be issued to the peer node.  In some exemplary embodiments, the PSN node 101x can be configured to perform a local-trust-secret-key-issue algorithm for using the attribute LT, an unique identity u' of a PSN node\n(e.g., PK_u'), and the secret key SK_u of the node 101x, to generate a secret attribute key SK_(LT,u,u') personalized for the node 101a, according an ABE scheme.  In an exemplary embodiment, SK_(TL,u,u') can be generated by the node 101x in response to a\nrequest from the node 101a.  In this regard, for example, when node 101a is eligible, the local-trust-secret-key-issue algorithm can generate a correct secret attribute key SK_(TL,u,u') corresponding to the attribute LT, otherwise the output of the\nalgorithm may be NULL.  In an exemplary embodiment, the personalized secret attribute keys SK_(TL,u,u') can be sent to the node 101a by the node 101x in a secure manner, for example by encrypting SK_(TL,u,u') with the public user key PK_u' of the node\n101a.\nWith these secret attribute keys, the node 101a can decrypt the encrypted communication key used by the node 101x for securing its communications.  In some exemplary embodiments, the node 101a can be configured to perform a decryption key\nalgorithm for using the cipher-key CK produced by the corresponding encryption key algorithm, a key ring SK_u' and SK_(LT,u,u') for the node 101a, and the access policy AA under which CK was encrypted, to generate the corresponding plain-key, i.e. the\ncommunication key.  When the attributes of a node 101a is sufficient to satisfy the access condition indicated by the access policy AA, a correct communication key can be obtained by the node 101a.  Otherwise, the encrypted communication key cannot be\ndecrypted.  For example, the output of the decryption key algorithm may be NULL.  This decryption of the encrypted communication key can be executed when an eligible node would like to access the communication data of a node.  For example, when the node\n101a receives a PSN chatting message from the node 101x, the node 101a can firstly checks the access policy AA of the encryption to determine which access condition is applied in the encryption of the encrypted communication key, and then conducts the\ncorresponding decryption with the key rings associated with the applied access condition.  As noted previously, in some exemplary embodiments, the access policy AA can be set by the node u, and informed to the other node u'. Alternatively, the access\npolicy AA can be a default policy which is commonly known by all nodes in the PSN including the nodes u and u'.\nWith the decrypted communication key, the node 101a can then access the encrypted communication data.  In some exemplary embodiments, the node 101a may be configured to perform a decryption algorithm for using the encrypted PSN communication\nmessage CT, the communication key S_u, and the access policy AA about the local trust, to obtain the plaintext M. As such, the node 101a can disclose the content of the communication data of the node 101x.\nFIG. 2 is a diagram of the components of user equipment capable of providing a secure communication based on trust evaluation in a distributed manner according to one embodiment.  It is contemplated that the functions of these components may be\ncombined in one or more components or performed by other components of equivalent functionality.  In this embodiment, the communication node 101 can includes a user behavior observer 201 to record social behaviors of nodes in the communication network, a\npervasive social networking module 211 to provide various social networking functionalities for a user of the node to do various pervasive social networking.\nThe communication node 101 can further include a trust evaluator 203 to evaluate the local trust level of other nodes based on their social behaviors.  As noted above, the trust evaluator 203 can evaluate trust levels locally.  In an exemplary\nembodiment, the results of the evaluation can be provided to the user of the node 101 via a user interface 209.\nIn addition, the communication node 101 can further include a node profile manager 205 to maintain various personal information of the node 101.  The node profile manager 205 can be further responsible for generating cryptography keys related to\na secure PSN communication, such as the communication key S_u, the public key PK_u and secret key SK_u, the public attribute key PK_LT and secret attribute key SK_LT discussed above.  The cryptography keys may be provided to the pervasive social\nnetworking module 211 to secure a PSN communication.\nAll data related to the above functional blocks in the node 101, such as records of the social behavior, the evaluated trust level, the cryptography keys related to secure PSN communications, and the like, can be stored in a trust dataset 207. \nFor example, the trust dataset may be settled in the node 101 or connected to the node 101.  In an exemplary embodiment, the data can be stored in a secure manner in the trust dataset 207.\nIn some exemplary embodiments, the user behavior observer 201 can collect social networking activities of other nodes via the pervasive social networking module 211.  The records of social networking activities can be utilized by the trust\nevaluator 203 to evaluate the local trust levels of other nodes.  In turn, the evaluated trust levels can be utilized by the node profile manager 205 to generate cryptography keys related to secure a PSN communication.  The node 101 may utilize the user\ninterface 209 to interact with users, and a pervasive social networking module 211 to interact with other nodes 101.  For example, the pervasive social networking module 211 may be utilized to communicate data with other nodes, issue and/or request a\ncommunication key S_u and personalized secret attribute keys SK_LT from the other nodes.\nIn certain embodiments, the pervasive social networking module 211 may includes a set of pervasive social networking applications which can be run on the node 101.  The pervasive social networking module 211 may further include multiple means of\ncommunication.  For example, the pervasive social networking module 211 may be able to communicate over SMS, internet protocol, instant messaging, voice sessions (e.g., over an internet protocol), or other types of communication.  In some examples, the\npervasive social networking module 211 can be used to transmit and receive information using protocols and methods associated with the user behavior observer 201 and the node profile manager 205.\nThe user interface 209 can include various means of communication.  For example, the user interface 209 can have outputs including a visual component (e.g., a screen), an audio component, a physical component (e.g., vibrations), and other means\nof communication.  User inputs can include a touch-screen interface, a scroll-and-click interface, a button interface, etc. In certain embodiments, the user interface 209 may additionally have a vocal user interface component.  As such, a text-to-speech\nmechanism may be utilized to provide textual information to the user.  Further, a speech-to-text mechanism may be utilized to receive vocal input and convert the vocal input into textual input.  Moreover, the user interface 209 may be utilized to present\ninformation and content associated with the trust evaluation, and receive inputs of a user associated with the trust evaluation.\nFIG. 3 is a flowchart of an overall system process for providing secure communications based on trust evaluations in a distributed manner according to an embodiment.  In an exemplary embodiment, when a node (such as the node 101x) in PSN wants\nto secure its data communication with the nearby nodes (such as 101a, 101b, 101c, .  . . ) based on its local trust evaluation, the node 101x can generate a symmetric communication key S_(u), and corresponding public attribute key PK_LT and personalized\nsecret attribute keys SK_LT based on the local trust level for encrypting and decrypting S_(u).  The node 101x can issue the personalized secret attribute keys SK_LT to those nodes that satisfy the decryption conditions.  The encrypted PSN data can be\nbroadcast to the nearby nodes.  Only those nodes that satisfy the access control policy (which can be called as eligible nodes) can decrypt the key and then decrypt the PSN data.  The detailed procedure is shown in FIG. 2 and described as below.\nIn an exemplary embodiment, the node 101x can evaluate (step 300) trust levels of other nodes (including the nodes 101a, 101b, 101c, .  . . ), for example based on pervasive social networking activities, behaviors and experiences.  This trust\nevaluation can be periodically executed, or triggered for example by bad experiences.  As noted previously, the trust evaluation is executed in a distributed manner, without any support of a centralized server.  In an exemplary embodiment, the trust\nlevels of the node 101a can be evaluated locally at the node 101x, by calling the trust evaluation algorithm as described above, by using the identities of node 101x and the node 101a and the behavior data of various PSN activities of the PSN node 101a.\nBased on the trust evaluation results, the node 101x can set (step 301) data access conditions for its data communication, such as a threshold of trust level, constituting an access policy.  In another embodiment, the access conditions can be\nset as default access conditions, and can be commonly known to all nodes in the PSN.\nTo secure the data communication, the node 101x can encrypt (step 302) its PSN data M with a symmetric communication key S_u, for example, by calling the encryption algorithm as discussed above which uses S_u, AA, and M as input and output the\nencrypted communication data CT.  Then, the node 101x can broadcast (step 303) its encrypted PSN data to the nearby nodes, such as 101a, 101b, 101c.  In some exemplary embodiments, the node 101x can generate a symmetric encryption key if needed.  For\nexample, when the trust levels of other nodes have reduced compared to a previous trust level evaluation, the node 101x can generate a symmetric communication key S_(u).  When the trust levels of other nodes do not changed, the node 101x can use the\ncommunication key which was generated previously.\nAt least one of the nearly nodes, e.g. the node 101a and 101b, may receive the PSN data from the node 101x, and decide to access the PSN data or communicate with the node 101x.  In an exemplary embodiment, the decision can be made by checking\nthe eligibility of the node 101x.  For example, the node 101a can evaluate and check a local trust level of the node 101x at step 304.  In an embodiment, the node 101a may be configured to implement a trust evaluation algorithm similar as described\nabove, for using the identities of the node 101a and node 101x and the behavior data of various PSN activities of the PSN node 101x to evaluate a trust level of the PSN node 101x.  Then, the node 101a and 101b can send requests (305) for the symmetric\ncommunication key S_(u) from the node 101x, respectively.  In some exemplary embodiment, the requests can carry the public user key and/or the unique identity of respective request nodes.\nThe node 101x can check (306) the local trust levels of the node 101a and 101b.  When they satisfies the access policy, and the node 101x can issue (307) to each of the eligible nodes an encrypted communication key and respective secret\nattribute keys personalized each of the eligible nodes.  For example, the encrypted communication key can be multicast to the eligible nodes, together with secret attribute keys.  In some exemplary embodiments, when the node 101x hasn't generated a\npublic encryption key and/or corresponding personalized secret attribute keys for these eligible nodes, the node 101x can generate proper keys for eligible nodes.  For example, the node 101x can call a local-trust public-key-creation algorithm for using\na trust level related attribute LT and its secret user key to generate the public attribute key, and call a local-trust-secret key-issue algorithm for using LT, the secret user key of the node 101x, and at least one of the identity and public user key of\nthe node 101a to generate personalized secret attribute keys for the node 101a, and for using LT, the secret user key of the node 101x, and at least one of the identity and public user key of the node 101b to generate personalized secret attribute keys\nfor the node 101b.  For example, the symmetric communication key can be encrypted by calling an encryption key algorithm which can use the communication key S_(u), access policy AA, and the public encryption key to get a CK.\nIn step 308, the eligible node 101a and 101b can decrypt the encrypted symmetric communication key with their personalized secret keys.  For example, the node 101a can call a decryption key algorithm for using the CK, the access policy AA, the\nsecret user key of the node 101a and the secret attribute key personalized for the node 101a to get the symmetric communication key.  In a similar way, the node 101b can call a decryption key algorithm for using the CK, the access policy AA, the secret\nuser key of the node 101b and the secret attribute key personalized for the node 101b to get the symmetric communication key.  Then, they can get plain PSN data by decrypting the symmetric communication key, for example via calling the decryption\nalgorithm described above.  In an exemplary embodiment, the eligible nodes can utilize the decrypted symmetric communication key for communicating with the node 101x.  In this regard, the eligible nodes can encrypt the PSN data sent from the eligible\nnodes to the node 101x by using the symmetric communication key.\nDue to the dynamic change of trust level, a previous eligible node (e.g. the node 101b) may become distrusted, after it got from the node 101x the personalized secret attribute keys.  In this situation, the node 101x won't allow the node 101b to\naccess the PSN data communication any more although the node 101x has already issued to the node 101b the secret attribute keys.  In this case, the node 101x will regenerate a new symmetric communication key and issue it to the current eligible nodes\nusing the attribute based encryption through multicast.  The later communication data sent from the node 101x will be then encrypted with the new symmetric communication key.  In an exemplary embodiment, the node 101x can re-evaluate the trust levels of\nthe nearby nodes to find the revoke nodes, whose re-evaluated trust level goes below the threshold, for example.\nWhile the above embodiments have been described in a context that the node 101x provides secure communication based trust levels, it should be appreciated that each node in the PSN can provide secure communications between itself and other nodes\nin parallel and in a similar manner with the node 101x.  Although many operations are described in a certain order with reference to FIG. 3, it should be appreciated that these operations can be performed in alternative orders, and some operations can be\nadjusted, combined, or even omitted.  For example, the encrypted communication key can be issued to eligible nodes separately from the personalized secret attribute keys.  In an example embodiment, the encrypted communication key can even be broadcast to\nall other nodes in an unsolicited manner, for example at the beginning of the PSN communication between the node 101x and its nearby nodes 101a-101c.  Furthermore, it should be appreciated that encryption and decryption for the communication key can be\nimplemented through any encryption theory for encrypting and decrypting based on attribute.  For example, the public attribute key (e.g. PK_LT) and secret attribute key (e.g. SK_LT) and the related algorithms, such as the a\nlocal-trust-public-key-creation algorithm, the encryption key algorithm, the local-trust-secret-key-issue algorithm, and the decryption key algorithm, can be implemented with an Attribute-Based Encryption (ABE) scheme, or an ABE-IBS (Attribute-Based\nEncryption with Identity-Based Signature) based encryption scheme, or other suitable encryption theory based on the attribute regarding local trust level.\nFIG. 4 is a flowchart of a process for providing secure communication based on a trust level in a distributed manner, according to one embodiment.  In such an embodiment, the process 400 is performed by one or more communication node (such as\nthe PSN node 101x), and is implemented in, for instance, a chip set including a processor and a memory as shown in FIG. 5.  As such, the communication node can provide means for accomplishing various parts of the process 400 as well as means for\naccomplishing other processes in conjunction with other components.  In one embodiment, a trust evaluator 203 can be used to locally evaluate trust levels based on social networking activities in the PSN.\nIn step 401, a communication device (such as the PSN node 101x) can communicate data with a plurality of communication devices (such as the PSN node 101a, 101b, 101c), and the data are encrypted with a communication key.  For example, the\ncommunication key can be maintained in the communication device, and/or generated by the communication device in response to the beginning of the communication or changes of a local trust evaluation.\nIn step 403, the communication device encrypts the communication key with public attribute keys (such as PK_LT,) associated with attributes, e.g. according to an ABE scheme.  The attributes can comprises at least one trust level related\nattribute (such as LT) representing an access condition for the communication data based on a trust level.  In one embodiment, the access condition can be set by the communication devices.\nIn step 405, the communication device can evaluate a trust level of each device of the plurality of devices, to identify eligible devices whose trust levels satisfy the access condition.  In some exemplary embodiments, the evaluation can be\nperformed in response to receive a request, for example for accessing the communication data.  In some exemplary embodiments, the evaluation can be performed automatically.  Based on the evaluated trust level, the communication device can identify\neligible devices of the plurality of devices whose trust levels satisfy the access condition.  For example, the communication device can check whether the trust level of a device is greater or equal to a predetermined threshold.  When the trust level of\na device meets (e.g. greater or equal to) the threshold, it can be determined that the device is eligible.  Otherwise, the device is ineligible.\nNext in step 407, the communication device issues the encrypted communication key (such as CK) to the eligible devices.  Furthermore, the communication device issues secret attribute keys (such as SK_LT) associated with the attributes to each\ndevice of the eligible devices, wherein the secret attribute keys are personalized for the each device of the eligible devices.  Then, the eligible devices can decrypt the encrypted communication key by using their respective personal secret attribute\nkeys, and then decrypt the encrypted communication data with the decrypted communication key.  In some exemplary embodiment, the encrypted communication key and the secret attribute keys are multicast to the eligible devices in response to a request from\nthe eligible devices.\nIn some exemplary embodiments, the communication device can inform an access policy of the communication data to the plurality device, wherein the access policy indicates a corresponding access condition used for a particular access context. \nThen, the secret attribute keys can be generated based on the identity of each eligible device and the at least one trust level related attribute TL representing the corresponding access condition indicated by the access policy.\nAs such, it is flexible for the communication devices to control a data communication, no matter if there is a centralized server to manage cryptography keys or not.  This is because that the corresponding cryptography keys can be managed by\neach node locally, and then the data communication can be secured in a distributed manner.  Meanwhile, no matter what new device joining the communication or old device leaving the communication, each communication device only need to generate one public\nattribute key, and generate secret attribute keys for another particular communication device for one time.  Meanwhile, whether issuing the personalized secret attribute keys for getting the communication key or not can be controlled by the local trust\nevaluation.\nIn various embodiments, the secure communication is provided in a distributed manner.  In this regard, the trust can be evaluated and managed in a distributed manner to support a distributed access control demand, for example in a pervasive\nsocial networking.  Furthermore, personal access policies can be handled by each individual device.  Each communication device can set its own data access policy and manage the corresponding keys by itself.\nThrough various embodiments, the security of the communication can be ensured by the attributed-based encryption theory and the symmetric key encryption theory.  In some exemplary embodiments, the security can be further ensured by fine-grained\nencryption mechanism controlled by the frequency of trust evaluation at each communication node device.  The symmetric key can be regenerated and issued to current eligible node devices if needed, for example when the trust levels of some devices are\nchanged to unmeet the threshold.  Meanwhile, since the trust management is distributed, various embodiments can fight against the DoS and DDoS attack on a centralized server that manages keys and personal information of all PSN nodes.\nFurthermore, in various embodiments, the computational cost is low.  As noted above, to provide secure communications of a device, the device needs to generate the attribute-based encryption keys (including PK_LT and SK_LT) once based on its\naccess policy, and does not need to generate these keys multiple times due to trust level changes.  Meanwhile, the cost for generating the communication key (e.g. a symmetric key) is very low.  In some embodiments, the communication key can be controlled\nby the local trust evaluation, and thus the regeneration of communication key is not always needed during the communication.  The re-generated communication key will be issued to the current eligible nodes through multicast.\nNow reference is made to FIG. 5 illustrating a simplified block diagram of various electronic devices that are suitable for use in practicing the exemplary embodiments of the present invention.  In FIG. 5, a communication node 500 (such as the\nPSN node 101a, 101b, 101c, 101x) is adapted for communication with other communication devices (such as PSN node 101a, 101b, 101c, 101x).  A control for secure communications between these communication nodes can be executed according to the exemplary\nembodiments of the present invention as discussed above.\nThe node 500 includes a data processor (DP) 501, a memory (MEM) 503 that stores a program (PROG) 505, and a suitable transceiver 507 for communications with other communication nodes via one or more communication networks.  In an exemplary\nembodiment, the transceiver 507 can be a suitable radio frequency (RF) transceiver for bidirectional wireless communications via one or more antennas.  The PROG 505 is assumed to include program instructions that, when executed by the DP 501, enable the\nuser equipment to operate in accordance with the exemplary embodiments of this invention, as discussed above.  That is, the exemplary embodiments of this invention may be implemented at least in part by computer software executable by the DP 501, or by\nhardware, or by a combination of software and hardware.  The basic structure and operation of the communication node 500 are known to one skilled in the art.\nThe MEM 503 may be of any type suitable to the local technical environment and may be implemented using any suitable data storage technology, such as semiconductor based memory devices, flash memory, magnetic memory devices and systems, optical\nmemory devices and systems, fixed memory and removable memory.  The DP 501 may be of any type suitable to the local technical environment, and may include one or more of general purpose computers, special purpose computers, microprocessors, digital\nsignal processors (DSPs) and processors based on multi-core processor architectures, as non-limiting examples.\nIn general, the various exemplary embodiments may be implemented in hardware or special purpose circuits, software, logic or any combination thereof.  For example, some aspects may be implemented in hardware, while other aspects may be\nimplemented in firmware or software which may be executed by a controller, microprocessor or other computing device, although the invention is not limited thereto.  While various aspects of the exemplary embodiments of this invention may be illustrated\nand described as block diagrams, flow charts, or using some other pictorial representation, it is well understood that these blocks, apparatus, systems, techniques or methods described herein may be implemented in, as non-limiting examples, hardware,\nsoftware, firmware, special purpose circuits or logic, general purpose hardware or controller or other computing devices, or some combination thereof.\nAs such, it should be appreciated that at least some aspects of the exemplary embodiments of the inventions may be practiced in various components such as integrated circuit chips and modules.  It should thus be appreciated that the exemplary\nembodiments of this invention may be realized in an apparatus that is embodied as an integrated circuit, where the integrated circuit may comprise circuitry (as well as possibly firmware) for embodying at least one or more of a data processor, a digital\nsignal processor, baseband circuitry and radio frequency circuitry that are configurable so as to operate in accordance with the exemplary embodiments of this invention.\nIt should be appreciated that at least some aspects of the exemplary embodiments of the inventions may be embodied in computer-executable instructions, such as in one or more program modules, executed by one or more computers or other devices. \nGenerally, program modules include routines, programs, objects, components, data structures, etc. that perform particular tasks or implement particular abstract data types when executed by a processor in a computer or other device.  The computer\nexecutable instructions may be stored on a computer readable medium such as a hard disk, optical disk, removable storage media, solid state memory, RAM, etc. As will be appreciated by one of skill in the art, the function of the program modules may be\ncombined or distributed as desired in various embodiments.  In addition, the function may be embodied in whole or in part in firmware or hardware equivalents such as integrated circuits, field programmable gate arrays (FPGA), and the like.\nThe present invention includes any novel feature or combination of features disclosed herein either explicitly or any generalization thereof.  Various modifications and adaptations to the foregoing exemplary embodiments of this invention may\nbecome apparent to those skilled in the relevant arts in view of the foregoing description, when read in conjunction with the accompanying drawings.  However, any and all modifications will still fall within the scope of the non-Limiting and exemplary\nembodiments of this invention.", "application_number": "14431056", "abstract": " An approach is provided for providing secure communications based on\n     trust evaluation in a distributed manner. A method can comprises: sending\n     data to a plurality of devices, the data being encrypted with a\n     communication key; encrypting the communication key with public attribute\n     keys associated with attributes, wherein the attributes comprising at\n     least one trust level related attribute representing an access condition\n     for the data based on a trust level; evaluating a trust level of each\n     device of the plurality of devices, to identify eligible devices of the\n     plurality of devices whose trust levels satisfy the access condition;\n     sending the encrypted communication key to the plurality of devices; and\n     sending secret attribute keys associated with the attributes to each\n     device of the eligible devices for decrypting the encrypted communication\n     key, the secret attribute keys being personalized for the each device of\n     the eligible devices.\n", "citations": ["7263619", "7707122", "20030099361", "20030126464", "20040228492", "20050039031", "20060023887", "20060184997", "20060233377", "20070055867", "20070192830", "20070214357", "20080084294", "20080165974", "20090046676", "20090049514", "20090125980", "20090225988", "20090276233", "20090296939", "20090328148", "20100119068", "20100251334", "20100262706", "20100329463", "20120174219", "20120203832", "20120260094", "20140164776"], "related": []}, {"id": "20150262282", "patent_code": "10373230", "patent_name": "Computer-implemented method for recommendation system input management", "year": "2019", "inventor_and_country_data": " Inventors: \nWalti; Christopher (Chicago, IL), Spalding; Tyler Robert (Chicago, IL), Hawkins; Brian Philip (San Diego, CA)  ", "description": "<BR><BR>STATEMENT REGARDING FEDERALLY SPONSORED\nRESEARCH OR DEVELOPMENT\nNot Applicable.\n<BR><BR>THE NAMES OF THE PARTIES TO A JOINT RESEARCH AGREEMENT\nNot Applicable.\n<BR><BR>INCORPORATION-BY-REFERENCE OF MATERIAL SUBMITTED ON A COMPACT DISC\nNot Applicable.\n<BR><BR>FIELD\nThe present invention relates to input management systems.  More particularly, the present invention relates to input management systems for recommendation systems.\n<BR><BR>BACKGROUND\nA plethora of varied recommendation systems exist on the Internet.  Recommendation systems typically apply knowledge discovery techniques to the problem of making product recommendations during a customer interaction.  These systems have found\ngreat utility in E-commerce, but the current systems are challenged by the exponential growth in the number of customers, and products available to those customers.\nCurrent recommender systems are challenged by their inherent approach to gathering and managing input to generate recommendations.  First, they rely on historical user data to develop an initial knowledge base for the recommendation engine. \nThis reliance causes a \"cold start\" problem, wherein a recommender system is generally inoperable and unreliable until a certain critical mass of user data input has been accumulated by the system.  Second, when dealing with sparse input data, these\nsystems are less able to provide relevant recommendations to customers.  For example, input data is considered sparse when product lines or brands are emerging rather than mature.\nCollaborative filtering is a type of recommender system technology that works by matching input of a customer's preferences to the aggregate inputted or observed preferences of other customers.  Collaborative filtering performance degrades as\nthe number of customers or products increases.  A recommendation system capable of quickly producing relevant recommendations without relying on management of inputs associated with preference matching would be desirable.  It is further desirable to\nprovide such as system capable of handling very large scale application would likewise be desirable.\nRecommendation systems have generally evolved in the extremely interactive environment of the World Wide Web, the system of interlinked hypertext documents accessed via the Internet.  These systems apply data analysis techniques to help\ncustomers find which products they would like to purchase at E-Commerce sites.  For instance, a recommender system of AMAZON.COM (www.amazon.com) suggests additional books for purchase by a customer based on books the customer have already purchased from\nAMAZON, or, based on books a customer has told AMAZON they like.  Another recommender system on CDNOW (http://www.cdnow.com) helps customers choose CDs to purchase as gifts, based on other CDs the recipient has liked in the past.\nIn general, many recommender systems are an application of a particular type of Knowledge Discovery in Databases (KDD) (Fayyad et al. 1996) technique.  KDD systems use subtle data analysis techniques to achieve two primary unsubtle goals. \nFirst, these systems attempt to save money by discovering the potential for efficiencies.  Second, these systems attempt to generate more revenue by discovering ways to sell more products to customers.  For instance, companies use KDD to discover which\nproducts sell well at which times of year, so they can manage their retail store inventory more efficiently, potentially saving millions of dollars a year (Brachman et al. 1996).  Other companies use KDD to discover which customers will be most\ninterested in a special offer, reducing the costs of direct mail or outbound telephone campaigns by hundreds of thousands of dollars a year (Bhattacharyya 1998, Ling et al. 1998).  Companies use KDD to discover a new sales model, and then, apply that\nmodel to a new sales application.  Businesses use KDD to increase sales of existing products by matching customers to the products they will be most likely to purchase.\nKDD-based recommender systems are limited in their ability to perform interactively due to their necessary reliance on association of historical data input.  For example, while a customer is at specific web site, typically an e-commerce site,\nthe recommender system must learn from the customer's behavior, develop a model of that behavior, and apply that model to recommend products to the customer.  The recommendations are based upon the management of historical data input gleaned from other\nusers.\nBoth collaborative and content-based filtering recommendation systems require management of a base input user profile, driven by textual input by the user, or, selection of various options.  This initial input is also known as seed data.  The\nuser profile is used to predict relevant items for each user.  Initial user inputs can be refined through subsequent user feedback including ranking or rating items, user purchase behavior, and user social network activity.  The recommendation system\nthen compares all the collected data and calculates a list of relevant items for the user.\nAdditionally, current recommender systems typically require iterative interaction by a user, supplemented by historical information concerning the behavior of other users.  For instance, in collaborative filtering approaches, like EBAY or\nAMAZON, a user's past or historical behavior is analyzed for similarities to the behavior of other users.  These types of systems are not flexible and do not allow users to actively participate in the development of their personal preference profile. \nUsers cannot remove actions from their history nor can they create an entirely new profile based on desired actions.  A user cannot hypothetically add purchases or browsing history to his account that did not actually occur.  Additionally, these systems\ngradually account for activity over some period of time; inputs cannot be changed instantaneously to adjust the personal preference profile.\nIn content-based filtering approaches, like PANDORA and NETFLIX, the systems require the user to rate items to provide initial seed data.  Inherently, these systems do not yield consistent results when their databases have only a few values,\ncreating an inability to derive the most relevant searchable key attributes.  Furthermore, where a recommender system requires a minimum amount of seed data to initiate, a user must spend more time at the outset to implement the system to provide\nrelevant results for the user.  In addition, content-based filtering approaches are limited to one-to-one comparisons of content types.  PANDORA, for example, can only recommend music; similarly, NETFLIX can only recommend films.\nIt would be preferable to allow each user to understand how the user's inputs are managed to create relevant recommendations.  Current recommendation systems do not lend themselves to user transparency in dealing with input management.  A user\ngenerally does not understand how a particular recommender system manages the user's inputs to generate subsequent product recommendations.  Accordingly, a user would not have a sense as to how to influence those recommendations.  Input management for\ncurrent recommender systems does not leverage visual cues or visual elements to assist a user in developing an understanding of how recommendations are developed by the system.\nConsequently, in light of the aforementioned limitations, a need exists for methods and systems to manage input for recommendation systems, using visual cues and elements, wherein user input can be changed instantly and resulting recommendations\nare likewise changed instantly.  In addition, a need exists for methods and systems having transparency in operation so a user can play an active role in determining whether the resultant recommendations are consistent with the user's own perception of\nhis or her personal preferences.\n<BR><BR>SUMMARY\nIn view of the foregoing described needs, an aspect of the inventive subject matter is directed to a computer-implemented method and system to manage and support instantaneous and transparent modification of inputs to a recommender system by a\nuser wherein historical data is not a prerequisite to generation of relevant recommendations for items.  A further aspect of the inventive subject matter comprises an input management system for recommendation systems that satisfies the above needs for a\nstraightforward, less data-intensive approach for matching each user with relevant items of interest without the need for an initial usage baseline, or specific rating of items of interest prior to provision of relevant results.\nThe method and system of the inventive subject matter herein, also referred to herein as the \"StyleSeek.RTM.\" method and system, uniquely and directly maps individual users to discrete items without the need for historic user data.  The method\nand system comprises a software module programmed for operation on a computer to support interaction with a user via a plurality of user interfaces.  The user interface may be deployed on any one of a web browser across the Internet, a smart phone\ndisplay, a kiosk in a retail environment, a touchscreen, a holographic display, a gesture recognition interface and other such perceptual user interfaces which may evolve in the future.  This flexibility in deployment device and location supports use in\nboth static and mobile environments to suit the requirements of each user and the specific deployment scenarios.  The StyleSeek software module provides a means for selecting one or more images or other visual cues or elements to determine a user's\npreferences.  The resulting image selections serve as the initial input to one or more computer-implemented algorithms that transform metadata and attributes associated with the image selections into the user's unique personal preference profile.  The\npersonal preference profile is then used by the system software to evaluate, correlate and display relevant recommendations for the user.  Hence, the method and system provide input management via visual elements.  Although input to the user interface\ncan occur via keyboard and mouse, the method and system is uniquely suited to touch and other such perceptual input and display modalities, including voice and gesture recognition, since the invention emphasizes the use of visual elements, images and\ngraphic representations rather than textual or numeric input.\nIn keeping with the use of visual elements to create input, an aspect of the inventive subject matter facilitates the use of cognitive and emotional responses from users via the user's visual perception and cognitive interpretation of multiple\nimages to allow digital transformation of the user's cognitive and emotional responses to create the user's personal preference profile, hereinafter, also referred to as the user's \"StyleDNA.RTM..\" Of course, depending on the selected underpinning for\nthe recommendation system, the user's personal preference profile could be referred to as the user's \"Social DNA,\" \"Health DNA,\" \"PoliticalDNA,\" \"Emotional DNA,\" \"SexualDNA,\" \"CulinaryDNA,\" or other such foundational underpinnings.  The method and system\nsubtly accesses the user's visceral response to one or more images to generate a collection of images that is subsequently digitally transformed to aptly represent the user's tastes and preferences.  The method and system is designed to elicit a visceral\nresponse, generated in a fluid manner, where the user is able to provide input merely by selecting various images through the display used for interaction with the system.\nThe inventive subject matter comprises a computer-implemented method and system for creating, managing, modifying, importing, and sharing inputs to a user personal preference profile, which may then be uses as one or more inputs to a relevance\nassessment engine to determine a user's personal product, service and lifestyle preferences.  In one embodiment targeted toward fashion and lifestyle, the system comprises software for assessing and aggregating lifestyle items via style dimension mapping\nvia one or more computer-implemented algorithms to process metadata associated with one or more selected images.  The method and system is easily expanded to support recommendations for personal preferences for other subject matter areas beyond lifestyle\npreferences.  For example, images may be related to a user's religious, political, social, emotional, athletic, sexual, culinary, experiential and other such personal underpinnings or personal attributes that cause each user to have a unique personal\npreference profile.  In other embodiments, images, and therefore resulting recommendations, may be tied to one or a combination of any of the subject matter areas described above.  For simplicity in describing the inventive subject matter, the method and\nsystem are described in relation to an embodiment wherein \"lifestyle\" preferences are assessed and recommendations are based upon those lifestyle preferences.\nImage metadata need not be disclosed to a user since the system uses preexisting metadata associated with each user-selected image to create individualized vector inputs to create an individualized user lifestyle preference index (i.e. the\nuser's StyleDNA.RTM.) and subsequent individualized lifestyle preference output parameters.  The generated output parameters are then associated or mapped to a plurality of correlated products, services, lifestyles and experiences for presentation to the\nuser.  The system interactively gathers and manages input information about a user's unique preferences driven by the user's image selections.  The method and system directly matches each user to discrete items without access to historic data.\nThe method and system flexibly allows users to continuously interact with the system throughout its breadth to manage inputs to the system.  Input management leverages various activities by a user, including (1) the user's instantaneous\nselection of images relevant to the user's tastes and preferences, (2) creation of one or more separate and distinct user personal preference profiles, StyleDNA, based on user selections, (3) on-demand modification of existing StyleDNA through the\nselection of a single image, (4) instantaneous import of preferences from another user's personal preference profile (StyleDNA) to create a new or additional StyleDNA for the user, and (5) sharing of the user's StyleDNA and associated personal\npreferences with other users.  The computer-implemented methods and system of the inventive subject matter likewise provides a process to use the aforementioned inputs to immediately generate an updated personal preference profile, which is then used to\nsubsequently generate output to identify relevant items of interest to the user.\nIn an embodiment of the method and system of the inventive subject matter, multiple images are presented to a user for consideration.  Each image serves as an opportunity for visual visceral perception by a user, wherein the image is correlated\nwith associated metadata indicative of a basis for selection of the image by a user.  Each image presented to a user for potential selection is pre-associated with structured metadata, which is then applied and processed using various algorithms\nincorporated within the system software to transform the selected images into the user's StyleDNA.  Historical data collection is not a requirement of the method and system.  Images used within the method and system have no subject constraints.  Images\ncan feature any type of content, including but not limited to, various products, brands, logos, trademarks, landscapes, and even specific people.\nAlthough each image is associated with specific metadata, the use of images to develop a user's StyleDNA provides a more vigorous approach and a greater level of definition for the spectrum of a user's preferences since the user has an innate\nand instinctive response to each image, in other words, a visceral and subliminal response.  Hence, the method and system allows a user to select one or more images based upon the user's conscious and subliminal preference.  The selected images then\ndrive the creation of the user's individualized StyleDNA through a unique combination of inputs from the user.\nVisual perception, and the subliminal aspects of such visual perception, is an element of the subject matter of the invention.  Hermann von Helmholtz is often credited with the first study of visual perception in modern times.  Helmholtz\nexamined the human eye and concluded that it was, optically, rather poor.  The poor-quality information gathered via the eye seemed to Helmholtz to make vision impossible.  He therefore concluded that vision could only be the result of some form of\nunconscious inferences: a matter of making assumptions and conclusions from incomplete data, based on previous experiences.  Hence, the method and system according to various embodiments of the invention uniquely leverages each individual's user-centric\nexperience to refine choices that drive preference definitions.  The consideration of an image allows a user to make selections based on unconscious inferences that rely on assumptions and conclusions from incomplete data based on a user's previous\nexperiences.  Although every image presented to a user of the system may be interpreted as being visually incomplete, the user's experiential assumptions and conclusions associated with each image create a more complex yet complete view of the user's\nparticular personal preferences.  This selection methodology avoids limits found where choices are made using direct selection of structured data attributes.  For example, where a user is asked to describe a preference in textual form, or select a\npreference from a list of descriptors, the user will not necessarily be leveraging unconscious inferences associated with the sense of sight.  Hence, where a user may select two images for similar reasons due to his unconscious preferences, the metadata\nwith each image may be distinct, causing the development of a more accurate and reliable assessment of user preferences.\nThe input management features of the method and system allows users to modify their individual or multiple StyleDNA at any time, using any image within the system.  An entire StyleDNA can be replaced with new images; no historical data is\nrequired.  Determination of a user's StyleDNA is flexible; a StyleDNA can be driven by as little as one image, two or more, or, a plurality of images.  In one aspect, the user's StyleDNA is driven by a group of images selected by a user.  The number of\nimages selected for the user's StyleDNA group can be adapted based on results of user interaction.\nThe method and system supports creation of additional StyleDNA by the user, which may be used interchangeably, for example, depending on the mood of the user.  Additionally, a user may share their StyleDNA with another individual so that\nindividual can shop for the user or select gifts more likely to satisfy the user's personal preferences.  Further, the system allows each user to share his or her StyleDNA with other users, or, import StyleDNA shared by other users.  In addition, the\nsystem supports the use of exemplary StyleDNA, which may be associated with persons of note, including celebrities, politicians, scientists and other such notable figures.  Hence, the method and system provides each user with various alternatives to\nmanage inputs to the recommender system. <BR><BR>BRIEF DESCRIPTION OF THE SEVERAL VIEWS OF THE DRAWINGS\nFor a better understanding of the inventive subject matter, reference is made to the detailed description contained herein and the accompanying drawings numbered below which are given by way of illustration only and are not intended to be\nlimitative to any extent.  Commonly used reference numbers identify the same or equivalent parts of the claimed invention throughout the several figures.  These and other features, aspects and advantages of various embodiments of the inventive subject\nmatter will become better understood with regard to the following description, appended claims, and accompanying drawings where:\nFIG. 1 is a diagram of an overview of the method and system embodying principles of the invention.\nFIG. 2 is a block diagram of the various vectors used in the method and system embodying principles of the invention.\nFIG. 3 is a high-level flowchart for management of inputs to the computer-implemented method and system embodying principles of the invention.\nFIG. 4 is a block diagram illustrating the top-level structure of the software interface embodying principles of the invention.\nFIG. 5 is a block diagram illustrating the structure and components of the Manage StyleDNA module of the software embodying principles of the invention.\nFIG. 6 is a block diagram illustrating the structure and components of the Global module of the software embodying principles of the invention.\nFIG. 7 is a block diagram illustrating the structure and components of the user Account module of the software embodying principles of the invention.\nFIG. 8 is an exemplary screen shot of the user interface associated with the \"All Brands\" selection from the Global module of FIG. 6 embodying principles of the invention.\nFIG. 9 is an exemplary screen shot of the user interface associated with the \"Occasions\" selection from the Global module of FIG. 6 embodying principles of the invention.\nFIG. 10 is an exemplary screen shot of the user interface associated with a selection of \"Business casual\" from the \"Occasions\" drop down list of FIG. 9 embodying principles of the invention.\nFIG. 11 is a flowchart illustrating the computer-implemented method of the StyleGame embodying principles of the invention.\nFIG. 12A is a first view of an exemplary screen of the user interface associated with the StyleGame of FIG. 11 wherein a user has not made any image selections embodying principles of the invention.\nFIG. 12B is a subsequent view of an exemplary screen of the user interface associated with the StyleGame of FIG. 11 wherein a user has made several image selections embodying principles of the invention.\nFIG. 12C is a final view of an exemplary screen of the user interface associated with the StyleGame of FIG. 11 wherein a user has completed his selection of images embodying principles of the invention.\nFIG. 13 is a functional block diagram of the structure and operation of the Manage StyleDNA module embodying principles of the invention.\nFIG. 14 is an exemplary screen shot of a first user interface associated with the Manage StyleDNA module of FIG. 13 embodying principles of the invention.\nFIG. 15 is an exemplary screen shot of \"Rename StyleDNA 40\" associated with the Manage StyleDNA user interface of FIG. 14 embodying principles of the invention.\nFIG. 16 is an exemplary screen shot of \"Create StyleDNA\" associated with the Manage StyleDNA user interface of FIG. 14 embodying principles of the invention.\nFIG. 17 is an exemplary screen shot of another view of the Manage StyleDNA user interface embodying principles of the invention.\nFIG. 18 is an exemplary screen shot of the Browse StyleDNA module user interface embodying principles of the invention.\nFIG. 19 is an exemplary screen shot of the detail for another user's StyleDNA selected from the Browse StyleDNA module user interface embodying principles of the invention.\nFIG. 20 is an exemplary screenshot of the Imported StyleDNA user interface embodying principles of the invention.\nFIG. 21 is a functional block diagram of the Explore module embodying principles of the invention.\nFIG. 22 is an exemplary screenshot of the Explore user interface embodying principles of the invention.\nFIG. 23A is an exemplary screenshot of the Explore user interface wherein a user has hovered a pointer over a particular item embodying principles of the invention.\nFIG. 23B is an exemplary screenshot of the Explore user interface wherein a user has selected the item hovered over in FIG. 23A and added the item to his MyDNA account embodying principles of the invention.\nFIG. 24 is an exemplary screenshot of the detail page associated with the item added to the user's MyDNA account of FIG. 23A embodying principles of the invention.\nFIG. 25 is an exemplary screenshot of the user interface dropdown for Manage StyleDNA to allow a user to change StyleDNA.\nFIG. 26 is an exemplary screenshot of the new Explore user interface after the user has selected a new StyleDNA from the dropdown of FIG. 25 embodying principles of the invention.\nFIG. 27 is a functional block diagram of the Buy module embodying principles of the invention.\nFIG. 28 is an exemplary screenshot of the Buy user interface embodying principles of the invention.\nFIG. 29 is an exemplary screenshot of the detail page for an item selected from the Buy user interface of FIG. 28 embodying principles of the invention.\nFIG. 30 is a functional block diagram of the Brands module embodying principles of the invention.\nFIG. 31 is an exemplary screenshot of the Brands user interface embodying principles of the invention.\nFIG. 32 is an exemplary screenshot of the detail page for a particular brand selected from the Brands user interface of FIG. 31 embodying principles of the invention.\nFIG. 33 is an exemplary screenshot of the detail page for a particular representative brand embodying principles of the invention.\nFIG. 34 is an illustration of a representative network used to implement the method and system embodying principles of the invention.\nFIG. 35 is a block diagram for a representative computer system used to implement the method and system embodying principles of the invention.\n<BR><BR>ASPECTS OF THE INVENTIVE SUBJECT MATTER\nOne aspect of the inventive subject matter discloses a user-centric method and system for recommendation system input management wherein inputs to the recommender system need not rely on historical data from other users.\nAnother aspect of the inventive subject matter discloses a means by which a user can provide input to the recommendation system using an inferred or subconscious visceral response to selected images, thereby avoiding reliance on selection of\nspecific narrative text by the user to indicate preferences.\nAnother aspect of the inventive subject matter discloses a user-centric method and system to transform images selected by the user into an individualized set of recommendations for lifestyle items incorporating intangible style elements,\nbranding, and public perception to provide relevant and accurate results matched to the user's unique personal preferences.\nAnother aspect discloses a personalized recommendation method and system operable with limited data wherein historic user data is not required to generate accurate results to overcome the cold-start problem inherent to other recommender systems. The first user of the system will receive recommendations equal in quality to any subsequent user of the system.\nAnother aspect discloses a personalized recommendation method and system operable wherein data from the user is sparse.\nAnother aspect discloses a personalized recommendation method and system for managing inputs associated with user preferences and associated lifestyle items wherein the user is not required to rate, evaluate, or give scaled or objective\npreferences for any lifestyle item.\nAnother aspect discloses a method and system for managing inputs to a recommendation system wherein the user is directly matched to discrete items and products, including, but not limited to, clothing, lifestyle items, and brands, as opposed to\nbeing assigned to predetermined categories and then shown specific groups of products.\nAnother aspect discloses a method and system wherein a user may immediately change his or her inputs to the system by selecting new images for inclusion or replacement of other images in the selection matrix and then receive an immediate update\nof recommendations from the system based upon the changed inputs.\nAnother aspect discloses a method and system wherein both user inputs and outputs are delivered in a visual manner rather than through the input and output of text or other data, including selections from drop-down menus.\nAnother aspect discloses a method and system wherein a user may have one or more personal preference profiles and change between such profiles instantaneously, thereby receiving updated recommendations instantaneously.\nAnother aspect discloses a user input management method and system wherein the user may elect to use either an entire set of inputs or individual inputs from other users or templates within the user's own inputs.\n<BR><BR>DETAILED DESCRIPTION\nThe following description is merely exemplary in nature and is in no way intended to limit the invention, the inventive subject matter, its application, or its uses.  Before the inventive subject matter is described in further detail, it is to\nbe understood that the invention is not limited to the particular aspects described, as such may, of course, vary.  It is also to be understood that the terminology used herein is for describing particular aspects only, and is not intended to be\nlimiting, since the scope of the present invention will be limited only by the appended claims.  In particular, the recommender method and system may be described in the context of \"lifestyle\" item recommendations, but the method and system is equally\napplicable to providing recommendations for items of any type, in any category, subject matter, domain or classification.\nUnless defined otherwise, all technical and scientific terms used herein have the same meaning as commonly understood by one of ordinary skill in the art to which this inventive subject matter belongs.  Although any methods and materials similar\nor equivalent to those described herein can also be used in the practice or testing of the inventive subject matter, a limited number of the exemplary methods and materials are described herein.\nIt must be noted that as used herein and in the appended claims, the singular forms \"a\", \"an\", and \"the\" include plural referents unless the context clearly dictates otherwise.\nAll publications mentioned herein are incorporated herein by reference to disclose and describe the methods and/or materials in connection with which the publications are cited.  The publications discussed herein are provided solely for their\ndisclosure prior to the filing date of the present application.  Nothing herein is to be construed as an admission that the present invention is not entitled to antedate such publication by virtue of prior invention.  Further, the dates of publication\nprovided may be different from the actual publication dates, which may need to be independently confirmed.\nFollowing is a description of computer-implemented method(s) and system(s) for managing inputs in a recommendation system.\nFirst, referring to FIG. 1, features of the method(s) and system(s) are illustrated and disclosed.  For simplicity and brevity, the method and system may hereinafter be likewise referred to as the system or the method.  In one embodiment,\ninitially, a new user accesses the computer-implemented method and system to initiate a \"game\" module, hereinafter referred to as the StyleGame.RTM.  module 20.  The StyleGame module 20 causes one or more images 22, 24 to be displayed to the user for\nvisual perception V and mental processing B. The user relies on his or her personal preferences to select one or more images 24 as representative of the user's personal preferences or tastes.  The user leaves unselected those images 22 that do not match\nthe user's personal preferences.  The selected images 24 are then put through a transformation 30 according to the method and system using a computer and software programmed to operate on the computer to implement the method to generate a unique user\npreference profile 40 for the user, herinafter the user's StyleDNA 40.  After the user's StyleDNA 40 has been generated, the StyleDNA 40 drives correlation 50 against an item database 60.  During correlation 50, uncorrelated items 62 are ignored and\ncorrelated items 64 are selected.  The selected correlated items 64 are then transformed for presentation 70 to the user.  The presentation transformation 70 sends images 85 of the selected correlated items 64 to a display 80 presentation to the user for\nadditional visual perception V and mental processing B.\nVector Structure--Now referring to FIG. 2, the vector structure 90 of the system in one embodiment is described in greater detail.  First, the system creates user vector 92 based on earlier image selections.  The preliminary input vector 92\ndrives the selection of item/brand/content matches from multiple databases wherein the matches are deemed to correlate with the user's StyleDNA 40.  The method and system is not limited in the number of databases 60 and in various aspects, the prescribed\nnumber of database matches can be limited to just one database 60 or any number of additional databases 60 with additional category specifications.  Individual image vectors 91 driven by the selections by a user from each of the image matrices 1225 are\ncombined by the system to create the individualized user vector 92.  The user vector 92 and corresponding product images 1225 comprise a user's StyleDNA 40.\nA variety of supplemental inputs can impact input image vectors 91 in providing matched results.  These supplemental inputs may be combined to form separate vectors, or merely act as filters against database queries.  For instance, account\ninformation provided by the user from other Internet sites such as FACEBOOK, LINKED-IN, or PINTEREST may be used within a system of algorithms to enhance the quality of recommendations.  Data that may be used includes demographic information, FACEBOOK\nlikes, keywords within comments, occupations, and followers/friends/connections.  Additionally, users may select specific items within the StyleSeek database 60 to refine their recommendations.  For instance, a user may provide a positive preference for\nblue dress shirts, and the system will provide a bias towards other similar items.  Alternatively, a user may provide a negative preference for sunglasses, for example, and therefore never be shown those item types again, regardless of their match due to\nthe input image vectors 91.  The rules for these supplemental systems may be turned on or off by the user to control the results.  In other examples, a user may provide a positive preference for a particular piece of furniture, and the system will\nprovide a bias toward other items having similar or complementary associations.  For example, a user may select an image of a leather desk chair and the system will provide a bias toward items having similar metadata, such as button-down shirts for men\nor mahogany desks or brass writing utensils.  In other words, the system facilitates selection of items of interest without requiring the user to view and rank similar items of interest.  For example, the system does not require a user to assess,\nevaluate and rank different styles of shirts to determine that the user might be biased toward button down shirts.  Likewise, a user may be shown an image of a vehicle, storefront, house or other item and the system will determine the user's preferences\nfor food, sports teams, and other items and products.\nNow, referring to FIG. 3, a structured flowchart of the method and system is disclosed.  At input level 100, the user provides key inputs 105 to the system software, which then performs various calculations.  At output level 200, the system\ngenerates various outputs 205 based on the inputs 105 in the form of images of various items and supports basic interaction by the user.  At advanced user interactive level 300, the system provides additional functionality to allow advanced user\nactivity, which includes additional refinement of the system via additional user input.\nNow, in greater detail, additional features and function at input level 100 are described.  At Start step 110, the user visits a web page associated with the system.  At choice step 120, the user is prompted to create an account or use the\nStyleGame 20.  If the user elects to use the StyleGame 20, at selection step 130, the user is prompted to select one or more items 1225 from a group 1220 of images of those items 1225.  At user vector creation step 140, the system creates a user vector\n92 based upon the item images 1225 selected and then, at confirmation step 150, the system requests confirmation to confirm that the user is satisfied with his choices.  If the user is not satisfied with the choices, the user can repeat the StyleGame 20\nand make different choices.  If satisfied, the method and system proceeds to output level 200.\nAt output level 200, the system generates various outputs 205 and supports basic user activity.  At categorization step 210, the system categorizes the user vector 92 and finds and displays related items to the user based on correlation with the\nuser vector 92.  At interactive step 220, the system software provides interactive functionality to allow the user to review, select and buy any of the items presented to the user.  In addition, at filter step 230, the user is able to filter displayed\nitems by various criteria.\nAt level 300, the system provides more advanced input management functionality to the user for system refinement.  At feedback step 310, the user provides feedback to the system on displayed items and browses a more extensive database 60 of\nitems.  At user profile input step 320, the user inputs additional user profile information.  At refinement step 330, the system aggregates the additional user input to refine the user vector 92 according to the tastes and preferences of the user.  At\nupdate step 340, the system updates and displays items deemed preferable to the user.\nNow, in greater detail, we describe the flowchart in FIG. 3 depicting a multilevel overview of one aspect of the method and system of the inventive subject matter.  The method and system manages correlation at level 100 between inputs 105 to the\nsystem and at level 200 to outputs 205 of the system.  Only a de minimis initial input 105 from the user is required to initiate the system.  At step 130, a user chooses lifestyle items from an image matrix.  Although identified herein as a matrix, other\naspects support organization of the images in any geometric grouping.  For example, the images might be displayed in circular groupings, hierarchical groupings or other similar geometric layouts.  At step 140, the system creates an N-Dimensional User\nVector 92 from images selected by the user.  In one aspect, testing by the inventors has shown that the efficiency and utility of the input management method and system appears to be maximized when the number of choices of lifestyle items available from\nthe image matrix is equal to nine.  Users appeared to be best served by this number; cognitively evaluating nine images provides a balance between useful inputs for the system while minimizing the level of effort required by a user, thus minimizing the\nnumber of users abandoning the input process due to length of completion time.\nImportantly, a user does not rate or rank items displayed in an image matrix.  The system does not require an initial baseline assessment of items by the user for initialization, thus overcoming the well-known \"cold start\" issue associated with\nexisting recommender systems and methods.  Instead, at step 210, the method and system according to an embodiment of the invention uniquely and directly maps the user to each specific item, and not to categories, genres, or tags associated with the item. In one aspect, the method and system does not rely on inputs from historical user data or associated historical product acquisition data.  A first user of the StyleSeek method and system will experience results equivalent in accuracy to all subsequent\nusers.  No machine learning is required.  The item/brand/content vectors 93 do not change over time based upon input 105 to the system or user feedback; the item/brand/content vectors 93 are independent of user interactions.\nAt input level 100, the method and system is configured to first receive initial user inputs 105 and perform various calculations based upon those inputs 105.  Next, at output level 200, the method and system uses the results from input level\n100 to generate output 205, such as recommended items, which are then displayed to the user for other basic user activity.  Finally, at interactive level 300, the method and system provides additional functionality to support more advanced user activity\nand support system refinement.\nAt step 110, Visit web page, a user enters the site.  The user may enter the site by visiting the web page on their computer, or by using a mobile phone application to view the web page or a phone-specific version of the web page. \nAlternatively, the user may enter the site to interact with the system and receive recommendations by visiting an in-store interface device.  The in-store interface device can be tuned to provide recommendations according to the available store inventory\nand/or product line.  Alternatively, the user may interact with the system while mobile within a mall or other similar environment.  The interaction once again may occur via direct interaction with an input device, such as a touchscreen, or, interaction\nmay occur via the passive delivery of a wirelessly transmitted unique identifier that communicates the user's identifier to initiate recommendations based upon the user's StyleDNA 40.  Likewise, a user may enter the site by interacting with an email,\ntext or other digital communication wherein the email or text communicates items of potential interest to the user and the user can directly investigate the item or access the site via a link on the email.\nAt step 120, the user is provided with two choices: 1) Create Account, or, 2) Use StyleGame.  If a first time user, the system will require the user to first create an account.  The system prompts the user to enter information to establish their\ncontractual relationship and account with the system.  If the user has an existing account, the system launches the user to an interactive interface, called the StyleGame 20, where a matrix of images is selected by the user.  The StyleGame 20\norchestrates the creation of a user's unique personal preference profile, otherwise known as the user's StyleDNA 40.\nAt step 130, Select Items from Matrix, the system prompts the user to select a plurality of items from various image sets for inclusion in the StyeGame 20 matrix.  The system repeats step 130 until the user has completely filled the StyleGame 20\nmatrix with images selected from the earlier image sets presented to the user.  FIG. 12A, FIG. 12B and FIG. 12C illustrate exemplary screens displayed to a user during the user's interaction with and completion of the StyleGame 20.  FIG. 12A is an\nillustration of the initial empty matrix displayed to a user before any items have been selected from various image matrices; FIG. 12B is an illustration of a partially completed matrix; FIG. 12C is an illustration of a completed matrix.\nThe user interacts with and selects images of items from one or more matrices of pictures or image sets.  At step 140, Create N-Dimensional User Vector, the system causes the computer system to process the various attributes associated with the\nuser's selections according to one or more algorithms.  Once the user has selected the number of images required to complete his StyleGame 20 matrix, the system generates an N-dimensional user vector 92.  At step 150, Confirm Matrix Choices, the system\nprompts the user to confirm his matrix choices.  The user confirms completion and satisfaction with item choices, with the option to change any previous image selections.  Any changes will be reflected in a newly created user vector 92.\nAt output level 200, System Outputs and Basic User Activity, the system causes various outputs 205 to be generated and supports basic user activity.  At step 210, Categorize Vector, Find & Display Related Item, the system categorizes the user\nvector 92 associated with the user's StyleDNA 40 and then correlates the user vector 92 against a database 60 of items to find and display relevant items for recommendation to the user.\nAt step 220, Review, Select, and Buy Items, the user may review displayed items, and then select them interactively to learn more about the item or to purchase the item via affiliate networks, or directly through the site.  At step 230, Filter\nItems by Selected Criteria, the user has the option to filter initial displayed results by style dimension, occasion, color, price, brand, or other attributes.\nAt level 300, Advanced User Activity, System Refinement, the method and system presents the user with additional options to alter various prior inputs 105.  At step 310, Provide Feedback, Browse Database, the system prompts the user to provide\nfeedback on an item a number of different ways: rating (like/dislike), commenting, recommending, or other options.  Additionally, the user may opt to browse other items in the database (whether related or not), \"follow\" other users of choice, or simply\nbrowse choices made by other users.  At step 320, Input User Profile Info, the system presents an input page to the user so that he may enter personal information for potential presentation to other users of the system.\nIn another aspect, the system provides additional input pages to allow the user to configure and adapt his StyleDNA 40 according to additional information input by the user, such as height, weight, hair color, brand preferences, price\npreferences, color preferences, material preferences, fit qualifiers and other relevant attributes, specific to the recommended items.\nAt step 330, Vector & Prediction Refinement, the system adapts and refines both the user's input vector 92 and predictive output.  As user activity, selection, and site input increases, the system dynamically adjusts a user's initial input\nvector 92 and related item predictions to account for and reflect these additional inputs.\nAt step 340, Update Preferred Items, the system automatically updates correlated items to present new or updated recommendations of preferred items to the user.  In addition to these automatic vector and prediction updates based on user\nactivity, a user may also force updates by changing his inputted preferences at any time.\nCreation of Input Vectors--Referring to FIG. 2, the input vector structure 90 drives multiple aspects of the method and system, the system leverages three primary vectors: 1) image vector 91, 2) user vector 92, and 3) item/brand/content vector\n93.  The system creates an individual image input vector 91 (hereinafter, the image vector 91) which is associated with each image of an item/brand/content presented to a user.  An aggregate input user vector 92 (hereinafter, the user vector 92), in one\naspect, is computed by the system as the weighted average of the image vectors 91.\nThis transformation of a user's preference of certain items into an aggregate user vector 92 is described by the following equation:\n.times..times.  ##EQU00001## Wherein, v.sub.input is the user vector 92 and i.sub.1 through i.sub.9 exemplify individual image vectors 91, with m the number of individual image vectors 91 created and used in establishing the user vector 92.\nIn a broader aspect, the method and system correlates and recommends any type of item including, among other things, clothing, accessories, jobs, colleges, hotels, food, furniture, decor, electronic devices, destinations, neighborhoods, cars,\netc. Likewise, the items and products can be correlated against a plurality of categories or domains.  For simplicity, in one aspect, the system herein focuses on recommendations for men's clothing.  However, the methodology and approach is the same for\nrecommendations for any type of item, product, etc.\nIn an embodiment emphasizing recommendation of lifestyle items, the user visits a website, mobile application or other user interface and is prompted with a set of lifestyle image groupings or matrices.  The image matrices can be randomized, but\ninclude categories such as Cars, Movies, Music, Magazines, Cities, Objects, Alcohol Brands, Activities/Sports, Restaurants, and Houses.  The user clicks one image he likes from each category grouping, and upon completion of all selections to complete the\nmatrix, the user is presented by the system with recommended items/brands/content deemed to correlate to the user's personal preferences and style.  In this instance, the user will receive recommendations and be shown specific articles of clothing for\npurchase, as well as information regarding the clothing brands deemed by the system to be most relevant to his personal preferences and style.\nFeatures of the method and system of the inventive subject matter are several.  For example, a first user of the system receives recommendations equal in quality to recommendations to subsequent users.  Additionally, the system does not require\na user to objectively or quantifiably rate, evaluate, or give preferences for clothing, clothing brands, or anything immediately related to fashion to generate his or her personal preference profile, known as the StyleDNA 40.  Further, the system\nuniquely and directly matches discrete clothing items, brands and other content with the user according to his or her StyleDNA 40.  Still further, the system does not associate or assign a user to predetermined categories to justify the presentation of\nspecific groups of products based upon those assigned predetermined categories.\nThe method and system provides a vehicle that gathers and receives input information about a user's unique lifestyle preferences.  This input information is then correlated to clothing, brands, content and other lifestyle items.  The\ncomputer-implemented method and system comprises elements of style dimension mapping, inputs, outputs, and one or more algorithms.\nNow, in greater detail, the structure, function and operation of the method and system of the input management aspect of the inventive subject matter is described.\nReferring to FIG. 4, in one aspect, upon visiting the StyleSeek website 400 associated with the method and system, the user is presented with an option to either directly Log In 402, wherein the user can access a previously-created account 700\nand saved preferences, or, to Create Account 404, wherein the user can generate a new user account to access the system.  Alternatively, in another aspect, a user may also engage with the system while reviewing the StyleDNA of another user or while\nsimply reviewing brands, items, and other content at another website.  Fundamentally, a prospective user can access the functionality of the system from any other application or even from an individual image of a product of interest to the user.  This\nelement of ubiquitous access expands the applicability of the system to any interactive digital source of information.\nIn the case of viewing another person's StyleDNA, the user is provided with an option on the StyleSeek website 400 to import the other person's StyleDNA.  Consequently, the user is able to access the Log In 402 and Create Account 404 options\ndirectly from an Import StyleDNA function 2620.  However, if a user is not logged into the site under an existing account 700, upon attempting to use the Import StyleDNA function 2620, the system presents the user with the option to either Log In 402 or\nCreate Account 404 options.  After the user has logged in or created a new user account, the system then performs a first-time user check 412 to determine whether the user is new or has previously used the StyleSeek website 400.  If the user is new, the\nsystem prompts the user to create a first StyleDNA 41 via an interactive computer-implemented process hereinafter referred to as a StyleGame module 20.  A user's first StyleDNA 41 is created through completion of the StyleGame 20.  If the user began the\nStyleSeek website 400 entry process with the Import StyleDNA function 2620, the particular StyleDNA 40 the user selected for import is added to the user's Imported StyleDNA 2120 along with the de novo creation of the user's initial StyleDNA 41.  If the\nuser is not new and has an existing account 700, the user is taken directly to the main web page 420 of the StyleSeek application, bypassing the initial StyleGame 20 process required for new users.\nManage StyleDNA Module--Now, referring to FIG. 5, a Manage StyleDNA module 500 of the method and system is disclosed.  In one aspect, a StyleDNA site section 510 can be directly accessed via a Log In screen 402.  After logging in, the user may\ngo directly to the Manage StyleDNA page 530, or, if it is the user's first time logging in, they may be taken to StyleGame 20 before accessing the Manage StyleDNA page 530.  At the Manage StyleDNA page 530, the user is presented with a list of his\nvarious StyleDNA 40, represented by a StyleDNA picture icon 2110, name, and date.  The user may hover over any StyleDNA picture icon 2110 included in the list with his mouse pointer or other input method and select a gear icon that appears while hovering\nover the picture icon 2110.  Selecting the gear icon enables a function to allow the user to rename the specific StyleDNA 40.\nGlobal Module--Now referring to FIG. 6, a Global module 600 allows a user to review non-personalized items.  A \"non-personalized\" item is defined herein as an item presented to a user wherein the item has not been earlier selected by the user\nfor incorporation as a vector used to create the user's active StyleDNA 40.  Access for review of non-personalized items is available through three primary functions.  First, a user may select the \"All Brands\" function 620.  Alternatively, a user may\nselect the \"Occasions\" function 640.  Finally, a user may select a separate Search function 660 at the top of the homepage.\nAdditionally, to further expand access to specific items that might be relevant to a user's StyleDNA 40, a search box 662 at a top right hand corner of the main web page 420 allows the user to access the Search function 660 and perform a keyword\nsearch for specific items like \"blue polo shirt,\" product features like \"Goodyear welt,\" or even styles like \"Street Style\" or \"Alternative.\" The search box 662 is available globally from any page on the StyleSeek website 400.\nUser Account--Now referring to FIG. 7, the system provides a user's account 700 containing data relevant to the user's individually identifiable information, the user's website preferences, and, general information concerning the website 400. \nIn one aspect, the user accesses his account 700 by selecting \"Account\" 702 in the upper right hand corner of the StyleSeek website 400.  The user may view and edit his individually identifiable information and preferences by selecting \"My Profile\" 710. \nHe may enable a function to submit content to the StyleSeek website 400 by selecting the \"Submit Content\" module 730.  He may contact the website owners or managers by selecting \"Contact Us\" 750.  He may access a help page with information about using\nthe StyleSeek website 400 by selecting \"Help\" 770.\nConcerning content contribution by a user, in addition to using the functionality of the system to develop his or her own StyleDNA 40, the system likewise provides functionality to allow a user to contribute original or sourced content to the\nStyleSeek website 400.  The system can use this contributed content in a number of different ways.  To contribute content, the user first selects and clicks on \"Account\" 702 in the upper right hand corner of the StyleSeek website 400.  This launches a\nseparate content submission module 730 to allow the user to \"Submit Content.\" The content submission module 730 allows the user to contribute original or sourced content.  In one aspect, before any user-contributed content may be added to the system, the\ncontributed content is reviewed by a site content review team, which may consist of human reviewers, an automated software review system, or a combination thereof, to determine if the offered content is relevant and appropriate to aggregate with the site\ndatabase for subsequent presentation to other users.\nReferring to FIG. 8, the method and system likewise supports search by all available brands in the system.  For example, a user can search broadly by specific brands by clicking the \"All Brands\" dropdown selector 622 on the main web page 420,\nor, by using the search box 662 on the main web page 420 to find a specific brand.  Clicking the All Brands dropdown selector 622 presents the user with a brands list 624 of all brands associated with content in the system, arranged alphabetically. \nReferring to FIG. 32, selecting a particular brand will filter content results to that brand, displaying brand images 5120 representing products aggregated from the selected brand.  The All Brands dropdown selector 622 and its associated functionality is\navailable globally from any page of the website 400.\nReferring to FIG. 9, the main web page 420 includes an \"Occasions\" dropdown selector 642 that allows the user to access the Occasions function 640 and view products and content grouped by occasion categories 644, such as \"Job Interview,\" \"Date\nNight,\" \"Tech Startup,\" and others.\nReferring to FIG. 10, results are displayed on an Occasions results page 646.  A product may be associated with multiple occasions results.  The Occasions dropdown selector 642 is available globally from any page on the website 400.\nStyleGame Module 1000--Now referring to FIG. 11, the structure and operation of the StyleGame module 1000 is illustrated and described.  As previously indicated, a user creates his or her own unique StyleDNA 40 by \"playing\" the StyleGame 20.  In\ninitiate step 1100, the system prompts a user to start the StyleGame 20.  An objective of the StyleGame 20 is to complete an image matrix 1210.  At selection step 1200, to create a first StyleDNA 40, a new user is presented with one or more image groups\n1220 and prompted by the system to select one or more images 1225 from the image groups 1220 to populate the image matrix 1210.  Each image group 1220 displayed to the user is comprised of variable image content.  Each image 1225 is indicative or\nillustrative of various lifestyle preferences.  Image groupings 1220 are provided to a user in categorical or randomized presentation.  In one aspect, each image group 1220 includes images 1225 having a common category likely to be implicitly or\nexplicitly discernible to a user.  Exemplary categories include but are not limited to Cars, Movies, Music, Magazines, Cities, Objects, Alcohol Brands, Activities, Sports, Restaurants, and Houses.  Each image 1225 provided in a group 1220 is mapped via\nassociated metadata to an assessment engine comprising one or more proprietary algorithms.  Each algorithm is configured to assess an n-dimensional space for various style components.\nReferring to FIGS. 12A, 12B and 12C, an illustrative example of the process associated with playing of the StyleGame 20 is described.  At selection step 1200, where the user selects items to populate a StyleGame input matrix 1210, the user is\npresented with a first interface screen (FIG. 12A), where the user is prompted to select at least one image 1225 from a first image grouping 1220 to fill a first empty cell 1215 of the StyleGame input matrix 1210.  After this image 1225 is selected and\nadded to the StyleGame input matrix 1210 to fill the empty cell 1215, additional image groupings 1220 are subsequently presented to the user for selection of an image 1225 from each subsequent image grouping 1220.\nReferring to FIG. 12B, an exemplary screen shot of the StyleGame input matrix 1210 is shown just prior to completion.  Eight of nine cells 1215 have been filled and only one empty cell 1215 remains.\nReferring to FIG. 12C, the StyleGame input matrix 1210 has been completed by the user.  The system then displays an option button 1402 to the user to allow the user to submit the current completed StyleGame input matrix 1210 to the system for\nprocessing.  Once the user selects and activates the Submit button 1402, the method and system transforms the image selections in the StyleGame input matrix 1210 and generates a preliminary input vector 92 for the user.  The preliminary input vector 92\nis a transformational composite of the individual image selections 1225 gathered in the StyleGame input matrix 1210.\nOnce again referring to FIG. 11, and with additional reference to FIG. 2, upon completion of the StyleGame 20, the system ingests and processes the user vector 92 created at step 1300.  The system at step 1400 presents the user with an option to\nconfirm selection of the chosen images 1225 in the StyleGame input matrix 1210.  Once the user has confirmed his matrix choices, at step 1500, the system then creates a StyleGame StyleDNA 41 based on the user vector 92.  The system then performs one or\nmore calculations driven by one or more algorithms to create an association of the preliminary user vector 92 with one or more databases 60.  Each database 60 is comprised of a plurality of different items to which the preliminary user vector 92 will be\ncorrelated.  At a higher level, once the user confirms choices at step 1400, and the system creates the user's first StyleDNA 41 at step 1500, at step 1600, the system then finds and displays correlated items to the user.\nNow referring to FIG. 11, FIG. 13, and FIG. 14, when a user completes the StyleGame 20, at step 1500, the system creates and saves a unique StyleDNA 41.  This StyleDNA 41 is displayed on the user's Manage StyleDNA page 530 as \"StyleGame DNA\ndd-mm-yyyy\", wherein \"dd\" is the day of the month, \"mm\" is the month, and \"yyyy\" is the current year.  This first StyleDNA 41 is fully customizable and re-nameable.  Images in any StyleDNA 40 may be removed or replaced at any time with other images a\nuser has selected and made available within an area of the website 400 referred to as the MyDNA Holding Area 2140.  A user can create additional StyleDNA 40 using the results of the StyleGame 20 or by using new images selected from the MyDNA Holding Area\n2140.\nOnce the system has created a first StyleGame StyleDNA 41 based on the user's completion of the StyleGame 20, the user is presented with access to a main web page 420 of the StyleSeek website 400.  In one aspect, the StyleSeek main web page 420\nprovides access for the user to three primary web page tabs 430, 440.  450.  The user may interactively select any of the tabs using a selection device such as a mouse, a touch screen interface or vocal activation.  The tabs include \"EXPLORE\" 430, \"BUY\"\n440, and \"BRANDS\" 450.  A user selects any of these tabs 430, 440, 450 to access content that has been personalized for the user based on the user's currently selected and active StyleDNA 40.\nManage StyleDNA--Referring to FIG. 13, the block diagram illustrating the structure and operation of the Manage StyleDNA module 2000 is described.  For purposes herein, StyleDNA are generally referred to with the reference numeral 40.  However,\nvarious StyleDNA may be described with other reference numerals for clarification, such as, 1) first StyleDNA 41, 2) new StyleDNA 42, 3) newly created StyleDNA 43 and 4) User-shared StyleDNA 44.  The Manage StyleDNA module 2000 may be accessed from the\nManage StyleDNA page 530.  The Manage StyleDNA module 2000 serves as a portal to more advanced functions associated with creation or modification of StyleDNA 40.  First, the StyleGame StyleDNA 41, which is first created by the user, is accessible. \nAdditionally, other StyleDNA 40 are accessible.  Further, other images 1225 are accessible via an area referred to as the MyDNA Holding Area 2140.  The MyDNA Holding Area 2140 displays other images 1225 of interest previously saved by the user, which may\nbe selected for use in one or more of current or new StyleDNA 40.\nThe Manage StyleDNA module 2000 supports several functions.  Referring to FIG. 15, at step 2200, a user may rename existing StyleDNA 40.  Referring to FIG. 16, at step 2300, a user may create a new StyleDNA 42.  At step 2400, a user may delete\none or more of his stored StyleDNA 40.  At step 2500, a user may retake the StyleGame 20 to create a new StyleDNA 42.  At step 2610, a user may browse the pre-created StyleDNA 40 of others.  Finally, at step 2620, a user may import the StyleDNA 40 of\nothers.  A user may also view StyleDNA 44 that has been created and publicly shared by other users.\nHaving developed an initial StyleGame StyleDNA 41, and recognizing that a user's style preferences may evolve or change as driven by various factors, including time, environmental factors, peer influence, media, magazines, family, lifestyle or\nother such influences, the method and system allows the user to modify his existing StyleDNA 40 at any time.  The modification is performed by substituting an existing selected image 1225 with any other image 1225 within one or more image database 60. \nAs a user identifies a desired image 1225, he can elect to make a substitution at any time.  The system will then automatically update his StyleDNA 40 with a new set of images 1225 and a corresponding user vector 92.  The method and system provides\nreal-time functional interactive input by the user to change any or all of the images 1225 that drive and comprise his existing StyleDNA 40.\nThe method and system allows a user to create additional StyleDNA 40 specific to the user without abandoning either his first StyleGame StyleDNA 41 or other subsequently developed StyleDNA 40.  The system allows a user to create a second new\nStyleDNA 42 from a blank template using any image within a StyleSeek database 60.  As with creation of a first StyleDNA 41, the system provides a user interface associated with the StyleGame 20 wherein a user is provided searchable access to one or more\ndatabase 60 of StyleSeek images.  The user may then select one or more images 1225 to add to his StyleDNA 40 profile.  In one aspect, six images 1225 are selected to generate a subsequent query to populate and implement one or more algorithms used in\ncalculating a user's lifestyle input vector 92.  Throughout the operation of the system, a user may remove or replace images 1225 at any time.  With each change, the system dynamically creates an updated corresponding input vector 92 that overwrites the\nexisting input vector 92.  As a user creates one or more StyleDNA 40, individual StyleDNA 40 can be saved to a user's account profile.\nOnce a StyleDNA 40 has been completed, the system then allows a user to designate whether that StyleDNA 40 is eligible for sharing with other users.  The owner user may click an option button to publish the image set associated with his or her\nselected StyleDNA 40 onto a public facing website, Shared StyleDNA 2630.  When published, other users can copy the User-shared StyleDNA 44, incorporate the User-shared StyleDNA 44 within their own user profile, and add the User-shared StyleDNA 44 to\ntheir store of other StyleDNA 40.  This may be accomplished by the Import StyleDNA function 2620 of the system.  A user may elect to enable or disable sharing of his StyleDNA 40 at his discretion.  In one aspect, any User-shared StyleDNA 44 previously\nshared and accessed by other users, will remain available to those users.  In another aspect, once a user elects to stop sharing his or her StyleDNA 40, the system will automatically extract the previously shared StyleDNA 44 from other user accounts. \nAlternatively, the system will support updates of a User-shared StyleDNA that are offered to those users currently sharing the specific StyleDNA.\nBefore a user can incorporate a User-shared StyleDNA 44 in the user's own account, the system requires the user to import the User-shared StyleDNA 44 into the user's account profile using Import StyleDNA 2620 function.  The system provides user\naccess to a database of User-shared StyleDNA 44.  The User-shared StyleDNA 44 are provided for access via Shared StyleDNA 2630 on a public facing Internet or web page.  New or existing users may click an option button on the User-shared StyleDNA 44 page\nto import images and input vectors associated with other shared StyleDNA 44 into their personal accounts.  Importation produces a local copy of the User-shared StyleDNA 44 in the user's account, allowing it to be used to create or modify existing\nStyleDNA 40, or, for sharing with others.\nPreferences change; attitudes change; moods change which may affect preferences.  Consequently, the system provides users with the option of selecting and activating any of their StyleDNA 40 at any time.  At a main web page 420 of the StyleSeek\nwebsite 400, a user can see all of the StyleDNA 40 vectors and image sets he has available for use.  The user simply selects a StyleDNA 40 from his library to activate that StyleDNA 40.  The activated StyleDNA 40 will then be used by the system as a\nbasis for generating recommendations until the user changes and activates another StyleDNA 40\nReferring to FIG. 17, a user can create new StyleDNA 40 through two options accessible via the Manage StyleDNA page 530.  In a first option, the user selects the \"+\" sign 2310.  Alternatively, the user can click the \"CREATE StyleDNA\" button 2302\nat the top right of the Manage StyleDNA page 530.  Creating New StyleDNA 42 will create a blank StyleDNA template 2133 with six boxes.  The user is then able to name the newly created StyleDNA 40 and customize the contents of the new StyleDNA 40 by\nselecting and dragging in any images 2142 from the MyDNA Holding Area 2140 on the page.  The user can hover over images 2142 in the StyleDNA template 2133 to reveal a \"Remove\" button 2135.  Selecting the \"Remove\" button will delete the image 2142 from\nthe StyleDNA template 2133, returning it to the MyDNA Holding Area 2140 and leaving a blank box that may be filled with other images 2142 from the MyDNA Holding Area 2140.\nAny image 1225 available through the databases 60 of the system can be added to the MyDNA Holding Area 2140 by clicking an \"Add to MyDNA\" button 3202 that appears when the user hovers over any image 1225 displayed by the system.  The image 1225\nis then converted and identified as a MyDNA Holding Area image 2142.\nWhen an image 2142 is added to the MyDNA Holding Area 2140, it becomes immediately available for use in any of the user's existing or newly created StyleDNA 40.  Images 2142 added to the MyDNA Holding Area 2140 do not influence a user's\nStyleSeek results until the user adds them to an existing StyleDNA 40 and activates the new/modified StyleDNA 40.  Hence, a user can freely add any images 2142 to the user's MyDNA Holding Area 2140 as the user browses the system site.  In addition, a\nuser may delete any or all images 2142 from the MyDNA Holding Area 2140.\nReferring to FIG. 2, in an alternative aspect, the method and system implements a set 94 of additional vectors to modify the application and comparison between the user vector 92 and item/brand/content vectors 93.  For example, the method and\nsystem computes a separate MyDNA input vector 95 from an algorithmic aggregation of the images 2142 in the MyDNA Holding Area 2140.  The system may then use the MyDNA input vector 95 to influence preferences presented to a user.  The system will allow\nthe MyDNA input vector 95 to be ascribed a lower, equal or higher weight than the aggregate user input vector 92 developed via the StyleGame 20.  In an additional alternative aspect, the method and system tracks and correlates those images that are\nremoved from the MyDNA Holding Area 2140 or from existing StyleDNA 40.  These deleted images may then be used by the system to create an additional MyDNA deleted images input vector 96.  Again, this deleted images vector 96 may be ascribed a lower, equal\nor higher weight than other vectors.  The system may then be configured to apply any of these vectors with differing weight during the correlation step to refine preferences presented to a user.  Still further, in another alternative aspect, the user\nvector 92 may be adapted by the system to be address and consider a user's specific likes and dislikes.  The user may indicate specific images or items as liked or disliked, such indications tracked by the system in a like filter vector 97 and a dislike\nfilter vector 98.  Other filter vectors 99 may be likewise be applied for other types of filters and processed by the system during the refinement of preferences and before display of recommendations back to the user.\nEXPLORE Module--Now referring to FIG. 21, the structure, function and operation of the EXPLORE module 3000 is disclosed.  By selecting the EXPLORE page tab 430 on the main StyleSeek web page 420, the Display Items Related to Active StyleDNA\nfunction 3100 is invoked, presenting the user with a selection of blog posts and reviews which the system has scoured and aggregated from across the Internet.  The method and system personalizes the presented selections according to the user's currently\nactive StyleDNA 40.  Selection of the EXPLORE page tab 430 by the user triggers the presentation to the user of a personalized digital magazine 3105 wherein all the images and articles are selected specifically for the user based on his StyleDNA 40.  At\nstep 296, the user may change the currently active StyleDNA 40 if he wishes to view a display of items selected with a different StyleDNA 40.\nAlso, as elsewhere within the StyleSeek website 400, while active within the EXPLORE module 3000, the user may elect to add items 1225 to the MyDNA holding area 2140.\nFurther, the system allows a user to view additional detail for a selected item.  Selecting any item within the personalized digital magazine 3105 on the EXPLORE page 430 displays an item detail page 432 providing additional information\nconcerning the item.  By selecting and invoking View Item Selection Detail function 3300, an item detail page 432 is presented containing a diverse set of information related to the selected item.  In one aspect, the item detail page 432 contains\nrelevant pictures, one or more short excerpts from relevant blog posts, and/or one or more links to the full text of each blog post or related items.  The system supports delivery of multiple forms of content on the item detail page 432 including\npublished articles, magazine reviews, detailed specifications and other narrative, graphic or descriptive content.\nAgain, as the user views detail associated with a selected item, any item from that detailed view may likewise be added to the MyDNA holding area 2140.  This immediate functionality allows a user to lever subliminal or visceral response to the\nitem and consider it for future use in his or her StyleDNA 40.  Further, the user may select and invoke the Visit External Source Articles Offsite function 3330 to access external articles outside the primary StyleSeek website 400.  Additionally, a user\nmay view Related Items 3350.\nFIG. 22 is an exemplary screen shot of a representative StyleSeek main web page 420 illustrating a personalized digital magazine 3105 with display of personalized items 3110 to a user.\nNow referring to FIG. 23A and FIG. 23B, while still within the EXPLORE page 430, a user may hover his pointing device over any item image to trigger an overlay 3130 displaying a headline relative to the content of the image and an option to add\nthe image to the user's MyDNA.  The user may then elect to add the image to the MyDNA Holding Area 2140 by selecting \"ADD TO MyDNA\" 3202, which invokes the Add Item Selection to MyDNA Holding Area function 3200.  As shown in FIG. 23B, the system will\nnotify the user that the particular item has been added to the MyDNA Holding Area 2140 by changing the overlay 3130 to show the text \"ADDED!\" 3220 in place of \"ADD TO MyDNA\" 3202.\nNow referring to FIG. 24, while still within the EXPLORE page 430, the user may also elect to explore the item detail page 432 and then select and add an item from that page to the MyDNA holding area 2140.  The user may also elect to drill down\ninto other elements such as the Visit Source Article Offsite hyperlink 3330 or view Related Item 3350, which will provide additional opportunities to add items to the MyDNA holding area 2140.\nThe functionality associated with the EXPLORE page 430 allows a user to freely explore and drill down throughout items displayed and continuously acquire images of items and add to the MyDNA Holding Area 2140 at any time.  This continual ability\nto acquire images representative of a user's lifestyle preferences at any time allows the system to adapt and leverage the user's visceral response to images and content.\nEXPLORE Blog Browse--A user may also buy products from blog posts presented via the EXPLORE page tab 430.  Note that the system allows a user to buy products from any content or article delivered to the user, including but not limited to email\nor text messages.  When reviewing articles in a blog post, relevant brands and products are presented to the user in a \"Related Items\" section 3350 of the Explore page.  When a product is available for purchase, the system will list the item in this the\nRelated Items section 3350.  A user may then elect to pursue purchase of the item by clicking on the image of the item of interest.  Then, as before, the system navigates the user to a specific product page where the user can purchase the item without\nfurther interaction from the StyleSeek system.  Again, the separation between the StyleSeek system and the product sellers ensures that the algorithmic and database aspects of the method and system may remain pure and untainted by other non-stylistic\ninfluences from retailers or vendors of the various products or services.\nNow referring to FIG. 25, the system provides a means to allow a user to identify the currently active StyleDNA 40, and, to change from one StyleDNA 40 to another StyleDNA 40.  In an upper left corner of the main web page 420, a smaller\nclickable image 2852 is presented.  The clickable image 2852 represents and correlates to the user's currently active StyleDNA 2920, which is used by the system to personalize the user's experience.  By selecting the clickable image 2852, the system\ncauses a separate dropdown list 2910 to be presented to the user.  The dropdown list 2910 presents icons for all the StyleDNA 40 currently in the user's account.  The user can elect to select and activate another of his existing StyleDNA 40 from the\ndropdown list 2910.  Alternatively, he may select the option, Manage StyleDNA, which will launch him to the \"Manage StyleDNA\" page 530 to further change or customize one or more of his StyleDNA 40.\nBUY Module--Now referring to FIG. 27 and FIG. 28, the function and operation of the BUY module 4000 is disclosed.  The selection of the BUY web page tab 440 causes the presentation of a new web page that invokes the Display Products Related to\nActive StyleDNA function 4020, displaying product items 4040 available for purchase based on the user's unique StyleDNA 40.  These products are generally presented in a manner that allows them to be purchased immediately via an e-commerce portal\nassociated with the product.  The user can directly add an item to the user's MyDNA Holding Area 2140 by hovering over the product item 4040 and invoking the Add Product Selection to MyDNA Holding Area function 4200.  Clicking an item on the BUY web page\n440 invokes the View Product Selection Detail function 4300 and displays a full product detail page 442, where a user is presented with additional detail about the item, including price alternatives, product reviews, and where the item might be\npurchased.  The user may select a View Brand Page link 4340 to view the page associated with the particular brand of the selected product.\nRelated Articles--Referring to FIG. 27, the method and system provides functionality that allows a user to browse and view related blogs posts, articles, reviews and other content in a \"Related Articles\" area 4350 displayed on individual full\nproduct detail pages 442.  Related articles may be displayed based on similarity in style of the article topics to the selected product or other criteria describing specific user interests and lifestyle preferences.\nProduct Alternatives--Referring again to FIG. 27, the method and system also provides functionality that allows a user to browse and view alternative products in \"Product Alternatives\" 4361 displayed on individual full product detail pages 442. \nAlternative products are defined herein as products that are very similar in style to the selected product, but are available in different price ranges.  The \"Product Alternatives\" area 4361 of an individual full product detail page 442 includes other\nitems of the same basic type (for example, pants, belts, or jackets) as a selected product that are deemed by the function 4360 of the method and system to be related in style to the selected product.  In one aspect, alternative products are arranged and\npresented to a user by price, arranged low to high.  In another aspect, the alternative products are filtered to display products in a desired price range selected by the user.  Thus, the system allows a user to explore various items without concern for\nprice, and then later, adapt recommendations and selections to conform to a predetermined price range.  Likewise, an additional aspect of the system allows a user to create a StyleDNA 40 without considering price.\nComplete The Look--Referring again to FIG. 27, the system provides a Complete the Look function 4370 to allow a user to select additional products to complement their existing stylistic configuration.  A \"Complete the Look\" area 4371 of an\nindividual full product detail page 442 includes other items that are deemed by the Complete the Look function 4370 of the method and system to be related in style to a selected product.  The method and system applies a user's StyleDNA 40 to identify\nother correlated items that are deemed to pair well with a product currently under review by the user.  For example, the system may present a pair of pants for consideration to the user wherein those pants have been deemed to stylistically complement and\ncorrelate with a pair of shoes the user is contemplating.  In one aspect, the system includes and presents items in the \"Complete the Look\" area 4371 that are in the same relative price range as the main product being viewed by the user.  The user can\nrefresh the recommendations in \"Complete the Look\" 4371 by clicking the Refresh button within that section, or by refreshing the web browser.  This refresh causes the system to present a new set of correlated items deemed to pair with the item currently\nunder consideration.  This rapid refresh of alternatives once again allows a user to leverage their visceral response to images to continually transform and evolve their StyleDNA.\nPrice Filtering--Referring to FIG. 28, the system also allows a user to modify or normalize their StyleDNA 40 to the user's desired price range.  The system provides two alternatives to filter presented products by price range.  First, when in\nthe BUY web page 440, the user can check one of the price filter options 4120 at the top right hand corner of the page.  The price filter options 4120 are presented as $, $$, $$$, and $$$$, where a single $ represents the lowest price, ranging to the\nhighest prices represented by the $$$$.  Second, the system allows a user to filter by price on an individual product page using the same selection criteria.  This filtering functionality delivered by the system allows the user to browse through the\nProduct Alternatives 4362 to view items of the same style in a price range acceptable to the user.\nNow referring to FIG. 29, in greater detail, shown on the full product detail page 442 is a section referred to as the Complete the Look area 4371, displaying results of the Complete the Look function 4370.  This area displays to the user other\nitems that the system deems related in style to a selected product and expects to pair well with that product.  Items displayed to the user in the Complete the Look 4371 area are selected by the system to fall in the same price range as the main product\nthe user is viewing.  The user may select an item to activate the View Complete the Look Product Selection Detail function 4372 and display the full detail page for the item.  Another function activated when a user visits the full product detail page 442\nis Product Alternatives 4360.  The Product Alternatives area 4361 of the product detail page 442 displays to the user other products of the same type deemed by the system to be very similar in style to the selected product and of potential interest to\nthe user.  The user may select an item to activate the View Product Alternative Selection Detail function 4362 and display the full detail page for the item.\nVendor Neutrality--Referring to FIG. 27 and FIG. 29, when viewing individual full product detail pages 442 on the StyleSeek site 400, the user selects and clicks a buy button 4330, which is typically presented to the right of the product image,\nto connect directly with the seller of the product.  Upon connection with the product seller, the user may elect to complete a purchase of a recommended product.  The method and system is implemented in a manner that maintains neutrality in\nrecommendations to users to ensure that any recommendations are driven by user-centric preferences and not vendor-centric sales preferences.  Hence, to maintain this neutral position on product selection and matching to users, the system is designed to\nconnect users directly with the sellers of products of interest.  Consequently, since the method and system are neither driven nor influenced by a desire to reduce existing product inventory, the method and system ensures purity in its recommendations,\nindependent of current economic drivers.  Consequently, the method and system provides direct connectivity to sellers.  Of course, in another aspect, the system may be configured to provide recommendations limited to certain brands, thus supporting the\nuse of the system as a marketing tool for a specific retailer or designer.\nBRANDS Module--Next, referring to FIG. 30 and FIG. 31, the function and operation of the BRANDS module 5000 is disclosed.  Selection of the BRANDS web page tab 450 activates the Display Brands Related to Active StyleDNA function 5100, causing\nthe system to display an assortment of brands which the method and system have deemed most relevant to the user's style, based upon the user's unique StyleDNA 40.  The user can directly add an item to the user's MyDNA Holding Area 2140 by hovering over\nthe brand item 5110 and invoking the Add Brand Selection to MyDNA Holding Area function 5200.  Selecting and clicking any brand item 5110 will activate the View Brand Selection Detail function 5300, displaying the item's own brand detail page 452 that\nincludes representative collages, blog reviews, and products.\nReferring to FIG. 33, the brand detail page 452 presents the user with further information about the selected brand, as well as several functions.  The user may select a Visit Brand Website hyperlink 5330 to access the external website, if\navailable, associated with the selected brand.  Furthermore, the brand detail page 452 contains sections for Brand Products 5340, displaying images with information and links to product detail pages 442 for products of the selected brand.  Also shown is\na section allowing the user to View Articles Featuring Specific Brand Products 5350, which aggregates links to articles from the site related to the selected brand.\nActive StyleDNA and Personalization--A user is able to manage his StyleDNA 40 throughout the StyleSeek website 400.  Referring to FIG. 26, we show an exemplary screen where the user has selected and activated a different StyleDNA 40, and thus,\nthe image associated with that particular StyleDNA 40 is now shown in the clickable image 2852 as the currently active StyleDNA 40.  In addition, the display of items 3110 displayed to the user has likewise changed to reflect the activation of the other\nStyleDNA 40.\nTo further manage his StyleDNA 40, the user may also select a StyleDNA link 531 above the search bar on the main StyleSeek web page 420, or from any page globally on the website, to access the Manage StyleDNA page 530.\nThe resulting StyleDNA 40 developed by the method and system through interaction with a user personalizes the user's StyleSeek experience.  The user's StyleDNA 40 tells the system what products and content are likely most relevant to display to\nthe user.  In one aspect, a user's StyleDNA 40 is represented by six images.  These six images are determined by the system to be the six strongest graphical representations of the user's personal style, selected from the system's database of items or\nproducts.  In additional aspects, a user can select more than six images to represent the user's individual style.  Additionally, the method and system likewise allow a user to create and experiment with alternative images to create additional StyleDNA\n40.\nImport StyleDNA--Referring to FIG. 13, the method and system provides software functionality to allow a user to browse and import one or more Pre-created StyleDNA 43 into his account 700.  Once imported, additional StyleDNA 40 can be activated\nand used to browse the StyleSeek system for content, products, and brands reflective of that Pre-created StyleDNA 43.  Pre-created StyleDNA 43 can be based upon personal or speculative preferences of real or fictional characters such as Kanye West,\nIndiana Jones, Mike Tyson, an Ivy-league university professor, a southern California surfer, current or past Presidents, or other such notable personas or individuals.  When leveraging an imported StyleDNA 40, a user is able to view the entire StyleSeek\nwebsite 400 and have a user experience as if the user were viewing the StyleSeek website 400 through the eyes of the person who created or is represented by the imported StyleDNA 40.  By enabling this experience, the method and system viscerally and\nsubliminally allows a user to refine his personal preference, which may influence the creation, modification or refinement of his StyleDNA 40.\nTo import a Pre-created StyleDNA 43, a user navigates to his Manage StyleDNA page 530 and clicks \"Browse\" 536 to view a variety of importable Pre-created StyleDNA 43 profiles that the user can select for activation.  Selecting the Browse link\n536 launches the user to a new Browse web page 540, as shown in FIG. 18.  The user clicks on any profile that interests him to view its full importable Pre-created StyleDNA 43 in a Browse selection detail page 542, shown in FIG. 19.  If the user still\nwishes to import the specific Pre-created StyleDNA 43, the user clicks the \"Import this DNA\" button 2622 to import the new Pre-created StyleDNA 43 to the user's account 700.  All imported StyleDNA 40, whether Pre-created StyleDNA 43 or Shared StyleDNA\n44, are contained separately within the Imported StyleDNA module 2120.  StyleDNA 40 in Imported StyleDNA 2120 can be activated and used to browse the StyleSeek system, but cannot be modified by the user.\nReferring to FIG. 20, the imported StyleDNA 40 will appear in the imported web page 550 of the user's Manage StyleDNA 530 page.  The user can access the Imported web page 550 by selecting the Imported link 534 from within the StyleDNA site\nsection 510.  Once imported, the imported StyleDNA 40 can be activated to start browsing the StyleSeek system and application as that imported profile.  The imported StyleDNA 40 may also be selected and viewed in full by the user in an Imported selection\ndetail page 552.  From other sections or pages of the StyleDNA site section 510, the user may select the MyDNA link 532 to return to the Manage StyleDNA page 530.\nAs with the user's original StyleDNA 40 inventory, a user may activate any imported and saved StyleDNA 40 by selecting the same image 2852 at the top left hand of the StyleSeek main web page 420.  Selecting the clickable image 2852 causes the\npresentation of a dropdown list of the user's available StyleDNA 40, including any Pre-created StyleDNA 43 and User-shared StyleDNA 44, from which the user can select any StyleDNA 40 and immediately be presented with updated results from the system.\nA user can likewise share any of his own StyleDNA 40 with other users of the StyleSeek community.  A user shares one or more of his StyleDNA 40 by first selecting any of the StyleDNA 40 listed on the user's Manage StyleDNA page 530 and then\nselecting the option to share the selected StyleDNA 40.\nThe user invokes the function 3200 by clicking the button 3202 to add items to the user's MyDNA holding area 2140, or, as the user adds and changes any images associated with his StyleDNA 40, the system immediately provides access for the user\nto purchase the products associated with the images of any of the items he may have just added.  This feature of the system supports the ability to satisfy the whims of the user, when circumstances, emotions or other motivators might cause the user to be\nhighly motivated to purchase the product.  As with products presented via application of a specific StyleDNA 40, to purchase a product, a user clicks on the image 2142 associated with a product.  The user is then taken to a detailed individual page\nassociated with the product where the user is provided with a link to complete the purchase.\nThe method and system allows a user to develop multiple StyleDNA 40.  A user is not limited to the StyleDNA 40 generated by the first playing of the StyleGame 20.  The StyleGame 20 functionality is always accessible from the Manage StyleDNA page\n530 and may be accessed by clicking the \"RETAKE StyleGame\" button 2502.  Retaking the StyleGame 20 causes the system to interactively create and add a new StyleGame StyleDNA 41 to the user's profile.  The new StyleGame StyleDNA 41 does not overwrite the\nuser's previous StyleDNA 40.\nJust as a user may select a StyleDNA 40 by hovering, a user may likewise elect to delete any StyleDNA 40 at any time by hovering over a StyleDNA 40 in the Manage StyleDNA page 530 and clicking the \"x\" that appears.\nBrand Selection Criteria--In one aspect, the computer-implemented method and system causes specific brands to be selected for inclusion in the database based on one or more criteria.  Exemplary criteria include a strong representation of style,\nan online brand presence, and products available for sale through an online retail channel.  A strong representation of style is deemed the most important criterion.  Other criteria are relevant in providing convenience to the user of the site by\nallowing well-represented brands to be easily purchased.\nInput Management Method--Now, in additional detail, the method by which various inputs 105 are managed and used to generate StyleDNA 40 and other outputs 205 are described.\n1.  Dimension Mapping--First, style characteristics are determined for each item.  For example, in one aspect, key elements identified for men's fashion are: (1) structure (sharpness, rigidity); (2) color combinations; (3) texture (material\nsoftness, thickness); (4) anchoring and supplemental accessories (such as hats, glasses, ties, shoes, belts, watches, and hair style); and (5) history/origin of the style.  These style characteristics form a basis for the item/brand/content vector 93.\n2.  Inputs 105--To compare users to brands and lifestyle items, an n-dimensional user vector 92 is created for the user with n being the number of style dimensions used.  In one aspect, the number of style dimensions used is nine.  The user\nvector 92 is created by first having the user select lifestyle images from pre-determined categories that are strongly correlated to the style dimensions.  Each lifestyle or brand image will have its own image vector 91.  A variety of lifestyle elements\nand brands can be used for this purpose, but exemplary elements and brands from a preferred embodiment include Movies, Cars, Music/Bands, Magazines, Restaurants, Cities/Locations, Houses/Architecture, Lifestyle Items, Lifestyle Activities, and Alcohol\nBrands.\nFor example, in one aspect, the user is first shown nine images from popular movies.  These images are representations or combinations of each of the nine style dimensions used for men's clothing.  After selecting an image, the user is assigned\nthe appropriate value(s) for those positions within an input array.\n3.  Outputs 205--The user vector 92 is subsequently compared to individual items and brands via one or more computer algorithms wherein the user vector 92 is correlated against the item/brand/content vector 93.  The top matches are recommended\nto the user to allow for purchase, browsing, and comparison.  At this point, the user can buy the items directly from the site or through pre-established affiliate networks via a referral system.  The user can also be shown relevant brands, \"looks\", and\noutfits that map to his style.\nThe user may opt to perform additional actions such as: (1) liking/disliking items or brands; (2) browse other users \"digital closets\" who have purchased, searched or own items; (3) \"follow\" other users based on their choice of style; (4) make\ncomments; on items/brands/other user profiles and make recommendations to others; (5) enter personal fit data and measurements, and add their favorite brands to their profile; (6) record comments regarding fit for particular items and brands; and (7) add\nitems that they own or want to a digital closet that other users may view.\nAs the user goes through these actions, a secondary algorithm allows for simple additional recommendations such as \"see items similar to this.\" These recommendations may be based on other user actions and provide an additional level of\npersonalization.\nAdditionally, in another aspect, the system will evaluate the likelihood that an article of clothing will physically fit a user based on his profile information, and the fit data gathered from other users.  For instance if a shirt is owned by\nuser A, and user B has similar body type dimensions (from his profile), the system will indicate that it is likely that the shirt will also fit user B.\n4.  Computer-implemented Algorithms--Calculating the correlation between a user vector 92 and item/brand/content vectors 93 is performed using a computer processor.  The correlation may be a computationally expensive process and, hence, in an\nalternative embodiment, the method and system benefits from application to flexible cloud computing infrastructure to allow rapid response.  Although the operative algorithm implemented may be fundamentally direct, the processing of the algorithm to\ntransform inputs 105 from a user into relevant outputs 205 and associated recommendations to the user, requires significant computational and storage overhead.  Iterating on tens of thousands of items, including all dimensions of the vector 93 for each\nitem or brand, creates a significant computational and storage overhead.\nIn another aspect, the results are cached.  Where a user vector 92 may change over time and the number of possible image vectors 91 or item/brand/content vectors 93 can expand, another aspect incorporates preprocessing of all relevant vectors to\nexpedite presentation of the output of those vectors to a user.  Again, implementation of either of the cache or preprocessing will still benefit via implementation using a cloud infrastructure to allow access to computing and data storage resources as\nneeded to ensure timely response to users.\nIn another aspect, the method and system supports pre-processing for a subset of possible vectors and approximating results based on these vectors.  Thus, the method and system expedites the assessment through a large number of items to identify\na smaller representative number for individual consideration.\nOther algorithmic approaches may be used and implemented as features of the method and system, including matching on aligned dimensions.\nAlternatively, an aspect of the method and system may be implemented without the requirement of approximating subsets.  Instead, the system iterates across all matched items for every request, and then determines individual scores, avoiding an\napproximation approach.\nAdditionally, the method and system can leverage score lookup tables for each user.  Such lookup tables are computationally intensive and require significant data storage space but would be applicable where the availability or cost of storage\nspace is not a significant factor.\nThe method and system may also deploy a hybrid approach where actual user vectors 92 are clustered to provide feedback for refinement of the applicable algorithms used by the system to match user vectors 92 with item/brand/content vectors 93.\nFurther, in another aspect of the method and system, different data structures may be implemented.  For example, data structures such as KD-trees will provide efficient lookups of \"nearby\" items, even in multiple dimensions.  However, this data\nstructure can be difficult to coordinate across the entire software stack.  Hash tables are another alternative to support pre-computation of results to shorten lookup times.  In another aspect, the method and system stores the scores in the database\nwith the items, allowing a SQL query to use the scores for sorting.  In this way, the score table acts roughly as a hash table would for the end user: acting simply as a reasonably efficient key-value store.\nProcessing Environment--Now referring to FIG. 34, the method and system is implemented across a global network, generally supported by the Internet and the World Wide Web.  FIG. 34 illustrates a computer network or similar digital processing\nenvironment 6000 in which the method and system may be implemented.  Client computer(s)/devices 6050 and server computer(s) 6060 provide processing, storage, and input/output devices executing application programs and the like.  Client\ncomputer(s)/devices 6050 can also be linked through communications network 6070 to other computing devices, including other client devices/processes 6050 and server computer(s) 6060.  Communications network 6070 can be part of a remote access network, a\nglobal network (e.g., the Internet), a worldwide collection of computers, Local area or Wide area networks, and gateways that currently use respective protocols (TCP/IP, Bluetooth, etc.) to communicate with one another.  Other electronic device/computer\nnetwork architectures are suitable.\nFIG. 35 is a diagram of the internal structure of a computer (e.g., client processor/device 6050 or server computers 6060) in the computer system of FIG. 34.  Each computer 6050, 6060 contains system bus 6179, where a bus is a set of hardware\nlines used for data transfer among the components of a computer or processing system.  Bus 6179 is essentially a shared conduit that connects different elements of a computer system (e.g., processor, disk storage, memory, input/output ports, network\nports, etc.) that enables the transfer of information between the elements.  Attached to system bus 6179 is an Input/Output (I/O) device interface 6182 for connecting various input and output devices (e.g., keyboard, mouse, displays, printers, speakers,\netc.) to the computer 6050, 6060.  Network interface 6186 allows the computer to connect to various other devices attached to a network (e.g., network 6070 of FIG. 21).  Memory 6185 provides volatile storage for computer software instructions 6192 and\ndata 6194 used to implement an embodiment (e.g., object models, codec and object model library discussed above).  Disk storage 6195 provides non-volatile storage for computer software instructions 6192 and data 6194 used to implement an embodiment. \nCentral processor unit 6184 is also attached to system bus 6179 and provides for the execution of computer instructions.\nIn one aspect, the processor routines 6192 and data 6194 are a computer program product, including a computer readable medium (e.g., a removable storage medium, such as one or more DVD-ROM's, CD-ROM's, diskettes, tapes, hard drives, etc.) that\nprovides at least a portion of the software instructions for the method and system.  Computer program product can be installed by any suitable software installation procedure, as is well known in the art.  In another embodiment, at least a portion of the\nsoftware instructions may also be downloaded over a cable, communication and/or wireless connection.  In other embodiments, the method and system programs are a computer program propagated signal product embodied on a propagated signal on a propagation\nmedium 6007 (e.g., a radio wave, an infrared wave, a laser wave, a sound wave, or an electrical wave propagated over a global network, such as the Internet, or other network(s)).  Such carrier medium or signals provide at least a portion of the software\ninstructions for the routines/program 6192.\nIn alternate aspects, the propagated signal is an analog carrier wave or digital signal carried on the propagated medium.  For example, the propagated signal may be a digitized signal propagated over a global network (e.g., the Internet), a\ntelecommunications network, or other network.  In one embodiment, the propagated signal is a signal that is transmitted over the propagation medium over a certain time period, such as the instructions for a software application sent in packets over a\nnetwork over a period of milliseconds, seconds, minutes, or longer.  In another embodiment, the computer readable medium of computer program product is a propagation medium that the computer system may receive and read, such as by receiving the\npropagation medium and identifying a propagated signal embodied in the propagation medium, as described above for computer program propagated signal product.\nThe term \"carrier medium\" or transient carrier encompasses the foregoing transient signals, propagated signals, propagated medium, storage medium and the like.\nWhile numerous aspects and embodiments of the inventive subject matter have been particularly shown and described with references to specific elements or features thereof, it will be understood by those skilled in the art that various changes in\nform and details may be made therein without departing from the scope of the inventive subject matter encompassed by the appended claims.\nFor example, the method and system may be implemented in a variety of computer architectures.  The computer network of FIG. 34 and FIG. 35 is for purposes of illustration and not limitation of the inventive subject matter.\nAs contemplated herein, various aspects and embodiments of the inventive subject matter can take the form of an entirely hardware embodiment, an entirely software embodiment or an embodiment containing both hardware and software elements.  In\none embodiment, the inventive subject matter is implemented in software, which includes but is not limited to firmware, resident software, microcode, and other forms.\nFurthermore, embodiments of the inventive subject matter can take the form of a computer program product accessible from a computer-usable or computer-readable medium providing program code for use by or in connection with a computer or any\ninstruction execution system.  For the purposes of this description, a computer-usable or computer readable medium can be any apparatus that can contain, store, communicate, propagate, or transport the program for use by or in connection with the\ninstruction execution system, apparatus, or device.\nThe medium can be an electronic, magnetic, optical, electromagnetic, infrared, or semiconductor system (or apparatus or device) or a propagation medium.  Examples of a computer-readable medium include a semiconductor or solid-state memory,\nmagnetic tape, a removable computer diskette, a random access memory (RAM), a read-only memory (ROM), a rigid magnetic disk and an optical disk.  Some examples of optical disks include compact disc-read only memory (CD-ROM), compact disc read/write\n(CD-R/W) and DVD.\nA data processing system suitable for storing and/or executing program code will include at least one processor coupled directly or indirectly to memory elements through a system bus.  The memory elements can include local memory employed during\nactual execution of the program code, bulk storage, and cache memories, which provide temporary storage of at least some program code in order to reduce the number of times code are retrieved from bulk storage during execution.\nInput/output or I/O devices (including but not limited to keyboards, displays, pointing devices, touch screens, gesture recognition interfaces, smart phones, kiosks, RFID identifiers, smart cards, etc.) can be coupled to the system either\ndirectly or through intervening I/O controllers.\nNetwork adapters may also be coupled to the system to enable the data processing system to become coupled to other data processing systems or remote printers or storage devices through intervening private or public networks.  Modems, cable modem\nand Ethernet cards are just a few of the currently available types of network adapters.\nThus, specific compositions and methods of the computer-implemented method and system for recommendation system input management have been disclosed.  It should be apparent, however, to those skilled in the art that many more modifications\nbesides those already described are possible without departing from the inventive concepts herein.  The inventive subject matter, therefore, is not to be restricted except in the spirit of the disclosure.\nMoreover, in interpreting the disclosure, all terms should be interpreted in the broadest possible manner consistent with the context.  In particular, the terms \"comprises\" and \"comprising\" should be interpreted as referring to elements,\ncomponents, or steps in a non-exclusive manner, indicating that the referenced elements, components, or steps may be present, or utilized, or combined with other elements, components, or steps that are not expressly referenced.", "application_number": "14433624", "abstract": " A user-centric computer-implemented method and system for managing inputs\n     and creating, modifying, importing, and sharing one or more user\n     lifestyle preference profiles as input into a relevance assessment engine\n     to determine a user's product or service preferences comprises a\n     personalized recommendation software for assessing and aggregating\n     lifestyle items via style dimension mapping of one or more\n     computer-implemented algorithms to process image-associated metadata to\n     create unique vector inputs, individualized lifestyle preference indices,\n     and lifestyle preference outputs, associated with a plurality of\n     correlated products, services and experiences. The recommendation system\n     then directly matches each user to discrete relevant items without the\n     need for management of historical data from other users.\n", "citations": ["20080209350", "20090018926", "20110093361", "20120089623"], "related": ["61710564"]}, {"id": "20160057095", "patent_code": "10277551", "patent_name": "Methods and systems for providing current email addresses and contact\n     information for members within a social network", "year": "2019", "inventor_and_country_data": " Inventors: \nFox; Kevin David (Sunnyvale, CA), Hess; Duane Scott (Mountain View, CA)  ", "description": "<BR><BR>FIELD OF THE INVENTION\nThe invention generally relates to social networks.  More particularly, the invention relates to methods and systems for providing current email addresses and contact information for members within a social network.\n<BR><BR>BACKGROUND\nConventional web email systems such as those hosted on Yahoo!.TM., Hotmail.TM.  or other web sites, facilitate communication between people.  These conventional websites generally do not provide a central repository for maintaining current email\naddresses for members within a social network.  Similarly, conventional email client systems such as Outlook.TM.  encounter similar problems in that the email addresses stored in a user's address book or contact list are not always current.  In addition\nto email addresses, electronic address books typically do not maintain current contact information.\nTypically, a user must physically enter contact information for each contact in a user's address book or contact list.  Recently, V-cards have helped in reducing the actual typing required to enter a new contact into a user's address book or\ncontact list.  Unfortunately, contact information including email addresses is not static, thus a user must update his or her address book or contact list whenever a contact changes his or her contact information.  However, in order to maintain current\ncontact information, the user must be aware of the changes.\n<BR><BR>SUMMARY\nEmbodiments of the present invention comprise systems and methods for providing current email addresses and contact information for members of a social network.  One aspect of an embodiment of the present invention comprises receiving a request\nfor an email address of a first member of a social network, the request comprising an entity identifier associated with the first member; determining an email address for the first member using profile information associated with the first member,\nreturning the email address in response to the request; and inserting the email address into a sending parameter of an email message.\nAnother exemplary method of one embodiment of the present invention comprises receiving a request for contact information associated with a first member of a social network, the request comprising a first entity identifier associated with the\nfirst member and a second entity identifier associated with the requester of the contact information, determining if the requester is authorized to receive the contact information using profile information associated with the first member, sending the\ncontact information to the requester if authorized, comparing the sent contact information with the contact information for the first member in an address book associated with the requester, and replacing differing contact information associated with the\nfirst member in the address book with the corresponding sent contact information.\nThese exemplary embodiments are mentioned not to limit or define the invention, but to provide examples of embodiments of the invention to aid understanding thereof.  Exemplary embodiments are discussed in the Detailed Description, and further\ndescription of the invention is provided there.  Advantages offered by the various embodiments of the present invention may be further understood by examining this specification. <BR><BR>BRIEF DESCRIPTION OF THE DRAWINGS\nThese and other features, aspects and advantages of the present invention are better understood when the following Detailed Description is read with reference to the accompanying drawings, wherein:\nFIG. 1 illustrates a block diagram of an exemplary system in accordance with an embodiment of the present invention;\nFIG. 2 illustrates one embodiment of a social network in accordance with an exemplary embodiment of the present invention;\nFIG. 3 illustrates a now diagram of a method in accordance with an exemplary embodiment of the present invention; and\nFIG. 4 illustrates another flow diagram of a method in accordance with an exemplary embodiment of the present invention.\n<BR><BR>DETAILED DESCRIPTION\n<BR><BR>Introduction\nEmbodiments of the present invention comprise systems and methods for providing current email addresses and contact information for members within a social network.  A social network can refer to a computer network connecting people or\norganizations by a set of social relationships, such as friendship, co-working, or information exchange.  Examples of a social network can include Orkut.TM., Friendster.TM., and Tribe.TM..  In one embodiment, using an email program application on a\nclient device or an email program application accessible via a browser program application on a client device, e.g., a laptop computer, a user can enter an entity identifier into the sending parameter of an email message.  The entity identifier attempts\nto identify an intended recipient of the email message, e.g., a member of a social network.  Entering the entity identifier triggers the email program application to send a request for an email address to a directory application.  The directory\napplication receives the request and parses out the entity identifier from the request.  The directory application uses the entity identifier to identify a member of the social network.  If there are multiple members identified with the entity\nidentifier, the directory application can prompt the user to select the appropriate member.  For example, if the user entered \"smith\" as the intended recipient of the email message, the directory application can prompt the user to select the proper\n\"smith,\" e.g., \"John Smith, Frank Smith, Robert Smith?\" Once the member is identified, the directory application obtains the email address from the user profile associated with identified member.  The directory application then outputs the email address\nto the email program application associated with the user who caused the request for email address to be sent.  The email message is then sent to the email address provided by the directory application.  Thus, a member of the social network can maintain\nhis or her current email address in his or her user profile.  By maintaining a current email address in the user profile, a member can ensure that he or she receives email messages regardless of whether the sender has the member's current address.\nIn another embodiment, current contact information for a member of a social network can be provided to a user who requests such information.  For example, using an email program application on a client device or an email program application\naccessible via a browser program application on a client device, e.g., a laptop computer, a user can trigger the sending of a request for the contact information of a member of a social network.  For example, by clicking on the member's name in the\naddress directory, the email program application can request the contact information for the member of a social network.  The request can comprise a second entity identifier identifying the requester of the contact information and a first entity\nidentifier identifying the contact, e.g., a member in a social network.  The request is sent to a directory application which identifies the requester and the contact.  Using the user profile associated with the contact, the directory application\ndetermines the relationship between the requester and the contact and determines if such a relationship permits the contact information associated with the contact to be released.  For example, if the user profile associated with the contact indicates\nthat all friends and business acquaintances can receive his or her contact information and if the requester and the contact have such a relationship as indicated in the user profile, then the contact information can be sent to the requester.  If the user\nprofile indicates that the relationship between the requester and contact is not an authorized relationship to receive such information, then the contact information is not sent to the requester.  If authorized, the directory application sends the\ncontact information associated with the contact to the requester.  The email program application receives the information and can compare the contact information from the directory application with the contact information stored in the address directory. The email program application can replace any differing information with the contact information from the directory application.  By maintaining current contact information and authorization information in his or her own profile, a member can control who\ncan receive such contact information.\nThis introduction is given to introduce the reader to the general subject matter of the application.  By no means is the invention limited to such subject matter.  Exemplary embodiments are described below.\n<BR><BR>System Architecture\nVarious systems in accordance with the present invention may be constructed.  FIG. 1 is a diagram illustrating an exemplary system in which embodiments of the present invention can operate.  The present invention may operate, and be embodied in,\nother systems as well.\nReferring now to the drawings in which like numerals indicate like elements throughout the several figures, FIG. 1 is a block diagram illustrating a system in accordance with an exemplary embodiment of the present invention.  The system 100\nshown in FIG. 1 comprises multiple client devices 102a-n in communication with one or more server devices 104, 108 over a network 106.  In one embodiment, the network 106 shown comprises the Internet.  In other embodiments, other networks, such as an\nintranet, WAN, LAN, or cellular network may be used.  In yet other embodiments, other suitable networks may be used.  Moreover, methods according to the present invention may operate within a single computer.\nThe client devices 102a-n shown each comprises a computer-readable medium, such as a random access memory (RAM) 112 coupled to a processor 110.  The processor 110 executes computer-executable program instructions stored in memory 112.  Such\nprocessors may comprise a microprocessor, an ASIC, and state machines.  Such processors comprise, or may be in communication with, media, for example computer-readable media, which stores instructions that, when executed by the processor, cause the\nprocessor to perform the steps described herein.  Embodiments of computer-readable media include, but are not limited to, an electronic, optical, magnetic, or other storage or transmission device capable of providing a processor, such as the processor\n110 of client 102a, with computer-readable instructions.  Other examples of suitable media include, but are not limited to, a floppy disk, CD-ROM, DVD, magnetic disk, memory chip, ROM, RAM, an ASIC, a configured processor, an optical media, all magnetic\ntape or other magnetic media, or any other suitable medium from which a computer processor can read instructions.  Also, various other forms of computer-readable media may transmit or carry instructions to a computer, including a router, private or\npublic network, or other transmission device or channel, both wired and wireless.  The instructions may comprise code from any suitable computer-programming language, including, for example, C, C++, C#, Visual Basic, Java, Python, Perl, and JavaScript.\nClient devices 102a-n may also comprise a number of external or internal devices such as a mouse, a CD-ROM, DVD, a keyboard, a display, or other input or output devices.  Examples of client devices 102a-n are personal computers, digital\nassistants, personal digital assistants, cellular phones, mobile phones, smart phones, pagers, digital tablets, laptop computers, Internet appliances, and other processor-based devices.  In general, a client device 102a may be any suitable type of\nprocessor-based platform that is connected to a network 106 and that interacts with one or more application programs.  Client devices 102a-n may operate on any suitable operating system, such as Microsoft.RTM.  Windows.RTM.  or Linux.  The client devices\n102a-n may also support a browser or browser-enabled application program, such as Microsoft Corporation's Internet Explorer.TM., Netscape Communication Corporation's Netscape Navigator.TM., and Apple Computer, Inc.'s Safari.TM..  The client devices\n102a-n can also include an email program application 114 to allow the users 112a-n to communicate with each other.  Examples of email program applications 114 include stand alone email clients such as Microsoft Corporation's Outlook.TM.  or Qualcomm\nEnterprises' Eudora.TM., or email program application accessible via a browser program application on a client device 102.  Examples of email program application accessible via a browser program application on a client device 102 can include Web page\nclients such as Microsoft Corporation's Hotmail.TM.  or Google's Gmail.TM., or an email reader such as AOL.TM.  as well as other email clients as known in the art.\nThrough the client devices 102a-n, users 112a-n can communicate over the network 106 with each other and with other systems and devices coupled to the network 106.  For example, using an email program application 114 on a client device 102a or a\nweb-based email program application on a server device (not shown) accessible via a browser program application on a client device 102a, a user 112a can send a request for the current email address or contact information for a member in a social network. As shown in FIG. 1, server devices 104 and 108 are also coupled to the network 106.\nThe server device 104 shown comprises a server executing a social network engine application program.  Similar to the client devices 102a-n, the saver devices 104 shown comprises a processor 116 coupled to a computer-readable medium, such as a\nrandom access memory (RAM) 118.  The server device 104 is in communication with a social network database 130.  Server device 104, depicted as a single computer system, may be implemented as a network of computer processors.  Examples of a server device\n104 are servers, mainframe computers, networked computers, a processor-based device, and similar types of systems and devices.  Client processor 110 and the server processor 116 can be any of suitable number of computer processors, such as processors\nfrom Intel Corporation of Santa Clara, Calif.  and Motorola Corporation of Schaumburg, Ill.\nMemory 118 contains a social network engine application program, also known as a social network engine 120.  The social network engine 120 allows users or members, such as user 112a, to interact with and participate in a social network.  A\nsocial network can comprise profiles that can be associated with other profiles.  Each profile may represent a member and a member can be, for example, a person, an organization, a business, a corporation, a community, a fictitious person, or other\nentity.  Each profile can contain entries, and each entry can comprise information associated with a profile.  Other examples of entries for a person profile can comprise information regarding relationship status, birth date, age, children, ethnicity,\nreligion, political view, sense of humor, sexual orientation, fashion preferences, smoking habits, drinking habits, pets, hometown location, passions, sports, activities, favorite books, music, TV, or movie preferences, favorite cuisines, location\ninformation, IM name, phone number, residential address, mailing address, skills, career, or any other information describing, associated with, or otherwise associated with a profile.  A profile can contain contact information associated with a member,\nsuch as, home telephone number, cell telephone number, home address, personal email address, etc. Similarly, a profile can contain business contact information associated with a members, such as, work telephone number, work address, business email\naddress.  A business profile can comprise such information as market sector, customer base, location, supplier information, net profits, net worth, number of employees, stock performance, website, business address, mailing address, telephone number, or\nother types of information associated with the business profile.  Typically a member may also include a representative image(s), audio/video or other multimedia information, etc. Additionally, entries within a profile can comprise associations with other\nprofiles.  Associations between profiles within a social network can include, for example, friendships, business relationships, acquaintances, community associations, activity partner associations, common interest associations, common characteristic\nassociations, or any other suitable type of association between profiles.  Such associations may be direct (i.e., without intermediary associations) or indirect (i.e., having intermediary associations).\nServer device 104 also provides access to storage elements, such as a social network storage element, in the example shown in FIG. 1, a social network database 130.  The social network database 130 can store member profiles 132.  Data storage\nelements may include any one or combination of methods for storing data, including it out limitation, arrays, hash tables, lists, and pairs.  Other similar types of data storage devices can be accessed by the server device 104.  The social network engine\n120 can receive data comprising the members profiles from the social network database 130 and can also send data comprising member profiles to the social network database 130 for storage.  The social network database 130 may be physically attached or\notherwise in communication with the social network engine 120 by way of a network or other connection.\nThe server device 108 shown can directory server, e.g., a server executing a directory application or protocol 144, e.g., a Lightweight Directory Access Protocol (LDAP).  The directory application 144 can respond to requests for the current\nemail address or current contact information sent from the email program application 114 or web-based email program application.  Similar to the client devices 102a-n, the server device 108 shown comprises a processor 140 coupled to a computer-readable\nmemory 142.  Server device 108, depicted as a single computer system, may be implemented as a network of computer processors.  Examples of a server device 108 are servers, mainframe computers, networked computers, a processor-based device, and similar\ntypes of systems and devices.  Server processor 140 can be any of a number of computer processors, such as processors from Intel Corporation of Santa Clara, Calif.  and Motorola corporation of Schaumburg, Ill.\nMemory 142 can contain the directory application or protocol 144, e.g., LDAP.  The directory application 144 can manage information related to members or users 112a-n within the social network.  The directory application 144 can act as a gateway\nor central repository for information associated with the members or users 112a-n within a social network.  In one embodiment, the profiles 132 for each member 112 are stored within the memory 142 of server device 108.  In other embodiments, partial\nprofiles or profile information are stored within the memory 142.  For example, a member's name and email address; a member's contact information; a member's email address, relationships, and authorization can be stored in the memory 118.  In other\nembodiments, the directory application 144 acts as a gateway to the social network engine 120 and obtains the necessary profile information from the social network database 130 and profiles 132 as needed.  As described below, the directory application\n144 can respond to lookup requests from the email application 114 or web-based email application With information associated with members 112a-n within the social network, e.g., profile information.  In one embodiment, the directory application 144\nprovides the current email address of a member 112 within the social network to a client device 102 in response to an email address request in another embodiment, the directory application 144 provides the current contact information of a member 112\nwithin the social network to a client device 102 in response to a request for contact information.\nIt should be noted that the present invention may comprise systems having different architecture than that which is shown in FIG. 1.  For example, in some systems according to the present invention, the server devices 104, 108 may comprise a\nsingle physical or logical server.  In other embodiments, the server devices 104, 108 can be single servers, a virtual server, multiple servers, etc. In yet other embodiments, the functions that are performed by the directory application 144 can be\nperformed by the social network engine 120.  The system 100 shown in FIG. 1 is merely exemplary, and is used to help explain the social networks and methods illustrated in FIGS. 2-4.\n<BR><BR>Exemplary Social Network\nFIG. 2 illustrates an exemplary embodiment of a social network 200.  According to the embodiment illustrated in FIG. 2, the social network 200 comprises a graph comprising vertices 202-212 and edges 218-234.  The vertices 202-212 comprise\nprofiles A-F. Each profile can represent a member.  The edges 218-234 comprise associations between profiles.  According to the embodiment shown in FIG. 2, the social network 200 comprises a plurality of differing types of associations represented by\nedges 218-234.  The types of associations listed in FIG. 2 for illustration purposes are business associations, activity partner associations, friendship associations, community associations, and common characteristic associations.  Common characteristic\nassociations can include associations based on some characteristic such as attending the same high school or being from the same hometown, but can indicate a lower level of significance that another type of association, such as a friendship association. \nIn one embodiment, the social network 200 comprises a single associations, such as a friendship association.  One or more associations can have different levels.  For example, a friendship association can have the following levels: haven't met,\nacquaintance, friend, good friend, and best friend.\nFor example, edge 220 and edge 222 each comprise an association between profile A at vertex 202 and Profile D at vertex 208.  The edge 220 represents a business association, and the edge 222 represents a friendship association.  Profile A is\nalso associated with profile E by a common characteristic association comprising edge 218.  The association between profile A and profile E may be more attenuated than the association between profile A and D, but the association can still be represented\nby the social network depicted in FIG. 2.\nEach member represented by the profiles A-F comprising the vertices 202-212, for purposes of illustration is a person.  Other types of members can be in social network 200.  The associations 218-234 illustrated in FIG. 2 comprise bi-directional\nassociations.  The associations are bi-directional because when one profile, for example profile A, is associated with another profile, for example profile D, then profile D is also associated with profile A. In one embodiment, A and D will not be\nassociated with each other until both profiles consent to such association; e.g., A may invite D to be associated therewith, and the association occurs upon D's acceptance of such invitation.  The invitation, for example, may include sending an email or\nother message to D indicating that A has requested an association with D.\nOther embodiments of the present invention may comprise directed associations or other types of associations.  Directed associations associate a first profile with a second profile while not requiring the second profile to be associated with the\nfirst profile.  For example, in a directed chart, profile A can be associated by a friendship association with profile B, and profile B can be unassociated by a friendship connection with profile A. Thus a display of profile A's friends would include\nprofile B, but a display of profile B's friends would not include profile A.\nWithin a social network, a degree of separation can be determined for associated profiles.  One method of determining a degree of separation is to determine the fewest number of edges of a certain type separating the associated profiles.  This\nmethod of determining a degree of separation can produce a type-specific degree of separation.  A type-specific degree of separation is a degree of separation determined based on one particular type of association.  For example, a profile A has a friend\nassociation degree of separation of two from profile E. The fewest number of friendship associations between profile A and profile F is two--the friendship association comprising edge 220 and the friendship association comprising edge 234.  Thus, for the\nassociated profiles A and E, the degree of friendship separation, determined according to one aspect of one embodiment of the present invention is two.\nAnother type-specific degree of separation can also be determined for profiles A and E. For example, a common characteristic degree of separation can be determined by determining the fewest number of common characteristic associations separating\nprofile A and profile E. According to the embodiment depicted in FIG. 2, there is one common characteristic association, comprising edge 218, separating profiles A and E. Thus, the common characteristic association degree of separation according to the\nembodiment depicted in FIG. 2, is one.  The common characteristic in this example, can be that profile A attended the same high school as profile E. A common characteristic association may be selected by profiles A and E to represent that they are\nassociated in some fashion, but to not create a close association such as with a friendship association.\nAccording to other aspects of certain embodiments of the present invention, the degree of separation may be determined by use of a weighting factor assigned to each association.  For example, \"best\" friends can be weighted higher than \"haven't\nmet\" friends.  According to certain aspects of embodiments using a weighting factor, a higher weight factor for an association can reduce the degree of separation between profiles and lowering weighting factors can increase the degree of separation. \nThis can be accomplished, for example, by establishing an inverse relationship between each associations and a corresponding weighting factor prior to summing the associations.  Thus, highly weighted associations would contribute less to the resulting\nsum than lower weighted associations.\n<BR><BR>Process\nVarious methods in accordance with the present invention may be constructed.  For example, in one embodiment, the method begins with receiving a request for an email address for a first member in a social network.  The request comprises an\nentity identifier associated with the first member.  After receiving the request, the entity identifier is parsed from the request and the corresponding email address is obtained using profile information associated with the entity identifier.  The email\naddress is than sent to the requester where the email address is entered into the send-to parameter of an email message.\nIn another embodiment, the method begins with receiving a request for contact information associated with a first member in a social network.  The request comprises an entity identifier associated with the first member, e.g., a contact.  After\nreceiving the request, the relationship between the contact and the sender of the request, e.g. a requester, is determined using profile information associated with the contact and a determination is made whether the relationship between the contact and\nthe requester is an authorized relationship.  If the requester is authorized to receive the contact information, then the contact information is sent to the requester.  The sent contact information is then compared with the contact information for the\ncontact stored in the requester's address book.  If the information differs, then the differing contact information in the address book is replaced with the sent contact information.\nFIG. 3 illustrates an exemplary method 300 that provides the current email address for a member 112 within a social network, in accordance with an embodiment of the present invention.  This exemplary method is provided by way of example, as\nthere are a variety of ways to carry out methods according to the present invention.  The method 300 shown in FIG. 3 can be executed or otherwise performed by one or a combination of various systems.  The method 300 is described below as carried out by\nthe system 100 shown in FIG. 1 by way of example, and various elements of the system 100 are referenced in explaining the example method of FIG. 3.\nThe method 300 begins in block 302 when a user enters an entity identifier associated with a member of a social network into a sending parameter of an email message.  For example, using an email program application 114 on a client device 102a or\na web-based email program application accessible via a browser program application on a client device 102a, a user 112a types in a name of an entity identifier, e.g., an intended recipient of an email message, into \"to\" or \"send-to\" parameter of an email\nmessage.  The entity identifier can take various forms depending on the email program application, with each entity identifier attempting to identify an intended recipient of the email message.  For example, each entity identifier can be a name, first\nand last name, nickname, partial name, a first initial with the last name, an entity, an email address, an emailing group name, a group name, etc.\nAt block 304, an email address request comprising the at least one entity identifier is sent to the directory application 144.  For example, the email program application (client or web-based) sends the email address request to the directory\napplication 144 in response to a triggering event.  Examples of triggering events can be using a send button, using function or function short keys to cause the triggering, e.g., simultaneously hitting the control key and \"k\" key in Microsoft\nOutlook.TM., clicking out of or exiting from the send-to parameter field, expiration of time, or other known triggers as known in the art.  The email address request can also include an entity identifier associated with the requester 112a who causes the\nemail address request to be sent.\nDepending on the configuration of the email program application, the email program application can access one or more name exchange servers or directories, e.g., a local name exchange server, prior to causing the email address request being sent\nto the directory application 144.  For example, the email program application can automatically replace the entity identifier with the name (typically, last name, first name) of each intended recipient associated with the entity identifier or can provide\na list of potential recipients to the user who can select the intended recipient.  In one embodiment, if the entity identifier is a group email name, the email program application can replace the entity identifier with an entity identifier for each user\nin the group email name.\nReturning to FIG. 3, after receiving the email address request, the method 300 proceeds to block 306, wherein the email address for the entity identifier is identified.  The directory application 144 parses the entity identifier from the email\nmessage to identify the intended recipient of the email message.  The directory application 144 obtains the email address from the profile information associated with the entity identifier, e.g., a member of a social network.  If more than one member is\nassociated with an entity identifier, then the directory application 144 can provide a list of email addresses to the email program application which can prompt the requester to identify the intended recipient.  For example, if the entity identifier was\n\"Smith\", then the directory application 144 generates and provides a list of names containing \"Smith\" to the requester prompting a selection of the appropriate Smith.\nSimilarly, if more than one email address is associated with an entity identifier, then the directory application 144 can cause a prompt to be sent to the requester to select an email address associated with the entity identifier. \nAlternatively, if more than one email address is associated with an entity identifier, then the appropriate email address can be selected based on the relationship between the intended recipient and the sender of the email address request.  For example,\nif the profile associated with the intended recipient of an email message indicates that the sender of the email address request is a friend of the intended recipient, then the private email address of the intended recipient can be provided.  Similarly,\nif the profile indicates that the sender of the email address request is a business acquaintance of the intended recipient of the email message, then a business email address of the intended recipient can be provided.  In instances, where the profile\nindicates that the intended recipient and the sender of the email address request have multiple relationships, then the sender of the email address request can be provided with a list of the appropriate email addresses associated with the intended\nrecipient.  Then the directory application 144 prompt the sender of the email address request to select one or more of the email addresses.\nSince the directory application 144 does not need a member's entire profile, the server device 108 does not have to store entire profiles in memory 142 or obtain entire profiles 132 from the social network database 130.  In one embodiment, the\nprofile information stored in the memory 142 on the server device 108 can be limited.  For example, the profile information in the memory 142 can include the member's name and email address for each member.  In one embodiment, the directory application\n144 accesses the social network database for all requested profile information.  Regardless of how much profile information is stored in the memory 142, the profile information should match with the profile information stored in the social network\ndatabase 130.  Since a member of the social network can update his or her profile at any time, the member controls whether his or her email address is current.\nReturning to FIG. 3, after identifying the email address for the intended recipient of the email message, the method 300 proceeds to block 308, wherein the email address for the intended recipient is returned or outputted to the sender of the\nemail address request.  For example, the directory application 144 sends the email address to the email program application that caused the email address request to be sent.  Since each member 112 can update his or her own profile within the social\nnetwork, the method 300 allows members to control whether the email address listed in his or her profile is current.  As a result, email messages can be sent to the most current email address for members 112a-n in the social network.  Hence, an\nadministrator is not required to update a person's email address on a name exchange server as required in most email client systems.\nFIG. 4 illustrates an exemplary method 400 that provides current contact information for a member within a social network, in accordance with one embodiment of the invention.  This exemplary method is provided by way of example, as there are a\nvariety of ways to carry out methods according to the present invention.  The method 400 shown in FIG. 4 can be executed or otherwise performed by one or a combination of various systems.  The method 400 is described below as carried out by the system\n100 shown in FIG. 1 by way of example, and various elements of the system 100 are referenced in explaining to example method of FIG. 4.\nThe method 400 illustrated in FIG. 4 begins in block 402 with receiving a request for contact information (a contact request) associated with a member of a social network, e.g., a user 112.  For example, an email application 114 on a client\ndevice 102 or a web-based email application accessible via a browser program application on a client device 102 can send the contact request to the directory application 144 in response to a triggering event.  The contact request can contain a first\nentity identifier identifying the sender of the request and a second entity identifier identifying the contact whose contact information is being requested.  The entity identifier can be a name, first and last name, nickname, partial name, a first\ninitial with the last name, an entity; an email address, an emailing group name, etc. The triggering event can be an email address request as described above with respect to FIG. 3, using a send button, using function or function short keys to cause the\ntriggering, e.g., simultaneously hitting the control key and \"k\" key in Microsoft Outlook.TM., clicking out of or exiting from the send-to parameter field, replying to an email message, expiration of time, periodically, clicking on or accessing a contact\nname in an address directory, or other known triggers as known in the art.\nAfter receiving the contact request, the method 400 proceeds to block 404, wherein the requester and contact are identified.  For example the directory application 144 parses the entity identifiers from the request to identify the requester and\ncontact.  If more than one contact are associated with an entity identifier then the directory application 144 can cause the requester to be prompted to identify the contact as discussed above with respect to method 300.\nAfter identifying the requester and contact, the method 400 proceeds to block 406, wherein the relationship between the requester and contact is determined.  To determine the relationship between the requester and the contact, the directory\napplication 144 uses the profile information associated with the contact to determine what relationships, if any, exist between the contact and requester, e.g., whether the user profile lists any relationship between the requester and contact.  Exemplary\nrelationships can include none, friends, friends of friends, business associations, and other relationships known in the art.  Relationships can also have varying levels, such as, for example, haven't met, acquaintance, friend, good friend, and best\nfriend.\nAfter determining the relationship between the requester and contact, the method proceeds to block 408, wherein a determination is made as to whether the identified relationship is authorized to receive the contact information and the type of\ncontact information that can be received.  For example, using the profile information, the directory application 144 determines the type of relationships that are authorized to receive contact information associated with the contact, such as friends,\nfriends of friends, or all.  An authorized relationship can also be used on an email address domain name, e.g., \"@google.com\", where the contact request is granted based on an approved domain name.  Similarly, a member of the social network can designate\nthe type of contact information he or she is willing to provide to others.  This designation can be part of the profile associated with the member.  For example, a member can designate that only friends can receive the member's cell phone number and only\nbusiness acquaintances can receive the member's business telephone number.\nSince the directory application 144 does not need a member's entire profile, the server device 108 does not have to store entire profiles in memory 142 or obtain entire profiles from the social network database 130.  In one embodiment, the\nmemory 142 on the server device 108 can be limited, e.g., profile information which can include the member's relationship, authorization and contact information.  In one embodiment, the directory application 144 accesses the social network database for\nall requested profile information.  Regardless of how much profile information is stored in memory 142, the profile information should match with the profile information stored in the social network database 130.  Since a member of the social network can\nupdate his or her profile at any time, a member can ensure that his or her contact information is current.\nReturning to FIG. 4, after determining if the requester is authorized to receive the contact information, the method 400 proceeds to block 410, wherein the contact information is sent or outputted when the requester is authorized to receive such\ninformation.  For example, the directory application 144 sends the contact information associated with the contact to the email program application which caused the contact request to be sent.  The contact information that is sent can be limited to the\ninformation that the contact authorizes, e.g., the member's cell telephone number to friends and the member's business telephone number to business acquaintances.  If the requester is not authorized to receive such information, then no information is\nsent or a message indicating that the requester is not authorized to receive such information is sent.\nAfter sending or outputting the contact information, the method 400 proceeds to block 412 where the contact information from the directory application 144, e.g., the sent contact information, is compared with the contact information in the\naddress book, e.g., an electronic address book, with differing information being replaced with the contact information from the directory application 144.  For example, the email program application receives the contact information from the directory\napplication 144 and compares the two sets of contact information.  The email program application can replace the differing contact information in the address book with the corresponding contact information from the directory application 144.  In one\nembodiment, the replacement of the differing information is automatic.  In another embodiment, the requester can be prompted to replace the differing contact information.\nThus, a member can help to maintain his or her contact information in other member's address books without having the other members physically enter the changes.  If a member is in the process of changing jobs, the member can change the contact\ninformation in his or her profile and provide the updated information when someone sends a contact request.  In addition, a member can determine which members can receive his or her contact information, as well as the specific contact information that\ncan be provided, based on one or more authorization parameters within his or her profile.\nAlthough the exemplary methods 300, 400 are described with the intended recipient of the email message and the contact, being members of a social network, the sender of the email address request and/or the sender of the contact request can be\nmembers of the same social network or can be members of a different social network than the intended recipient and/or contact.  In another embodiment, the sender of the email address request and/or the sender of the contact request do not have to belong\nto any social networks.  The exemplary methods 300, 400 are described with requests with single entity identifiers, however the requests can contain multiple entity identifiers for obtaining information for multiple members.\n<BR><BR>GENERAL\nThe foregoing description of the preferred embodiments of the invention has been presented only for the purpose of illustration and description and is not intended to be exhaustive or to limit the invention to the precise forms disclosed. \nNumerous modifications and adaptations thereof will be apparent to those skilled in the art without departing from the spirit and scope of the present invention.", "application_number": "14835551", "abstract": " Methods and systems for providing current email addresses or contact\n     information to members within a social network are described. In one\n     described method, an email program application requests an email address\n     for a member within a social network. Using profile information\n     associated with the member, the email address is provided to the email\n     program application which sent the request. The email address is then\n     entered into the send-to parameter field of an email message. In another\n     described method, contact information associated with a first member of a\n     social can be provided to a second member of the social network. The\n     contact information is provided if the relationship between the first and\n     second members is an authorized relationship. The contact information\n     associated with the first member can be used to update the contact\n     information for the first member in an electronic address book associated\n     with the second member.\n", "citations": ["5287498", "5537586", "5796393", "5809297", "5950200", "5963951", "5978673", "6041311", "6052122", "6061681", "6073105", "6073138", "6073141", "6091948", "6092049", "6130938", "6192119", "6256648", "6327590", "6366962", "6389372", "6421678", "6442567", "6594673", "6658423", "6665715", "6678681", "6697478", "6754322", "6782425", "6799176", "6834195", "6837436", "6865546", "6867733", "6871186", "6912505", "7013292", "7069308", "7080117", "7092821", "7106848", "7113917", "7117254", "7155608", "7177904", "7188153", "7225249", "7269590", "7356490", "7366990", "7383258", "7395075", "7418268", "7433832", "7433876", "7440746", "7478078", "7555110", "7610287", "7742468", "7808980", "7907903", "8412780", "20010011247", "20020023230", "20020059130", "20020059201", "20020103682", "20020124053", "20020137490", "20020143874", "20020169835", "20020174073", "20030020977", "20030063072", "20030069749", "20030083898", "20030101227", "20030217151", "20040093224", "20040093317", "20040122681", "20040122803", "20040148275", "20040153512", "20040162830", "20040172378", "20040193684", "20040215793", "20040249811", "20040258220", "20040260781", "20050015432", "20050015457", "20050021750", "20050050158", "20050071741", "20050105697", "20050120084", "20050152521", "20050159970", "20050165785", "20050171832", "20050171954", "20050177385", "20050177599", "20050193054", "20050198031", "20050209999", "20050210409", "20050216300", "20050216550", "20050246420", "20050267766", "20050267940", "20060026288", "20060077957", "20060136419", "20060184997", "20060206604", "20070127631", "20070171898", "20070173236", "20070233736", "20070248077", "20080004941", "20080153480", "20080056475", "20080133716", "20080192656", "20090005070", "20090013386", "20090082001", "20090131026", "20100128857", "20100130228", "20100279673", "20110059732", "20110098156", "20110112768", "20110209221"], "related": ["13618194", "11095337"]}, {"id": "20160063111", "patent_code": "10346533", "patent_name": "Management of content tailoring by services", "year": "2019", "inventor_and_country_data": " Inventors: \nLink; Claudius (Kassel, DE), Seul; Matthias (Kassel, DE)  ", "description": "<BR><BR>FIELD OF THE INVENTION\nThe present invention relates generally to the field of web based content providers, and more particularly to managing content tailoring services and enriching responses from services.\n<BR><BR>BACKGROUND OF THE INVENTION\nWeb services that serve as content providers, such as search engines, social networks, and media outlets, often utilize recommender systems that tailor content for a user.  For example, a recommender system may tailor content for a user by\nproviding advertisements, search results, articles, and/or other content that pertains to a user's interests, demographic, or other preferences.\nWhile tailoring content can be useful to filter large amounts of general information, recommender systems can also create a \"content bubble\", where a user's requests for information are consistently fulfilled with non-diverse, personalized\nresponses.  Content bubbles may, therefore, limit a user's exposure to diverse content, such as content that pertains to alternative viewpoints and topics, even when such diverse content may be of interest to the user.\n<BR><BR>SUMMARY\nEmbodiments of the present invention provide systems, methods, and program products for processing a response from a service.  In one embodiment, a method is provided, the method comprising: receiving, by one or more computer processors, a first\nresponse from a service, wherein the first response is generated as a response to a query sent to the service from a computer system; extracting, by one or more computer processors, text content from the first response; determining, by one or more\ncomputer processors, whether the extracted text content from the first response is diverse in accordance with a user specification; and responsive to determining that the extracted text content from the first response is not diverse in accordance with\nthe user specification, modifying, by one or more computer processors, the first response to create a second response that is diverse in accordance with the user specification. <BR><BR>BRIEF DESCRIPTION OF THE DRAWINGS\nFIG. 1 is a block diagram of a computing environment, in accordance with an embodiment of the present invention;\nFIG. 2 is a flowchart illustrating operational steps for creating a theme, in accordance with an embodiment of the present invention;\nFIG. 3 is a flowchart illustrating operational steps for creating a refinement of a theme, in accordance with an embodiment;\nFIG. 4 is a flowchart illustrating operational steps for creating a refinement of a theme, in accordance with another embodiment of the present invention;\nFIG. 5 is a flowchart illustrating operational steps for creating a service entry, in accordance with an embodiment of the present invention;\nFIG. 6 is a flowchart illustrating operational steps for processing a client request, in accordance with an embodiment of the present invention;\nFIG. 7 and FIG. 7 (CONT.) are a flowchart illustrating operational steps for processing a service response, in accordance with an embodiment of the present invention;\nFIG. 8 is a flowchart illustrating operational steps for creating an enriched response, in accordance with an embodiment of the present invention; and\nFIG. 9 is a block diagram of internal and external components of the computer systems of FIG. 1, in accordance with an embodiment of the present invention.\n<BR><BR>DETAILED DESCRIPTION\nEmbodiments of the present invention provide systems, methods, and computer program products for managing content tailoring by services and/or recommender systems used by those services.  Embodiments of the present invention can help prevent\ncontent bubbles and can afford users with the ability to control the diversity of content in responses provided by services.  Furthermore, embodiments of the present invention may be used to provide users with enriched responses from services without\nneeding the cooperation of those services.\nFIG. 1 is a functional block diagram of computing environment 100, in accordance with an embodiment of the present invention.  Computing environment 100 includes gateway computer system 102, enrichment services 116, service 118, and client\ncomputer system 120, all interconnected by network 122.  Gateway computer system 102 and client computer system 120 can be desktop computers, laptop computers, specialized computer servers, or any other computer systems known in the art.  In certain\nembodiments, gateway computer system 102 and client computer system 120 represent computer systems utilizing clustered computers and components to act as a single pool of seamless resources when accessed through network 122.  In certain embodiments,\ngateway computer system 102 and client computer system 120 represent virtual machines.  In general, gateway computer system 102 and client computer system 120 are representative of any electronic device, or combination of electronic devices, capable of\nexecuting machine-readable program instructions, as discussed in greater detail with regard to FIG. 9.\nGateway computer system 102 includes content analysis engine 104, theme creation program 106, service entry program 108, classification database 110, service description database 112, and session database 114.  Gateway computer system 102\ncaptures requests sent from client computer system 120 to service 118 via network 122, and captures responses sent from service 118 to client computer system 120.  In this exemplary embodiment, gateway computer system 102 is configured as an intermediary\ncomputer system, such as an HTTP gateway.\nContent analysis engine 104 manages requests sent from client computer system 120 to service 118, as well as responses sent from service 118 to client computer system 120.  In this embodiment, content analysis engine 104 captures and processes\noutgoing HTTP requests sent from client computer system 120 to service 118 (i.e., preventing the requests from being sent directly to service 118), as well as responses from service 118 to client computer system 120 (i.e., preventing the responses from\nbeing sent directly to client computer system 120).  As discussed in greater detail later in this specification, content analysis engine 104 may process responses from service 118 to ensure that the content of such responses is sufficiently diverse.  In\nsome instances, content analysis engine 104 may access enrichment services 116 via network 122 to obtain additional content with which to enrich a response from service 118, and then initiate transmission of the enriched response to client computer\nsystem 120.  In other instances, content analysis engine 104 may determine that content in a response from service 118 is sufficiently diverse, and then initiate transmission of the original response to client computer system 120.\nTheme creation program 106 creates themes that are used to classify content of responses received by content analysis engine 104 from service 118 or enrichment services 116.  In this exemplary embodiment, an administrative user of gateway\ncomputer system 102 can use theme creation program 106 to create themes (e.g., \"cars\", \"computers\", or \"vacations\"), each of which comprises a plurality of text elements that correspond to that theme.  Theme creation program 106 may also create\nrefinements of themes, each of which comprises a plurality of text elements that correspond to a subcategory for that theme (e.g., \"sports cars\").\nService entry program 108 creates service entries for service 118, enrichment services 116, and one or more other services.  In this exemplary embodiment, an administrative user of gateway computer system 102 can use service entry program 108 to\ncreate service entries and store the service entries in service description database 112, as discussed in greater detail with regard to FIG. 5.\nClassification database 110 stores themes and refinements created by theme creation program 106.  Content analysis engine 104 can access classification database 110 to obtain stored themes and refinements.\nService description database 112 stores service entries for service 118, enrichment services 116, and one or more other services.  In this exemplary embodiment, service entries stored in service description database 112 comprise information\npertaining to identification, accessibility, and capabilities of services, along with any instructions for managing schema for services and reducing content tailoring.\nSession database 114 stores information pertaining to active or previously established sessions created by content analysis engine 104 for requests received from client computer system 120 and/or responses received from service 118.  For\nexample, session information may include a record of a user's query, records of prior queries to service 118 and other services, identification information for a user, and/or tracking information that can be used to associate a request sent to service\n118 with a corresponding response received from service 118.\nClassification database 110, service description database 112, and session database 114 can be implemented using any database architecture known in the art, such as a relational database, an object-oriented database, and/or one or more tables. \nSimilarly, in other embodiments, classification database 110, service description database 112, and/or session database 114 can be hosted remotely and accessed by gateway computer system 102 via network 122.\nService 118 is a service (e.g., a web service or content provider) accessible by client computer system 120 and gateway computer system 102 via network 122.  Service 118 can comprise one or more programs executing on one or more computer\nsystems.  Service 118 receives one or more requests for content and, in response, service 118 delivers one or more responses.  Service 118 may include one or more recommender systems that tailor content provided in response to received requests based on\nthe particular user of client computer system 120 (i.e., personalized content for that user).  Examples of services which may be represented by service 118 include, but are not limited to, search engines, blogging platforms, social media outlets, and\nnews outlets.  Examples of recommender systems which may be utilized by service 118 include, but are not limited to, systems that customize search results, articles, news information, messages, alerts, product recommendations, other multimedia content,\nand combinations thereof.\nEnrichment services 116 are one or more services (e.g., a web service or content provider, as previously discussed) accessible by gateway computer system 102 via network 122.  In this exemplary embodiment, content analysis engine 104 can query\nenrichment services 116 to obtain content with which to enrich a response from service 118 (e.g., to increase content diversity), prior to transmitting the response to client computer system 120.  In some instances, service 118 may also be used as an\nenrichment service 116.\nNetwork 122 can be, for example, a local area network (LAN), a wide area network (WAN) such as the Internet, or a combination of the two, and include wired, wireless, or fiber optic connections.  In general, network 122 can be any combination of\nconnections and protocols that will support communications between gateway computer system 102, client computer system 120, service 118, and enrichment services 116, in accordance with embodiments of the present invention.\nIt should be understood that, for illustrative purposes, FIG. 1 does not show other computer systems and elements which may be present when implementing embodiments of the present invention.  For example, while FIG. 1 shows a single client\ncomputer system 120 and service 118, computing environment 100 can include additional client computer systems 120 that access multiple services 118.\nFIG. 2 is a flowchart 200 illustrating operational steps for creating a theme, in accordance with an embodiment of the present invention.  The term \"theme\", as used herein, refers to a list of text elements that relate to, describe, or otherwise\npertain to a particular topic of interest.  The term \"text element\", as used herein, is a string of one or more characters that is significant as a group (e.g., a token).  A text element may be, for example, a keyword, phrase, numerical value, and/or\ncombinations thereof.\nIn step 202, theme creation program 106 receives a sample set of content that is related to the theme (i.e., a related sample set), and a sample set of content that is not related to the theme (i.e., a non-related sample set).  In this exemplary\nembodiment, a user selects a related sample set of content comprising content that relates to, describes, or otherwise embodies the topic of the theme.  For example, if creating a theme for the topic \"car\", a related sample set of content may comprise\ncontent that depicts or discusses cars or subjects related to cars (e.g., car companies, car components, etc.).  The user selects a non-related sample set of content comprising content that does not relate to, or otherwise embody, the topic of the theme. For example, if creating a theme for the topic \"car\", a non-related sample set of content may comprise content depicting or discussing subjects having no relation to cars.\nContent contained in the related and non-related sample sets can be of any suitable type, such as text documents, web articles, or any other web-based content with textual information.  The user may compile the sample sets of content manually,\nin an assisted fashion (e.g., using existing sample sets of content), or using any combination of both techniques.  The size of the related and non-related sample sets may also be varied by the user.  Typically, as discussed in greater detail below,\nlarger sample sets result in a theme whose text elements are more likely to appear in content pertaining to the topic, while being less likely to appear in content that does not pertain to the topic.  In one embodiment, the size of the related sample set\nis at least 100,000 pieces of sample content, and the size of the non-related sample set is at least 1,500,000 pieces of sample content.\nIn step 204, theme creation program 106 extracts text content from the content contained in the related and non-related sample sets.  Depending on the type of content, the text content may already be in suitable form for subsequent processing\n(e.g., plain text form) and theme creation program 106 may copy the text content therefrom.  Where the content exists in a structured form, such as in XML and HTML documents, theme creation program 106 extracts text content from the documents, in\naccordance with the appropriate schemas.\nIn step 206, theme creation program 106 parses the extracted text content of the related and non-related sample sets to obtain one or more text elements.  Theme creation program 106 also determines the number of occurrences for each text element\nin the extracted text content of the related and non-related sample sets (i.e., the total number of times each text element appears in all of the text content extracted from the related sample set, and the total number of times each text element appears\nin all of the text content extracted from the non-related sample set).  In this exemplary embodiment, a user may specify how theme creation program 106 parses the text content, including a limit on the maximum number of keywords allowed for a given text\nelement.  For example, if the user specifies a maximum number of two keywords per text element, theme creation program 106 can parse the extracted text content of the related and non-related sample sets to obtain text elements comprising individual\nkeywords and two-keyword combinations.\nIn step 208, theme creation program 106 compiles lists of text elements and their respective occurrences that were identified in step 206.  In this exemplary embodiment, theme creation program 106 compiles a list of text elements identified in\nthe extracted content of the related sample set (excluding duplicate text elements) and a separate list of text elements identified in the extracted content of the non-related sample set (excluding duplicate text elements).  Theme creation program 106\nmay also maintain a text element list for each individual piece of content containing the text elements found in that piece of content.  Such individual lists may be used, for example, to facilitate creation of refinements of themes, as discussed in\ngreater detail with regard to FIG. 3.\nIn step 210, theme creation program 106 compares the compiled list of text elements for the related sample set with the compiled list of text elements for the non-related sample set, and theme creation program 106 removes any matching elements\npresent in both compiled lists from the compiled list of text elements for the related sample set.  Stated differently, theme creation program 106 removes from the compiled list of text elements for the related sample set any text elements which are also\nfound in the compiled list for the non-related sample set.\nIn step 212, theme creation program 106 stores the compiled list of text elements for the related sample set, along with their respective numbers of occurrences, as a theme in classification database 110.\nAccordingly, by performing the operational steps of FIG. 2, theme creation program 106 can create a theme comprising a list of text elements which pertain to the topic of the theme and are specific to the topic of the theme, while eliminating\ntext elements that do not pertain to the topic of the theme, or which might pertain to the topic of the theme but also pertain to content that is not related to the topic of the theme.  The operational steps of FIG. 2 may be repeated for multiple topics\nand themes.  Similarly, additional related and non-related sample sets of content may be processed to build a more comprehensive list of text elements for a theme, and/or to remove additional text elements that pertain to the topic but also pertain to\nnon-related topics.  In other embodiments of the present invention, a theme can be created using an existing list of text elements related to the topic of the theme, such as text elements from an existing commercial classification database or text\nelements obtained through behavior studies designed to identify words associated with a given topic.\nFIG. 3 is a flowchart 300 illustrating the operational steps for creating a specific refinement, in accordance with an embodiment of the present invention.  The term \"specific refinement\", as used herein, refers to a list of text elements that\nrelate to, describe, or otherwise pertain to a particular subcategory of the theme.  For example, specific refinements for the theme \"car\" may include \"maker type\", \"model type\", or \"body type\", each of which comprises a list of text elements that relate\nto, describe, or otherwise pertain to those respective subcategories.\nIn step 302, theme creation program 106 receives a sub-sample set of content that is related to the specific refinement (i.e., a related sub-sample set) of a theme.  In this exemplary embodiment, the sub-sample set of content is selected from\nthe related sample set of content for the theme (e.g., by a user, or using one or more automation techniques), and the related sub-sample set of content comprises content that relates to, describes, or otherwise embodies the specific refinement.  For\nexample, if creating a specific refinement for \"model type\" of a theme \"cars\", the related sub-sample set of content may comprise content selected from the related sample set for the theme \"cars\" that depicts, discusses, or otherwise relates specifically\nto model types of cars (e.g., reviews or comparisons of different model types of cars).\nIn step 304, theme creation program 106 compiles a list of text elements for the sub-sample set of content.  In this exemplary embodiment, theme creation program 106 compiles the list of text elements by using individual lists of text elements\nassociated with each of the pieces of content in the sub-sample set that were previously created by theme creation program 106 during creation of the theme (e.g., in step 206 of FIG. 2).  In other embodiments, theme creation program 106 may compile the\nlist of text elements by again extracting text content from the sub-sample set of content, and then parsing the extracted text content for text elements, as previously discussed with regard to FIG. 2.\nIn step 306, theme creation program 106 compares the compiled list of text elements for the related sub-sample set with the compiled list of text elements for the theme, and theme creation program 106 removes any non-matching text elements from\nthe compiled list of text elements for the related sub-sample set.  Stated differently, theme creation program 106 removes from the compiled list of text elements for the related sub-sample set any text elements which are not found in the list of text\nelements for the theme.\nIn step 308, theme creation program 106 stores the compiled list of text elements for the related sub-sample set, along with their respective occurrences, as a specific refinement in classification database 110.\nAccordingly, by performing the operational steps of FIG. 3, theme creation program 106 can create a specific refinement comprising a list of text elements which pertain to the subcategory of the theme and are specific to the subcategory of the\ntheme, while eliminating text elements that do not pertain to the subcategory of the theme, or which might pertain to the subcategory of the theme but also pertain to content that is not related to the subcategory of the theme.  The operational steps of\nFIG. 3 may be repeated for multiple refinements of one or more themes.  As previously discussed, a specific refinement can also be created using an existing list of text elements related to the topic of the specific refinement, taken from a larger list\nof text elements related to the theme.\nFIG. 4 is a flowchart 400 illustrating the operational steps for creating a generic refinement, in accordance with an embodiment of the present invention.  The term \"generic refinement\", as used herein, refers to a compiled list of text elements\nthat relate to, describe, or otherwise pertain to a topic that is applicable to multiple themes.  Generic refinements, once created, can be applied to one or more themes to create refinements of those themes.  For example, a generic refinement for \"red\"\nwould be a compiled list of text elements that relate to, describe, or otherwise pertain to the topic \"red\".  The generic refinement for \"red\" may then be applied, for example, to themes for \"cars\", \"consumer products\", \"planets\", etc. to create\nrefinements of those themes, such as \"red cars\", \"red consumer products\", \"red planets\", etc.\nIn step 402, theme creation program 106 receives a sample set of content that is related to the topic of the generic refinement (i.e., a generic related sample set), and a sample set of content that is not related to the topic of the generic\nrefinement (i.e., a generic non-related sample set).  In this exemplary embodiment, a user selects a generic related sample set of content comprising content that relates to, describes, or otherwise embodies the topic of the generic theme.  For example,\nif creating a generic refinement for the topic \"red\", a related sample set of content may comprise content that pertains to, or discusses, various things that are red (e.g., animals, objects, names of colors that are shades of red, etc.).  The user\nselects a non-related generic sample set of content comprising content that does not relate to or otherwise embody the topic of the generic refinement.  For example, if creating a generic refinement for the topic \"red\", a non-related sample set of\ncontent may comprise content that does not pertain to or discuss any colors, does not pertain to or discuss the color red, or pertains to or discusses colors other than red.\nIn step 404, theme creation program 106 extracts text content from the content contained in the generic related and generic non-related sample sets.  As previously discussed, the content of these sample sets may be of any suitable type and,\ndepending on the type of the content, theme creation program 106 may copy the text content and/or extract text content in accordance with appropriate schemas.\nIn step 406, theme creation program 106 parses the extracted text content of the generic related and generic non-related sample sets to obtain one or more text elements.  Theme creation program 106 also determines the number of occurrences for\neach text element in the extracted text content of the generic related and generic non-related sample sets, as previously discussed.  Again, a user may specify how theme creation program 106 should parse the text content.\nIn step 408, theme creation program 106 compiles lists of text elements and their respective occurrences that were identified in step 406.  In this exemplary embodiment, theme creation program 106 compiles a list of text elements identified in\nthe extracted content of the generic related sample set (excluding duplicate text elements), and a separate list of text elements identified in the extracted content of the generic non-related sample set (excluding duplicate text elements).\nIn step 410, theme creation program 106 compares the compiled list of text elements for the generic related sample set with the compiled list of text elements for the generic non-related sample set, and theme creation program 106 removes any\nmatching elements present in both compiled lists from the compiled list of text elements for the generic related sample set.  Stated differently, theme creation program 106 removes from the compiled list of text elements for the generic related sample\nset any text elements which are also found in the compiled list for the generic non-related sample set.\nIn step 412, theme creation program 106 stores the compiled list of text elements for the generic related sample set, along with their respective numbers of occurrences, as a generic refinement in classification database 110.\nIn step 414, theme creation program 106 applies the generic refinement to a theme.  In this exemplary embodiment, theme creation program 106 accesses classification database 110 to obtain the compiled lists of text elements for the generic\nrefinement and the theme to which the generic refinement will be applied.  Theme creation program 106 then compares the lists and removes from the compiled list for the theme all text elements that are not present in the compiled list for the generic\nrefinement.  Theme creation program 106 then stores the compiled list for the theme in classification database 110 as a refinement of the theme, without overwriting the original theme.\nAccordingly, by performing the operational steps of FIG. 4, theme creation program 106 can create a generic refinement comprising a list of text elements which pertain to a topic that is applicable to multiple themes.  Once created and stored in\nclassification database 110, the generic refinement can be applied to one or more themes to create refinements of those themes, which can in turn be stored in classification database 110.  Using generic refinements can, therefore, be a more efficient way\nto create refinements for multiple themes.\nFIG. 5 is a flowchart 500 illustrating operational steps for creating a service entry for a service, in accordance with an embodiment of the present invention.  The term \"service entry\", as used herein, refers to an entry in service description\ndatabase 112 comprising information pertaining to identification, accessibility, and capabilities of a service.  A service entry is created and stored in service description database 112 for each service used for service 118 and enrichment services 116. \nContent analysis engine 104 may then access one or more service entries while processing requests and responses to and from service 118 and enrichment services 116, as discussed in greater detail later in this specification.  In this exemplary\nembodiment, service entry program 108 creates and stores a service entry using information provided by an administrative user of gateway computer system 102.  For example, the administrative user of gateway computer system 102 may be a vendor deploying\nan embodiment of the present invention, or a system administrator configuring gateway computer system 102.\nIn step 502, service entry program 108 receives identification information for the service.  In this exemplary embodiment, the administrative user provides information comprising a name and description of the service.\nIn step 504, service entry program 108 receives information pertaining to accessibility and capabilities of the service.  In this exemplary embodiment, the administrative user provides accessibility information comprising any uniform resource\nlocators (URLs), Internet Protocol (IP) addresses, port numbers, or other information needed for content analysis engine 104 to connect to the service via network 122.  Regarding capabilities of the service, in this exemplary embodiment, the service is\neither retrieve capable, enrich capable, or both.  The term \"retrieve capable\", as used herein, refers to a service (e.g., service 118) whose requests and/or responses can be processed and potentially modified by content analysis engine 104, in\naccordance with embodiments of the present invention.  The term \"enrich capable\", as used herein, refers to services (e.g., enrichment services 116) whose requests and responses can be processed by content analysis engine 104, and which can be queried by\ncontent analysis engine 104 to obtain content with which to enrich a response from a retrieve capable service.  As discussed, service 118 and enrichment services 116 may be implemented with one or more of the same services.  For example, content analysis\nengine 104 may process requests sent to, and responses received from, a search engine service.  At another time, content analysis engine 104 may query the same search engine service to obtain content with which to enrich a response from a service.\nIf the service is retrieve capable, the administrative user provides information needed for content analysis engine 104 to process requests sent to the service from client computer system 120, as well as information needed for content analysis\nengine 104 to processes responses received from the service.  In this exemplary embodiment, the administrative user provides query schemas used when making requests to the service, such that content analysis engine 104 may properly parse requests made to\nthe service.  The administrative user also provides response schemas used for responses from the service, such that content analysis engine 104 may properly parse responses from the service.  The administrative user also provides response injection\nschema and one or more templates that content analysis engine 104 may use to inject additional content into the response from the service, and to ensure that such additional content conforms to the format of the response.\nIf the service is enrich capable, the administrative user provides information needed for content analysis engine 104 to query the service and process responses from the service.  In addition to the identification and accessibility information\ndiscussed above, the administrative user provides query schemas used when making requests to the service such that content analysis engine 104 may properly generate a request.  The administrative user also provides response schemas used for responses\nfrom the service, such that content analysis engine 104 may properly parse responses from the service.\nIn step 506, service entry program 108 optionally receives instructions for modifying requests sent to the service in order to reduce content tailoring in responses from the service.  In this exemplary embodiment, the administrative user\noptionally provides the instructions to service entry program 108.  For example, if the service historically tailors content for users using identification information (e.g., cookies, referrers, identifiers in URLs, etc.), then the administrative user\nmay provide instructions to service entry program 108 to strip such identifying information from requests made to the service in order to reduce content tailoring in responses from the service.\nIn step 508, service entry program 108 stores the service entry in service description database 112.  In this exemplary embodiment, the operational steps of FIG. 5 are repeated to create and store a service entry for each service used for\nservice 118 and enrichment services 116.  A vendor, system administrator, or other party deploying an embodiment of the present invention may create and compile a number of service entries and provide them pre-configured with service description database\n112.  Content analysis engine 104 may then access the service entries while processing requests and responses to and from service 118 and enrichment services 116, to ensure that content in responses from service 118 is sufficiently diverse, as discussed\nin greater detail later in this specification.\nFIG. 6 is a flowchart 600 illustrating operational steps for processing a new request, in accordance with an embodiment of the present invention.  In this exemplary embodiment, content analysis engine 104 on gateway computer system 102 captures\nthe new request being sent from client computer system 120, to service 118, through network 122.\nIn step 602, content analysis engine 104 intercepts a new request from client computer system 120 and extracts information from the request.  Depending on the service type of service 118, a new request to service 118 may be, for example, a\nsearch query, a request for social media or news content, a request to another internet application, and/or combinations thereof.  In this exemplary embodiment, content analysis engine 104 extracts information from the new request that enables content\nanalysis engine 104 to identify service 118, along with query terms.  For example, content analysis engine 104 may extract one or more of targeted host information, URLs, parameters, POST content, cookies and other meta information, along with terms of a\nsearch query.\nIn step 604, content analysis engine 104 determines whether service 118 is a retrieve capable service.  In this exemplary embodiment, content analysis engine 104 searches service description database 112 to determine whether there exists a\nservice entry for service 118, using the extracted information from step 602.\nIf, in step 604, content analysis engine 104 determines that service 118 is not a retrieve capable service (i.e., there is no service entry in service description database 112, or the service entry indicates that service 118 is only enrich\ncapable), then, in step 616, content analysis engine 104 initiates transmission of the request (unmodified) to service 118.\nIf, in step 604, content analysis engine 104 determines that service 118 is a retrieve capable service (i.e., there is a service entry in service description database 112 and it indicates that service 118 is retrieve capable), then, in step 606,\ncontent analysis engine 104 creates and stores a new session in session database 114.  In this exemplary embodiment, the session is specific to the particular request from client computer system 120 and includes information pertinent to the request\n(e.g., a unique identifier, one or more portions of the request, date and location information, etc.).  Content analysis engine 104 may access the session when handling a response from service 118, as described later in this specification in FIG. 7 and\nFIG. 7 (CONT.).\nIn step 608, content analysis engine 104 optionally modifies the request.  In this exemplary embodiment, a user can specify instructions for modifying content in the service entry for service 118.  Depending on the service entry and user\nspecification for service 118, the request may already be suitable for subsequent processing (e.g., no instructions to reducing content tailoring).  Where the service entry indicates a modification, such as removing information identifying a user (i.e.,\na user associated with transmitting request) from the request or injecting tracing data into the request, content analysis engine 104 modifies the request in accordance with appropriate service entries and user specifications.\nIn step 610, content analysis engine 104 optionally pre-fetches enrichment content.  In an exemplary embodiment, this optional process can be performed concurrently with subsequent processing (i.e., a parallel process).  Content analysis engine\n104 may query enrichment services 116 using terms of the query to obtain content with which to enrich responses, as discussed in greater detail with regard to FIG. 8.  Accordingly, content analysis engine 104 may expedite enrichment content retrieval\nfrom enrichment services 116.\nIn step 612, content analysis engine 104 determines whether the request has been modified.  If, in step 612, content analysis engine 104 determines that the request has been modified (i.e., in step 608), then, in step 614, content analysis\nengine 104 initiates transmission of the modified request to service 118.\nIf, in step 612, content analysis engine 104 determines that the request has not been modified then, in step 616, content analysis engine 104 initiates transmission of the original, unmodified request to service 118.\nFIG. 7 and FIG. 7 (CONT.) are a flowchart 700 illustrating operational steps for processing a response from service 118, in accordance with an embodiment of the present invention.  In this exemplary embodiment, content analysis engine 104 on\ngateway computer system 102 captures the response being sent from service 118 to client computer system 120 through network 122.\nIn step 702, content analysis engine 104 receives a response from service 118 and extracts information that identifies service 118.  In this exemplary embodiment, the user specifies the information content analysis engine 104 extracts.  For\nexample, content analysis engine 104 may capture response headers and/or response bodies.  The extracted information assists content analysis engine 104 in identifying service 118 and determining its capabilities.\nIn step 704, content analysis engine 104 determines whether there is an existing session for service 118 in session database 114.  In this exemplary embodiment, content analysis engine 104 searches session database 114 for sessions that match\nthe extracted information for the response (e.g., information comprising X-headers, cookies, tracing data, and similar information) to retrieve an existing session.\nIf, in step 704, content analysis engine 104 determines that there is an existing session for service 118 in session database 114, then, in step 706, content analysis engine 104 accesses the session.\nIf, in step 704, content analysis engine 104 determines that there is not an existing session for service 118 in session database 114, then, in step 708, content analysis engine 104 creates and stores a new session in session database 114, as\npreviously discussed with regard to step 606 of FIG. 6.\nIn step 710, content analysis engine 104 determines whether service 118 is a retrieve capable service.  In this exemplary embodiment, content analysis engine 104 searches service description database 112 to determine whether there exists a\nservice entry for service 118.\nIf, in step 710, content analysis engine 104 determines that service 118 is not a retrieve capable service, then, in step 711, content analysis engine 104 initiates transmission of the original, unmodified response to client computer system 120,\nas content analysis engine 104 may not possess the information needed to analyze or later enrich the response.\nIf, in step 710, content analysis engine 104 determines that service 118 is a retrieve capable service, then, in step 712, content analysis engine 104 identifies schemas for service 118, extracts text content from the response, and parses the\ntext content into text elements.  In this exemplary embodiment, content analysis engine 104 identifies the respective schema through the service entry for service 118 stored in service description database 112.  As previously discussed with regard to\ntheme creation program 106, a user may specify how content analysis engine 104 parses the text content, including a limit on the maximum number of keywords allowed for a given text element.\nIn step 714, content analysis engine 104 determines whether the response from service 118 contains requested content.  For example, the response from service 118 may contain error messages, or may not otherwise contain content requested by a\nuser (i.e., a \"no content\" situation).  In this exemplary embodiment, content analysis engine 104 detects a \"no content\" situation by analyzing the HTTP header of the response for specific error codes such as \"501\", \"403\" or \"404\", and by searching the\ntext content for keywords that indicate the response does not include requested content, such as \"no results found\" or \"access denied\".\nIf, in step 714, content analysis engine 104 determines that the response from service 118 does not contain requested content, then, in step 722, content analysis engine 104 enriches the response.  In this exemplary embodiment, content analysis\nengine 104 can obtain additional content from one or more of enrichment services 116 and enrich the response from service 118 by modifying the response to include the additional content, thereby providing the user with content where the user would\notherwise receive a response that does not contain the requested content.  For example, content analysis engine 104 can query enrichment services 116 using terms of the user's query to obtain the additional content.  In such cases, content analysis\nengine 104 may also include a notice in the enriched response to signal that a large part of the content in the response (or all of the content in the response) was provided by enrichment.  Enrichment of responses is discussed in greater detail with\nregard to FIG. 8.  In another embodiment, responsive to content analysis engine 104 determining that the response from service 118 does not contain requested content, processing may instead proceed to step 726, where content analysis engine 104 initiates\ntransmission of the original, unmodified response to the client computer system 120 via network 122.\nIf, in step 714, content analysis engine 104 determines that the response from service 118 does contain requested content (i.e., no error information was found in the text content or HTTP header of the response), then, in step 716, content\nanalysis engine 104 determines whether the response includes significant content.  In this exemplary embodiment, content analysis engine 104 determines whether the response includes significant content based on a comparison of themes that match the\ncontent in the response and themes that match the terms of the query in the request to service 118.\nTo detect themes and refinements in the content of the response, content analysis engine 104 searches themes and refinements (i.e., lists of text elements associated with those themes and refinements) stored in classification database 110 for\nthe text elements parsed from the response in step 712.  In this exemplary embodiment, content analysis engine 104 first searches the lists of text elements for the themes.  Content analysis engine 104 calculates and records a significance score for each\ntheme, expressed as number of occurrences of matched text elements against the total number of text elements for that specific theme (i.e., the total number of times text elements from the theme are found in the text content against the total number of\ntext elements from the theme).  If the significance score for a theme satisfies a user specified threshold (e.g., 10%), content analysis engine 104 will then search the lists of text elements for all refinements of the theme.  In other embodiments,\ndifferent methodologies may be used to determine how themes and refinements are searched.\nTo detect themes and refinements of the terms of the query in the request to service 118, content analysis engine 104 searches the lists of text elements for the themes and refinements stored in classification database 110 for the terms of the\nquery extracted during processing of the request (e.g., step 602 of FIG. 2).  In this exemplary embodiment, the themes and refinements searched are determined using the same user specified methodology discussed above.\nContent analysis engine 104 compares the themes and refinements detected in the response with the themes and refinements detected in the terms of the query; if there is no match in these themes and/or refinements, or if themes and/or refinements\ndetected in the response and terms of the query have high significance scores (e.g., greater than 30%) but are in unrelated categories (e.g., \"cars\" and \"planets\"), then content analysis engine 104 determines that the response content is not significant,\nand, in step 722, content analysis engine 104 enriches the response.  As previously discussed, content analysis engine 104 can obtain additional content from one or more of enrichment services 116, and enrich the response from service 118 by modifying\nthe response to include the additional content.  Here, however, the response from service 118 includes content, but content analysis engine 104 has determined that the content is not significant content (e.g., is unrelated to the terms of the user's\nquery, or is nonsensical).  Accordingly, content analysis engine 104 enriches the response by replacing less than all (e.g., less than or equal to 50%) of the original content with the additional content obtained from enrichment services 116.  In another\nembodiment, responsive to content analysis engine 104 determining that the response from service 118 does not contain significant content, processing may instead proceed to step 726, where content analysis engine 104 initiates transmission of the\noriginal, unmodified response to the client computer system 120 via network 122.\nIf, in step 716, content analysis engine 104 determines that there is a match in the themes detected in the response and the terms of the query, or if the themes and/or refinements detected in the response and terms of the query have high\nsignificance scores (e.g., greater than 30%) and are in related categories (e.g., \"cars\" and \"trucks\"), then content analysis engine 104 determines that the response content is significant, and, in step 718, content analysis engine 104 determines whether\nthe content in the response is sufficiently diverse in accordance with a user specification.\nIn this exemplary embodiment, diversity of content in a response is based upon the themes and refinements detected in the content of the response.  A user can specify what constitutes a \"sufficiently diverse\" response by specifying a requisite\nnumber of themes and/or refinements that must be detected.  For example, a user can specify that at least four themes and two refinements must be detected in the content of the response (i.e., text elements from the response must be found in the lists of\ntext elements for at least four themes and two refinements) to constitute a sufficiently diverse response.  Furthermore, a user can define what constitutes sufficient diversity based on significance scores or other measures of the extent to which\ndetected themes and refinements are represented in the content.  For example, a user may specify that if only two themes are detected, the content may still be regarded as being sufficiently diverse so long as either theme is not considerably over\nrepresented (e.g., has a significance score that is greater than 50 points higher).\nIf, in step 718, content analysis engine 104 determines that the content in the response is sufficiently diverse in accordance with the user specification (i.e., the requisite themes and/or refinements are detected in the content of the\nresponse), then, in step 726, content analysis engine 104 initiates transmission of the original, unmodified response to client computer system 120 via network 122.\nIf, in step 718, content analysis engine 104 determines that the content in the response is not sufficiently diverse in accordance with the user specification (i.e., the requisite themes and/or refinements are not detected in the content of the\nresponse), then, in step 720, content analysis engine 104 identifies one or more lacking themes.  The term \"lacking themes\", as used herein, refers to detected themes which possess the least amount of text elements that match the text elements of the\nresponse text content.\nIn step 722, content analysis engine 104 enriches the response.  As previously discussed, content analysis engine 104 can obtain additional content from one or more of enrichment services 116 and enrich the response from service 118 by modifying\nthe response to include the additional content.  Here, the response from service 118 includes significant content, but content analysis engine 104 has determined that the content is not sufficiently diverse.  Accordingly, content analysis engine 104\nenriches the response by obtaining additional content pertaining to the identified one or more lacking themes, thereby increasing the diversity of content in the response, as discussed in greater detail with regard to FIG. 8.\nContent analysis engine 104 may also enrich the response to include one or more input mechanisms in the enriched response that allow a user to make on-the-fly changes to criteria for diversity or other specified parameters.  For example, content\nanalysis engine 104 may insert code into the enriched response that displays a slider bar that enables the user to adjust criteria for diversity by sliding a handle from one side of the slider bar to another, representing a continuum of criteria\nrequiring the least amount of content diversity (e.g., only one theme or refinement must be detected) to criteria requiring the greatest amount of content diversity (e.g., at least five themes or refinements must be detected, with differences in\nsignificance scores not to exceed 30 points).  In another example, content analysis engine 104 may insert code into the enriched response that displays selectable elements (e.g., radio buttons or checkboxes) that enable the user to include or exclude\ncontent pertaining certain themes and refinements.\nIn step 724, content analysis engine 104 initiates the transmission of the enriched response to client computer system 120 via network 122.\nIn step 728, content analysis engine 104 determines whether modified criteria for diversity have been received from client computer system 120.  In this exemplary embodiment, content analysis engine 104 may receive modified criteria for\ndiversity from client computer system 120 in response to a user using one or more input mechanisms included in the enriched response.  For example, after viewing the enriched response displayed by client computer system 120, the user may drag a slider\nbar included therein to increase or decrease criteria for diversity, causing client computer system 120 to transmit modified criteria for diversity to gateway computer system 102 and content analysis engine 104 via network 122.  In other embodiments, a\nuser may use other forms of input.\nIf, in step 728, content analysis engine 104 determines that modified criteria for diversity have been received, then processing repeats at step 718, as previously discussed, except that content analysis engine 104 applies the modified criteria\nfor the purpose of determining whether the content in the response from service 118 is sufficiently diverse and for subsequent processing.  In this embodiment, content analysis engine 104 applies the modified criteria on an ad hoc basis for a respective\nsession and response from service 118 (i.e., modified criteria are only temporary criteria for determining diversity).  A user may continue to modify criteria for determining sufficient diversity in this manner, causing updated, enriched responses to be\ntransmitted to the client computer system 120 for display to user (e.g., as a page refresh).  If the user creates and transmits a new request to service 118 (e.g., a different query to the same service or a query to a different service), then content\nanalysis engine 104 will apply the original specified criteria when determining whether content is sufficiently diverse.\nIf, in step 728, content analysis engine 104 determines that modified criteria for diversity have not been received, then the operational steps of FIG. 7 and FIG. 7 (CONT.) end.\nAccordingly, by performing the operational steps of FIG. 7 and FIG. 7 (CONT.), a request sent by client computer system 120 to service 118, and a corresponding response sent by service 118 to client computer system 120, may be intercepted by\ngateway computer system 102.  Content analysis engine 104 may determine the diversity of content included in the response and, if needed, enrich the response with additional content.  The enriched response may then be transmitted to the client computer\nsystem 120 instead of the original response from service 118, where it may be provided to a user of client computer system 120 (e.g., displayed in a web browser).  Furthermore, the user may make on-the-fly adjustments to control the diversity of content\nincluded in the response.  In this manner, embodiments of the present invention provide a non-intrusive, efficient, and customizable way for users to control content tailoring of responses from service 118 and ensure that such content is sufficiently\ndiverse.  Furthermore, since enriched responses are delivered to the user at client computer system 120, embodiments of the present invention can help reduce the time, computational resources, and network bandwidth that might otherwise be consumed if the\nuser made repeated queries from client computer system 120 to service 118 to obtain diverse results.\nFIG. 8 is a flowchart 800 illustrating operational steps for enriching a response from service 118, in accordance with an embodiment of the present invention.  For example, the operational steps of flowchart 800 may be performed at step 722 of\nflowchart 700.\nIn step 802, content analysis engine 104 identifies one or more enrichment services 116 and accesses their service entries in service description database 112.  In this exemplary embodiment, a user may specify which enrichment services 116 to\nuse.  For example, a user may specify that at least four general enrichment services 116 (e.g., search engine services, encyclopedias, etc.) should be used, along with at least one specific enrichment service 116 (e.g., a service specific to a theme\ndetected in the query terms).\nIn step 804, content analysis engine 104 queries enrichment services 116 identified in step 802.  In this exemplary embodiment, content analysis engine 104 creates queries using the appropriate schemas stored in the respective service entries,\nand includes query terms found in the original request sent to service 118 (e.g., the user's search terms).  Content analysis engine 104 may also optionally impersonate a user by including identifying information in the query (e.g., where a certain\ndegree of content personalization is desirable).  Content analysis engine 104 then transmits the created queries to the identified enrichment services 116 via network 122.\nIn step 806, content analysis engine 104 receives responses from enrichment services 116, and extracts text content therefrom, and parses the text content into text elements.  As previously discussed with regard to service 118, enrichment\nservices 116 may use different schema and formatting, so content analysis engine 104 accesses service description database 112 to extract text content pursuant to the appropriate schemas.  In addition, a user may specify how content analysis engine 104\nparses the text content, including a limit on the maximum number of keywords allowed for a given text element.\nIn step 808, content analysis engine 104 detects one or more themes and refinements in the response content.  In this exemplary embodiment, content analysis engine 104 detects themes and refinements in the response content by searching themes\nand refinements (i.e., lists of text elements associated with those themes and refinements) stored in classification database 110 for the text elements parsed from the response content in step 806, using the same methodologies discussed with regard to\nFIG. 7 and FIG. 7 (CONT.).\nIn step 810, content analysis engine 104 optionally detects censorship being performed by one or more of enrichment services 116.  In this exemplary embodiment, content analysis engine 104 may optionally detect censorship by sending a query to\nenrichment services 116 using multiple connection paths (e.g., different proxies, VPN gateways, or other services) and comparing the themes and refinements detected in the corresponding responses.  If content analysis engine 104 determines there is\ndiscrepancy in the detected themes and refinements, or determines that some responses include no content, content analysis engine 104 may flag services that return such responses as being potentially censored, signaling that that the service should\nalways be queried using obfuscated connections in the future.\nIn another embodiment of the present invention, content analysis engine 104 may also optionally detect censorship being performed by service 118.  For example, the absence of requested content in the response from service 118 (i.e., a \"no\ncontent\" situation) and the presence of content in responses obtained from enrichment services 116 (e.g., steps 714 and 722 of FIG. 7 (CONT.)), may indicate potential censorship by service 118.  In response, content analysis engine 104 may retransmit the\nrequest to service 118 using multiple connection paths.  If content analysis engine 104 determines that these responses include requested content, content analysis engine 104 may flag service 118 as being potentially censored, signaling that the service\nshould always be queried using obfuscated connections in the future.\nResponsive to content analysis engine 104 determining that the response from service 118 does not contain requested data, and responsive to obtaining additional content enrichment services 116, content analysis engine 104 may also optionally\ndetect censorship by service 118.  For example, content analysis engine 104 may optionally detect censorship by sending a query to enrichment services 116 using multiple connection paths (e.g., different proxies, VPN gateways, or other services) and\ncomparing the themes and refinements detected in the corresponding responses.  If content analysis engine 104 determines there is discrepancy in the detected themes and refinements, or determines that some responses include no content, content analysis\nengine 104 may flag services that return such responses as being potentially censored, signaling that that the service should always be queried using obfuscated connections in the future.  In another exemplary embodiment, content analysis engine 104 may\nreceive a no content response from service 118 during an initial request from client computer system 120, but receive relevant responses from enrichment services 116.  Accordingly, content analysis engine 104 may flag service 118 for potential\ncensorship.\nIn step 812, content analysis engine 104 filters the responses from enrichment services 116 pursuant to user specified criteria.  In this exemplary embodiment, content analysis engine 104 determines whether the responses contain content that is\nsufficiently diverse, as described in step 718 of FIG. 7 (CONT.).  Content analysis engine 104 also determines whether the themes and/or refinements detected in the content of the responses match one or more lacking themes identified for the response\nfrom service 118 (e.g., as identified in step 720 of FIG. 7 (CONT.)).  In this exemplary embodiment, content analysis engine 104 discards responses from enrichment services 116 whose detected themes and/or refinements do not match a lacking theme, and\ncontent analysis engine 104 discards responses from enrichment services 116 whose content is not sufficiently diverse.  In other embodiments, other criteria may be used to filter the responses from enrichment services 116.  After performing step 812, one\nor more responses from enrichment services 116 may remain for use in enriching the response from service 118.\nIn step 814, content analysis engine 104 creates an enriched response.  In this exemplary embodiment, content analysis engine 104 selects a remaining response having the most matches for the one or more lacking themes.  Content analysis engine\n104 then modifies the response from service 118 to include the extracted text content from the selected response.  In some instances, content analysis engine 104 may modify the response from service 118 to include extracted text content from multiple\nresponses from enrichment services 116.\nIn this exemplary embodiment, content analysis engine 104 modifies the response from service 118, in accordance with response injection schemas and one or more templates obtained from service description database 112.  More specifically, the\ninjection schema specify any content to be extracted from the original response, a reference to a template file containing code to use for responses from service 118, and an insertion point for the template code.  The extracted text content from the\nselected response may be inserted into the template code (e.g., replacing generic placeholders in the template code), and the modified template code may then be inserted into the response at the specified insertion point to generate the enriched\nresponse.  Accordingly, the injection schemas and templates enable content analysis engine 104 to remove content and/or add additional content into the response from service 118, while ensuring that such additional content conforms to the format of\nresponses from service 118 and will, therefore, display properly to a user of client computer system 120.\n<BR><BR>EXAMPLE\nThe following example discusses a hypothetical scenario in which a response from service 118 is enriched, and the enriched response is sent to client computer system 120.\nIn this example, service 118 is a search engine, and the response from service 118 comprises a webpage incorporating HTML, CSS, and XML to display a plurality of search results, where each search result is a list item, &lt;li&gt;, in an ordered\nlist, &lt;ol&gt;.  The enrichment content to be added to the response from service 118 is an alternative search result, obtained from another search engine serving as one of enrichment services 116.  The injection schema for service 118 comprises\nextraction and integration information defining a target XPath for content to be extracted from the response (i.e., a list item for a particular search result in the ordered list for the search results), a reference to the template file to use for the\nservice, and the insertion point for the template contents.  The insertion point, in this example, is defined using a selector identifying the ordered list in which the alternative search result should be inserted (e.g., ol[@id=\"search_results\"]).  The\ntemplate in this example specifies the code used by this particular service for each list element of the identified ordered list, with generic place holders for URLS, captions, and other attributes of the search result.\nAfter obtaining an alternative search result (i.e., enrichment content) from one of enrichment services 116, content analysis engine 104 inserts the details of that alternative search result into the generic place holders of the template, and\nthen inserts the completed template code into the code of the response from service 118 as a list item member of the ordered list \"search_results\".  The modified response is then transmitted to a user of client computer system 120, where the page can be\ndisplayed to the user in a browser, including the alternative search result in addition to, or instead of, a search result that would otherwise have been provided by service 118 in the original response.\nFIG. 9 is a block diagram of internal and external components of a computer system 900, which is representative the computer systems of FIG. 1, in accordance with an embodiment of the present invention.  It should be appreciated that FIG. 9\nprovides only an illustration of one implementation and does not imply any limitations with regard to the environments in which different embodiments may be implemented.  In general, the components illustrated in FIG. 9 are representative of any\nelectronic device capable of executing machine-readable program instructions.  Examples of computer systems, environments, and/or configurations that may be represented by the components illustrated in FIG. 9 include, but are not limited to, personal\ncomputer systems, server computer systems, thin clients, thick clients, laptop computer systems, tablet computer systems, cellular telephones (e.g., smart phones), multiprocessor systems, microprocessor-based systems, network PCs, minicomputer systems,\nmainframe computer systems, and distributed cloud computing environments that include any of the above systems or devices.\nComputer system 900 includes communications fabric 902, which provides for communications between one or more processors 904, memory 906, persistent storage 908, communications unit 912, and one or more input/output (I/O) interfaces 914. \nCommunications fabric 902 can be implemented with any architecture designed for passing data and/or control information between processors (such as microprocessors, communications and network processors, etc.), system memory, peripheral devices, and any\nother hardware components within a system.  For example, communications fabric 902 can be implemented with one or more buses.\nMemory 906 and persistent storage 908 are computer-readable storage media.  In this embodiment, memory 906 includes random access memory (RAM) 916 and cache memory 918.  In general, memory 906 can include any suitable volatile or non-volatile\ncomputer-readable storage media.  Software is stored in persistent storage 908 for execution and/or access by one or more of the respective processors 904 via one or more memories of memory 906.\nPersistent storage 908 may include, for example, a plurality of magnetic hard disk drives.  Alternatively, or in addition to magnetic hard disk drives, persistent storage 908 can include one or more solid state hard drives, semiconductor storage\ndevices, read-only memories (ROM), erasable programmable read-only memories (EPROM), flash memories, or any other computer-readable storage media that is capable of storing program instructions or digital information.\nThe media used by persistent storage 908 can also be removable.  For example, a removable hard drive can be used for persistent storage 908.  Other examples include optical and magnetic disks, thumb drives, and smart cards that are inserted into\na drive for transfer onto another computer-readable storage medium that is also part of persistent storage 908.\nCommunications unit 912 provides for communications with other computer systems or devices via a network (e.g., network 122).  In this exemplary embodiment, communications unit 912 includes network adapters or interfaces such as a TCP/IP adapter\ncards, wireless Wi-Fi interface cards, or 3G or 4G wireless interface cards or other wired or wireless communication links.  The network can comprise, for example, copper wires, optical fibers, wireless transmission, routers, firewalls, switches, gateway\ncomputers and/or edge servers.  Software and data used to practice embodiments of the present invention can be downloaded through communications unit 912 (e.g., via the Internet, a local area network or other wide area network).  From communications unit\n912, the software and data can be loaded onto persistent storage 908.\nOne or more I/O interfaces 914 allow for input and output of data with other devices that may be connected to computer system 900.  For example, I/O interface 914 can provide a connection to one or more external devices 920 such as a keyboard,\ncomputer mouse, touch screen, virtual keyboard, touch pad, pointing device, or other human interface devices.  External devices 920 can also include portable computer-readable storage media such as, for example, thumb drives, portable optical or magnetic\ndisks, and memory cards.  I/O interface 914 also connects to display 922.\nDisplay 922 provides a mechanism to display data to a user and can be, for example, a computer monitor.  Display 922 can also be an incorporated display and may function as a touch screen, such as a built-in display of a tablet computer.\nThe present invention may be a system, a method, and/or a computer program product.  The computer program product may include a computer readable storage medium (or media) having computer readable program instructions thereon for causing a\nprocessor to carry out aspects of the present invention.\nThe computer readable storage medium can be a tangible device that can retain and store instructions for use by an instruction execution device.  The computer readable storage medium may be, for example, but is not limited to, an electronic\nstorage device, a magnetic storage device, an optical storage device, an electromagnetic storage device, a semiconductor storage device, or any suitable combination of the foregoing.  A non-exhaustive list of more specific examples of the computer\nreadable storage medium includes the following: a portable computer diskette, a hard disk, a random access memory (RAM), a read-only memory (ROM), an erasable programmable read-only memory (EPROM or Flash memory), a static random access memory (SRAM), a\nportable compact disc read-only memory (CD-ROM), a digital versatile disk (DVD), a memory stick, a floppy disk, a mechanically encoded device such as punch-cards or raised structures in a groove having instructions recorded thereon, and any suitable\ncombination of the foregoing.  A computer readable storage medium, as used herein, is not to be construed as being transitory signals per se, such as radio waves or other freely propagating electromagnetic waves, electromagnetic waves propagating through\na waveguide or other transmission media (e.g., light pulses passing through a fiber-optic cable), or electrical signals transmitted through a wire.\nComputer readable program instructions described herein can be downloaded to respective computing/processing devices from a computer readable storage medium or to an external computer or external storage device via a network, for example, the\nInternet, a local area network, a wide area network and/or a wireless network.  The network may comprise copper transmission cables, optical transmission fibers, wireless transmission, routers, firewalls, switches, gateway computers and/or edge servers. \nA network adapter card or network interface in each computing/processing device receives computer readable program instructions from the network and forwards the computer readable program instructions for storage in a computer readable storage medium\nwithin the respective computing/processing device.\nComputer readable program instructions for carrying out operations of the present invention may be assembler instructions, instruction-set-architecture (ISA) instructions, machine instructions, machine dependent instructions, microcode, firmware\ninstructions, state-setting data, or either source code or object code written in any combination of one or more programming languages, including an object oriented programming language such as Smalltalk, C++ or the like, and conventional procedural\nprogramming languages, such as the \"C\" programming language or similar programming languages.  The computer readable program instructions may execute entirely on the user's computer, partly on the user's computer, as a stand-alone software package,\npartly on the user's computer and partly on a remote computer or entirely on the remote computer or server.  In the latter scenario, the remote computer may be connected to the user's computer through any type of network, including a local area network\n(LAN) or a wide area network (WAN), or the connection may be made to an external computer (for example, through the Internet using an Internet Service Provider).  In some embodiments, electronic circuitry including, for example, programmable logic\ncircuitry, field-programmable gate arrays (FPGA), or programmable logic arrays (PLA) may execute the computer readable program instructions by utilizing state information of the computer readable program instructions to personalize the electronic\ncircuitry, in order to perform aspects of the present invention.\nAspects of the present invention are described herein with reference to flowchart illustrations and/or block diagrams of methods, apparatus (systems), and computer program products according to embodiments of the invention.  It will be\nunderstood that each block of the flowchart illustrations and/or block diagrams, and combinations of blocks in the flowchart illustrations and/or block diagrams, can be implemented by computer readable program instructions.\nThese computer readable program instructions may be provided to a processor of a general purpose computer, special purpose computer, or other programmable data processing apparatus to produce a machine, such that the instructions, which execute\nvia the processor of the computer or other programmable data processing apparatus, create means for implementing the functions/acts specified in the flowchart and/or block diagram block or blocks.  These computer readable program instructions may also be\nstored in a computer readable storage medium that can direct a computer, a programmable data processing apparatus, and/or other devices to function in a particular manner, such that the computer readable storage medium having instructions stored therein\ncomprises an article of manufacture including instructions which implement aspects of the function/act specified in the flowchart and/or block diagram block or blocks.\nThe computer readable program instructions may also be loaded onto a computer, other programmable data processing apparatus, or other device to cause a series of operational steps to be performed on the computer, other programmable apparatus or\nother device to produce a computer implemented process, such that the instructions which execute on the computer, other programmable apparatus, or other device implement the functions/acts specified in the flowchart and/or block diagram block or blocks.\nThe flowchart and block diagrams in the figures illustrate the architecture, functionality, and operation of possible implementations of systems, methods and computer program products according to various embodiments of the present invention. \nIn this regard, each block in the flowchart or block diagrams may represent a module, segment, or portion of code, which comprises one or more executable instructions for implementing the specified logical function(s).  It should also be noted that, in\nsome alternative implementations, the functions noted in the block may occur out of the order noted in the figures.  For example, two blocks shown in succession may, in fact, be executed substantially concurrently, or the blocks may sometimes be executed\nin the reverse order, depending upon the functionality involved.  It will also be noted that each block of the block diagrams and/or flowchart illustration, and combinations of blocks in the block diagrams and/or flowchart illustration, can be\nimplemented by special purpose hardware-based systems that perform the specified functions or acts, or combinations of special purpose hardware and computer instructions.\nThe descriptions of the various embodiments of the present invention have been presented for purposes of illustration, but are not intended to be exhaustive or limited to the embodiments disclosed.  Many modifications and variations will be\napparent to those of ordinary skill in the art without departing from the scope and spirit of the invention.  The terminology used herein was chosen to best explain the principles of the embodiment, the practical application or technical improvement over\ntechnologies found in the marketplace, or to enable others of ordinary skill in the art to understand the embodiments disclosed herein.", "application_number": "14726893", "abstract": " Embodiments of the present invention provide systems, methods, and\n     computer program products for processing responses from services (e.g.,\n     content providers) and managing content tailoring by services and/or\n     recommender systems used by those services. Embodiments of the present\n     invention can afford users with the ability to control the diversity of\n     content in responses provided by services based one or more detected\n     themes of the responses. Furthermore, embodiments of the present\n     invention may be used to provide users with enriched responses from\n     services, without needing cooperation of those services.\n", "citations": ["7761464", "8001064", "8086621", "8086631", "8112407", "8180776", "8239380", "8244721", "8352465", "8631001", "8631030", "9298813", "9576574", "20070294225", "20090327270", "20100131563", "20110295678", "20120005183", "20130103672", "20140379708", "20150161124", "20150161176", "20170017694"], "related": ["14475805"]}, {"id": "20160092090", "patent_code": "10296192", "patent_name": "Dynamic visual profiling and visualization of high volume datasets and\n     real-time smart sampling and statistical profiling of extremely large\n     datasets", "year": "2019", "inventor_and_country_data": " Inventors: \nStojanovic; Alexander Sasha (Los Gatos, CA), Rivas; Luis E. (Denver, CO), Markey; Kevin L. (Longmont, CO), Bidwell; Christopher F. (Golden, CO)  ", "description": "<BR><BR>BACKGROUND\nThe present disclosure relates generally to data preparation and analysis.  More particularly, techniques are disclosed for profiling data sets and providing visualizations of profiling using a visual-interactive interface in a client\napplication.\nBefore \"big data\" systems can analyze data to provide useful results, the data needs to be added to the big data system and formatted such that it can be analyzed.  This data onboarding presents a challenge for current cloud and \"big data\"\nsystems.  Typically, data being added to a big data system is noisy (e.g., the data is formatted incorrectly, erroneous, outdated, includes duplicates, etc.).  When the data is analyzed (e.g., for reporting, predictive modeling, etc.) the poor signal to\nnoise ratio of the data means the results are not useful.  As a result, current solutions require substantial manual processes to clean and curate the data and/or the analyzed results.  However, these manual processes cannot scale.  As the amount of data\nbeing added and analyzed increases, the manual processes become impossible to implement.\nCertain embodiments of the present invention address these and other problems.\n<BR><BR>BRIEF SUMMARY\nThe present disclosure relates generally to data preparation and analysis.  More particularly, techniques are disclosed for profiling data sets and providing visualizations of profiling using a visual-interactive interface in a client\napplication.\nA data enrichment service is disclosed that can extract, repair, and enrich datasets, resulting in more precise entity resolution and correlation for purposes of subsequent indexing and clustering.  The data enrichment service can include a\nvisual recommendation engine and language for performing large-scale data preparation, repair, and enrichment of heterogeneous datasets.  This enables the user to select and see how the recommended enrichments (e.g., transformations and repairs) will\naffect the user's data and make adjustments as needed.  The data enrichment service can receive feedback from users through a user interface and can filter recommendations based on the user feedback.\nThe data enrichment service can automatically profile data sets and provide visualizations of the profiles using a visual-interactive model within a client application (such as a web browser or mobile app).  The visual profiling can be refined\nthrough end user interaction with the visualization objects and guide exploratory data visualization and discovery.  Additionally, data sampling of heterogeneous data streams can be performed during ingestion to extract statistical attributes from\nmulti-columnar data (e.g., standard deviation, median, mode, correlation coefficient, histogram, etc.).  Data sampling can continue in real-time as data sources are updated.\nIn some embodiments, a computing system may be implemented for generating and displaying interactive visualizations for profiling data sets and providing visualizations of profiling using a visual-interactive interface in a client application. \nThe computing system may implement a data enrichment service.  The computing system may be configured to implement methods and operations described herein.  In some embodiments, a system is disclosed that may include a plurality of data sources and a\nplurality of data targets.  The system may include a cloud computing infrastructure system comprising one or more processors communicatively coupled to the plurality of data sources and communicatively coupled to the plurality of data targets, over at\nleast one communication network.  The cloud computing infrastructure system may include a memory coupled to the one or more processors, the memory storing instructions to provide a data enrichment service, where the instructions, when executed by the one\nor more processors, cause the one or more processors to perform one or more methods or operations described herein.  Yet other embodiments relate to systems and machine-readable tangible storage media, which employ or store instructions for methods and\noperations described herein.\nIn at least one embodiment, a method includes identifying one or more patterns in data obtained from one or more data sources.  The method includes matching an identified pattern to entity information from a knowledge system.  The method\nincludes generating a graphical visualization based on the identified pattern matching the entity information.  The method includes causing the graphical visualization to be displayed in a user interface.  The method includes receiving input related to\nthe graphical visualization through the user interface.  The method includes updating the graphical visualization based on the input.\nIn some embodiments, the method may include monitoring the one or more data sources in real-time; periodically updating the identified pattern based on updated data obtained from the one or more data sources by the monitoring; generating an\nupdated graphical visualization based on an update to the identified pattern; and causing the updated graphical visualization to be displayed in the user interface.\nIn some embodiments, identifying the one or more patterns in the data includes: profiling the data as it is obtained from the one or more data sources; and determining sampled data that is a representative sample of one or more characteristics\nwithin the profiled data, where determining the sampled data includes oversampling a first portion of the profiled data and undersampling a second portion of the profiled data.  A graphical visualization may include a graphical dashboard.  The graphical\ndashboard may indicate a plurality of metrics, each of the plurality of metrics indicating a real time metric of the data relative to a time that the data is profiled.  The plurality of metrics can represent a user-specific set of metrics calculated for\nthe data.  In at least one embodiment, receiving the input related to the graphical visualization through the user interface includes: receiving a selection of a first point in time in the user interface; displaying a first plurality of metrics\nassociated with the first point in time; receiving a gesture-based input indicating a second point in time in the user interface; and displaying a second plurality of metrics associated with the second point in time.  In at least one embodiment,\nreceiving the input related to the graphical visualization through the user interface includes: receiving a gesture-based input in the graphical dashboard; and based on the gesture-based input, adjusting a displayed time scale of the graphical dashboard.\nThe foregoing, together with other features and embodiments will become more apparent upon referring to the following specification, claims, and accompanying drawings. <BR><BR>BRIEF DESCRIPTION OF THE DRAWINGS\nFIG. 1 depicts a simplified high level diagram of a data enrichment service, in accordance with an embodiment of the present invention.\nFIG. 2 depicts a simplified block diagram of a technology stack, in accordance with an embodiment of the present invention.\nFIG. 3A depicts a simplified block diagram of an interactive visualization system, in accordance with an embodiment of the present invention.\nFIG. 3B depicts an example data flow of a profile process of an interactive visualization system, in according with an embodiment of the present invention.\nFIGS. 4A-4D depict examples of a user interface that provides interactive data enrichment, in accordance with an embodiment of the present invention.\nFIGS. 5A-5D depict examples of various user interfaces that provide visualizations of datasets, in accordance with an embodiment of the present invention.\nFIGS. 6A-6B depict examples of visualizations of datasets, in accordance with an embodiment of the present invention.\nFIGS. 7A-7C depict examples of interactive data visualizations, in accordance with an embodiment of the present invention.\nFIG. 8 depicts a flowchart of a method of interactive data visualization, in accordance with an embodiment of the present invention.\nFIG. 9 depicts a simplified diagram of a distributed system for implementing an embodiment.\nFIG. 10 is a simplified block diagram of one or more components of a system environment in which services may be offered as cloud services, in accordance with an embodiment of the present disclosure.\nFIG. 11 illustrates an exemplary computer system that may be used to implement an embodiment of the present invention.\n<BR><BR>DETAILED DESCRIPTION\nIn the following description, for the purposes of explanation, specific details are set forth in order to provide a thorough understanding of embodiments of the invention.  However, it will be apparent that various embodiments may be practiced\nwithout these specific details.  The figures and description are not intended to be restrictive.\nThe present disclosure relates generally to a data enrichment service that extracts, repairs, and enriches datasets, resulting in more precise entity resolution and correlation for purposes of subsequent indexing and clustering.  In some\nembodiments, the data enrichment service includes an extensible semantic pipeline, which processes the data in a number of stages, from ingestion of the data to analysis of the data, to publishing of the data-to-data targets.\nIn certain embodiments of the present invention, prior to loading data into a data warehouse (or other data target) the data is processed through a pipeline (also referred to herein as a semantic pipeline) which includes various processing\nstages.  In some embodiments, the pipeline can include an ingest stage, prepare stage, profile stage, transform stage, and publish stage.  During processing, the data can be analyzed, prepared, and enriched.  The resulting data can then be published\n(e.g., provided to a downstream process) into one or more data targets (such as local storage systems, cloud-based storage services, web services, data warehouses, etc.) where various data analytics can be performed on the data.  Because of the repairs\nand enrichments made to the data, the resulting analyses produce useful results.  Additionally, because the data onboarding process is automated, it can be scaled to process very large data sets that cannot be manually processed due to volume.\nIn some embodiments, data can be analyzed to extract entities from the data, and based on the extracted entities, the data can be repaired.  For example, misspellings, address errors, and other common mistakes present a complex problem to big\ndata systems.  For small quantities of data, such errors can be manually identified and corrected.  However, in very large data sets (e.g., billions of nodes or records) such manual processing is not possible.  In certain embodiments of the present\ninvention, the data enrichment service can analyze data using a knowledge service.  Based on the contents of the knowledge service, entities in the data can be identified.  For example, an entity can be an address, a business name, a location, a person\nname, an identification number, etc.\nFIG. 1 depicts a simplified high-level diagram 100 of a data enrichment service, in accordance with an embodiment of the present invention.  As shown in FIG. 1, a cloud-based data enrichment service 102 can receive data from various data sources\n104.  In some embodiments, a client can submit a data enrichment request to data enrichment service 102 which identifies one or more of the data sources 104 (or portions thereof, e.g., particular tables, datasets, etc.).  The data enrichment service 102\nmay then request data to be processed from the identified data sources 104.  In some embodiments, the data sources may be sampled, and the sampled data analyzed for enrichment, making large data sets more manageable.  The identified data can be received\nand added to a distributed storage system (such as a Hadoop Distributed Storage (HDFS) system) accessible to the data enrichment service.  The data may be processed semantically by a number of processing stages (described herein as a pipeline or semantic\npipeline).  These processing stages can include preparation stages 108, enrichment stages 110, and publishing stages 112.  In some embodiments, data can be processed in one or more batches by the data enrichment services.  In some embodiments, a\nstreaming pipeline can be provided that processes data as it is received.\nIn some embodiments, a prepare stage 108 can include various processing sub-stages.  This may include automatically detecting a data source format and performing content extraction and/or repair.  Once the data source format is identified, the\ndata source can be automatically normalized into a format that can be processed by the data enrichment service.  In some embodiments, once a data source has been prepared, it can be processed by an enrich stage 110.  In some embodiments, inbound data\nsources can be loaded into a distributed storage system 105 accessible to the data enrichment service (such as an HDFS system communicatively coupled to the data enrichment service).  The distributed storage system 105 provides a temporary storage space\nfor ingested data files, which can then also provide storage of intermediate processing files, and for temporary storage of results prior to publication.  In some embodiments, enhanced or enriched results can also be stored in the distributed storage\nsystem.  In some embodiments, metadata captured during enrichment associated with the ingested data source can be stored in the distributed storage system 105.  System level metadata (e.g., that indicates the location of data sources, results, processing\nhistory, user sessions, execution history, and configurations, etc.) can be stored in the distributed storage system or in a separate repository accessible to the data enrichment service.\nIn certain embodiments, the enrichment process 110 can analyze the data using a semantic bus (also referred to herein as a pipeline or semantic pipeline) and one or more natural language (NL) processors that plug into the bus.  The NL processors\ncan automatically identify data source columns, determine the type of data in a particular column, name the column if no schema exists on input, and/or provide metadata describing the columns and/or data source.  In some embodiments, the NL processors\ncan identify and extract entities (e.g., people, places, things, etc.) from column text.  NL processors can also identify and/or establish relationships within data sources and between data sources.  As described further below, based on the extracted\nentities, the data can be repaired (e.g., to correct typographical or formatting errors) and/or enriched (e.g., to include additional related information to the extracted entities).\nIn some embodiments, a publish stage 112 can provide data source metadata captured during enrichment and any data source enrichments or repairs to one or more visualization systems for analysis (e.g., display recommended data transformations,\nenrichments, and/or other modifications to a user).  The publishing sub-system can deliver the processed data to one or more data targets.  A data target may correspond to a place where the processed data can be sent.  The place may be, for example, a\nlocation in memory, a computing system, a database, or a system that provides a service.  For example, a data target may include Oracle Storage Cloud Service (OSCS), URLs, third party storage services, web services, and other cloud services such as\nOracle Business Intelligence (BI), Database as a Service, and Database Schema as a Service.  In some embodiments, a syndication engine provides customers with a set of APIs to browse, select, and subscribe to results.  Once subscribed and when new\nresults are produced, the results data can be provided as a direct feed either to external web service endpoints or as bulk file downloads.\nFIG. 2 depicts a simplified block diagram 200 of a technology stack, in accordance with an embodiment of the present invention.  In some embodiments, the data enrichment service can be implemented using the logical technology stack shown in FIG.\n2.  The technology stack can include a user interface/experience (UX) layer 202 that provides access to the data enrichment service through one or more client devices (e.g., using a thin client, thick client, web browser, or other application executing\non the client devices).  A scheduler service 204 can manage requests/responses received through the UX layer and can manage the underlying infrastructure on which the data enrichment service executes.\nIn some embodiments, the processing stages described above with respect to FIG. 1, can include a number of processing engines.  For example, the prepare processing stage 108 can include ingest/prepare engines, a profiling engine and a\nrecommendation engine.  As data is ingested during prepare processing, the data (or samples thereof) can be stored in a distributed data storage system 210 (such as a \"big data\" cluster).  The enrich processing stage 110 can include semantic/statistical\nengines, an entity extraction engine, and repair/transform engines.  As described further below, the enrich processing stage 110 can utilize information obtained from knowledge service 206 during the enrichment process.  Enrichment actions (e.g., the\naddition and/or transformation of data) can be performed on the data stored in the distributed storage system 210.  Transformation of data may include modification to add missing data or data to enrich the data.  Transformation of data may include\nmodifying errors in the data or repairing the data.  The publish processing stage 112 can include a publish engine, a syndication engine, and a metadata results manager.  In some embodiments, various open source technologies can be used to implement some\nfunctionality within the various processing stages and/or processing engines.  For example, file format detection can use Apache Tika.\nIn some embodiments, a management service 208 can monitor changes made to the data during enrichment processing 110.  The monitored changes can include tracking which users accessed the data, which data transformations were performed, and other\ndata.  This can enable the data enrichment service to roll back enrichment actions.\nTechnology stack 200 can be implemented in an environment such as a cluster 210 for big data operations (\"Big Data Cluster\").  Cluster 210 can be implemented using Apache Spark, which provides a set of libraries for implementing a distributed\ncomputing framework compatible with a distributed file system (DFS) such as HDFS.  Apache Spark can send requests for map, reduce, filter, sort, or Sample cluster processing jobs to effective resource managers like YARN.  In some embodiments, cluster 210\ncan be implemented using a distributed file system offering such as one offered by Cloudera.RTM..  The DFS, such as one offered by Cloudera.RTM., may include HDFS and Yarn.\nFIG. 3A depicts a simplified block diagram of data enrichment system 300, in accordance with an embodiment of the present invention.  Data enrichment system 300 may implement a data enrichment service 302.  Data enrichment service 302 can\nreceive data enrichment requests from one or more clients 304.  Data enrichment service 302 may comprise one or more computers and/or servers.  Data enrichment service 302 may be a module that is comprised of several subsystems and/or modules, including\nsome, which may not be shown.  Data enrichment service 302 may have more or fewer subsystems and/or modules than shown in the figure, may combine two or more subsystems and/or modules, or may have a different configuration or arrangement of subsystems\nand/or modules.  In some embodiments, data enrichment service 302 may include user interface 306, ingest engine 328, recommendation engine 308, knowledge service 310, profile engine 326, transform engine 322, a prepare engine 312, and publish engine 324. The elements implementing data enrichment service 302 may operate to implement a semantic processing pipeline as described above.\nData enrichment system 300 may include a semantic processing pipeline, in accordance with an embodiment of the present invention.  All or part of the semantic processing pipeline may be implemented by data enrichment service 102.  When a data\nsource is added, the data source and/or the data stored thereon can be processed through a pipeline prior to loading the data source.  The pipeline can include one or more processing engines that are configured to process the data and/or data source\nbefore publishing the processed data to one or more data targets.  The processing engines can include an ingest engine that extracts raw data from the new data source and provides the raw data to a prepare engine.  The prepare engine can identify a\nformat associated with the raw data and can convert the raw data into a format (e.g., normalize the raw data) that can be processed by the data enrichment service 302.  A profile engine can extract and/or generate metadata associated with the normalized\ndata and a transform engine can transform (e.g., repair and/or enrich) the normalized data based on the metadata.  The resulting enriched data can be provided to the publish engine to be sent to one or more data targets.  Each processing engine is\ndescribed further below.\nIn some embodiments, data enrichment service 302 may be provided by a computing infrastructure system (e.g., a cloud computing infrastructure system).  The computing infrastructure system may be implemented in a cloud computing environment\nhaving one or more computing systems.  The computing infrastructure system may be communicatively coupled, over one or more communication networks, to one or more data sources or one or more data targets such as those described herein.\nThe clients 304 can include various client devices (such as desktop computers, laptop computers, tablet computers, mobile devices, etc.).  Each client device can include one or more client applications 304 through which the data enrichment\nservice 302 can be accessed.  For example, a browser application, a thin client (e.g., a mobile app), and/or a thick client can execute on the client device and enable the user to interact with the data enrichment service 302.  The embodiment depicted in\nFIGS. 3A and 3B are merely examples and are not intended to unduly limit the claimed embodiments of the present invention.  One of ordinary skill in the art would recognize many variations, alternatives, and modifications.  For example, there may be more\nor fewer client devices than those shown in the figures.\nThe client devices 304 may be of various different types, including, but not limited to personal computers, desktops, mobile or handheld devices such as a laptop, a mobile phone, a tablet, etc., and other types of devices.  A communication\nnetwork facilitates communications between client devices 304 and data enrichment service 302.  The communication network can be of various types and can include one or more communication networks.  Examples of communication network 106 include, without\nrestriction, the Internet, a wide area network (WAN), a local area network (LAN), an Ethernet network, a public or private network, a wired network, a wireless network, and the like, and combinations thereof.  Different communication protocols may be\nused to facilitate the communications including both wired and wireless protocols such as IEEE 802.XX suite of protocols, TCP/IP, IPX, SAN, AppleTalk, Bluetooth, and other protocols.  In general, the communication network may include any communication\nnetwork or infrastructure that facilitates communications between clients and data enrichment service 302.\nA user can interact with the data enrichment service 302 through user interface 306.  Clients 304 can render a graphical user interface to display the user's data, recommendations for transforming the user's data, and to send and/or receive\ninstructions (\"transformation instructions\") to the data enrichment service 302 through user interface 306.  The user interfaces disclosed herein, such as those references in FIGS. 4A-4D, 5A-5D, 6A-6B, and 7A-7C, may be rendered by data enrichment\nservice 302 or via clients 304.  For example, a user interface may be generated by user interface 306, and rendered by data enrichment service 302 at any one of clients 304.  A user interface may be provided by data enrichment system 302 via network as\npart of a service (e.g., a cloud service) or a network-accessible application.  In at least one example, an operator of a data enrichment service 302 may operate one of clients 304 to access and interact with any user interfaces disclosed herein.  The\nuser can send instructions to user interface 306 to add data sources (e.g., provide data source access and/or location information, etc.).\nData enrichment service 302 may ingest data using ingest engine 328.  Ingest engine 328 can serve as an initial processing engine when a data source is added.  The ingest engine 328 can facilitate safe, secure, and reliable uploading of user\ndata from one or more data sources 309 into data enrichment service 302.  In some embodiments, ingestion engine 328 can extract data from the one or more data sources 309 and store it in a distributed storage system 305 in data enrichment service 302. \nData ingested from one or more data sources 309 and/or one or more clients 304 can be processed as described above with respect to FIGS. 1-2 and stored in a distributed storage system 305.  Data enrichment service 302 can receive data from a client data\nstore 307 and/or from one or more data sources 309.  The distributed storage system 305 can serve as temporary storage for the uploaded data during the remaining processing stages of the pipeline, prior to the data being published to one or more data\ntargets 330.  Once an upload is complete, the prepare engine 312 can be invoked to normalize the uploaded data set.\nThe received data may include structured data, unstructured data, or a combination thereof.  Structure data may be based on data structures including, without limitation, an array, a record, a relational database table, a hash table, a linked\nlist, or other types of data structures.  As described above, the data sources can include a public cloud storage service 311, a private cloud storage service 313, various other cloud services 315, a URL or web-based data source 317, or any other\naccessible data source.  A data enrichment request from the client 304 can identify a data source and/or particular data (tables, columns, files, or any other structured or unstructured data available through data sources 309 or client data store 307). \nData enrichment service 302 may then access the identified data source to obtain the particular data specified in the data enrichment request.  Data sources can be identified by address (e.g., URL), by storage provider name, or other identifier.  In some\nembodiments, access to a data source may be controlled by an access management service.  The client 304 may display a request to the user to input a credential (e.g., username and password) and/or to authorize the data enrichment service 302 to access\nthe data source.\nIn some embodiments, data uploaded from the one or more data sources 309 can be modified into various different formats.  The prepare engine 312 can convert the uploaded data into a common, normalized format, for processing by data enrichment\nservice 302.  Normalizing may be performed by routines and/or techniques implemented using instructions or code, such as Apache Tika distributed by Apache.RTM..  The normalized format provides a normalized view of data obtained from the data source.  In\nsome embodiments, the prepare engine 312 can read a number of different file types.  Prepare engine 312 can normalize the data into a character separated form (e.g., tab separated values, comma separated values, etc.) or as a JavaScript Object Notation\n(JSON) document for hierarchical data.  In some embodiments, various file formats can be recognized and normalized.  For example, standard file formats such as Microsoft Excel.RTM.  formats (e.g., XLS or XLSX), Microsoft Word.RTM.  formats (e.g., DOC or\nDOCX), and portable document format (PDF), and hierarchical formats like JSON and extended markup language (XML), can be supported.  In some embodiments, various binary encoded file formats and serialized object data can also be read and decoded.  In\nsome embodiments, data can be provided to the pipeline in Unicode format (UTF-8) encoding.  Prepare engine 312 can perform context extraction and conversion to the file types expected by data enrichment service 302, and can extract document level\nmetadata from the data source.\nNormalizing a data set mat include converting raw data in a data set into a format that is processable by the data enrichment service 302, in particular profile engine 326.  In one example, normalizing the data set to create a normalized data\nset includes modifying the data set having one format to an adjusted format as a normalized data set, the adjusted format being different from the format.  A data set may be normalized by identifying one or more columns of data in the data set, and\nmodifying a format of the data corresponding to the columns to the same format.  For example, data having different formatted dates in a data set may be normalized by changing the formats to a common format for the dates that can be processed by profile\nengine 326.  Data may be normalized by being modified or converted from a non-tabular format to a tabular format, having one or more columns of data.\nOnce the data has been normalized, the normalized data can be passed to profile engine 326.  The profile engine 326 can perform a column by column analysis of normalized data to identify the types of data stored in the columns and information\nabout how the data is stored in the columns.  In this disclosure, although profile engine 326 is described in many instances as performing operations on data, the data processed by profile engine 326 has been normalized by prepare engine 312.  In some\nembodiments, the data processed by profile engine 326 may include data that is not normalized for being in a format (e.g., a normalized format) processable by profile engine 326.  The output, or results, of profile engine 326 may be metadata (e.g.,\nsource profile) indicating profile information about the data from a source.  The metadata may indicate one or more patterns about the data and/or a classification of the data.  As further described below, the metadata may include statistical information\nbased on analysis of the data.  For example, profile engine 326 can output a number of metrics and pattern information about each identified column, and can identify schema information in the form of names and types of the columns to match the data.\nThe metadata generated by profile engine 326 may be used by other elements of data enrichment service, e.g., recommendation engine 308 and transformation engine 322, to perform operations as described herein for data enrichment service 302.  In\nsome embodiments, the profile engine 326 can provide metadata to a recommendation engine 308.\nRecommendation engine 308 can identify repair, transform, and data enrichment recommendations for the data processed by profile engine 326.  The metadata generated by profile engine 326 can be used to determine recommendations for data based on\nthe statistical analysis and/or classifications indicated by the metadata.  In some embodiments, recommendations can be provided to the user through a user interface or other web service.  Recommendations can be tailored for business users, such that the\nrecommendations describe at a high level what data repairs or enrichments are available, how those recommendations compare to past user activity, and/or how unknown items can be classified based on existing knowledge or patterns.  Knowledge service 310\ncan access one or more knowledge graphs or other knowledge sources 340.  The knowledge sources can include publicly available information published by web sites, web services, curated knowledge stores, and other sources.  Recommendation engine 308 can\nrequest (e.g., query) knowledge service 310 for data that can be recommended to a user for the data obtained for a source.\nIn some embodiments, transform engine 322 can present the user with the sampled data for each column, or sample rows from the input dataset through user interface 306.  Through user interface 306, data enrichment service 302 may present a user\nwith recommended transformations.  The transformations may be associated with transformation instructions, which may include code and/or function calls to perform transformation actions.  The transformation instructions may be invoked by a user based on\nselection at user interface 306, such as by selecting a recommendation for transformation or by receiving input indicating an operation (e.g., an operator command).  In one example, transformation instructions include a transformation instruction to\nrename at least one column of data based on the entity information.  A further transformation instruction can be received to rename the at least one column of data to a default name.  A default name may include a name that is pre-determined.  A default\nname may be any name that is pre-defined when a name for a column of data cannot be determined or is not defined.  The transformation instructions can include a transformation instruction to reformat at least one column of data based on the entity\ninformation, and a transformation instruction to obfuscate at least one column of data based on the entity information.  In some embodiments, the transformation instructions can include an enrichment instruction to add one or more columns of data\nobtained from the knowledge service based on the entity information.\nThrough user interface 306, a user can perform transform actions, and the transform engine 322 can apply them to the data obtained from a data source and display the results.  This gives the user immediate feedback that can be used to visualize\nand verify the effects of the transform engine 322 configuration.  In some embodiments, the transform engine 322 can receive pattern and/or metadata information (e.g., column names and types) from profile engine 326 and recommendation engine 308, which\nprovides recommended transform actions.  In some embodiments, transform engine 322 can provide a user event model that orchestrates and tracks changes to the data to facilitate undo, redo, delete, and edit events.  The model can capture dependencies\nbetween actions so that the current configuration is kept consistent.  For example, if a column is removed, then recommended transform actions provided by the recommendation engine 308 for that column can also be removed.  Similarly, if a transform\naction results in inserting new columns and that action is deleted, then any actions performed on the new columns are also deleted.\nAs described above, during processing the received data can be analyzed and a recommendation engine 308 can present one or more recommended transforms to be made to the data, including enrichment, repair, and other transforms.  A recommended\ntransform for enriching data may be comprised of a set of transforms, each transform of which is a single transform action, or an atomic transformation, performed on the data.  A transform may be performed on data that was previously transformed by\nanother transform in the set.  The set of transforms may be performed in parallel or in a particular order, such that the data resulting after performing the set of transforms is enriched.  The set of transforms may be performed according to a transform\nspecification.  The transform specification may include transformation instructions that indicate how and when to perform each of the set of transforms on the data produced by profile engine 326 and the recommendation for enriching the data determined by\nrecommendation engine 308.  Examples of the atomic transformation may include, without limitation, transforms to headers, conversions, deletions, splits, joins, and repairs.  The data that is transformed according to the set of transforms may undergo a\nseries of changes, each of which results in intermediate data the data is enriched.  The data generated for intermediate steps for the set of transforms may be stored in a format such as an Resilient Distributed Dataset (RDD), text, a data record format,\na file format, any other format, or a combination thereof.\nIn some embodiments, the data generated as a result of the operations performed by any elements of data enrichment service 302 may be stored in an intermediary data format including, but not limited to, RDD, text, a document format, any other\ntype of format, or a combination thereof.  The data stored in the intermediary format may be used to further perform operations for data enrichment service 302.\nThe following tables illustrate examples of transformations.  Table 1 shows an outline of types of transforms actions.\nTABLE-US-00001 TABLE 1 Transform Function Types Parameter(s) Description Examples Update String =&gt; String Update column values Obfuscate, date format, Split String =&gt; Split a column's values Regex split, Array[String] into new columns\ndelimiter split Filter String =&gt; Boolean Filter rows based on a White list single column's values filtering, date range filtering Multi- Array[String] =&gt; Filter rows based on NER false column Boolean multiple column positives Filter values\nfiltering Edit Array[String] =&gt; Edit the existing Reorder, remove, Columns Array[String] columns swap columns Extract (String, String) =&gt; Extract values from a NER with Array[Array[String]] column into a new results RDD extracted to a new table\nInsert String =&gt; Insert new columns Insert timestamp Array[String] Insert 1:M String =&gt; Insert new columns in a Insert NER results Array[Array[String]] one-to-many way\nTable 2 shows transform actions that do not fit within the category types shown with reference to Table 1.\nTABLE-US-00002 TABLE 2 Transform Actions Description Rename column Rename a column Sample Replace the current RDD with a sample of it Join Performs a left-outer-join between two RDDs Export Export an RDD as columnar data to e.g. HDFS\nTable 3 below shows examples of types of transform examples.  Specifically Table 3 shows examples of transform actions and describes the type of transformations corresponding to those actions.  For example, a transform action may include\nfiltering data based on detecting the presence of words from a white list in data.  If a user wants to track communications (e.g., tweets) containing \"Android\" or \"iPhone\", a transform action could be added with those two words comprising the provided\nwhite list.  This is just one example of the way by which data could be enriched for a user.\nTABLE-US-00003 TABLE 3 Transform Actions Description Input Output R1 Obfuscate Obfuscate 123-45-6789 ###-##-#### Y sensitive information such as e.g. credit card numbers, ID's, or birth dates Date Reformat a 1330978536 March 05, 2012 Y Reformat\ncolumn 2012-03-12 03/12/12 containing a 14:13:49 02:13:49 PM date Rename Rename a tagged_0001 user_agent Y Column column text_label_0005 call_letters NER Perform named PopBooth turns Type: Product Y entity your iPhone or Text: PopBooth, recognition and\niPad into a iPhone, iPad insert values photo booth, (see next prints and all section) Search/ Perform search Search: Mozilla Value: Godzilla Y Replace and replace on a Replace: 5.0 column's values Godzilla Value: Mozilla 5.0 Change Change the case Case:\nProper Value: Eden Y case to lower, upper, Value: eden Prairie or proper prairie White list Filter rows List: Android, Keep all rows Y filter based on the iPhone whose presence of Value: I values contain words from a heart my \"Android\" or white list in a\niPhone \"iPhone\" text-valued column\nThe recommendation engine 308 can use information from a knowledge service 310, knowledge source 340 to generate recommendations for transform engine 322 and to instruct transform engine 322 to generate transform scripts that will transform the\ndata.  Transform scripts may include programs, code, or instructions that may be executable by one or more processing units to transform received data.  As such, the recommendation engine 308 can serve as an intermediary between the user interface 306\nand the knowledge service 310.\nAs discussed above, profile engine 326 can analyze data from a data source to determine whether any patterns exist, and if so, whether a pattern can be classified.  Once data obtained from a data source is normalized, the data may be parsed to\nidentify one or more attributes or fields in the structure of the data.  Patterns may be identified using a collection of regular expressions, each having a label (\"tag\") and being defined by a category.  The data may be compared to different types of\npatterns to identify a pattern.  Examples of pattern types that can be identified include, without limitation, integers, decimals, dates or date/time strings, URLs, domain addresses, IP addresses, email addresses, version numbers, locale identifiers,\nUUIDs and other hexidecimal identifiers, social security numbers, US box numbers, typical US street address patterns, zipcodes, US phone numbers, suite numbers, credit card numbers, proper names, personal information, and credit card vendors.\nIn some embodiments, profile engine 326 may identify patterns in data based on a set of regular expressions defined by semantic constraints or syntax constraints constraints.  A regular expression may be used to determine the shape and/or\nstructure of data.  Profile engine 326 may implement operations or routines (e.g., invoke an API for routines that perform processing for regular expressions) to determine patterns in data based on one or more regular expressions.  For example, a regular\nexpression for a pattern may be applied to data based on syntax constraints to determine whether the pattern is identifiable in the data.\nProfile engine 326 may perform parsing operations using one or more regular expressions to identify patterns in data processed by profile engine 326.  Regular expressions may be ordered according to a hierarchy.  Patterns may be identified based\non order of complexity of the regular expressions.  Multiple patterns may match data that is being analyzed; the patterns having the greater complexity will be selected.  As described further below, profile engine 326 may perform statistical analysis to\ndisambiguate between patterns based on the application of regular expressions that are applied to determine those patterns.\nIn some embodiments, data that is unstructured may be processed to analyze metadata-describing attributes in the data.  The metadata itself may indicate information about the data.  The metadata may be compared to identify similarities and/or to\ndetermine a type of the information.  The information identified based on the data may be compared to know types of data (e.g., business information, personal identification information, or address information) to identify the data that corresponds to a\npattern.\nIn accordance with an embodiment, the profile engine 326 may perform statistical analysis to disambiguate the patterns and/or the text in data.  Profile engine 326 may generate metadata including statistical information based on the statistical\nanalysis.  When patterns are identified, profile engine 326 may determine statistical information (e.g., a pattern metric) about each different pattern to disambiguate between the patterns.  The statistical information may include a standard deviation\nfor different patterns that are recognized.  The metadata including the statistical information can be provided to other components of data enrichment service 302, such as recommendation engine 308.  For example, the metadata may be provided to\nrecommendation engine 308 to enable recommendation engine 308 to determine recommendations for enrichment of the data based on the identified the pattern(s).  Recommendation engine 308 can use the patterns to query a knowledge service 310 to obtain\nadditional information about the patterns.  Knowledge service 310 can include or have access to one or more knowledge sources 340.  A knowledge sources can include publicly available information published by web sites, web services, curated knowledge\nstores, and other sources.\nProfile engine 326 may perform the statistical analysis to disambiguate between patterns identified in the data.  For example, data analyzed by profile engine 326, may be evaluated to compute a pattern metric (e.g., a statistical frequency of\ndifferent patterns in the data) for each of the different patterns identified in the data.  Each of the set of pattern metrics is computed for a different pattern of the patterns that are identified.  Profile engine 326 may determine a difference amongst\nthe pattern metrics computed for the different patterns.  One of the identified patterns may be selected based on the difference.  For example, one pattern may be disambiguated from another pattern based on a frequency of the patterns in the data.  In\nanother example, where the data consists of dates having multiple different formats, each corresponding to a different pattern, profile engine 326 may convert the dates to a standard format in addition to normalization and may then determine a standard\ndeviation for each format from different patterns.  In this example, profile engine 326 may statistically disambiguate between the formats in the data as having the format with the lowest standard deviation.  The pattern corresponding to the format of\nthe data having the lowest standard deviation may be selected as the best pattern for the data.\nProfile engine 326 may determine a classification of a pattern that it identifies.  Profile engine 326 may communicate with knowledge service 310 to determine whether the identified pattern can be classified within a knowledge domain.  Knowledge\nservice 310 may determine one or more possible domains associated with the data based on techniques described herein such as matching techniques and similarity analysis.  Knowledge service 310 may provide profile engine 326 with a classification of one\nor more domains possibly similar to data identified with a pattern.  Knowledge service 310 may provide, for each of the domains identified by knowledge service 310, a similarity metric indicating a degree of similarity to the domain.  The techniques\ndisclosed herein for similarity metric analysis and scoring can be applied by recommendation engine 308 to determine a classification of data processed by profile engine 326.  The metadata generated by profile engine 326 may include information about the\nknowledge domain, if any are applicable, and a metric indicating a degree of similarity with the data analyzed by profile engine 326.\nProfile engine 326 may perform statistical analysis to disambiguate text identified in data, regardless of whether patterns are identified in the data.  The text may be part of a pattern, and the analysis of the text may be used to further\nidentify a pattern, if any can be identified.  Profile engine 326 may request knowledge service 310 to perform domain analysis on text to determine whether the text can be classified into one or more domains.  Knowledge service 310 may operate to provide\ninformation about one or more domains that are applicable to the text being analyzed.  Analysis performed by knowledge service 310 to determine a domain may be performed using techniques described herein, such as similarity analysis used to determine a\ndomain for data.\nIn some embodiments, profile engine 326 may identify text data in a data set.  The text data may correspond to each entity identified in the set of entities.  A classification may be determined for each entity that is identified.  Profile engine\n326 may request knowledge service to identify a classification for the entity.  Upon determining a set of classifications for a set of entities (e.g., entities in a column), profile engine 326 may compute a set of metrics (\"classification metrics\") to\ndisambiguate between the set of classifications.  Each of the set of metrics may be computed for a different one of the set of classifications.  Profile engine 326 may statistically disambiguate the set of metrics by comparing them to each other to\ndetermine which classification most closely represents the set of entities.  A classification of the set of entities may be chosen based on the classification that represents the set of entities.\nUsing the knowledge sources 340, knowledge service 310 can match, in context, the patterns identified by profile engine 326.  Knowledge service 310 may compare the identified patterns in the data or the data if in text to entity information for\ndifferent entities stored by a knowledge source.  The entity information may be obtained from one or more knowledge sources 340 using knowledge service 310.  Examples of known entity may include social security numbers, telephone numbers, address, proper\nnames, or other personal information.  The data may be compared to entity information for different entities to determine if there is a match with one or more entities based on the identified pattern.  For example, the knowledge service 310 can match the\npattern \"XXX-XX-XXXX\" to the format of U.S.  social security numbers.  Furthermore, the knowledge service 310 can determine that social security numbers are protected or sensitive information, the disclosure of which is linked to various penalties.\nIn some embodiments, profile engine 326 can perform statistical analysis to disambiguate between multiple classifications identified for data processed by profile engine 326.  For example, when text is classified with multiple domains, profile\nengine 326 can process the data to statistically determine the appropriate classification determined by knowledge service 310.  The statistical analysis of the classification can be included in the metadata generated by profile engine 326.\nIn addition to pattern identification, profile engine 326 can analyze data statistically.  The profile engine 326 can characterize the content of large quantities of data, and can provide global statistics about the data and a per-column\nanalysis of the data's content: e.g., its values, patterns, types, syntax, semantics, and its statistical properties.  For example, numeric data can be analyzed statistically, including, e.g., N, mean, maximum, minimum, standard deviation, skewness,\nkurtosis, and/or a 20-bin histogram if N is greater than 100 and unique values is greater than K. Content may be classified for subsequent analysis.\nIn one example, global statistics may include, without restriction, the number of rows, the number of columns, the number of raw and populated columns and how they varies, distinct and duplicate rows, header information, the number of columns\nclassified by type or subtype, and the number of columns with security or other alerts.  Column-specific statistics may include populated rows (e.g., K-most frequent, K-least frequent unique values, unique patterns, and (where applicable) types),\nfrequency distributions, text metrics (e.g., minimum, maximum, mean values of: text length, token count, punctuation, pattern-based tokens, and various useful derived text properties), token metrics, data type and subtype, statistical analysis of numeric\ncolumns, L-most/least probable simple or compound terms or n-grams found in columns with mostly unstructured data, and reference knowledge categories matched by this naive lexicon, date/time pattern discovery and formatting, reference data matches, and\nimputed column heading label.\nThe resulting profile can be used to classify content for subsequent analyses, to suggest, directly or indirectly, transformations of the data, to identify relationships among data sources, and to validate newly acquired data before applying a\nset of transformations designed based on the profile of previously acquired data.\nThe metadata produced by profile engine 326 can be provided to the recommendation engine 308 to generate one or more transform recommendations.  The entities that match an identified pattern of the data can be used to enrich the data with those\nentities identified by classification determined using knowledge service 310.  In some embodiments, the data to the identified patterns (e.g., city and state) may be provided to knowledge service 310 to obtain, from a knowledge source 340, entities that\nmatch the identified patterns.  For example, knowledge service 310 may be invoked calling a routine (e.g., getCities( ) and getStates( )) corresponding to the identified patterns to receive entity information.  The information received from knowledge\nservice 310 may include a list (e.g., canonical list) of entities that have properly spelled information (e.g., properly spelled cities and states) for the entities.  Entity information corresponding to matching entities obtained from knowledge service\n310 can be used to enrich data, e.g., normalize the data, repair the data, and/or augment the data.\nIn some embodiments, the recommendation engine 308 can generate transform recommendations based on the matched patterns received from the knowledge service 310.  For example, for the data including social security numbers, the recommendation\nengine can recommend a transform that obfuscates the entries (e.g., truncating, randomizing, or deleting, all or a portion of the entries).  Other examples of transformation may include, reformatting data (e.g., reformatting a date in data), renaming\ndata, enriching data (e.g., inserting values or associating categories with data), searching and replacing data (e.g., correcting spelling of data), change case of letter (e.g., changing a case from upper to lower case), and filter based on black list or\nwhite list terms.  In some embodiments, recommendations can be tailored for particular users, such that the recommendations describe at a high level what data repairs or enrichments are available.  For example, an obfuscation recommendation may indicate\nthat the first five digits of the entries will be deleted.  In some embodiments, the recommendations can be generated based on past user activity (e.g., provide a recommended transform that was previously used when sensitive data was identified)\nTransform engine 322 can generate transform scripts based on the recommendations provided by recommendation engine 308 (e.g., a script to obfuscate the social security numbers).  A transform script may perform an operation to transform data.  In\nsome embodiments, a transform script may implement a linear transformation of data.  A linear transformation may be implemented through use of an API (e.g., Spark API).  The transform actions may be performed by operations invoked using the API.  A\ntransform script may be configured based on transform operations defined using the API.  The operations may be performed based on the recommendations.\nIn some embodiments, the transform engine 322 can automatically generate transform scripts to repair data at the data source.  Repairs may include automatically renaming columns, replacing strings or patterns within a column, modifying text\ncase, reformatting data, etc. For example, the transform engine 322 can generate a transformation script to transform a column of dates based on a recommendation from recommendation engine 308 to modify, or convert, the formats of the dates in the\ncolumn.  The recommendation may be selected from multiple recommendations to enrich or modify the data from a data source that is processed by profile engine 326.  The recommendation engine 308 may determine the recommendation based on metadata, or\nprofile, provided by the profile engine 326.  The metadata may indicate a column of dates identified for different formats (e.g., MM/DD/YYYY, DD-MM-YY, etc.).  The transform script generated by transform engine 322 can, for example, split and/or join\ncolumns based on suggestions from the recommendation engine 308.  The transform engine 322 may also remove columns based on the data source profiles received from profile engine 326 (e.g., to remove empty columns, or columns that include information that\nis not desired by the user).\nA transform script may be defined using a syntax that describes operations with respect to one or more algorithms (e.g., Spark Operator Trees).  As such, the syntax may describe operator-tree transduction/reduction.  A transform script may be\ngenerated based on a chosen recommendation or requested by a user interactively through a graphical user interface.  Examples of recommended transformations are described with reference to FIGS. 4A, 4B, 4C, and 4D.  Based on the transform operations\nspecified by a user through the graphical user interface, the transform engine 322 performs transform operations according to those operations.  The transform operations may be recommended to the user to enrich a data set.\nAs described further below, the clients 304 can display recommendations describing or otherwise indicating each recommended transform.  When a user selects a transform script to be run, the selected transform script can be run on all or more of\nthe data from the data source in addition to the data analyzed to determine the recommended transform(s).  The resulting transformed data can then be published to one or more data targets 330 by publish engine 324.  In some embodiments, the data targets\ncan be different data stores than the data sources.  In some embodiments, the data targets can be the same data stores as the data sources.  Data targets 330 can include a public cloud storage service 332, a private cloud storage service 334, various\nother cloud services 336, a URL or web-based data target 338, or any other accessible data target.\nIn some embodiments, recommendation engine 308 can query knowledge service 310 for additional data related to the identified platform.  For example, where the data includes a column of city names, related data (e.g., location, state, population,\ncountry, etc.) can be identified and a recommendation to enrich the dataset with the related data can be presented.  Examples of presenting recommendations and transforming data through a user interface are shown below with respect to FIGS. 4A-4D.\nKnowledge service 310 can implement a matching method to compare the data to reference data available through knowledge service 310.  Knowledge service 310 can include or have access to one or more knowledge sources 340.  The knowledge sources\ncan include publicly available information published by web sites, web services, curated knowledge stores, and other sources.  Knowledge service 310 can implement a method to determine the semantic similarity between two or more datasets.  This may also\nbe used to match the user's data to reference data available through the knowledge service 310.  Knowledge service 310 may perform similarity metric analysis as described in this disclosure.  The techniques performed by knowledge service 310 may include\nthose described in this disclosure including the techniques described by the references incorporated herein.\nKnowledge service 310 can perform operations to implement automated data analyses.  In some embodiments, knowledge service 310 can use an unsupervised machine learning tool, such as Word2Vec, to analyze an input data set.  Word2Vec can receive a\ntext input (e.g., a text corpus from a large data source) and generate a vector representation of each input word.  The resulting model may then be used to identify how closely related are an arbitrary input set of words.  For example, a Word2Vec model\nbuilt using a large text corpus (e.g., a news aggregator, or other data source) can be utilized to determine corresponding numeric vector for each input word.  When these vectors are analyzed, it may be determined that the vectors are \"close\" (in the\nEuclidean sense) within a vector space.  Although this can identify that input words are related (e.g., identifying input words that are clustered closely together within a vector space), Word2Vec may not be usable to identify a descriptive label for the\nwords (e.g., \"tire manufacturers\").  Knowledge service 310 may implement operations to categorize the related words using a curated knowledge source 340 (e.g., YAGO, from the Max Planck Institute for Informatics).  Using information from a knowledge\nsource 340, knowledge service 310 can add additional, related data to the input data set.\nIn some embodiments, knowledge service 310 may implement operations to perform trigram modeling to further refine categorization of related terms.  Trigram modeling can be used to compare sets of words for category identification.  The input\ndata set can be augmented with the related terms.\nUsing the input data set, which may include added data, knowledge service 310 can implement matching methods (e.g., a graph matching method) to compare the words from the augmented data set to categories of data from knowledge source 340. \nKnowledge service 310 can implement a method to determine the semantic similarity between the augmented data set and each category in knowledge source 340 to identify a name for the category.  The name of the category may be chosen based on a highest\nsimilarity metric.  The similarity metric may computed be based on the number of terms in the data set that match a category name.  The category may be chosen based on the highest number of terms matching based on the similarity metric.  Techniques and\noperations performed for similarity analysis and categorization are further described below.\nIn some embodiments, knowledge service 310 can augment an input data set and use information from a knowledge source 340 to add additional, related data to the input data set.  For example, a data analysis tool such as Word2Vec can be used to\nidentify semantically similar words to those included in the input data set from a knowledge source, such as a text corpus from a news aggregation service.  In some embodiments, knowledge service 310 can implement trigram modeling to preprocess data\nobtained from a knowledge source 340 (such as YAGO) to generate an indexed table of words by category.  Knowledge service 310 can then create trigrams for each word in the augmented data set and match the word to a word from the indexed knowledge source\n340.\nUsing the augmented data set (or the trigram matched augmented data set), knowledge service 310 can compare the words from the augmented data set to categories of data from knowledge source 340.  For example, each category of data in the\nknowledge source 340 can be represented as a tree structure, with the root node representing the category, and each leaf node representing a different word belonging to that category.  Knowledge service 310 can implement a method (e.g., Jaccard index, or\nother similarity metric) to determine the semantic similarity between the augmented data set and each category in knowledge source 510.  The name of the category that matches the augmented data set (e.g., having a highest similarity metric) can then be\napplied as a label to the input data set.\nIn some embodiments, knowledge service 310 can determine the similarity of two data sets A and B, by determining the ratio of the size of the intersection of the data sets to the size of the union of the data sets.  For example, a similarity\nmetric may be computed based on the ratio of 1) the size of the intersection of an data set (e.g., an augmented data set) and a category and 2) the size of their union.  The similarity metric may be computed for comparison of a data set and a category as\nindicated above.  As such, a \"best match\" may be determined based on comparing the similarity metrics.  The data set used for the comparison may be enriched by being augmented with a label corresponding to the category for which the best match is\ndetermined using the similarity metric.\nAs described above, other similarity metrics may be used in addition, or as an alternative, to the Jaccard index.  One of ordinary skill in the art would recognize that any similarity metric may be used with the above described techniques.  Some\nexamples of alternative similarity metrics include, but are not limited to: the Dice-Sorensen index; the Tversky index; the Tanimoto metric; and the cosine similarity metric.\nIn some embodiments, knowledge service 310 may utilize a data analysis tool, such as Word2Vec, to compute a refined metric (e.g., score) that indicates a degree of match between data from a knowledge source 340 and an input data, which may be\naugmented with data from a knowledge source.  The score (\"knowledge score\") may provide greater knowledge about the degree of similarity between an input data set and a category to which a comparison is made.  The knowledge score may enable data\nenrichment service 302 to choose a category name that bests represents the input data.\nIn the techniques described above, knowledge service 310 may count the number of matches of terms in the input data set to a candidate category (e.g., genus) name in a knowledge source 340.  The result of the comparison may yield a value that\nrepresents a whole integer.  As such the value, although indicative of the degree of match between terms, may not indicate a degree of match between an input data set and different terms in a knowledge source.\nKnowledge service 310 may utilize Word2Vec to determine a similarity of a comparison of each term (e.g., a term for a genus) in a knowledge source and the terms of input data (e.g., species).  Using Word2Vec, knowledge service 310 can compute a\nsimilarity metric (e.g., cosine similarity or distance) between an input data set and one or more terms obtained from a knowledge source.  The cosine similarity may be computed as the cosine angle between a data set of terms (e.g., a domain or genus)\nobtained from a knowledge source and an input data set of terms.  The cosine similarity metric may be computed in a manner similar to the Tanimoto metric.  By computing a similarity metric based on a cosine similarity, each term in the input data set may\nbe considered as a faction of a whole-value integer, such as a value indicating a percentage of similarity between the term and candidate category.  For example, computing a similarity metric between a tire manufacturer and a surname might result in a\nsimilarity metric of 0.3, while the similarity metric between a tire manufacturer and a company name might results in a similarity metric of be 0.5.  Non-whole integer values representing similarity metrics can be close compared to provide greater\naccuracy for a closely matching category name.  The closely matching category name may be chosen as the most applicable category name based on the similarity metric closest to a value of 1.  In the example, above, based on the similarity metric, company\nname is more likely the correct category.  As such, knowledge service 310 can associated \"company\" instead of \"surname\" with a user-supplied column of data containing tire manufactures.\nKnowledge service 310 can determine information about knowledge groups (e.g., domains or categories).  Information about knowledge groups can be presented in a graphical user interface.  Information about knowledge domains may include a metric\n(e.g., a knowledge score) indicating a measure of similarity between a knowledge domain and an input data set of terms.  Input data may be compared to data from a knowledge source 340.  An input data set may correspond to a column of data of a data set\nspecified by a user.  The knowledge score may indicate a measure of similarity between an input data set and one or more terms provided by a knowledge source, each term corresponding to a knowledge domain.  The column of data may include terms that\npotentially belong to knowledge domain.\nIn at least one embodiment, knowledge service 310 may determine a more accurate matching score.  The score may correspond to a value computing using a scoring formula using techniques disclosed herein including references that are incorporated\nherein.  The scoring formula may determine a semantic similarity between two data sets, e.g., the input data set and terms in a domain (e.g., a candidate category) obtained from a knowledge source.  The domain for which the matching score indicates the\nbest match (e.g., the highest matching score), may be chosen as the domain having the greatest similarity with the input data set.  As such, the terms in the input data set may be associated with the domain name as the category.\nThe scoring formula may be applied to an input data set and a domain (e.g., a category of terms obtained from a knowledge source) to determine a score that indicates a measure of a match between the input data and the domain.  The domain may\nhave one or more terms, which collectively define the domain.  The score may be used to determine the domain to which an input data set is most similar.  The input data set may be associated with a term descriptive of the domain to which the input data\nset is most similar.\nIn some embodiments, user interface 306 can generate one or more graphical visualizations based on metadata provided by profile engine 326.  As explained above, the data provided by profile engine 326 may include statistical information\nindicating metrics about data that has been processed by profile engine 326.  Examples of graphical visualizations of metrics of profiled data are shown in FIGS. 5A-5D.  A graphical visualization can include a graphical dashboard (e.g., a visualization\ndashboard).  The graphical dashboard may indicate a plurality of metrics, each of the plurality of metrics indicating a real time metric of the data relative to a time that the data is profiled.  A graphical visualization may be displayed in a user\ninterface.  For example, the graphical visualization that is generated may be sent to a client device to cause the client device to display the graphical visualization in a user interface at the client device.  In some embodiments, a graphical\nvisualization may provide profiling results.\nAdditionally, the structural analyses by the profile engine 326 enable the recommendation engine to better focus its queries to knowledge service 310, improving processing speed and reducing load on system resources.  For example, this\ninformation can be used to limit the scope of knowledge being queried so that the knowledge service 310 does not attempt to match a column of numerical data to place names.\nFIG. 3B depicts an example data flow of a profile process 350 of an interactive visualization system, in according with an embodiment of the present invention.  Profile process 350 may be implemented by data enrichment service 302.  Profile\nengine 326 may implement all or part of profile process 350 to profile data ingested from various data sources.\nData enrichment service 302 may request data to be processed from data sources.  The data sources may be sampled and the sampled data may be stored in a distributed storage system (such as a Hadoop Distributed Storage (HDFS) system) accessible\nto data enrichment service.  In some embodiments, sampled data may be received from one or more data sources.  Profile process 350 may analyze sampled data for enrichment, making large data sets more manageable.  The data may be processed semantically by\na number of processing stages (described herein as a pipeline or semantic pipeline), such as processing stages described with reference to FIGS. 2 and 3A.\nProfile process 350 may begin at step 352 by accessing sampled data for profiling.  Data that is profiled 380 (\"profile data\") may be generated at one or more steps of process 350.  Profile data 380 may be stored in one or more data targets such\nas a distributed storage system 382.  Process 350 may analyze sampled data to determine global statistics including statistics about columns.\nAt step 354, sampled data may be characterized to determine global statistics, including a column profile.  A column profile may indicate column-specific statistics.  Examples of column-specific statistics include column count and column\npopulation.  At step 356, sampled data may be further profiled to determine column values.  Column values may be processed to reduce a format of unique values and their frequencies for each column.  At step 358, processing may continue to determine\ncolumn-specific metrics such as a K-most frequent unique values.  Examples of K-most frequent values may be stored as profile data 380 in distributed storage system 382.  At step 360, type discovery may be performed, whereby unique types are discovered\nfor column data.  The number of types may be stored as profile data 380 in distributed storage system 382.  At step 362, the unique types may be processed to determine metrics about type patterns, such as K-most frequent patterns types in column data. \nExamples of the types of patterns may be stored as profile data 380 in distributed storage system 382.  At step 364, column data may be further processed to determine n-grams found in columns.  Statistics about the N-grams may be stored as profile data\n380 in distributed storage system 382.  As described herein, profiled data 380 may be used to present data visualizations indicating statistics about large sets of data.  At step 366, profiled data may be modified for enrichment to impute labels, such as\ncolumn names.  The labels may be imputed on the basis of the statistics of the profiled data.\nWith reference to FIG. 3B, individual embodiments may be described as a process which is depicted as a flowchart, a flow diagram, a data flow diagram, a structure diagram, or a block diagram.  Although a flowchart may describe the operations as\na sequential process, many of the operations may be performed in parallel or concurrently.  In addition, the order of the operations may be re-arranged.  A process is terminated when its operations are completed, but could have additional steps not\nincluded in a figure.  A process may correspond to a method, a function, a procedure, a subroutine, a subprogram, etc. When a process corresponds to a function, its termination may correspond to a return of the function to the calling function or the\nmain function.\nThe processes depicted FIG. 3B may be implemented in software (e.g., code, instructions, program) executed by one or more processing units (e.g., processors cores), hardware, or combinations thereof.  The software may be stored in a memory\n(e.g., on a memory device, on a non-transitory computer-readable storage medium).  The particular series of processing steps in FIG. 3B is not intended to be limiting.  Other sequences of steps may also be performed according to alternative embodiments. \nFor example, alternative embodiments of the present invention may perform the steps outlined above in a different order.  Moreover, the individual steps illustrated in FIG. 3B may include multiple sub-steps that may be performed in various sequences as\nappropriate to the individual step.  Furthermore, additional steps may be added or removed depending on the particular applications.  One of ordinary skill in the art would recognize many variations, modifications, and alternatives.\nIn an aspect of some embodiments, each process in the flowchart of FIG. 3B can be performed by one or more processing units.  A processing unit may include one or more processors, including single core or multicore processors, one or more cores\nof processors, or combinations thereof.  In some embodiments, a processing unit can include one or more special purpose co-processors such as graphics processors, digital signal processors (DSPs), or the like.  In some embodiments, some or all of\nprocessing units can be implemented using customized circuits, such as application specific integrated circuits (ASICs), or field programmable gate arrays (FPGAs).\nFIGS. 4A-4D depict examples of a user interface that provides interactive data enrichment, in accordance with an embodiment of the present invention.  As shown in FIG. 4A, an example interactive user interface 400 can display transform scripts\n402, recommended transforms 404, and at least a portion of the data 406 being analyzed/transformed.  Transform scripts listed in panel 402 can include indicate transforms that have been applied to the data and are visible in panel 406.  Each transform\nscript 402 can be written in a simple declarative language intelligible to a business user.  Transform scripts listed in panel 402 may be automatically applied to the data and reflected in the portion of the data 406 displayed in the interactive user\ninterface 400.  For example, the transform scripts listed in patent 402 include renaming columns to be descriptive of their content.  Columns 408 shown in interactive user interface 400 have been renamed according to the transform scripts 402 (e.g.,\ncolumn 0003 is now named date_time_02, column 0007 is no named \"url\", etc.).  Recommended transforms 404, however, have not been automatically applied to the user's data.\nAs shown in FIG. 4B, a user can view recommendations in recommendation panel 404 and based on the recommendation, identify the data to be changed.  For example, recommendation 410 includes a recommendation to rename \"Col_0008 to city\".  Because\nthe recommendation is written such that a business user can understand it (instead of in, e.g., code or pseudo code) the corresponding data 412 can be readily identified by the user.  As shown in FIG. 4B, data 412 includes a column of strings\n(represented as a row in user interface 400).  The profile engine 326 can analyze the data to determine that it includes strings of two or fewer words (or tokens).  This pattern can be provided to recommendation engine 318 which can query knowledge\nservice 310.  In this case, knowledge service 310 has matched the data pattern to city names and recommendation 408 was generated to rename the column accordingly.\nIn some embodiments, transforms listed in panel 404 may have been applied at the direction of the user (e.g., in response to an instruction to apply the transform) or may have been applied automatically.  For example, in some embodiments,\nknowledge service 310 can provide a confidence score for a given pattern match.  A threshold can be set in recommendation engine 318 such that matches having a confidence score greater than the threshold are applied automatically.\nTo accept the recommendation, the user can select an accept icon 414 (in this example an up arrow icon) associated with the recommendation.  As shown in FIG. 4C, this moves the accepted recommendation 414 to transform scripts panel 402 and\nautomatically applies the transform to the corresponding data 416.  For example, in the embodiment shown in FIG. 4C, Col_0008 has now been renamed to \"city\" in accordance with the selected transform.\nIn some embodiments, data enrichment service 302 can recommend additional columns of data to be added to a data source.  As shown in FIG. 4D, continuing with the city example, transforms 418 have been accepted to enrich the data with new columns\nincluding city population, and city location detail including longitude and latitude.  When selected, the user's data set is enriched to include this additional information 420.  The data set now includes information that was not previously available to\nthe user in a comprehensive and automated fashion.  The user's data set can now be used to produce a nationwide map of locations and population zones associated with other data in the dataset (for example, this may be associated with a company's web site\ntransactions).\nFIGS. 5A-5D depict examples of various user interfaces that provide visualizations of datasets, in accordance with an embodiment of the present invention.\nFIG. 5A depicts an example of a user interface that provides visualizations of datasets, in accordance with an embodiment of the present invention.  As shown in FIG. 5A, an example interactive user interface 500 can display a profile summary 502\n(\"Profile Results\"), transform scripts 504, recommended transforms 506, and at least a portion of the data 508 being analyzed/transformed.  Transforms listed in panel 504 can include transforms that have been applied to the data and are visible in panel\n508.\nProfile summary 502 can include global statistics (e.g., total rows and columns) as well as column-specific statistics.  The column-specific statistics can be generated from analysis of data processed by data enrichment service 302.  In some\nembodiments, the column-specific statistics can be generated based on column information determined by analysis of data process by data enrichment service 302.\nProfile summary 502 may include a map (e.g., \"a heat map\") of the United States, where different areas of the United States are shown in different colors, based on statistics identified from the data being analyzed 508.  The statistics may\nindicate how frequently those locations are identified as being associated with the data.  In one illustrative example, data may represent purchase transactions at an online retailer, where each transaction can be associated with a location (e.g., based\non shipping/billing addresses, or based on recorded IP addresses).  Profile summary 502 may indicate locations of transactions based on processing of the data representing the purchase transactions.  In some embodiments, visualizations can be modified\nbased on user input to assist the user in searching the data and finding useful correlations.  These features are described further below.\nFIGS. 5B, 5C, and 5D show examples of results of interactive data enrichment for data sets.  FIG. 5B shows a user interface 540 that can include a profile metric panel 542.  Panel 542 can show a summary of metrics associated with the selected\ndata source.  In some embodiments, as shown in FIG. 5C, a profile metric panel 560 can include metrics for a particular column 562, instead of an entire data set.  For example, the user can select the particular column on the user's client device and the\ncorresponding column profile 564 can be displayed.  In this example, the profiler indicates a 92% match of column_0008 with known cities in the knowledge source.  A high probability in some embodiments can cause the transform engine to automatically\nlabel col_0008 to \"city\".\nFIG. 5D shows a profile metric panel 580 that includes global metrics 582 (e.g., metrics related to an entire dataset), and column-specific visualizations 584.  The column specific visualizations 584 can be selected by a user and/or used to\nnavigate the data (e.g., by clicking, dragging, swiping, etc.).  The examples described above represent simplified transforms to small data sets.  Similar and more complex processing can also be applied automatically to large data sets comprising\nbillions of records.\nFIGS. 6A-6B depict examples of visualizations of datasets, in accordance with an embodiment of the present invention.  As shown in FIG. 6A, a data visualization user interface 600 can include a panel that displays multiple real-time runtime\nmetrics (e.g., corresponding to multiple columns of data being analyzed).  A legend can be provided to distinguish between different metrics.  In some embodiments, by default all metrics can be displayed.  In some embodiments, the user can select which\nmetrics are to be displayed.  For example, as shown in FIG. 6B, a single metric can be displayed in user interface 602.  Additionally, the time period being analyzed and/or the time scale over which the data is displayed can be modified by the user.  In\nsome embodiments, the data can be updated periodically to reflect real-time data, and the refresh rate can be configurable by the user.\nExamples of global metrics of a dataset that can be determined by the profile engine 326 can include one or more of: number of rows, number of columns, number of raw and populated columns and how those vary, distinct and duplicate rows, header\ninformation, number of columns classified by type or subtype, number of columns with security or other alerts.  In some embodiments, column-specific metrics can include one or more of: populated rows, K-most frequent, K-least frequent unique values,\nunique patterns, and/or types, frequency distributions, text metrics: minimum, maximum, mean values of: text length, token count, punctuation, pattern-based tokens.  Additional column-specific metrics can include data type and subtype, statistical\nanalysis of numeric columns, L-most/least probable simple or compound terms or n-grams found in columns with mostly unstructured data, and reference knowledge categories matched by this naive lexicon.\nFIGS. 7A-7C depict examples of interactive data visualizations, in accordance with an embodiment of the present invention.  As shown in FIG. 7A, a user can interact with a data visualization 700, by clicking, tapping, swiping, or otherwise\nproviding a user input.  For example, a user can view details for specific times in the graph by clicking or single touching the screen.  This can activate a vertical line across the metrics bars and add actual details for each of the metrics for the\npoint in time the bar is crossing.  The user can drag or swipe, as shown in FIG. 7A, to see those displayed values over time.  In some embodiments, when the user removes their finger from the screen, or cursor from the panel, the vertical bar and\naccompanying values can be cleared.  As shown in a data visualization 702 of FIG. 7B, this feature may be similarly implemented in user interfaces that display a single metric.\nAs shown in a data visualization 704 of FIG. 7C, gestures can be used to adjust the time scale being displayed.  For example, a pinch/spread gesture (or corresponding mouse movement and/or keyboard command) can enable users to compress or expand\nthe displayed timeline.\nWith reference to FIG. 8, individual embodiments may be described as a process which is depicted as a flowchart, a flow diagram, a data flow diagram, a structure diagram, or a block diagram.  Although a flowchart may describe the operations as a\nsequential process, many of the operations may be performed in parallel or concurrently.  In addition, the order of the operations may be re-arranged.  A process is terminated when its operations are completed, but could have additional steps not\nincluded in a figure.  A process may correspond to a method, a function, a procedure, a subroutine, a subprogram, etc. When a process corresponds to a function, its termination may correspond to a return of the function to the calling function or the\nmain function.\nThe processes depicted FIG. 8 may be implemented in software (e.g., code, instructions, program) executed by one or more processing units (e.g., processors cores), hardware, or combinations thereof.  The software may be stored in a memory (e.g.,\non a memory device, on a non-transitory computer-readable storage medium).  The particular series of processing steps in FIG. 8 is not intended to be limiting.  Other sequences of steps may also be performed according to alternative embodiments.  For\nexample, alternative embodiments of the present invention may perform the steps outlined above in a different order.  Moreover, the individual steps illustrated in FIG. 8 may include multiple sub-steps that may be performed in various sequences as\nappropriate to the individual step.  Furthermore, additional steps may be added or removed depending on the particular applications.  One of ordinary skill in the art would recognize many variations, modifications, and alternatives.\nIn an aspect of some embodiments, each process in the flowchart of FIG. 8 can be performed by one or more processing units.  A processing unit may include one or more processors, including single core or multicore processors, one or more cores\nof processors, or combinations thereof.  In some embodiments, a processing unit can include one or more special purpose co-processors such as graphics processors, digital signal processors (DSPs), or the like.  In some embodiments, some or all of\nprocessing units can be implemented using customized circuits, such as application specific integrated circuits (ASICs), or field programmable gate arrays (FPGAs).\nFIG. 8 depicts a flowchart 800 of a method of interactive data visualization, in accordance with an embodiment of the present invention.  In some embodiments, process depicted in FIG. 8 can be implemented by a computing system of a data\nenrichment service 302.\nAt step 802, one or more patterns in data from one or more data sources are identified.  As described above, the data sources can include local data sources, cloud storage services, or other network accessible storage services and systems.\nIn some embodiments, identifying can include profiling the data as it is received from the one or more data sources, and determining sampled data.  The sampled data may be determined by sampling the profiled data to obtain sampled data is a\nrepresentative sample of one or more characteristics within the profiled data.  As described above, sampling can include oversampling a first portion of the data and undersampling a second portion of the data to generate the representative sample.\nAt step 804, one or more identified patterns can be matched to entity information from a knowledge system.  The knowledge system may implement a knowledge service that provides entity information.  In one example, an entity can be an address, a\nbusiness name, a location, a person name, an identification number, etc. Matching can include identifying the pattern in the data to correspond to a particular entity.  As described above, this may be useful in automatically identifying a category to\nwhich a particular subset of data belongs.  Transformations, enrichments, and or repairs, may be suggested based on the matched patterns.\nAt step 806, a graphical visualization may be generated based on the identified pattern matching the entity information.  In some embodiments, a graphical visualization can include a graphical dashboard (e.g., a visualization dashboard).  The\ngraphical dashboard may indicate a plurality of metrics, each of the plurality of metrics indicating a real time metric of the data relative to a time that the data is profiled.  Described herein are techniques for profiling data.\nIn at least one example, a graphical visualization may be generated that displays a number of processed rows and/or a number of recommended transformations for an identified pattern that matches entity information.  Similarly, when a pattern\nmatches sensitive data (e.g., if a pattern matches the entity \"social security numbers\"), a graphical visualization may include a warning visualization.  The warning visualization may summarize the matched pattern(s), the nature of the warning(s), and\nrecommended transformations to address the warnings.  Other processing metrics may also be generated and displayed, as generally described above with respect to FIGS. 5A-5D, 6A, 6B, and 7A-7C.\nAt step 808, a graphical visualization may be displayed in a user interface.  For example, the graphical visualization that is generated may be sent to a client device to cause the client device to display the graphical visualization in a user\ninterface at the client device.\nAt step 810, input related to a graphical visualization can be received through the user interface.  In some embodiments, various gesture-based inputs may be received with respect to a graphical visualization.  For example, receiving input\nrelated to a graphical visualization through the user interface can include receiving a selection of a first point in time in the user interface, displaying a first plurality of metrics associated with the first point in time, receiving a gesture-based\ninput indicating a second point in time in the user interface, and displaying second plurality of metrics associated with the second point in time.  In some embodiments, a gesture-based input may be received in a graphical dashboard and, based on the\ngesture-based input, a displayed time scale of the graphical dashboard may be adjusted.  At step 812, the graphical visualization may then be updated based on the input.\nIn at least one embodiment, the method of interactive data visualization shown by flowchart 800 may include monitoring the one or more data sources in real-time.  Updated data may be obtained from one or more data sources by the monitoring.  An\nidentified pattern (e.g., a pattern identified at 804) may be periodically updated based on updated data obtained from a data source.  A graphical visualization generated based on the identified pattern may be updated.  For example, an updated graphical\nvisualization may be generated based on an update to the identified pattern.  In some embodiments, the graphical visualization may be updated rather than generating an updated graphical visualization.  An updated graphical visualization may be generated\nand then the graphical visualization may be updated with the updated graphical visualization.  A user interface may be updated to display the updated graphical visualization.\nIn some embodiments, a graphical dashboard (e.g., a data visualization dashboard) included in a graphical visualization may indicate a plurality of metrics.  One or more of the plurality of metrics may indicate a real-time metric of data (e.g.,\ndata obtained from a data source) over a time period.  The time period may be relative to a time that the data is profiled, such as profiling described above with reference to step 802.  One or more of the plurality of metrics may represent a\nuser-specific set of metrics calculated for the data.  In at least one embodiment, the plurality of metrics may include a user-selected subset of global metrics calculated for the data.\nFIG. 9 depicts a simplified diagram of a distributed system 900 for implementing an embodiment.  In the illustrated embodiment, distributed system 900 includes one or more client computing devices 902, 904, 906, and 908, which are configured to\nexecute and operate a client application such as a web browser, proprietary client (e.g., Oracle Forms), or the like over one or more network(s) 910.  Server 912 may be communicatively coupled with remote client computing devices 902, 904, 906, and 908\nvia network 910.\nIn various embodiments, server 912 may be adapted to run one or more services or software applications such as services and applications that provide the document (e.g., webpage) analysis and modification-related processing.  In certain\nembodiments, server 912 may also provide other services or software applications can include non-virtual and virtual environments.  In some embodiments, these services may be offered as web-based or cloud services or under a Software as a Service (SaaS)\nmodel to the users of client computing devices 902, 904, 906, and/or 908.  Users operating client computing devices 902, 904, 906, and/or 908 may in turn utilize one or more client applications to interact with server 912 to utilize the services provided\nby these components.\nIn the configuration depicted in FIG. 9, software components 918, 920 and 922 of system 900 are shown as being implemented on server 912.  In other embodiments, one or more of the components of system 900 and/or the services provided by these\ncomponents may also be implemented by one or more of the client computing devices 902, 904, 906, and/or 908.  Users operating the client computing devices may then utilize one or more client applications to use the services provided by these components. \nThese components may be implemented in hardware, firmware, software, or combinations thereof.  It should be appreciated that various different system configurations are possible, which may be different from distributed system 900.  The embodiment shown\nin FIG. 9 is thus one example of a distributed system for implementing an embodiment system and is not intended to be limiting.\nClient computing devices 902, 904, 906, and/or 908 may include various types of computing systems.  For example, client device may include portable handheld devices (e.g., an iPhone.RTM., cellular telephone, an iPad.RTM., computing tablet, a\npersonal digital assistant (PDA)) or wearable devices (e.g., a Google Glass.RTM.  head mounted display), running software such as Microsoft Windows Mobile.RTM., and/or a variety of mobile operating systems such as iOS, Windows Phone, Android, BlackBerry\n9, Palm OS, and the like.  The devices may support various applications such as various Internet-related apps, e-mail, short message service (SMS) applications, and may use various other communication protocols.  The client computing devices may also\ninclude general purpose personal computers including, by way of example, personal computers and/or laptop computers running various versions of Microsoft Windows.RTM., Apple Macintosh.RTM., and/or Linux operating systems.  The client computing devices\ncan be workstation computers running any of a variety of commercially-available UNIX.RTM.  or UNIX-like operating systems, including without limitation the variety of GNU/Linux operating systems, such as for example, Google Chrome OS.  Client computing\ndevices may also include electronic devices such as a thin-client computer, an Internet-enabled gaming system (e.g., a Microsoft Xbox gaming console with or without a Kinect.RTM.  gesture input device), and/or a personal messaging device, capable of\ncommunicating over network(s) 910.\nAlthough distributed system 900 in FIG. 9 is shown with four client computing devices, any number of client computing devices may be supported.  Other devices, such as devices with sensors, etc., may interact with server 912.\nNetwork(s) 910 in distributed system 900 may be any type of network familiar to those skilled in the art that can support data communications using any of a variety of available protocols, including without limitation TCP/IP (transmission\ncontrol protocol/Internet protocol), SNA (systems network architecture), IPX (Internet packet exchange), AppleTalk, and the like.  Merely by way of example, network(s) 910 can be a local area network (LAN), networks based on Ethernet, Token-Ring, a\nwide-area network, the Internet, a virtual network, a virtual private network (VPN), an intranet, an extranet, a public switched telephone network (PSTN), an infra-red network, a wireless network (e.g., a network operating under any of the Institute of\nElectrical and Electronics (IEEE) 802.11 suite of protocols, Bluetooth.RTM., and/or any other wireless protocol), and/or any combination of these and/or other networks.\nServer 912 may be composed of one or more general purpose computers, specialized server computers (including, by way of example, PC (personal computer) servers, UNIX.RTM.  servers, mid-range servers, mainframe computers, rack-mounted servers,\netc.), server farms, server clusters, or any other appropriate arrangement and/or combination.  Server 912 can include one or more virtual machines running virtual operating systems, or other computing architectures involving virtualization.  One or more\nflexible pools of logical storage devices can be virtualized to maintain virtual storage devices for the server.  Virtual networks can be controlled by server 912 using software defined networking.  In various embodiments, server 912 may be adapted to\nrun one or more services or software applications described in the foregoing disclosure.  For example, server 912 may correspond to a server for performing processing as described above according to an embodiment of the present disclosure.\nServer 912 may run an operating system including any of those discussed above, as well as any commercially available server operating system.  Server 912 may also run any of a variety of additional server applications and/or mid-tier\napplications, including HTTP (hypertext transport protocol) servers, FTP (file transfer protocol) servers, CGI (common gateway interface) servers, JAVA.RTM.  servers, database servers, and the like.  Exemplary database servers include without limitation\nthose commercially available from Oracle, Microsoft, Sybase, IBM (International Business Machines), and the like.\nIn some implementations, server 912 may include one or more applications to analyze and consolidate data feeds and/or event updates received from users of client computing devices 902, 904, 906, and 908.  As an example, data feeds and/or event\nupdates may include, but are not limited to, Twitter.RTM.  feeds, Facebook.RTM.  updates or real-time updates received from one or more third party information sources and continuous data streams, which may include real-time events related to sensor data\napplications, financial tickers, network performance measuring tools (e.g., network monitoring and traffic management applications), clickstream analysis tools, automobile traffic monitoring, and the like.  Server 912 may also include one or more\napplications to display the data feeds and/or real-time events via one or more display devices of client computing devices 902, 904, 906, and 908.\nDistributed system 900 may also include one or more databases 914 and 916.  These databases may provide a mechanism for storing information such as user interactions information, usage patterns information, adaptation rules information, and\nother information used by embodiments of the present invention.  Databases 914 and 916 may reside in a variety of locations.  By way of example, one or more of databases 914 and 916 may reside on a non-transitory storage medium local to (and/or resident\nin) server 912.  Alternatively, databases 914 and 916 may be remote from server 912 and in communication with server 912 via a network-based or dedicated connection.  In one set of embodiments, databases 914 and 916 may reside in a storage-area network\n(SAN).  Similarly, any necessary files for performing the functions attributed to server 912 may be stored locally on server 912 and/or remotely, as appropriate.  In one set of embodiments, databases 914 and 916 may include relational databases, such as\ndatabases provided by Oracle, that are adapted to store, update, and retrieve data in response to SQL-formatted commands.\nIn some embodiments, the document analysis and modification services described above may be offered as services via a cloud environment.  FIG. 10 is a simplified block diagram of one or more components of a system environment 1000 in which\nservices may be offered as cloud services, in accordance with an embodiment of the present disclosure.  In the illustrated embodiment in FIG. 10, system environment 1000 includes one or more client computing devices 1004, 1006, and 1008 that may be used\nby users to interact with a cloud infrastructure system 1002 that provides cloud services, including services for dynamically modifying documents (e.g., webpages) responsive to usage patterns.  Cloud infrastructure system 1002 may comprise one or more\ncomputers and/or servers that may include those described above for server 1012.\nIt should be appreciated that cloud infrastructure system 1002 depicted in FIG. 10 may have other components than those depicted.  Further, the embodiment shown in FIG. 10 is only one example of a cloud infrastructure system that may incorporate\nan embodiment of the invention.  In some other embodiments, cloud infrastructure system 1002 may have more or fewer components than shown in the figure, may combine two or more components, or may have a different configuration or arrangement of\ncomponents.\nClient computing devices 1004, 1006, and 1008 may be devices similar to those described above for 902, 904, 906, and 908.  Client computing devices 1004, 1006, and 1008 may be configured to operate a client application such as a web browser, a\nproprietary client application (e.g., Oracle Forms), or some other application, which may be used by a user of the client computing device to interact with cloud infrastructure system 1002 to use services provided by cloud infrastructure system 1002. \nAlthough exemplary system environment 1000 is shown with three client computing devices, any number of client computing devices may be supported.  Other devices such as devices with sensors, etc. may interact with cloud infrastructure system 1002.\nNetwork(s) 1010 may facilitate communications and exchange of data between clients 1004, 1006, and 1008 and cloud infrastructure system 1002.  Each network may be any type of network familiar to those skilled in the art that can support data\ncommunications using any of a variety of commercially-available protocols, including those described above for network(s) 1010.\nIn certain embodiments, services provided by cloud infrastructure system 1002 may include a host of services that are made available to users of the cloud infrastructure system on demand.  In addition to services related to dynamic document\nmodification responsive usage patterns, various other services may also be offered including without limitation online data storage and backup solutions, Web-based e-mail services, hosted office suites and document collaboration services, database\nprocessing, managed technical support services, and the like.  Services provided by the cloud infrastructure system can dynamically scale to meet the needs of its users.\nIn certain embodiments, a specific instantiation of a service provided by cloud infrastructure system 1002 may be referred to herein as a \"service instance.\" In general, any service made available to a user via a communication network, such as\nthe Internet, from a cloud service provider's system is referred to as a \"cloud service.\" Typically, in a public cloud environment, servers and systems that make up the cloud service provider's system are different from the customer's own on-premises\nservers and systems.  For example, a cloud service provider's system may host an application, and a user may, via a communication network such as the Internet, on demand, order and use the application.\nIn some examples, a service in a computer network cloud infrastructure may include protected computer network access to storage, a hosted database, a hosted web server, a software application, or other service provided by a cloud vendor to a\nuser, or as otherwise known in the art.  For example, a service can include password-protected access to remote storage on the cloud through the Internet.  As another example, a service can include a web service-based hosted relational database and a\nscript-language middleware engine for private use by a networked developer.  As another example, a service can include access to an email software application hosted on a cloud vendor's web site.\nIn certain embodiments, cloud infrastructure system 1002 may include a suite of applications, middleware, and database service offerings that are delivered to a customer in a self-service, subscription-based, elastically scalable, reliable,\nhighly available, and secure manner.  An example of such a cloud infrastructure system is the Oracle Public Cloud provided by the present assignee.\nCloud infrastructure system 1002 may also provide \"big data\" elated computation and analysis services.  The term \"big data\" is generally used to refer to extremely large data sets that can be stored and manipulated by analysts and researchers to\nvisualize large amounts of data, detect trends, and/or otherwise interact with the data.  This big data and related applications can be hosted and/or manipulated by an infrastructure system on many levels and at different scales.  Tens, hundreds, or\nthousands of processors linked in parallel can act upon such data in order to present it or simulate external forces on the data or what it represents.  These data sets can involve structured data, such as that organized in a database or otherwise\naccording to a structured model, and/or unstructured data (e.g., emails, images, data blobs (binary large objects), web pages, complex event processing).  By leveraging an ability of an embodiment to relatively quickly focus more (or fewer) computing\nresources upon an objective, the cloud infrastructure system may be better available to carry out tasks on large data sets based on demand from a business, government agency, research organization, private individual, group of like-minded individuals or\norganizations, or other entity.\nIn various embodiments, cloud infrastructure system 1002 may be adapted to automatically provision, manage and track a customer's subscription to services offered by cloud infrastructure system 1002.  Cloud infrastructure system 1002 may provide\nthe cloud services via different deployment models.  For example, services may be provided under a public cloud model in which cloud infrastructure system 1002 is owned by an organization selling cloud services (e.g., owned by Oracle Corporation) and the\nservices are made available to the general public or different industry enterprises.  As another example, services may be provided under a private cloud model in which cloud infrastructure system 1002 is operated solely for a single organization and may\nprovide services for one or more entities within the organization.  The cloud services may also be provided under a community cloud model in which cloud infrastructure system 1002 and the services provided by cloud infrastructure system 1002 are shared\nby several organizations in a related community.  The cloud services may also be provided under a hybrid cloud model, which is a combination of two or more different models.\nIn some embodiments, the services provided by cloud infrastructure system 1002 may include one or more services provided under Software as a Service (SaaS) category, Platform as a Service (PaaS) category, Infrastructure as a Service (IaaS)\ncategory, or other categories of services including hybrid services.  A customer, via a subscription order, may order one or more services provided by cloud infrastructure system 1002.  Cloud infrastructure system 1002 then performs processing to provide\nthe services in the customer's subscription order.\nIn some embodiments, the services provided by cloud infrastructure system 1002 may include, without limitation, application services, platform services and infrastructure services.  In some examples, application services may be provided by the\ncloud infrastructure system via a SaaS platform.  The SaaS platform may be configured to provide cloud services that fall under the SaaS category.  For example, the SaaS platform may provide capabilities to build and deliver a suite of on-demand\napplications on an integrated development and deployment platform.  The SaaS platform may manage and control the underlying software and infrastructure for providing the SaaS services.  By utilizing the services provided by the SaaS platform, customers\ncan utilize applications executing on the cloud infrastructure system.  Customers can acquire the application services without the need for customers to purchase separate licenses and support.  Various different SaaS services may be provided.  Examples\ninclude, without limitation, services that provide solutions for sales performance management, enterprise integration, and business flexibility for large organizations.\nIn some embodiments, platform services may be provided by cloud infrastructure system 1002 via a PaaS platform.  The PaaS platform may be configured to provide cloud services that fall under the PaaS category.  Examples of platform services may\ninclude without limitation services that enable organizations (such as Oracle) to consolidate existing applications on a shared, common architecture, as well as the ability to build new applications that leverage the shared services provided by the\nplatform.  The PaaS platform may manage and control the underlying software and infrastructure for providing the PaaS services.  Customers can acquire the PaaS services provided by cloud infrastructure system 1002 without the need for customers to\npurchase separate licenses and support.  Examples of platform services include, without limitation, Oracle Java Cloud Service (JCS), Oracle Database Cloud Service (DBCS), and others.\nBy utilizing the services provided by the PaaS platform, customers can employ programming languages and tools supported by the cloud infrastructure system and also control the deployed services.  In some embodiments, platform services provided\nby the cloud infrastructure system may include database cloud services, middleware cloud services (e.g., Oracle Fusion Middleware services), and Java cloud services.  In one embodiment, database cloud services may support shared service deployment models\nthat enable organizations to pool database resources and offer customers a Database as a Service in the form of a database cloud.  Middleware cloud services may provide a platform for customers to develop and deploy various business applications, and\nJava cloud services may provide a platform for customers to deploy Java applications, in the cloud infrastructure system.\nVarious different infrastructure services may be provided by an IaaS platform in the cloud infrastructure system.  The infrastructure services facilitate the management and control of the underlying computing resources, such as storage,\nnetworks, and other fundamental computing resources for customers utilizing services provided by the SaaS platform and the PaaS platform.\nIn certain embodiments, cloud infrastructure system 1002 may also include infrastructure resources 1030 for providing the resources used to provide various services to customers of the cloud infrastructure system.  In one embodiment,\ninfrastructure resources 1030 may include pre-integrated and optimized combinations of hardware, such as servers, storage, and networking resources to execute the services provided by the PaaS platform and the SaaS platform, and other resources.\nIn some embodiments, resources in cloud infrastructure system 1002 may be shared by multiple users and dynamically re-allocated per demand.  Additionally, resources may be allocated to users in different time zones.  For example, cloud\ninfrastructure system 1002 may enable a first set of users in a first time zone to utilize resources of the cloud infrastructure system for a specified number of hours and then enable the re-allocation of the same resources to another set of users\nlocated in a different time zone, thereby maximizing the utilization of resources.\nIn certain embodiments, a number of internal shared services 1032 may be provided that are shared by different components or modules of cloud infrastructure system 1002 to enable provision of services by cloud infrastructure system 1002.  These\ninternal shared services may include, without limitation, a security and identity service, an integration service, an enterprise repository service, an enterprise manager service, a virus scanning and white list service, a high availability, backup and\nrecovery service, service for enabling cloud support, an email service, a notification service, a file transfer service, and the like.\nIn certain embodiments, cloud infrastructure system 1002 may provide comprehensive management of cloud services (e.g., SaaS, PaaS, and IaaS services) in the cloud infrastructure system.  In one embodiment, cloud management functionality may\ninclude capabilities for provisioning, managing and tracking a customer's subscription received by cloud infrastructure system 1002, and the like.\nIn one embodiment, as depicted in FIG. 10, cloud management functionality may be provided by one or more modules, such as an order management module 1020, an order orchestration module 1022, an order provisioning module 1024, an order management\nand monitoring module 1026, and an identity management module 1028.  These modules may include or be provided using one or more computers and/or servers, which may be general purpose computers, specialized server computers, server farms, server clusters,\nor any other appropriate arrangement and/or combination.\nIn an exemplary operation, at 1034, a customer using a client device, such as client device 1004, 1006 or 1008, may interact with cloud infrastructure system 1002 by requesting one or more services provided by cloud infrastructure system 1002\nand placing an order for a subscription for one or more services offered by cloud infrastructure system 1002.  In certain embodiments, the customer may access a cloud User Interface (UI) such as cloud UI 1012, cloud UI 1014 and/or cloud UI 1016 and place\na subscription order via these UIs.  The order information received by cloud infrastructure system 1002 in response to the customer placing an order may include information identifying the customer and one or more services offered by the cloud\ninfrastructure system 1002 that the customer intends to subscribe to.\nAt 1036, the order information received from the customer may be stored in an order database 1018.  If this is a new order, a new record may be created for the order.  In one embodiment, order database 1018 can be one of several databases\noperated by cloud infrastructure system 1018 and operated in conjunction with other system elements.\nAt 1038, the order information may be forwarded to an order management module 1020 that may be configured to perform billing and accounting functions related to the order, such as verifying the order, and upon verification, booking the order.\nAt 1040, information regarding the order may be communicated to an order orchestration module 1022 that is configured to orchestrate the provisioning of services and resources for the order placed by the customer.  In some instances, order\norchestration module 1022 may use the services of order provisioning module 1024 for the provisioning.  In certain embodiments, order orchestration module 1022 enables the management of business processes associated with each order and applies business\nlogic to determine whether an order should proceed to provisioning.\nAs shown in the embodiment depicted in FIG. 10, at 1042, upon receiving an order for a new subscription, order orchestration module 1022 sends a request to order provisioning module 1024 to allocate resources and configure resources needed to\nfulfill the subscription order.  Order provisioning module 1024 enables the allocation of resources for the services ordered by the customer.  Order provisioning module 1024 provides a level of abstraction between the cloud services provided by cloud\ninfrastructure system 1000 and the physical implementation layer that is used to provision the resources for providing the requested services.  This enables order orchestration module 1022 to be isolated from implementation details, such as whether or\nnot services and resources are actually provisioned on the fly or pre-provisioned and only allocated/assigned upon request.\nAt 1044, once the services and resources are provisioned, a notification may be sent to the subscribing customers indicating that the requested service is now ready for use.  In some instance, information (e.g., a link) may be sent to the\ncustomer that enables the customer to start using the requested services.\nAt 1046, a customer's subscription order may be managed and tracked by an order management and monitoring module 1026.  In some instances, order management and monitoring module 1026 may be configured to collect usage statistics regarding a\ncustomer use of subscribed services.  For example, statistics may be collected for the amount of storage used, the amount data transferred, the number of users, and the amount of system up time and system down time, and the like.\nIn certain embodiments, cloud infrastructure system 1000 may include an identity management module 1028 that is configured to provide identity services, such as access management and authorization services in cloud infrastructure system 1000. \nIn some embodiments, identity management module 1028 may control information about customers who wish to utilize the services provided by cloud infrastructure system 1002.  Such information can include information that authenticates the identities of\nsuch customers and information that describes which actions those customers are authorized to perform relative to various system resources (e.g., files, directories, applications, communication ports, memory segments, etc.) Identity management module\n1028 may also include the management of descriptive information about each customer and about how and by whom that descriptive information can be accessed and modified.\nFIG. 11 illustrates an exemplary computer system 1100 that may be used to implement an embodiment of the present invention.  In some embodiments, computer system 1100 may be used to implement any of the various servers and computer systems\ndescribed above.  As shown in FIG. 11, computer system 1100 includes various subsystems including a processing unit 1104 that communicates with a number of peripheral subsystems via a bus subsystem 1102.  These peripheral subsystems may include a\nprocessing acceleration unit 1106, an I/O subsystem 1108, a storage subsystem 1118 and a communications subsystem 1124.  Storage subsystem 1118 may include tangible computer-readable storage media 1122 and a system memory 1110.\nBus subsystem 1102 provides a mechanism for letting the various components and subsystems of computer system 1100 communicate with each other as intended.  Although bus subsystem 1102 is shown schematically as a single bus, alternative\nembodiments of the bus subsystem may utilize multiple buses.  Bus subsystem 1102 may be any of several types of bus structures including a memory bus or memory controller, a peripheral bus, and a local bus using any of a variety of bus architectures. \nFor example, such architectures may include an Industry Standard Architecture (ISA) bus, Micro Channel Architecture (MCA) bus, Enhanced ISA (EISA) bus, Video Electronics Standards Association (VESA) local bus, and Peripheral Component Interconnect (PCI)\nbus, which can be implemented as a Mezzanine bus manufactured to the IEEE P1386.1 standard, and the like.\nProcessing subsystem 1104 controls the operation of computer system 1100 and may comprise one or more processing units 1132, 1134, etc. A processing unit may include be one or more processors, including single core or multicore processors, one\nor more cores of processors, or combinations thereof.  In some embodiments, processing subsystem 1104 can include one or more special purpose co-processors such as graphics processors, digital signal processors (DSPs), or the like.  In some embodiments,\nsome or all of the processing units of processing subsystem 1104 can be implemented using customized circuits, such as application specific integrated circuits (ASICs), or field programmable gate arrays (FPGAs).\nIn some embodiments, the processing units in processing subsystem 1104 can execute instructions stored in system memory 1110 or on computer readable storage media 1122.  In various embodiments, the processing units can execute a variety of\nprograms or code instructions and can maintain multiple concurrently executing programs or processes.  At any given time, some or all of the program code to be executed can be resident in system memory 1110 and/or on computer-readable storage media 1122\nincluding potentially on one or more storage devices.  Through suitable programming, processing subsystem 1104 can provide various functionalities described above for dynamically modifying documents (e.g., webpages) responsive to usage patterns.\nIn certain embodiments, a processing acceleration unit 1106 may be provided for performing customized processing or for off-loading some of the processing performed by processing subsystem 1104 so as to accelerate the overall processing\nperformed by computer system 1100.\nI/O subsystem 1108 may include devices and mechanisms for inputting information to computer system 1100 and/or for outputting information from or via computer system 1100.  In general, use of the term \"input device\" is intended to include all\npossible types of devices and mechanisms for inputting information to computer system 1100.  User interface input devices may include, for example, a keyboard, pointing devices such as a mouse or trackball, a touchpad or touch screen incorporated into a\ndisplay, a scroll wheel, a click wheel, a dial, a button, a switch, a keypad, audio input devices with voice command recognition systems, microphones, and other types of input devices.  User interface input devices may also include motion sensing and/or\ngesture recognition devices such as the Microsoft Kinect.RTM.  motion sensor that enables users to control and interact with an input device, the Microsoft Xbox.RTM.  360 game controller, devices that provide an interface for receiving input using\ngestures and spoken commands.  User interface input devices may also include eye gesture recognition devices such as the Google Glass.RTM.  blink detector that detects eye activity (e.g., \"blinking\" while taking pictures and/or making a menu selection)\nfrom users and transforms the eye gestures as input into an input device (e.g., Google Glass.RTM.).  Additionally, user interface input devices may include voice recognition sensing devices that enable users to interact with voice recognition systems\n(e.g., Siri.RTM.  navigator), through voice commands.\nOther examples of user interface input devices include, without limitation, three dimensional (3D) mice, joysticks or pointing sticks, gamepads and graphic tablets, and audio/visual devices such as speakers, digital cameras, digital camcorders,\nportable media players, webcams, image scanners, fingerprint scanners, barcode reader 3D scanners, 3D printers, laser rangefinders, and eye gaze tracking devices.  Additionally, user interface input devices may include, for example, medical imaging input\ndevices such as computed tomography, magnetic resonance imaging, position emission tomography, medical ultrasonography devices.  User interface input devices may also include, for example, audio input devices such as MIDI keyboards, digital musical\ninstruments and the like.\nUser interface output devices may include a display subsystem, indicator lights, or non-visual displays such as audio output devices, etc. The display subsystem may be a cathode ray tube (CRT), a flat-panel device, such as that using a liquid\ncrystal display (LCD) or plasma display, a projection device, a touch screen, and the like.  In general, use of the term \"output device\" is intended to include all possible types of devices and mechanisms for outputting information from computer system\n1100 to a user or other computer.  For example, user interface output devices may include, without limitation, a variety of display devices that visually convey text, graphics and audio/video information such as monitors, printers, speakers, headphones,\nautomotive navigation systems, plotters, voice output devices, and modems.\nStorage subsystem 1118 provides a repository or data store for storing information that is used by computer system 1100.  Storage subsystem 1118 provides a tangible non-transitory computer-readable storage medium for storing the basic\nprogramming and data constructs that provide the functionality of some embodiments.  Software (programs, code modules, instructions) that when executed by processing subsystem 1104 provide the functionality described above may be stored in storage\nsubsystem 1118.  The software may be executed by one or more processing units of processing subsystem 1104.  Storage subsystem 1118 may also provide a repository for storing data used in accordance with the present invention.\nStorage subsystem 1118 may include one or more non-transitory memory devices, including volatile and non-volatile memory devices.  As shown in FIG. 11, storage subsystem 1118 includes a system memory 1110 and a computer-readable storage media\n1122.  System memory 1110 may include a number of memories including a volatile main random access memory (RAM) for storage of instructions and data during program execution and a non-volatile read only memory (ROM) or flash memory in which fixed\ninstructions are stored.  In some implementations, a basic input/output system (BIOS), containing the basic routines that help to transfer information between elements within computer system 1100, such as during start-up, may typically be stored in the\nROM.  The RAM typically contains data and/or program modules that are presently being operated and executed by processing subsystem 1104.  In some implementations, system memory 1110 may include multiple different types of memory, such as static random\naccess memory (SRAM) or dynamic random access memory (DRAM).\nBy way of example, and not limitation, as depicted in FIG. 11, system memory 1110 may store application programs 1112, which may include client applications, Web browsers, mid-tier applications, relational database management systems (RDBMS),\netc., program data 1114, and an operating system 1116.  By way of example, operating system 1116 may include various versions of Microsoft Windows.RTM., Apple Macintosh.RTM., and/or Linux operating systems, a variety of commercially-available UNIX.RTM. \nor UNIX-like operating systems (including without limitation the variety of GNU/Linux operating systems, the Google Chrome.RTM.  OS, and the like) and/or mobile operating systems such as iOS, Windows.RTM.  Phone, Android.RTM.  OS, BlackBerry.RTM.  9 OS,\nand Palm.RTM.  OS operating systems.\nComputer-readable storage media 1122 may store programming and data constructs that provide the functionality of some embodiments.  Software (programs, code modules, instructions) that when executed by processing subsystem 1104 a processor\nprovide the functionality described above may be stored in storage subsystem 1118.  By way of example, computer-readable storage media 1122 may include non-volatile memory such as a hard disk drive, a magnetic disk drive, an optical disk drive such as a\nCD ROM, DVD, a Blu-Ray.RTM.  disk, or other optical media.  Computer-readable storage media 1122 may include, but is not limited to, Zip.RTM.  drives, flash memory cards, universal serial bus (USB) flash drives, secure digital (SD) cards, DVD disks,\ndigital video tape, and the like.  Computer-readable storage media 1122 may also include, solid-state drives (SSD) based on non-volatile memory such as flash-memory based SSDs, enterprise flash drives, solid state ROM, and the like, SSDs based on\nvolatile memory such as solid state RAM, dynamic RAM, static RAM, DRAM-based SSDs, magnetoresistive RAM (MRAM) SSDs, and hybrid SSDs that use a combination of DRAM and flash memory based SSDs.  Computer-readable media 1122 may provide storage of\ncomputer-readable instructions, data structures, program modules, and other data for computer system 1100.\nIn certain embodiments, storage subsystem 1100 may also include a computer-readable storage media reader 1120 that can further be connected to computer-readable storage media 1122.  Together and, optionally, in combination with system memory\n1110, computer-readable storage media 1122 may comprehensively represent remote, local, fixed, and/or removable storage devices plus storage media for storing computer-readable information.\nIn certain embodiments, computer system 1100 may provide support for executing one or more virtual machines.  Computer system 1100 may execute a program such as a hypervisor for facilitating the configuring and managing of the virtual machines. \nEach virtual machine may be allocated memory, compute (e.g., processors, cores), I/O, and networking resources.  Each virtual machine typically runs its own operating system, which may be the same as or different from the operating systems executed by\nother virtual machines executed by computer system 1100.  Accordingly, multiple operating systems may potentially be run concurrently by computer system 1100.  Each virtual machine generally runs independently of the other virtual machines.\nCommunications subsystem 1124 provides an interface to other computer systems and networks.  Communications subsystem 1124 serves as an interface for receiving data from and transmitting data to other systems from computer system 1100.  For\nexample, communications subsystem 1124 may enable computer system 1100 to establish a communication channel to one or more client devices via the Internet for receiving and sending information from and to the client devices.\nCommunication subsystem 1124 may support both wired and/or wireless communication protocols.  For example, in certain embodiments, communications subsystem 1124 may include radio frequency (RF) transceiver components for accessing wireless voice\nand/or data networks (e.g., using cellular telephone technology, advanced data network technology, such as 3G, 4G or EDGE (enhanced data rates for global evolution), WiFi (IEEE 802.11 family standards, or other mobile communication technologies, or any\ncombination thereof), global positioning system (GPS) receiver components, and/or other components.  In some embodiments communications subsystem 1124 can provide wired network connectivity (e.g., Ethernet) in addition to or instead of a wireless\ninterface.\nCommunication subsystem 1124 can receive and transmit data in various forms.  For example, in some embodiments, communications subsystem 1124 may receive input communication in the form of structured and/or unstructured data feeds 1126, event\nstreams 1128, event updates 1130, and the like.  For example, communications subsystem 1124 may be configured to receive (or send) data feeds 1126 in real-time from users of social media networks and/or other communication services such as Twitter.RTM. \nfeeds, Facebook.RTM.  updates, web feeds such as Rich Site Summary (RSS) feeds, and/or real-time updates from one or more third party information sources.\nIn certain embodiments, communications subsystem 1124 may be configured to receive data in the form of continuous data streams, which may include event streams 1128 of real-time events and/or event updates 1130, that may be continuous or\nunbounded in nature with no explicit end.  Examples of applications that generate continuous data may include, for example, sensor data applications, financial tickers, network performance measuring tools (e.g., network monitoring and traffic management\napplications), clickstream analysis tools, automobile traffic monitoring, and the like.\nCommunications subsystem 1124 may also be configured to output the structured and/or unstructured data feeds 1126, event streams 1128, event updates 1130, and the like to one or more databases that may be in communication with one or more\nstreaming data source computers coupled to computer system 1100.\nComputer system 1100 can be one of various types, including a handheld portable device (e.g., an iPhone.RTM.  cellular phone, an iPad.RTM.  computing tablet, a PDA), a wearable device (e.g., a Google Glass.RTM.  head mounted display), a personal\ncomputer, a workstation, a mainframe, a kiosk, a server rack, or any other data processing system.\nDue to the ever-changing nature of computers and networks, the description of computer system 1100 depicted in FIG. 11 is intended only as a specific example.  Many other configurations having more or fewer components than the system depicted in\nFIG. 11 are possible.  Based on the disclosure and teachings provided herein, a person of ordinary skill in the art will appreciate other ways and/or methods to implement the various embodiments.\nAlthough specific embodiments of the invention have been described, various modifications, alterations, alternative constructions, and equivalents are also encompassed within the scope of the invention.  Embodiments of the present invention are\nnot restricted to operation within certain specific data processing environments, but are free to operate within a plurality of data processing environments.  Additionally, although embodiments of the present invention have been described using a\nparticular series of transactions and steps, it should be apparent to those skilled in the art that the scope of the present invention is not limited to the described series of transactions and steps.  Various features and aspects of the above-described\nembodiments may be used individually or jointly.\nFurther, while embodiments of the present invention have been described using a particular combination of hardware and software, it should be recognized that other combinations of hardware and software are also within the scope of the present\ninvention.  Embodiments of the present invention may be implemented only in hardware, or only in software, or using combinations thereof.  The various processes described herein can be implemented on the same processor or different processors in any\ncombination.  Accordingly, where components or modules are described as being configured to perform certain operations, such configuration can be accomplished, e.g., by designing electronic circuits to perform the operation, by programming programmable\nelectronic circuits (such as microprocessors) to perform the operation, or any combination thereof.  Processes can communicate using a variety of techniques including but not limited to conventional techniques for interprocess communication, and\ndifferent pairs of processes may use different techniques, or the same pair of processes may use different techniques at different times.\nThe specification and drawings are, accordingly, to be regarded in an illustrative rather than a restrictive sense.  It will, however, be evident that additions, subtractions, deletions, and other modifications and changes may be made thereunto\nwithout departing from the broader spirit and scope as set forth in the claims.  Thus, although specific invention embodiments have been described, these are not intended to be limiting.  Various modifications and equivalents are within the scope of the\nfollowing claims.", "application_number": "14864505", "abstract": " The present disclosure relates generally to a data enrichment service\n     that automatically profiles data sets and provides visualizations of the\n     profiles using a visual-interactive model within a client application\n     (such as a web browser or mobile app). The visual profiling can be\n     refined through end user interaction with the visualization objects and\n     guide exploratory data visualization and discovery. Additionally, data\n     sampling of heterogeneous data streams can be performed during ingestion\n     to extract statistical attributes from multi-columnar data (e.g.,\n     standard deviation, median, mode, correlation coefficient, histogram,\n     etc.). Data sampling can continue in real-time as data sources are\n     updated.\n", "citations": ["6047283", "6556983", "6807558", "7571177", "8155951", "8234285", "8874616", "20020107861", "20020152201", "20040260695", "20050071140", "20050278307", "20060075021", "20070112827", "20080027929", "20080281820", "20090006460", "20100131844", "20100205475", "20100274821", "20110106791", "20120101975", "20120117076", "20120136859", "20120166180", "20130110792", "20130232452", "20140052688", "20140067728", "20140074829", "20140115155", "20140222181", "20140279865", "20140337331", "20150106324", "20150370775", "20160092474", "20160092475", "20160092476", "20160092557", "20160188701", "20160286544"], "related": ["62056474"]}, {"id": "20160132563", "patent_code": "10324934", "patent_name": "Method and device for providing content recommending information to\n     devices", "year": "2019", "inventor_and_country_data": " Inventors: \nBhandari; Ashish (Noida, IN), Jain; Ayush (Noida, IN)  ", "description": "<BR><BR>CROSS-REFERENCE TO RELATED APPLICATION(S)\nThis application claims the benefit under 35 U.S.C.  .sctn.  119(a) of an Indian patent application filed on Nov.  12, 2014 in the India Patent Office and assigned Serial number 3266/DEL/2014, and a Korean patent application filed on Oct.  26,\n2015 in the Korean Intellectual Property Office and assigned Serial number 10-2015-0148823, the entire disclosure of each of which is hereby incorporated by reference.\n<BR><BR>TECHNICAL FIELD\nThe present disclosure relates to a device and method for providing content recommendation information.  More particularly, the present disclosure relates to a device and method for providing content recommending information for a device based\non other devices in an Internet of things (IOT) or a smart home environment.\n<BR><BR>BACKGROUND\nContent includes various types of information provided through the Internet or computer communication.  Owing to developments in Internet and communication technologies, a large amount of content has become available to be provided to users,\nwhich has caused a new expression \"content stress\" to be formed and makes it difficult for users to select necessary content.\nTo solve such a difficulty for users, many systems that recommend content to users according to at least one of user preference and interest, popularity depending on the times, and category, are provided.\nThe above information is presented as background information only to assist with an understanding of the present disclosure.  No determination has been made, and no assertion is made, as to whether any of the above might be applicable as prior\nart with regard to the present disclosure.\n<BR><BR>SUMMARY\nAspects of the present disclosure are to address at least the above-mentioned problems and/or disadvantages and to provide at least the advantages described below.  Accordingly, an aspect of the present disclosure is to provide methods and\nsystems capable of generating content recommending information and displaying the content recommending information to a device by using a keyword included in user log information of the device.\nAdditional aspects will be set forth in part in the description which follows and, in part, will be apparent from the description, or may be learned by practice of the presented various embodiments.\nIn accordance with an aspect of the present disclosure, an operating method performed by a first device is provided.  The operating method includes receiving first log information of an external device; generating content recommending\ninformation based on the first log information and second log information of the first device; and displaying the content recommending information.\nIn accordance with another aspect of the present disclosure, a first device is provided.  The first device includes a communication unit configured to receive first log information of an external device; a control unit configured to generate\ncontent recommending information based on the first log information and second log information of the first device; and a display unit configured to display the content recommending information.\nIn accordance with another aspect of the present disclosure, a first device is provided.  The first device includes a communication unit configured to receive a plurality of log information, each corresponding to an external device; a control\nunit configured to generate content recommending information based on the plurality of log information and log information of the first device; and a display unit configured to display the content recommending information.\nOther aspects, advantages, and salient features of the disclosure will become apparent to those skilled in the art from the following detailed description, which, taken in conjunction with the annexed drawings, discloses various embodiments of\nthe present disclosure. <BR><BR>BRIEF DESCRIPTION OF THE DRAWINGS\nThe above and other aspects, features, and advantages of certain embodiments of the present disclosure will be more apparent from the following description taken in conjunction with the accompanying drawings, in which:\nFIG. 1 is a diagram describing a method in which a first device provides content recommending information by using log information of a second device according to an embodiment of the present disclosure;\nFIG. 2 is a flowchart of a method of communicating between a first device and a second device and a method of providing content recommending information by using device log information according to an embodiment of the present disclosure;\nFIG. 3 is a flowchart of a method in which a first device provides content recommending information according to an embodiment of the present disclosure;\nFIG. 4 is a flowchart of a method in which a first device provides content recommending information according to an embodiment of the present disclosure;\nFIG. 5 is a diagram describing a method in which a first device generates and provides content recommending information based on its log information and log information of a plurality of external devices according to an embodiment of the present\ndisclosure;\nFIG. 6 is a diagram describing a method in which a server generates and provides content recommending information based on log information of a first device and external devices according to an embodiment of the present disclosure;\nFIG. 7 is a block diagram of a configuration of a first device for providing content recommending information according to an embodiment of the present disclosure;\nFIG. 8 is a block diagram of a configuration of a first device for providing content recommending information according to an embodiment of the present disclosure;\nFIG. 9 is a flowchart of a process in which a first device generates content recommending information according to an embodiment of the present disclosure;\nFIG. 10 is a diagram of an example of a process in which a first device generates content recommending information according to an embodiment of the present disclosure;\nFIG. 11 is a flowchart of a method in which a first device receives user login information and generates and provides content recommending information according to an embodiment of the present disclosure;\nFIG. 12 is a diagram of an example in which a first device receives user login information according to an embodiment of the present disclosure;\nFIG. 13 is a diagram of an example of a method in which a first device displays content recommending information according to an embodiment of the present disclosure;\nFIG. 14 is a diagram of an example of a method in which a first device displays content recommending information according to an embodiment of the present disclosure;\nFIG. 15 is a diagram of an example of a method in which a first device displays content recommending information according to an embodiment of the present disclosure;\nFIG. 16 is a diagram of an example in which a first device outputs content recommending information as audio through an audio output unit according to an embodiment of the present disclosure; and\nFIG. 17 is a diagram of an Internet of things (IOT) scenario that generates content recommending information based on log information received from a plurality of second devices according to an embodiment of the present disclosure.\nThroughout the drawings, it should be noted that like reference numbers are used to depict the same or similar elements, features, and structures.\n<BR><BR>DETAILED DESCRIPTION\nThe following description with reference to the accompanying drawings is provided to assist in a comprehensive understanding of various embodiments of the present disclosure as defined by the claims and their equivalents.  It includes various\nspecific details to assist in that understanding, but these are to be regarded as merely exemplary.  Accordingly, those of ordinary skill in the art will recognize that various changes and modifications of the various embodiments described herein can be\nmade without departing from the scope and spirit of the present disclosure.  In addition, descriptions of well-known functions and constructions may be omitted for clarity and conciseness.\nThe terms and words used in the following description and claims are not limited to the bibliographical meanings, but are merely used by the inventor to enable a clear and consistent understanding of the present disclosure.  Accordingly, it\nshould be apparent to those skilled in the art that the following description of various embodiments of the present disclosure is provided for illustration purposes only and not for the purpose of limiting the present disclosure as defined by the\nappended claims and their equivalents.\nIt is to be understood that the singular forms \"a,\" \"an,\" and \"the\" include plural referents unless the context clearly dictates otherwise.  Thus, for example, reference to \"a component surface\" includes reference to one or more of such\nsurfaces.\nThroughout the present application, when a part \"includes\" an element, it is to be understood that the part may additionally include other elements rather than excluding other elements as long as there is no particular opposing recitation. \nThus, a process or method that comprises a list of operations does not include only those operations but may include other operations not expressly listed or inherent to such process or method.  Similarly, one or more devices or sub-systems or elements\nor structures proceeded by \"includes\" does not, without more constraints, preclude the existence of other devices or other sub-systems.  Also, the terms such as \" .  . . unit\", \"module\", or the like used in the present application indicate an unit, which\nprocesses at least one function or motion, and the unit may be implemented by hardware or software, or by a combination of hardware and software.\nThroughout this description, the term \"first device\" is broadly referred to any device which may provide content recommendation based on its own log information and log information of at least one second device by either generating content\nrecommending information itself or by transmitting the log information used to generate the content recommending information to a server.  The term \"second device\" or \"external device\" is broadly referred to any device which may receive the content\nrecommending information but may not generate the content recommending information.\nThe various embodiments will now be described more fully with reference to the accompanying drawings for those of ordinary skill in the art to be able to perform the various embodiments.  The various embodiments may, however, be embodied in many\ndifferent forms and should not be construed as being limited to the embodiments set forth herein; rather, these embodiments are provided so that this disclosure will be thorough and complete, and will fully convey the concept of the disclosure to those\nof ordinary skill in the art.  Also, parts in the drawings unrelated to the detailed description are omitted to ensure clarity of the various embodiments.  Like reference numerals in the drawings denote like elements, and thus their description will not\nbe repeated.  As used herein, the term \"and/or\" includes any and all combinations of one or more of the associated listed items).  Expressions such as \"at least one of,\" when preceding a list of elements, modify the entire list of elements and do not\nmodify the individual elements of the list.\nFIG. 1 is a diagram describing a method in which a first device provides content recommending information by using log information of a second device according to an embodiment of the present disclosure.\nReferring to FIG. 1, the first device 100 may be a smart television (TV) but this is merely an example.  The first device 100 may be implemented as a smart phone, a tablet, a digital camera, a camcorder, a laptop computer, a desktop, an e-book\nterminal, a digital broadcasting terminal, a personal digital assistant (PDA), a portable multimedia player (PMP), a navigation system, a Moving Picture Experts Group phase 1 or phase 2 (MPEG-1 or MPEG-2) audio layer 3 (MP3) player, a wearable device, or\na home appliance.\nThe second device 200 may, for example, be a smart phone.  The second device 200 may also be implemented as a smart TV, a tablet, a digital camera, a camcorder, a laptop computer, a desktop, an e-book terminal, a digital broadcasting terminal, a\nPDA, PMP, a navigation system, an MP3 player, a wearable device, or a home appliance.\nIn an embodiment of the present disclosure, the first device 100 may perform handshaking with the second device 200 to receive first log information from the second device 200.  Handshaking means transmitting and receiving signals for\nestablishing a connection and synchronization between two devices.\nTo perform handshaking, the second device 200 may transmit a synchronization signal to the first device 100, and the first device 100 may transmit an acknowledgement signal to the second device 200 in response to the synchronization signal.  If\nhandshaking is completely performed, the first device 100 may receive the first log information from the second device 200.  The first log information may include at least one of cache files, cookies, a browsing history, a download history, and a search\nhistory that are stored in the second device 200, content stored in the second device 200, and data necessary for executing at least one piece of content in the second device 200.\nThe first device 100 may generate the content recommending information by using the first log information and second log information.  The second log information may include at least one of cache files, cookies, a browsing history, a download\nhistory, and a search history that are stored in the first device 100, contents stored in the first device 100, and data necessary for executing at least one piece of content in the first device 100.\nThe first device 100 may detect recommendation keywords from the first log information and the second log information.  The first device 100 may generate the content recommending information based on the recommendation keyword.\nIn an embodiment, the first device 100 may generate the content recommending information by using only the first log information.\nIn an embodiment, the first device 100 may display the content recommending information on a display unit thereof.\nIn an embodiment, the first device 100 may transmit the content recommending information to the second device 200.\nFIG. 2 is a flowchart of a method of communicating between a first device and a second device and a method of providing content recommending information by using device log information according to an embodiment of the present disclosure.\nReferring to FIG. 2, the first device 100 may perform handshaking with the second device 200.\nThe second device 200 may transmit a synchronization signal to the first device 100 at operation S210.  The first device 100 may transmit an acknowledgement signal to the second device 200 in response to the synchronization signal at operation\nS220.  If handshaking is completely performed, the second device 200 may transmit first log information to the first device 100 at operation S230.  The first device 100 may generate the content recommending information by using the received first log\ninformation and second log information thereof at operation S240.  The first device 100 may transmit the content recommending information to the second device 200 at operation S250.  The first device 100 and the second device 200 may display the content\nrecommending information on a display unit at operations S260 and S270.\nIn an embodiment, the first device 100 may generate the content recommending information by using only the received first log information.\nIn an embodiment, the first log information may include at least one of cache files, cookies, a browsing history, a download history, and a search history that are stored in the second device 200, content stored in the second device 200, and\ndata necessary for executing at least one piece of content in the second device 200.  The second log information may include at least one of cache files, cookies, a browsing history, a download history, and a search history that are stored in the first\ndevice 100, content stored in the first device 100, and data necessary for executing at least one piece of content in the first device 100.\nIn an embodiment, the first log information may be received from the second device 200 through a short range communication technology.  The short range communication technology may include at least one of near field communication (NFC), Wi-Fi,\nBluetooth, infrared (IR), or Wi-Fi direct.\nIn an embodiment, the first device 100 and the second device 200 may be included in a home network or Internet of things (IOT).\nIn an embodiment, content may include at least one of applications, books, music, audio/video (A/V) data, services, game, multimedia, video, calendar, schedule, configuration, and user accessible data.\nIn an embodiment, the first device 100 and the second device 200 may store the content recommending information in a storage unit.\nIn an embodiment, the first device 100 and the second device 200 may control a display unit based on the generated content recommending information.\nIn an embodiment, the first device 100 may control the display unit based on the content recommending information.  For example, the first device 100 may display content included in the content recommending information differently from content\nthat is not included in the content recommending information on the display unit.  For example, the first device 100 may differentiate display locations or magnitude of the content included in the content recommending information and the content that is\nnot included in the content recommending information.\nWhen the first device 100 does not store a recommended content included in the content recommending information, the first device 100 according to an embodiment controls downloading of the recommended content from an external server.\nFIG. 3 is a flowchart of a method in which a first device provides content recommending information according to an embodiment of the present disclosure.\nReferring to FIG. 3, the first device 100 may receive first log information from an external device at operation S310.  The first device 100 may perform handshaking with the external device.  To perform handshaking, the external device may\ntransmit a synchronization signal to the first device 100, and the first device 100 may transmit an acknowledgement signal to the external device in response to the synchronization signal.  If handshaking is completely performed, the first device 100 may\nreceive the first log information from the external device.  The first log information may include at least one of cache files, cookies, a browsing history, a download history, and a search history that are stored in the external device, content stored\nin the external device, and data necessary for executing at least one piece of content in the external device.\nThe first device 100 may generate the content recommending information based on the first log information and second log information at operation S320.  The second log information may include at least one of cache files, cookies, a browsing\nhistory, a download history, and a search history that are stored in the first device 100, contents stored in the first device 100, and data necessary for executing at least one piece of content in the first device 100.\nThe first device 100 may analyze and process the first log information and the second log information and generate a user profile.  The user profile may include information reflecting user preference for selecting content.\nIn an embodiment, the user profile may include recommendation keywords detected based on the frequency among keywords included in the first log information and the second log information.\nIn an embodiment, the first device 100 may generate the content recommending information including one or more pieces of recommended contents based on the user profile.  The first device 100 may compare the recommendation keywords and content's\ninformation and include a content having the content's information matching the recommendation keywords in the recommended content.  The content's information may include titles of contents, metadata thereof, and descriptions thereof.\nIn an embodiment, the first device 100 may receive only log information relating to a specific user by using user login input information.  The log information relating to the specific user may include a search history, a browsing history, a\ncontent play list, etc., which are compiled as the specific user uses the first device 100 or the external device, among log information stored in a device.  When the first device 100 generates the user profile based on only the log information relating\nto the specific user, a personalized user profile may be generated.  When the first device 100 generates the content recommending information based on the personalized user profile, the content recommending information reflecting only content preference\nof the specific user may be generated.\nIn an embodiment, the first device 100 may transmit the first log information and the second log information to a server.  The server may generate the content recommending information based on the first log information and the second log\ninformation and transmit the generated content recommending information to the first device 100.\nIn an embodiment, the first device 100 may transmit the user profile to the server.  The server that has received the user profile may generate the content recommending information based on the user profile and transmit the generated content\nrecommending information to the first device 100.\nIn an embodiment, the first device 100 may store the user profile in a storage unit.  The first device 100 may update a user profile that is previously stored in the storage unit by using at least one of the newly received first log information\nand second log information.\nThe first device 100 may display the content recommending information through a display unit at operation S330.  The display unit may differently display content included in the content recommending information and content that is not included\nin the content recommending information on the display unit.  For example, the display unit of the first device 100 may differentiate display locations or magnitude of the content included in the content recommending information and the content that is\nnot included in the content recommending information.  In addition, the display unit may differentiate the content included in the content recommending information and the content that is not included in the content recommending information using graphic\nadjustment such as highlighting, grouping, etc.\nIn an embodiment, the first device 100 may output the content recommending information as audio through an audio output unit.\nIn an embodiment, the first device 100 may transmit the content recommending information to the external device.\nFIG. 4 is a flowchart of a method in which a first device provides content recommending information according to an embodiment of the present disclosure.\nReferring to FIG. 4, the first device 100 may receive first log information from an external device at operation S410.  The first device 100 may perform handshaking with the external device.  The first log information may include a device use\nhistory of a user stored in the external device as described above.\nThe first device 100 may generate the content recommending information based only the first log information at operation S420.  The first device 100 may generate the content recommending information by using the first log information received\nfrom the external device.  In this regard, the first device 100 may store log information for the first device 100 but may not use the stored log information to generate the content recommending information.  Alternatively, the first device 100 may be a\ndevice that does not store its own log information.\nIn an embodiment, the first device 100 may generate a user profile by analyzing and processing the first log information.  The user profile may include information reflecting user preference for selecting content.\nIn an embodiment, the user profile may include recommendation keywords detected based on the frequency among keywords included in the first log information.\nIn an embodiment, the first device 100 may generate the content recommending information including one or more pieces of recommended contents based on the user profile.  The first device 100 may compare the recommendation keywords and content\ninformation and include content having the content's information matching the recommendation keywords in recommended content.  The content's information may include titles of contents, metadata thereof, and descriptions thereof.\nIn an embodiment, the first device 100 may receive only log information relating to a specific user among the log information stored in the external device by using user login input information.  The log information relating to the specific user\nmay include a search history, a browsing history, a content reproduction list, etc., which are compiled as the specific user uses the external device, among the log information stored in the external device.  When the first device 100 generates the user\nprofile based on only the log information relating to the specific user, a personalized user profile may be generated.  When the first device 100 generates the content recommending information based on the personalized user profile, the content\nrecommending information reflecting only content preference of the specific user may be generated.\nIn an embodiment, the first device 100 may transmit the first log information to a server.  The server may generate the content recommending information based on the first log information and transmit the generated content recommending\ninformation to the first device 100.\nIn an embodiment, the first device 100 may transmit the user profile to the server.  The server that has received the user profile may generate the content recommending information based on the user profile and transmit the generated content\nrecommending information to the first device 100.\nIn an embodiment, the first device 100 may store the user profile in a storage unit.  In this regard, the first device 10 may update a user profile that is previously stored in the storage unit by using the newly received first log information.\nThe first device 100 may display the content recommending information through a display unit at operation S430.  The display unit may display content included in the content recommending information differently from content that is not included\nin the content recommending information.  The display unit of the first device 100 may differentiate display locations or magnitude of the content included in the content recommending information and the content that is not included in the content\nrecommending information.  In addition, the display unit may differentiate the content included in the content recommending information and the content that is not included in the content recommending information using graphic adjustment such as\nhighlighting, grouping, etc.\nIn an embodiment, the first device 100 may output the content recommending information as audio through an audio output unit.\nIn an embodiment, the first device 100 may transmit the content recommending information to the external device.\nFIG. 5 is a diagram describing a method in which a first device generates and provides content recommending information based on second log information and first log information of a plurality of external devices according to an embodiment of\nthe present disclosure.\nReferring to FIG. 5, the first device 100 may be a smart TV.  The plurality of external devices 201 and 202 may include a mobile device and a tablet.  However, the embodiment is not limited thereto.  The first device 100 and the plurality of\nexternal devices 201 and 202 may be implemented as various devices.  The mobile device 201 and the tablet 202 may transmit first log information from the mobile device 201 and the tablet 202 to the smart TV 100.  The smart TV 100 may generate the content\nrecommending information based on the received first log information and its second log information.  In this regard, the content recommending information may include a recommended application.  The smart TV 100 may display the recommended applications\nincluded in the content recommending information on a display unit.  As shown in FIG. 5, the smart TV 100 may transmit the content recommending information to the mobile device 201 and the tablet 202.\nIn an embodiment, the smart TV 100 may generate the content recommending information based on only the received first log information.\nIn an embodiment, the mobile device 201 may be a master device, and the tablet 202 may be a slave device.\nThe slave device 202 and the master device 201 may perform handshaking.  For example, the slave device 202 may transmit a synchronization signal to the master device 201.  The master device 201 may transmit an acknowledgement signal to the slave\ndevice 202 in response to the synchronization signal.\nIf handshaking is completely performed, the slave device 202 may transmit log information (log information A) of the slave device 202 to the master device 201.  The first device 100 and the master device 201 may perform handshaking.  If\nhandshaking is completely performed, the master device 210 may transmit the log information A and log information (log information B) of the master device 201 to the first device 100.  The first device 100 may generate the content recommending\ninformation by using the log information A, the log information B, and log information for the first device 100 (second log information).  The first device 100 may transmit the content recommending information to the master device 201.  The master device\n201 may transmit the received content recommending information to the slave device 202.\nIn an embodiment, the first device 100 may receive first log information from the external devices 201 and 202 through short range communication and may transmit the content recommending information to the external devices 201 and 202.\nIn an embodiment, short range communication may include at least one of NFC, Wi-Fi, Bluetooth, IR, or Wi-Fi direct.\nFIG. 6 is a diagram describing a method in which a server generates and provides content recommending information based on log information of a first device and external devices according to an embodiment of the present disclosure.\nReferring to FIG. 6, the first device 100 may be a smart TV.  The plurality of external devices 201 and 202 may include a mobile device and a tablet.  The server may be a desktop.  However, the embodiment is not limited thereto.  The first\ndevice 100, the server 300, and the plurality of external devices 201 and 202 may be implemented as various devices.  The mobile device 201 and the tablet 202 may transmit respective first log information to the smart TV 100.  The smart TV 100 may\ntransmit the received first log information and the second log information for the smart TV 100 to the server 300.  The server 300 may generate the content recommending information based on the first log information and the second log information and\ntransmit the content recommending information to the smart TV 100.  The content recommending information may include recommended applications.  In this regard, the smart TV 100 may display the recommended applications on a display unit.  The smart TV 100\nmay transmit the content recommending information to at least one of the mobile device 201 and the tablet 202.  Each of the external devices 201 and 202 may display the received content recommending information on a display unit.\nIn an embodiment, the first device 100 may receive the first log information from the external devices 201 and 202 through short range communication and may transmit the content recommending information to the server 300.  The server 300 may\ntransmit the content recommending information to the first device 100 and the external devices 201 and 202 through short range communication.  The short range communication may include at least one of NFC, Wi-Fi, Bluetooth, IR, or Wi-Fi direct.\nIn an embodiment, the mobile device 201 may be a master device, and the tablet 202 may be a slave device.\nFIG. 7 is a block diagram of a configuration of a first device for providing content recommending information according to an embodiment of the present disclosure.\nReferring to FIG. 7, the first device 100 may include a communication unit 110, a control unit 120, and a display unit 130.\nThe display unit 130 may generate a driving signal by converting an image signal, a data signal, an on screen display (OSD) signal, a control signal, etc. that are processed by the control unit 120.  The display unit 130 may be implemented as a\nplasma display panel (PDP), a liquid crystal display (LCD), an organic LCD (OLCD), a flexible display, etc. or may be implemented as a three dimensional (3D) display.  The display unit 130 may be configured as a touch screen and thus may be used an input\napparatus in addition to an output apparatus.\nIn an embodiment, the display unit 130 may display a content list including at least one content item.\nThe control unit 120 according to an embodiment may process and input the image signal to the display unit 130.  Accordingly, an image corresponding to the image signal may be displayed on the display unit 130.\nThe control unit 120 may include a profile generation unit (not shown) that generates a user profile based on first log information and second log information.  The control unit 120 may include a keyword detection unit (not shown) and a\nrecommending information generation unit (not shown).\nThe control unit 120 may detect recommendation keywords based on the frequency of keywords included in the first log information and the second log information.  The recommendation keywords may include a keyword reflecting user tendency or\npreference.  The first device 100 may compare the recommendation keywords and content information and generate the content recommending information based on contents included in the content information.  The content information may include titles of the\ncontent, metadata thereof, and descriptions thereof.\nIn an embodiment, the control unit 120 may include a keyword collection unit (not shown) that collects keywords from the first log information and the second log information, a filtering unit (not shown) that filters a keyword which does not\nreflect user content selection preference among the collected keywords and remains only the recommendation keyword, and a weighting unit (not shown) that assigns weights to the recommendation keywords according to a predefined weight criterion.\nIn an embodiment, the user profile may include one or more recommendation keywords.\nIn an embodiment, the control unit 120 may generate the content recommending information including the at least one recommended content based on the user profile.\nIn an embodiment, the communication unit 110 may include a receiving unit (not shown) that may receive the first log information from the second device 200 and a transmission unit (not shown) that may transmit the content recommending\ninformation to the second device 200.\nIn an embodiment, the receiving unit may perform handshaking with an external device.  For example, the external device may transmit a synchronization signal to the first device 100, and the first device 100 may transmit an acknowledgement\nsignal to the external device in response to the synchronization signal.\nIn an embodiment, the communication unit 110 may use short range communication.  The short range communication technology may include at least one of NFC, Wi-Fi, Bluetooth, IR, or Wi-Fi direct.\nIn an embodiment, the first device 100 may further include a user input unit (not shown) that receives user login information.  The first device 100 may receive only the first log information relating to a specific user among log information\nstored in the external device by using the user login information.  Likewise, the first device 100 may use only the second log information relating to the specific user among the log information stored in a storage unit by using the user login\ninformation.  The log information relating to the specific user may include a search history, a browsing history, a content reproduction list, etc., which are compiled as the specific user uses the first device 100 or the external device.  When the first\ndevice 100 generates the user profile based on only the log information relating to the specific user, a personalized user profile may be generated.  When the first device 100 generates the content recommending information based on the personalized user\nprofile, the content recommending information reflecting only content preference of the specific user may be generated.\nIn an embodiment, the first device 100 may further include a storage unit (not shown) that may store at least one of the first log information received from the external device, the user profile, and the content recommending information.\nFIG. 8 is a block diagram of a configuration of a first device for providing content recommending information according to an embodiment of the present disclosure.\nReferring to FIG. 8, the first device 100 according to an embodiment may include the communication unit 110, the control unit 120, an output unit including the display unit 130 and an audio output unit 140, a detection unit 150, an input/output\nunit 160, a storage unit 170, and a power supply unit 180.\nThe same descriptions of the communication unit 110, the control unit 120, and the display unit 130 as provided with reference to FIG. 7 above are omitted in FIG. 8.\nThe communication unit 110 may connect the first device 100 to an external device under control of the control unit 120.  The control unit 120 may perform transmission/reception to/from the external device connected via the communication unit\n110, download an application from the external device, or perform web browsing.  The communication unit 110 may include a combination of a wireless local area network (LAN) (not shown), Bluetooth (not shown), and wired Ethernet (not shown) in\ncorrespondence to performance and structure of a display apparatus.  The communication unit 110 may receive a control signal under control of the control unit 120.  The control signal may be implemented as a Bluetooth type signal, an RF type signal, or a\nWi-Fi type signal.\nThe control unit 120 may control general operations of the first device 100 and signal flows between internal elements thereof and processing data.  When a user input is present or a preset and stored condition is satisfied, the control unit 120\nmay execute an operating system (OS) and various pieces of contents that are stored in the storage unit 170.\nThe control unit 120 may include a random access memory (RAM) (not shown) that stores a signal or data that is input from the outside or that is used as a storage region corresponding to various operations performed by the first device 100, a\nread only memory (ROM) (not shown) that stores a control program for controlling the first device 100, and a processor (not shown).\nThe processor may include a graphic processing unit (not shown) for graphic processing corresponding to a video.  The processor may be implemented as a system on chip (SOC) that integrates a core (not shown) and a graphics processing unit (GPU)\n(not shown).  The processor may be a single core, dual core, triple core, quadruple core, or multi-core processor.\nThe processor may include a plurality of processors.  For example, the processor may be implemented as a main processor and a sub processor that operates in a sleep mode.\nAs used herein, the term \"control unit of a first device\" includes a processor, a RAM, and a ROM.\nThe audio output unit 140 may output audio included in a broadcasting signal received under control of the control unit 120.  The audio output unit 140 may output audio (for example, voice and sound) that is input through the communication unit\n110 or the input/output unit 160.  The audio output unit 140 may output audio stored in the storage unit 170 under control of the control unit 120.  The audio output unit 140 may include at least one of a speaker, a headphone output terminal, and a\nSony/Philips digital interface (S/PDIF) output terminal.  The audio output unit 140 may include a combination of the speaker, the headphone output terminal, and the S/PDIF output terminal.\nThe detection unit 150 may detect user voice, a user image, or a user interaction.\nThe input/output unit 160 may receive a video (for example, a moving image, etc.), audio (for example, voice, music, etc.), additional information (for example, an EPG, etc.), and the like from an external device or network under control of the\ncontrol unit 120.  The input/output unit 160 may include one of a high definition multimedia interface (HDMI) port (not shown), a component jack (not shown), a personal computer (PC) port (not shown), and a universal serial bus (USB) port (not shown). \nThe input/output unit 160 may include a combination of the HDMI port, the component jack, the PC port, and the USB port.\nIt will be understood by those of ordinary skill in the art that the configuration and the operation of the input/output unit 160 may be implemented in various ways according to various embodiments.\nThe storage unit 170 may store various data, programs or applications for driving and controlling the first device 100 under control of the control unit 120.  The storage unit 170 may store signals or data that are input and output in\ncorrespondence to driving the display unit 130, the audio output unit 140, the power supply unit 180, the communication unit 110, the detection unit 150, and the input/output unit 160.  The storage unit 170 may store control programs for controlling the\nfirst device 100 and the control unit 120, applications that are initially provided by a manufacturer or are downloaded, graphical user interfaces (GUIs) relating to the applications, objects (for example, image text, icons, buttons, etc.) for providing\nthe GUIs, user information, documents, databases, or relevant data.\nIn an embodiment, the term \"storage unit\" may include the storage unit 170, the RAM and the RAM of the control unit 120, or a memory card (not shown), for example, a micro secure digital (SD) card and a USB memory, mounted in the first device\n100.  The storage unit 170 may include a non-volatile memory, a volatile memory, a hard disk drive (HDD), or a solid state drive (SDD).\nThe power supply unit 180 may supply power that is input from an external power source to internal elements of the first device 100 under control of the control unit 120.  The power supply unit 180 may supply power that is output from one\nbattery or two or more batteries located in the first device 100 to the internal elements of the first device 100 under control of the control unit 120.\nFIG. 9 is a flowchart of a process in which a first device generates content recommending information according to an embodiment of the present disclosure.\nReferring to FIG. 9, the first device 100 may detect recommendation keywords from keywords included in log information based on the frequency at operation S910.\nFor example, the first device 100 may detect the recommendation keywords based on an occurrence frequency of the keywords included in first log information and second log information.  The first device 100 may process the first log information\nand the second log information in at least one of (1) full text unigrams that include body text of each web page stripped of html tags; (2) title unigrams that include words containing a &lt;title&gt; tag on html pages; (3) metadata description unigrams\nthat include content containing a &lt;meta name=\"description\"&gt; tag; (4) metadata keywords unigrams that include content containing a &lt;meta name=\"keywords\"&gt; tag; (5) extracted terms that include a set of keywords extracted from web pages and\nuniform resource locators (URLs) that a user visited; and (6) noun phrases that are extracted from text of each web page and split into sentences using a sentence splitter or a tokenization script.\nIn an embodiment, the control unit 120 of the first device 100 may filter keywords that do not reflect user content selection preference.  To this end, the control unit 120 may use a well-known filtering technology such as WorldNet dictionary\nfiltering and Google N-gram filtering.\nIn an embodiment, the control unit 120 of the first device 100 may assign weights to the filtered keywords or keywords that are not filtered.  A weighting algorithm may include TF weighting, TF-IDF weighting, BM25 weighting, and combination\nthereof.\nTF weighting is a weight value based on an occurrence frequency of a term and may be expressed in the following Equation: TF.sub.ij=f.sub.ij/max.sub.k Equation 1\nIn the Equation above, f.sub.ij denotes an occurrence frequency of a term i in a document j among N documents.  TF.sub.ij is the weight value may be calculated by dividing f.sub.ij by occurrence frequency max.sub.k of a most frequent term.  In\nthis regard, only the occurrence frequency of the most frequent term may be max.sub.k excluding stop words.  TF.sub.ij of the most frequent term in the document j is determined as 1, while TF.sub.ij of remaining terms of the document j is determined as a\nvalue smaller than 1.\nTF-IDF weighting is a weight value indicating how important a specific word is in a set of documents including several documents.  Term frequency (TF) is a value indicating how frequently a specific term occurs in a document.  Document frequency\n(DF) is a value indicating how frequently a specific term occurs in a set of documents.  Inverse (IDF) is an inverse value of DF.  TF-IDF is a value by multiplying TF and IDF.  IDF is determined according to a nature of the set of documents.  For\nexample, since a term \"atom\" does not usually occur in a general document, the IDF value of the \"atom\" may be increased and may be a core term of a document.  However, since the \"atom\" is a common term in a set of documents regarding the atom, other\nterms used to classify and identify documents may obtain high weights.  The TF value may be obtained as the total occurrence frequency of a term in a document.  When the total occurrence frequency of a term t in a document is f(t,d), a most simple\nEquation of calculating TF(t,d) may be expressed as TF(t,d)=f(t,d).  In addition, the TF value may be calculated using the following:\nBoolean frequency: TF(t,d)=1 or 0, (if t occurs in d once, TF(t,d)=1, and if not, TF(t,d)=0);\nLog scale frequency: TF(t,d)=log(f(t,d)+1);\nIncrease frequency: a frequency value of a term is adjusted according to a length of a document.\n.times..times..times..times..function..times..function..times..times.  .times..times..times..times.  ##EQU00001##\nThe IDF is a value indicating how frequently a specific term occurs in a set of documents.  The IDF value may be obtained using a log by dividing the number of all documents included in the set of documents by the number of documents including\nthe term.\n.times..times..times..times..times..times..times..times..times.  .times..times..times..times.  .times..times..times..times.  ##EQU00002##\n|D|: number of all documents included in the set of documents\n|{d.di-elect cons.D:t.di-elect cons.d}|: number of documents including the term t (when the term t is not present in any of the documents, this results in 0 as a denominator.  To prevent this, `1+|{d.di-elect cons.D:t.di-elect cons.d}|` is\ngenerally used).\nTF-IDF may be expressed in the following Equation: TF-IDF(t,d,D)=TF(t,d)*IDF(t,D) Equation 4\nThe TF-IDF value may be greater when TF is higher in a specific document and the number of documents including a term among all documents included in a set of documents is smaller.  Thus, the TF-IDF value may be used to obtain an effect of\nfiltering a term that frequently occurs in all documents.\nBM25 weighting is given by the following Equation:\n.times..times..times..times..times..times..times..times..times.  ##EQU00003##\nIn the Equation above, N denotes the number of documents on the web which may be estimated using an N-Gram corpus tool.  nt.sub.i denotes the number of documents in a corpus that contains the term t.sub.i.  R denotes the number of documents in\nbrowsing history.  rt.sub.i denotes the number of documents in the browsing history that contains the term t.sub.i.\nOnly TF weighting, TF-IDF weighting, and BM25 weighting are described as the weighting algorithm above but the various embodiments are not limited thereto.  Other algorithms or methods may be used to assign weights.\nThe first device 100 may generate a user profile including at least one of recommendation keywords, URLs of web pages visited by the user, the number of the URLs, and a search word list of the user.\nThe storage unit 170 of the first device 100 may store the user profile.  The first device 100 may update the stored user profile based on at least one of first log information and second log information.\nA method of generating the user profile according to an embodiment may include, but are not limited to, relevance feedback, genetic algorithms, neural networks, and the Bayesian classifier.\nThe first device 100 may generate the content recommending information based on contents including the recommendation keywords in content's information at operation 5920.\nThe content information according to an embodiment may include titles of contents, metadata thereof, and descriptions thereof.\nThe first device 100 according to an embodiment may compare the content information and the recommendation keywords.  When the content information includes the recommendation keywords, the first device 100 may set corresponding content as\nrecommended content.\nThe content recommending information according to an embodiment may include at least one recommended content.\nFIG. 10 is a diagram of an example of a process in which the first device 100 generates content recommending information according to an embodiment of the present disclosure.\nReferring to FIG. 10, a user profile according to an embodiment may include a recommendation keyword 1010 `Skype` and `Football and Europe`.\nThe first device 100 may compare `Skype` and `Football and Europe` and content titles.  For example, the first device 100 may determine whether `Skype` is included in the content titles.  When the content titles include `Skype`, the first device\n100 may set corresponding content as recommended content.  As shown in FIG. 10, when `Skype` matches a title of an application 1020 called `Skype`, the first device 100 may set the application 1020 as the recommended content.\nWhen the content titles do not include `Skype`, the first device 100 may compare `Skype` and descriptions of contents or metadata thereof.  As shown in FIG. 10, `Football and Europe` is not included in a title of an application 1030 `Goal` but\nis included in a description of the application 1030.  Thus, the first device 100 may set the application 1030 `Goal` as the recommended content.\nThe first device 100 according to an embodiment may generate the content recommending information based on the recommended contents.\nFIG. 11 is a flowchart of a method in which the first device 100 receives user login information and generates and provides content recommending information according to an embodiment of the present disclosure.\nReferring to FIG. 11, the first device 100 and the second device 200 may perform handshaking.  For example, the second device 200 may transmit a synchronization signal to the first device 100 at operation S1110.  The first device 100 may\ntransmit an acknowledgement signal to the second device 200 in response to the synchronization signal at operation S1120.\nThe first device 100 may receive login information of a user 1 through a user input unit at operation S1130.  The first device 100 may receive first log information relating to the user 1 among log information stored in the second device 200\nbased on the login information of the user 1 at operation S1140.  The first device 100 may generate the content recommending information based on second log information relating to the user 1 among log information of the first device 100 and the first\nlog information at operation S1150.  The log information relating to the user 1 may include a search history, a content reproduction list, and a browsing history, etc., which are compiled as the user 1 uses the first device 100 or the second device 200. \nWhen the first device 100 generates the content recommending information based on only the log information relating to the user 1, the content recommending information personalized to the user 1 may be provided.\nThe first device 100 may transmit the content recommending information to the second device 200 at operation S1160.  The first device 100 and the second device 200 may display the content recommending information through display units at\noperations S1170 and S1180.\nIn an embodiment, the first device 100 may generate the content recommending information based on only the first log information received from the second device 200.\nIn an embodiment, the first log information may include at least one relating to the user 1 among cache files, cookies, a browsing history, a download history, and a search history that are stored in the second device 200, contents stored in the\nsecond device 200, and data necessary for executing at least one content item in the second device 200.  The second log information may include at least one relating to the user 1 among cache files, cookies, a browsing history, a download history, and a\nsearch history that are stored in the first device 100, contents stored in the first device 100, and data necessary for executing at least one piece of content in the first device 100.\nIn an embodiment, the first device 100 may use a short range communication technology to receive the first log information from the second device 200.  The short range communication technology may include at least one of NFC, Wi-Fi, Bluetooth,\nIR, or Wi-Fi direct.\nIn an embodiment, the first device 100 and the second device 200 may be included in a home network or IOT.\nIn an embodiment, the content may include at least one of applications, books, music, A/V data, services, games, multimedia, video, calendars, schedules, environment settings, and user accessible data.\nIn an embodiment, the first device 100 and the second device 200 may store the content recommending information in the storage unit 170.\nIn an embodiment, the first device 100 and the second device 200 may control the display unit 130 based on the generated content recommending information.\nIn an embodiment, the first device 100 may control the display unit 130 based on the content recommending information.  For example, the first device 100 may display content included in the content recommending information differently from\ncontent that is not included in the content recommending information on the display unit 130.  For example, the first device 100 may differentiate display locations or magnitude of the content included in the content recommending information and the\ncontent that is not included in the content recommending information.\nWhen the first device 100 does not store the recommended content included in the content recommending information, the first device 100 according to an embodiment control downloading of the recommended content from an external server.\nFIG. 12 is a diagram of an example in which a first device receives user login information according to an embodiment of the present disclosure.\nReferring to FIG. 12, in an embodiment, the first device 100 may display a GUI screen 1200 that may receive the user login information.  For example, a user may select an icon matching his/her user login information on the GUI screen 1200.  As\nshown in FIG. 12, a user 1 may click an icon \"user 1\", and a user 2 may input user login information by clicking an icon \"user 2\".  A new user may generate new user login information by clicking an icon \"new user\".\nThe first device 100 may receive first log information relating to a user who logged in by using the user login information.  The first device 100 may generate a user profile by using the first log information and second log information that is\nstored in the first device 100 and is related to the user who logged in.\nIn an embodiment, an input tool for selecting an icon may include a remote controller, a mouse, a touch pad, a keyboard, a button, and a touch screen.\nFIG. 13 is a diagram of an example of a method in which a first device displays content recommending information according to an embodiment of the present disclosure.\nReferring to FIG. 13, the smart TV 100 may receive application information stored in the mobile device 200 and display application recommending information for a user 1.  The smart TV 100 may receive information (first log information) that an\napplication \"baseball live\" 1310 is stored in the mobile device 200.  In this regard, the smart TV 100 may detect a term \"baseball\" as a recommendation keyword.  The smart TV 100 may generate the application recommending information for the user 1 based\non the recommendation keyword.  The application recommending information may include recommended applications such as games relating to \"baseball\", a glossary of terms, a baseball ticket reservation, a glossary of baseball, etc. The display unit 130 of\nthe smart TV 100 may display the recommended applications differently from other applications displayed thereon.  As shown in FIG. 13, the display unit 130 may display \"user 1 recent recommended applications\" and \"recent recommended applications\" by\ndifferentiating display regions of the \"user 1 recent recommended applications\" and the \"recent recommended applications\".  FIG. 13 shows the example of displaying the \"user 1 recent recommended applications\" on an upper side of a display region and the\n\"recent recommended applications\" on a lower side thereof.  The first device 100 and the second device 200 are respectively illustrated as the smart TV 100 and the mobile device 200 in FIG. 13 but are not limited thereto.\nIn an embodiment, the first device 100 may display content included in the content recommending information differently from content that are not included in the content recommending information using graphic adjustment.  Graphic adjustment may\ninclude highlighting, resizing, moving, shortlisting, arranging, grouping, etc.\nFIG. 14 is a diagram of an example of a method in which a first device displays content recommending information according to an embodiment of the present disclosure.\nReferring to FIG. 14, the smart TV 100 may receive information (first log information) that an application \"baseball live\" 1410 is stored in the mobile device 200.  In this regard, the smart TV 100 may detect a term \"baseball\" as a\nrecommendation keyword.  The smart TV 100 may generate the application recommending information for a user 1 based on the recommendation keyword.  The application recommending information may include recommended applications such as games relating to\n\"baseball\", a glossary of terms, a baseball ticket reservation, a glossary of baseball, etc. The display unit 130 of the smart TV 100 may display the recommended applications differently from other applications displayed thereon.  As shown in FIG. 14,\nthe display unit 130 may display \"user 1 recent recommended applications\" and \"recent recommended applications\" by differentiating display regions of the \"user 1 recent recommended applications\" and the \"recent recommended applications\".  FIG. 14 shows\nthe example of displaying the \"user 1 recent recommended applications\" on a left side of a display region and the \"recent recommended applications\" on a right side thereof.  The first device 100 and the second device 200 are respectively illustrated as\nthe smart TV 100 and the mobile device 200 in FIG. 14 but are not limited thereto.\nFIG. 15 is a diagram of an example of a method in which a first device displays content recommending information according to an embodiment of the present disclosure.\nReferring to FIG. 15, the smart TV 100 may receive information (first log information) that an application \"baseball live\" 1510 is stored in the mobile device 200.  In this regard, the smart TV 100 may detect a term \"baseball\" as a\nrecommendation keyword.  The smart TV 100 may generate the application recommending information for a user 1 based on the recommendation keyword.  The application recommending information may include recommended applications such as games relating to\n\"baseball\", a glossary of terms, a baseball ticket reservation, a glossary of baseball, etc. The display unit 130 of the smart TV 100 may display the recommended applications differently from applications displayed thereon.  As shown in FIG. 15, the\ndisplay unit 130 may display \"baseball games\", \"baseball ticket reservation\", \"glossary of baseball\", and \"glossary of baseball terms\" and other applications displayed thereon by magnifying \"baseball games\", \"baseball ticket reservation\", \"glossary of\nbaseball\", and \"glossary of baseball terms\" at a first magnification and reducing the other applications at a second magnification determined based on the first magnification.  In this regard, a ratio between the first magnification and the second\nmagnification may vary according to a user and a peripheral environment.  The first device 100 and the second device 200 are respectively illustrated as the smart TV 100 and the mobile device 200 in FIG. 15 but are not limited thereto.\nFIG. 16 is a diagram of an example in which a first device outputs content recommending information as audio through an audio output unit according to an embodiment of the present disclosure.\nReferring to FIG. 16, the smart TV 100 may provide 1620 application recommending information through the audio output unit 140.  For example, the smart TV 100 may output application information included in \"user 1 recent recommended\napplications\" as audio through the audio output unit 140.  In this way, a user may receive the application recommending information when the user is away from the smart TV 100 or is unable to recognize information through the display unit 130 of the\nsmart TV 100.  The application's information may include titles of applications, metadata thereof, and descriptions thereof\nIn an embodiment, the smart TV 100 may output the application information through the audio output unit 140 and simultaneously display the content recommending information through the display unit 130.  However, display and output of audio are\nnot necessarily provided simultaneously and may vary according to a user input or a peripheral environment.  The first device 100 and the second device 200 are respectively illustrated as the smart TV 100 and the mobile device 200 in FIG. 16 but are not\nlimited thereto.\nFIG. 17 is a diagram of an IOT scenario that generates content recommending information based on log information received from a plurality of external devices according to an embodiment of the present disclosure.\nReferring to FIG. 17, a microwave oven 100 (the first device 100) may receive the log information including a search history from the tablet 201 and/or the mobile phone 202.  For example, the log information may include a history that a user\nsearches for \"pizza recipe\" or \"how to make pizza using a microwave oven\" by using the tablet 201 and/or the mobile phone 202.  The control unit 120 of the microwave oven 100 may generate a recommended cooking mode based on a cooking mode frequently used\nby the user among a plurality of cooking modes stored in the storage unit 170 of the microwave oven 100.\nIn an embodiment, the microwave oven 100 may display the recommended cooking mode to the user or automatically set a cooking mode.\nIn an embodiment, the microwave oven 100 may generate the recommended cooking mode based only the log information received from the tablet 201 and/or the mobile phone 202.\nIn an embodiment, the microwave oven 100 may display the recommended cooking mode through the display unit 130.\nIn an embodiment, the microwave oven 100 may output information regarding the recommended cooking mode as audio through the audio output unit 140.\nAs described above, according to an embodiment, a first device may communicate with a plurality of devices to receive relevant information and accordingly may generate content recommending information by using log information included in the\nplurality of devices.\nAccording to an embodiment, a first device may provide content recommending information to a user by displaying the content recommending information through a display unit or transmitting the content recommending information to an external\ndevice.\nAccording to an embodiment, a first device may provide personalized content recommending information of users by using user login information.\nThe image display method according to the above-described embodiments may be implemented as computer instructions which may be executed by various computer means, and recorded on a non-transitory computer-readable recording medium.  The\nnon-transitory computer-readable recording medium may include program commands, data files, data structures, or a combination thereof.  The program commands recorded on the non-transitory computer-readable recording medium may be specially designed and\nconstructed for the inventive concept or may be known to and usable by one of ordinary skill in a field of computer software.  Examples of the non-transitory computer-readable recording medium include hardware devices specially configured to store and\nperform program instructions such as magnetic storage media (e.g., ROM, floppy disks, hard disks, etc.), and optical recording media (e.g., compact disc-ROMs (CD-ROMs), or digital versatile discs (DVDs)), etc.).  Examples of the program commands include\na high-level language code that may be executed by a computer using an interpreter as well as a machine language code made by a complier.\nIt should be understood that various embodiments described herein should be considered in a descriptive sense only and not for purposes of limitation.  Descriptions of features or aspects within each embodiment should typically be considered as\navailable for other similar features or aspects in other embodiments.\nWhile the present disclosure has been shown and described with reference to various embodiments thereof, it will be understood by those skilled in the art that various changes in form and details may be made therein without departing from the\nspirit and scope of the present disclosure as defined by the appended claims and their equivalents.", "application_number": "14939487", "abstract": " A method and a device for providing content recommending information are\n     provided. The method includes receiving first log information of an\n     external device, generating content recommending information based on the\n     first log information and second log information of the first device, and\n     displaying the content recommending information.\n", "citations": ["8607267", "9026668", "9071886", "20080214157", "20090248680", "20130014158", "20140082515", "20150172777"], "related": []}, {"id": "20160188713", "patent_code": "10255358", "patent_name": "Systems and methods for clustering items associated with interactions", "year": "2019", "inventor_and_country_data": " Inventors: \nGreen; Bradley Ray (Snohomish, WA)  ", "description": "<BR><BR>FIELD OF THE INVENTION\nThe present technology relates to the field of content provision.  More particularly, the present technology relates to techniques for clustering items associated with interactions of a social networking system.\n<BR><BR>BACKGROUND\nToday, people often utilize computing devices (or systems) for a wide variety of purposes.  Users can use their computing devices to, for example, interact with one another, access content, share content, and create content.  In some cases,\ncontent items can include postings from members of a social network.  The postings may include text and media content items, such as images, videos, and audio.  The postings may be published to the social network for consumption by others.\nUnder conventional approaches, a user may navigate to or be presented with various content items in a social network.  The content items can come from pages associated with members of the social network.  In some instances, the content items may\nbe of high interest to the user.  If the user expresses interest in a particular content item, the social network may attempt, based on the content item, to provide to the user additional content items that likewise would be of high interest to the user. Provision of additional content items that are of high interest to the user enhances user experience and can help realize the full potential of the social network.  Unfortunately, attempts to provide such additional content items and to maintain a high\nlevel of interest from the user often fail.\n<BR><BR>SUMMARY\nVarious embodiments of the present disclosure can include systems, methods, and non-transitory computer readable media configured to generate session information based on information regarding items of a plurality of item types associated with\ninteractions performed by active users of a social networking system.  A graph is generated based on the session information.  At least a first item of the items is assigned to a cluster based on similarity between the item and the cluster.  The cluster\nis provided to a recommender system to facilitate selection of relevant information for potential presentation to a user.\nIn an embodiment, the plurality of item types include at least one of other users, profiles, groups, pages, hashtags, topics, links, photos, and search terms.\nIn an embodiment, the session information is based on a user or a post.\nIn an embodiment, the information regarding items of a plurality of item types is limited by at least one of a threshold number of the active users and a threshold number of interactions associated with the active users.\nIn an embodiment, noise in the session information is removed based on at least one of spending less than a first threshold amount of time for each interaction, activity for more than a second threshold amount of time for a session, and\nengagement in a cycle of interaction.\nIn an embodiment, edges of a node of the graph are rebalanced to optimize memory usage in storage of the graph.\nIn an embodiment, the rebalancing edges of a node of the graph further comprises multiplying transition probabilities between the node and each of connected nodes by a constant value when the total count of edges for the node satisfies a\nthreshold value.\nIn an embodiment, the constant value is based on a threshold value divided by a transition probability of a k-th largest connected node by weight when the transition probability is greater than the threshold value.\nIn an embodiment, a similarity score between the first item and a representative item of the cluster is determined.  It is determined whether the similarity score satisfies a threshold value.\nIn an embodiment, bi-directional agreement between the first item and a representative item of the cluster interact and internal cohesion of the cluster are determined.\nIt should be appreciated that many other features, applications, embodiments, and/or variations of the disclosed technology will be apparent from the accompanying drawings and from the following detailed description.  Additional and/or\nalternative implementations of the structures, systems, non-transitory computer readable media, and methods described herein can be employed without departing from the principles of the disclosed technology. <BR><BR>BRIEF DESCRIPTION OF THE DRAWINGS\nFIG. 1 illustrates an example clustering system, according to an embodiment of the present disclosure.\nFIG. 2 illustrates an example joiner module, according to an embodiment of the present disclosure.\nFIG. 3 illustrates an example graph module, according to an embodiment of the present disclosure.\nFIG. 4 illustrates a first example method, according to an embodiment of the present disclosure.\nFIG. 5 illustrates a second example method, according to an embodiment of the present disclosure.\nFIG. 6 illustrates a network diagram of an example system that can be utilized in various scenarios, according to an embodiment of the present disclosure.\nFIG. 7 illustrates an example of a computer system that can be utilized in various scenarios, according to an embodiment of the present disclosure.\nThe figures depict various embodiments of the disclosed technology for purposes of illustration only, wherein the figures use like reference numerals to identify like elements.  One skilled in the art will readily recognize from the following\ndiscussion that alternative embodiments of the structures and methods illustrated in the figures can be employed without departing from the principles of the disclosed technology described herein.\n<BR><BR>DETAILED DESCRIPTION\nEntity Clustering\nPeople use computing devices (or systems) for a wide variety of purposes.  Computing devices can provide different kinds of functionality.  Users can utilize their computing devices to produce information, access information, and share\ninformation.  In some cases, users can use their computing devices to generate and publish content postings.  Content can include any combination of content types, such as text, images, videos, and audio.  The content can be shared for consumption by\nothers through a social networking system.  The content can be shared in a variety of formats, such as pages of or posts to the social networking system.\nThe conventional presentation of content can entail many disadvantages.  The social networking system may attempt to identify additional content that is of interest to the user.  However, when presented to the user, the additional content may\nnot be desirable to the user because they are not well matched with the interests of the user.  In such circumstances, the user can be provided with content that the user deems unfamiliar, irrelevant, or worse.  As a result, the user experience of the\nsocial networking system can suffer.\nAn improved approach to the presentation of additional content overcomes the foregoing and other disadvantages associated with conventional approaches.  The present disclosure is a real time (or near real time) system that can be used to improve\nrecommender systems that present content to a user.  For example, with respect to a user, the present disclosure can collect the items (or entities) users have interacted (engaged) with in sequence.  Noise reduction techniques can be applied to the\ncollection of the items.  Sequences can be aggregated together to form a graph of items with edge weights reflecting a count of transitions between two items.  The edge weights in the graph can provide a transition probability from one item to another\nitem.  The edge weights can be rebalanced to optimize memory usage and to address rapid edge decay in certain circumstances.  The transition probabilities can be used for clustering of items that can be used in real time (or near real time) by\nrecommender systems to provide additional, relevant information to the user.\nFIG. 1 illustrates an example system 100 including an example clustering module 102 configured to facilitate the determination of additional content by recommender systems 104 to present to a user of a social networking system, according to an\nembodiment of the present disclosure.  The recommender systems 104, including user-to-item recommender systems and item-to-item recommender systems, can include one or more types of techniques for providing relevant information to the user in a social\nnetworking system.  In some instances, the example system 100 can also include at least one data store 116.\nThe clustering module 102 can include a tailer module 108, a joiner module 110, and a graph module 112.  The components (e.g., modules, elements, etc.) shown in this figure and all figures herein are exemplary only, and other implementations may\ninclude additional, fewer, integrated, or different components.  Some components may not be shown so as not to obscure relevant details.\nIn some embodiments, the clustering module 102 can be implemented, in part or in whole, as software, hardware, or any combination thereof.  In general, a module as discussed herein can be associated with software, hardware, or any combination\nthereof.  In some implementations, one or more functions, tasks, and/or operations of modules can be carried out or performed by software routines, software processes, hardware, and/or any combination thereof.  In some cases, the clustering module 102\ncan be implemented, in part or in whole, as software running on one or more computing devices or systems.  In some embodiments, the clustering module 102 and data managed by the clustering module 102, such as graph data, can be distributed over an array\nof computing devices, such as servers, and sharding techniques can be used to localize related or connected data (e.g., connected nodes and associated edges in the graph) in one computing device to optimize speed and minimize latency.  In some instances,\nthe clustering module 102 can, in part or in whole, be implemented within or configured to operate in conjunction with a social networking system (or service), such as the social networking system 630 of FIG. 6.  It should be understood that many\nvariations are possible.\nThe tailer module 108 can access data relating to interaction (engagement) with the social networking system or other websites for which the social networking system acts as a platform.  The data can be provided by a system that interfaces with\nfront end servers to track in real time (or near real time) all interactions with items (entities).  Items can include, for example, other users, groups, pages, hashtags, topics, links, photos, search terms, etc. Interactions can include, for example,\nproduction, clicking, viewing, navigating, etc. As some examples, interactions can relate to page visits, page likes, profile follows, URL shares, hashtag authoring, topic authoring, etc. The data can be log entries in the form of messages.  In\nparticular, the tailer module 108 can receive desired categories of the messages and extract information about interactions.  The information can include, for example, identity of the user performing the interaction (User-Id), identity of an item with\nwhich user is interacting (Item-Id), the type of the item, the time of the interaction, and the location of the interaction.  This information can be encoded in a message for consumption by the joiner module 110.  The tailer module 108 can queue messages\nfor consumption by the joiner module 110 in a first-in-first-out manner.\nThe joiner module 110 can collect interactions of active users.  The joiner module 110 can maintain a time and space efficient indexed (or hash) table designed to support concurrent writes.  In one example, the table can be keyed by a user (or\nassociated User-Id).  Each User-Id value can contain a sequence of items with which the user has interacted.  The sequence can be referred to as a session.  The items in the session can be ordered by recency of interaction with each item.  In another\nexample, the table can be keyed by a post (or associated post-ID).  The joiner module 110 can maintain memory efficiency by limiting the size of the indexed table and the number of items with which the user has interacted.  The joiner module 110 also can\nidentify sources of noise and accordingly ignore or eliminate associated interactions.  The joiner module 110 is discussed in more detail herein.\nThe graph module 112 can manage a multi-level graph reflecting user interaction with items and track transitions between the same type of items (homogeneous) and between different types of items (heterogeneous).  The graph can be implemented as\na time and space efficient indexed table designed to support concurrent writes.  The graph module 112 can track transitions by a variety of metadata, such as by type of item and by location.  The graph module 112 can perform a rebalancing technique\nrelating to transition (edge) counts to optimize memory efficiency and to address rapid decay in certain circumstances.  The graph module 112 can generate similarity scores based on transitions to facilitate the determination of clusters of items.  The\ngraph module 112 can generate clusters of the items according to the similarity scores and provide the clusters to the recommender systems 104.  The graph module 302 is discussed in more detail herein.\nThe recommender systems 104 can include systems that select content for potential presentation to a user relating to, for example, a trending topic, page recommendations, group recommendations, search recommendations, and the like.  The\nrecommender systems 104 can be used in connection with underlying techniques that monitor activities on the social networking system.  Such techniques can include, for example, co-visitation, co-interaction, co-production, and co-liking.  The recommender\nsystems 104 can provide relevant information for potential presentation to a user based on the clusters provided by the graph module 112.\nThe data store 116 can be configured to store and maintain various types of data associated with the clustering system 102 and the social networking system.  The information associated with the social networking system can include data about\nusers, social connections, social interactions, locations, geo-fenced areas, maps, places, events, groups, posts, communications, content, account settings, privacy settings, and various other types of data.  In some implementations, the data store 116\ncan store information associated with users, such as user identifiers, user information, user specified settings, content produced by users, and various other types of user data.  As shown in the example system 100, the clustering module 102 can be\nconfigured to communicate and/or operate with the data store 116.\nFIG. 2 illustrates an example joiner module 202, according to an embodiment of the present disclosure.  In some embodiments, the joiner module 110 can be implemented by the joiner module 202.  As shown in the example of FIG. 2, the joiner module\n202 can include a session module 204 and a noise reduction module 206.\nThe session module 204 can join relevant interaction data to create sessions maintained as indexed tables.  Each session may include all relevant interactions with items based on a key.  The session module 204 can order the items based on\nrecency.  The items in a session may include the same type of items or may include different types of items.  For example, the session module 204 can collect interactions based on a user in a session.  In this regard, the user can visit a page, fan the\npage, post regarding the page, visit a group, and perform other interactions.  These interactions can be included in a session associated with the user.  As another example, the session module 204 can collect interactions based on an identification of a\npost (Post-ID).  In this regard, if a user published a post having a hashtag and a URL, the hashtag and the URL can be joined on the Post-ID and included in a session associated with the Post-ID.  The session module 204 can maintain sessions in a queue\nfor provision to the graph module 112.\nThe session module 204 can maintain memory efficiency through various techniques.  For example, the session module 204 can limit the users tracked to only active users.  As another example, the session module 204 can limit the number of active\nusers tracked to a selected maximum number of active users.  When a new active user surfaces, the oldest active user may be dropped from tracking.  In addition, the session module 204 can limit the number of interactions of each active user that are\ntracked to a maximum number of interactions.  A circular list (counter) may be applied to limit the number of interactions to the maximum number.\nThe noise reduction module 206 can identify sources of noise and accordingly ignore or eliminate associated interactions according to a variety of techniques.  The sources of noise can be reflected in interaction data and undesirably impact\nprobabilities of transition for nodes and related clustering.  The sources of noise can be automated third party processes responsible for spam, malware, or malicious activity on the social networking system.\nIn one technique, the noise reduction module 206 can determine whether a user is spending less than a threshold amount of time for each interaction (e.g., page visit).  Spending relatively small amounts of time on interactions can be indicative\nof automated behavior and a third party process designed to scrape content from some or all of the pages of the social networking system.  The threshold amount of time for each interaction can be based on a type of the item on which the interaction was\nperformed.  The threshold amount of time for each interaction can be selected by an administrator of the social networking system.  When interactions do not equal or exceed the threshold amount of time, the noise reduction module 206 can blacklist the\nUser-ID associated with the interactions.  All interactions associated with the User-ID can be ignored by the joiner module 110 and not used in updating the graph.\nIn another technique, the noise reduction module 206 can determine whether a user is active for more than a threshold amount of time for each session of interactions.  Spending relatively large amounts of time for each session can be indicative\nof automated behavior and usage of the social networking system that is not intended.  The threshold amount of time for each session can be selected by an administrator of the social networking system.  When a session of a user equals or exceeds the\nthreshold amount of time for each session, the noise reduction module 206 can black list the User-ID associated with the interactions.  All interactions associated with the User-ID can be ignored by the joiner module 110 and not used in updating the\ngraph.\nIn yet another technique, the noise reduction module 206 can determine whether a user has engaged in a cycle (pattern) of interaction.  Cycles of interaction can be indicative of automated behavior and usage of the website of the social\nnetworking system that is not intended.  The noise reduction module 206 can select a predetermined number of interactions (e.g., page visits) of a user.  The predetermined number of interactions can be selected by an administrator of the social\nnetworking system.  For example, the noise reduction module 206 can determine the page IDs of a selected number of consecutive pages that were visited by the user.  The noise reduction module 206 can analyze the historical page visits associated with the\nuser.  If the noise reduction module 206 detects the user visited the same consecutive pages on another occasion, the noise reduction module can black list the User-ID associated with the interactions.  All interactions associated with the User-ID can be\nignored by the joiner module 110 and not used in updating the graph.  FIG. 3 illustrates an example graph module 302, according to an embodiment of the present disclosure.  The graph module 302 can be configured to manage a graph reflecting interaction\nwith items and track transitions between items.  In some embodiments, the graph module 112 can be implemented by the graph module 302.  The graph module 302 can include, a generation module 304, a rebalancing module 306, and a clustering module 308.\nThe generation module 304 is configured to build a graph representing the items and interactions.  The items are represented by nodes in the graph and the transitions between items are represented by edges in the graph.  The generation module\n304 can continuously update edges in the graph.  The edges of a node can be incoming, outgoing, or bi-directional.  Each edge can be added to the graph by a count of integer values.  The graph can be a multi-level graph reflecting interaction between the\nsame type of items (homogeneous) and between different types of items (heterogeneous).  The generation module 304 can track transitions by a variety of metadata, such as by type of item and by location.\nThe graph can reflect a wide array of interactions involving different items.  For example, if a user visited a first page, and then visited a second page, and then visited a profile, and then visited a group, the generation module 304 can\nappropriately reflect the items and interactions in the graph.  A node can be created for each of the first page, the second page, the profile, and the group.  Edges, or transitions, can be created among the nodes.  In particular, a transition from the\nfirst page to the second page can be created, a transition between the second page to the profile can be created, and a transition from the profile to the group.  For a multitude of users whose interactions may involve various interactions with the first\npage, the second page, the profile, and the group, corresponding transitions may be created among the associated nodes.  Not all interactions with the first page, the second page, the profile, and the group may proceed in the stated sequence.  For\ninstance, some users may visit the second page, and then visit the first page, and then visit the profile, and then visit the group.  In another instance, some users may visit the second page, and then visit the group, and then visit the first page, but\nnot visit the first page.\nAs another example, if a post (e.g., status update, comment) is published, the text of the post may result in the generation of, for example, topic tags, hashtags, and URLs.  The generation module 304 can appropriately reflect the topic tags,\nthe hashtags, and the URLs in the graph.  Nodes and transitions can be created for the topic tags, the hashtags, and the URLs.\nThe generation module 304 can generate transitions based on the different interactions and generated relationships between items.  Over a threshold number of users and generated relationships over time, the transitions, when aggregated, can\nconverge on certain ratios or transition probabilities with respect to one another.  The transition probabilities can be used to cluster items and facilitate the selection of relevant information by the recommender systems 104.\nThe rebalancing module 306 can manage edges in the graph to optimize the use of memory for storage of the graph and to address rapid decay in certain circumstances involving, for example, trending.  The rebalancing module 306 can apply a decay\n(reduction) to the number of edges between a node and its connected nodes in a graph in certain circumstances.  In some embodiments, the rebalancing module 306 can count all of the edges for the node.  If the total number of edges for the node is greater\nthan or equal to a threshold total number of edges, the rebalancing module 306 can decay the total number of edges.\nThe decay can in whole or in part maintain the probabilities of transition reflected in the edges prior to the decay.  The probability of transition associated with a node and a particular connected node can be represented by the count of\ntransitions between the node and the particular connected node (i.e., weight of the edges between the node and the particular connected node) divided by the sum of the count of transitions between the node and all of the connected nodes (i.e., weight of\nall edges between the node and all connected nodes).  The rebalancing module 306 can determine a constant value between zero and one.  Each count of transitions between the node and a connected node can be multiplied by a constant value, such as a\nfraction.  The product of the count of transitions between the node and a connected node and the constant value can generate a weight, which is rounded down to the nearest integer.  Any connected node associated with a weight equal to zero can be removed\nfrom the graph.\nIn some embodiments, undesirable rapid edge decay can be addressed.  Such rapid decay can occur in connection with trending items.  A constant value can be selected as a function of transition probabilities to preserve the top k transition\nprobabilities above a threshold value through edge decay.  The threshold value can be a minimum percentage of the weight of the edges of all connected nodes.  When the transition probability of the k-th largest connected node by weight among the\nconnected nodes is greater than the threshold value, the constant value is equal to the threshold value divided by the transition probability of the k-th largest connected node by weight among the connected nodes.  The constant value can be multiplied by\neach of the transition probabilities associated with the node and each of the connected nodes.  The product of the constant value and each of the transition probabilities can generate a new weight between the node and each of the connected nodes.  When\nthe transition probability of the k-th largest connected node by weight among the connected nodes is not greater than the threshold value, the constant value can be any default value.\nThe clustering module 308 can generate similarity scores based on transitions to facilitate the determination of clusters of items.  The clustering module 308 can cluster items based on similarity scores and the clusters can be provided to the\nrecommender systems 104 for the selection and presentation of relevant information to users.  The clusters of items can include items of the same type and items of different type.  The similarity scores can reflect a degree of similarity between two\nitems based on the edges connecting the items.\nWith respect to items of the same type, the clustering module 308 can generate clusters based on the similarity scores of the items.  The similarity score between an item and a particular, connected item can be represented by the count of\ntransitions between a node associated with the item and a node associated with the particular, connected item (i.e., weight of the particular node) divided by the sum of the count of transitions between the node and all of the nodes connected to the node\n(i.e., weight of all connected nodes).  The clustering module 308 also can determine a similarity score between an item and a cluster.  To determine the similarity score between the item and the cluster, the clustering module 308 can select any item in\nthe cluster or an item in the cluster that is representative of the items in the cluster.  The similarity score between the item and the cluster can be based on the similarity score between the item and the item in the cluster.\nIn some embodiments, the similarity score can be determined in a manner that applies a threshold value to account for random transitions between items that are not significant in the determination of clusters of items.  The threshold value may\nbe a suitable percentage of the total number of transitions of the item.  When the total count of transitions between the item and another item connected to the item is less than or equal to the threshold value, then the similarity score between the item\nand the other item can be set to zero.  A similarity score of zero indicates that two items are not related and that the two items should not be included in the same cluster.\nTwo items can be assigned to a cluster based on the similarity scores between the two items.  When the similarity score between the two items is greater than or equal to a threshold value, the two items can be included in the same cluster. \nLikewise, when the similarity score between an item and a cluster is greater than or equal to the threshold value, the item can be determined to be sufficiently similar to the cluster to warrant assignment of the item in the cluster.\nWith respect to items of different type, clusters can be generated based on bi-directional agreement between clusters and internal cohesion of the clusters.  For example, assume a set of items of both a first type and a second type and the\nexistence of a first cluster.  Assume further that a first item in the set is of the first type and that the first item is representative of the first cluster.  The clustering module 108 can determine whether a second item of the second type in the set\nis to be included in the first cluster or included as part of a new cluster.  The determination can be based on the extent to which the second item interacts (e.g., co-visits) with the first item in a bi-directional manner and on the internal cohesion of\nthe first cluster.  If the second item interacts with the first item in a bi-directional manner to an extent that is greater than or equal to a threshold value, such interaction with the first item is greater than interaction with other clusters, and\ninternal cohesion of the first cluster satisfies a threshold value, then the second item can be included in the cluster of the first item.  Otherwise, the second item is not included in the cluster including the first item.  In this case, the second item\ncan be included in a new second cluster.\nThe recommender systems 104 can be provided with clusters associated with an item with which the user is interacting.  Based on the clusters, the recommender systems 104 can identify additional items of relevant information for potential\npresentation to the user.  The recommender systems 104 may select the additional items based on the transition probabilities (or similarity scores) with respect to the node associated with the item.  For example, the recommender systems 104 may select a\nthreshold number of connected items having the highest transition probabilities with respect to an item for potential provision to the user.\nFIG. 4 illustrates a first example method 400, according to an embodiment of the present disclosure.  It should be appreciated that there can be additional, fewer, or alternative steps performed in similar or alternative orders, or in parallel,\nwithin the scope of the various embodiments unless otherwise stated.\nAt block 402, the method 400 can generate session information based on information regarding items of a plurality of item types associated with interactions performed by active users of a social networking system.  At block 404, the method 400\ncan generate a graph based on the session information.  At block 406, the method 400 can assign at least a first item of the items to a cluster based on similarity between the item and the cluster.  At block 408, the method 400 can provide the cluster to\na recommender system to facilitate selection of relevant information for potential presentation to a user.  Other suitable techniques are possible.\nFIG. 5 illustrates a second example method 500, according to an embodiment of the present disclosure.  It should be appreciated that there can be additional, fewer, or alternative steps performed in similar or alternative orders, or in parallel,\nwithin the scope of the various embodiments unless otherwise stated.\nAt block 502, the method 500 can generate session information based on information regarding items of a plurality of item types associated with interactions performed by active users of a social networking system.  At block 504, the method 500\ncan limit the information regarding items of a plurality of item types by at least one of a number of the active users and a number of interactions associated with the active users.  At block 506, the method 500 can remove noise in the session\ninformation based on at least one of spending less than a first threshold amount of time for each interaction, activity for more than a second threshold amount of time for a session, and engagement in a cycle of interaction.  At block 508, the method 500\ncan generate a graph based on the session information.  At block 510, the method 500 can rebalance edges of a node of the graph to optimize memory usage in storage of the graph.  At block 512, the method 500 can determine a similarity score between a\nfirst item of the items and a representative item of a cluster and determine whether the similarity score satisfies a threshold value.  At block 514, the method 500 can assign the first item of the items to the cluster based on similarity between the\nitem and the cluster.  At block 516, the method 500 can provide the cluster to a recommender system to facilitate selection of relevant information for potential presentation to a user.  Other suitable techniques are possible.\nSocial Networking System--Example Implementation\nFIG. 6 illustrates a network diagram of an example system 600 that can be utilized in various scenarios, in accordance with an embodiment of the present disclosure.  The system 600 includes one or more user devices 610, one or more external\nsystems 620, a social networking system (or service) 630, and a network 650.  In an embodiment, the social networking service, provider, and/or system discussed in connection with the embodiments described above may be implemented as the social\nnetworking system 630.  For purposes of illustration, the embodiment of the system 600, shown by FIG. 6, includes a single external system 620 and a single user device 610.  However, in other embodiments, the system 600 may include more user devices 610\nand/or more external systems 620.  In certain embodiments, the social networking system 630 is operated by a social network provider, whereas the external systems 620 are separate from the social networking system 630 in that they may be operated by\ndifferent entities.  In various embodiments, however, the social networking system 630 and the external systems 620 operate in conjunction to provide social networking services to users (or members) of the social networking system 630.  In this sense,\nthe social networking system 630 provides a platform or backbone, which other systems, such as external systems 620, may use to provide social networking services and functionalities to users across the Internet.\nThe user device 610 comprises one or more computing devices that can receive input from a user and transmit and receive data via the network 650.  In one embodiment, the user device 610 is a conventional computer system executing, for example, a\nMicrosoft Windows compatible operating system (OS), Apple OS X, and/or a Linux distribution.  In another embodiment, the user device 610 can be a device having computer functionality, such as a smart-phone, a tablet, a personal digital assistant (PDA), a\nmobile telephone, etc. The user device 610 is configured to communicate via the network 650.  The user device 610 can execute an application, for example, a browser application that allows a user of the user device 610 to interact with the social\nnetworking system 630.  In another embodiment, the user device 610 interacts with the social networking system 630 through an application programming interface (API) provided by the native operating system of the user device 610, such as iOS and ANDROID. The user device 610 is configured to communicate with the external system 620 and the social networking system 630 via the network 650, which may comprise any combination of local area and/or wide area networks, using wired and/or wireless communication\nsystems.\nIn one embodiment, the network 650 uses standard communications technologies and protocols.  Thus, the network 650 can include links using technologies such as Ethernet, 702.11, worldwide interoperability for microwave access (WiMAX), 3G, 4G,\nCDMA, GSM, LTE, digital subscriber line (DSL), etc. Similarly, the networking protocols used on the network 650 can include multiprotocol label switching (MPLS), transmission control protocol/Internet protocol (TCP/IP), User Datagram Protocol (UDP),\nhypertext transport protocol (HTTP), simple mail transfer protocol (SMTP), file transfer protocol (FTP), and the like.  The data exchanged over the network 650 can be represented using technologies and/or formats including hypertext markup language\n(HTML) and extensible markup language (XML).  In addition, all or some links can be encrypted using conventional encryption technologies such as secure sockets layer (SSL), transport layer security (TLS), and Internet Protocol security (IPsec).\nIn one embodiment, the user device 610 may display content from the external system 620 and/or from the social networking system 630 by processing a markup language document 614 received from the external system 620 and from the social\nnetworking system 630 using a browser application 612.  The markup language document 614 identifies content and one or more instructions describing formatting or presentation of the content.  By executing the instructions included in the markup language\ndocument 614, the browser application 612 displays the identified content using the format or presentation described by the markup language document 614.  For example, the markup language document 614 includes instructions for generating and displaying a\nweb page having multiple frames that include text and/or image data retrieved from the external system 620 and the social networking system 630.  In various embodiments, the markup language document 614 comprises a data file including extensible markup\nlanguage (XML) data, extensible hypertext markup language (XHTML) data, or other markup language data.  Additionally, the markup language document 614 may include JavaScript Object Notation (JSON) data, JSON with padding (JSONP), and JavaScript data to\nfacilitate data-interchange between the external system 620 and the user device 610.  The browser application 612 on the user device 610 may use a JavaScript compiler to decode the markup language document 614.\nThe markup language document 614 may also include, or link to, applications or application frameworks such as FLASH.TM.  or Unity.TM.  applications, the SilverLight.TM.  application framework, etc.\nIn one embodiment, the user device 610 also includes one or more cookies 616 including data indicating whether a user of the user device 610 is logged into the social networking system 630, which may enable modification of the data communicated\nfrom the social networking system 630 to the user device 610.\nThe external system 620 includes one or more web servers that include one or more web pages 622a, 622b, which are communicated to the user device 610 using the network 650.  The external system 620 is separate from the social networking system\n630.  For example, the external system 620 is associated with a first domain, while the social networking system 630 is associated with a separate social networking domain.  Web pages 622a, 622b, included in the external system 620, comprise markup\nlanguage documents 614 identifying content and including instructions specifying formatting or presentation of the identified content.\nThe social networking system 630 includes one or more computing devices for a social network, including a plurality of users, and providing users of the social network with the ability to communicate and interact with other users of the social\nnetwork.  In some instances, the social network can be represented by a graph, i.e., a data structure including edges and nodes.  Other data structures can also be used to represent the social network, including but not limited to databases, objects,\nclasses, meta elements, files, or any other data structure.  The social networking system 630 may be administered, managed, or controlled by an operator.  The operator of the social networking system 630 may be a human being, an automated application, or\na series of applications for managing content, regulating policies, and collecting usage metrics within the social networking system 630.  Any type of operator may be used.\nUsers may join the social networking system 630 and then add connections to any number of other users of the social networking system 630 to whom they desire to be connected.  As used herein, the term \"friend\" refers to any other user of the\nsocial networking system 630 to whom a user has formed a connection, association, or relationship via the social networking system 630.  For example, in an embodiment, if users in the social networking system 630 are represented as nodes in the social\ngraph, the term \"friend\" can refer to an edge formed between and directly connecting two user nodes.\nConnections may be added explicitly by a user or may be automatically created by the social networking system 630 based on common characteristics of the users (e.g., users who are alumni of the same educational institution).  For example, a\nfirst user specifically selects a particular other user to be a friend.  Connections in the social networking system 630 are usually in both directions, but need not be, so the terms \"user\" and \"friend\" depend on the frame of reference.  Connections\nbetween users of the social networking system 630 are usually bilateral (\"two-way\"), or \"mutual,\" but connections may also be unilateral, or \"one-way.\" For example, if Bob and Joe are both users of the social networking system 630 and connected to each\nother, Bob and Joe are each other's connections.  If, on the other hand, Bob wishes to connect to Joe to view data communicated to the social networking system 630 by Joe, but Joe does not wish to form a mutual connection, a unilateral connection may be\nestablished.  The connection between users may be a direct connection; however, some embodiments of the social networking system 630 allow the connection to be indirect via one or more levels of connections or degrees of separation.\nIn addition to establishing and maintaining connections between users and allowing interactions between users, the social networking system 630 provides users with the ability to take actions on various types of items supported by the social\nnetworking system 630.  These items may include groups or networks (i.e., social networks of people, entities, and concepts) to which users of the social networking system 630 may belong, events or calendar entries in which a user might be interested,\ncomputer-based applications that a user may use via the social networking system 630, transactions that allow users to buy or sell items via services provided by or through the social networking system 630, and interactions with advertisements that a\nuser may perform on or off the social networking system 630.  These are just a few examples of the items upon which a user may act on the social networking system 630, and many others are possible.  A user may interact with anything that is capable of\nbeing represented in the social networking system 630 or in the external system 620, separate from the social networking system 630, or coupled to the social networking system 630 via the network 650.\nThe social networking system 630 is also capable of linking a variety of entities.  For example, the social networking system 630 enables users to interact with each other as well as external systems 620 or other entities through an API, a web\nservice, or other communication channels.  The social networking system 630 generates and maintains the \"social graph\" comprising a plurality of nodes interconnected by a plurality of edges.  Each node in the social graph may represent an entity that can\nact on another node and/or that can be acted on by another node.  The social graph may include various types of nodes.  Examples of types of nodes include users, non-person entities, content items, web pages, groups, activities, messages, concepts, and\nany other things that can be represented by an object in the social networking system 630.  An edge between two nodes in the social graph may represent a particular kind of connection, or association, between the two nodes, which may result from node\nrelationships or from an action that was performed by one of the nodes on the other node.  In some cases, the edges between nodes can be weighted.  The weight of an edge can represent an attribute associated with the edge, such as a strength of the\nconnection or association between nodes.  Different types of edges can be provided with different weights.  For example, an edge created when one user \"likes\" another user may be given one weight, while an edge created when a user befriends another user\nmay be given a different weight.\nAs an example, when a first user identifies a second user as a friend, an edge in the social graph is generated connecting a node representing the first user and a second node representing the second user.  As various nodes relate or interact\nwith each other, the social networking system 630 modifies edges connecting the various nodes to reflect the relationships and interactions.\nThe social networking system 630 also includes user-generated content, which enhances a user's interactions with the social networking system 630.  User-generated content may include anything a user can add, upload, send, or \"post\" to the social\nnetworking system 630.  For example, a user communicates posts to the social networking system 630 from a user device 610.  Posts may include data such as status updates or other textual data, location information, images such as photos, videos, links,\nmusic or other similar data and/or media.  Content may also be added to the social networking system 630 by a third party.  Content \"items\" are represented as objects in the social networking system 630.  In this way, users of the social networking\nsystem 630 are encouraged to communicate with each other by posting text and content items of various types of media through various communication channels.  Such communication increases the interaction of users with each other and increases the\nfrequency with which users interact with the social networking system 630.\nThe social networking system 630 includes a web server 632, an API request server 634, a user profile store 636, a connection store 638, an action logger 640, an activity log 642, and an authorization server 644.  In an embodiment of the\ninvention, the social networking system 630 may include additional, fewer, or different components for various applications.  Other components, such as network interfaces, security mechanisms, load balancers, failover servers, management and network\noperations consoles, and the like are not shown so as to not obscure the details of the system.\nThe user profile store 636 maintains information about user accounts, including biographic, demographic, and other types of descriptive information, such as work experience, educational history, hobbies or preferences, location, and the like\nthat has been declared by users or inferred by the social networking system 630.  This information is stored in the user profile store 636 such that each user is uniquely identified.  The social networking system 630 also stores data describing one or\nmore connections between different users in the connection store 638.  The connection information may indicate users who have similar or common work experience, group memberships, hobbies, or educational history.  Additionally, the social networking\nsystem 630 includes user-defined connections between different users, allowing users to specify their relationships with other users.  For example, user-defined connections allow users to generate relationships with other users that parallel the users'\nreal-life relationships, such as friends, co-workers, partners, and so forth.  Users may select from predefined types of connections, or define their own connection types as needed.  Connections with other nodes in the social networking system 630, such\nas non-person entities, buckets, cluster centers, images, interests, pages, external systems, concepts, and the like are also stored in the connection store 638.\nThe social networking system 630 maintains data about objects with which a user may interact.  To maintain this data, the user profile store 636 and the connection store 638 store instances of the corresponding type of objects maintained by the\nsocial networking system 630.  Each object type has information fields that are suitable for storing information appropriate to the type of object.  For example, the user profile store 636 contains data structures with fields suitable for describing a\nuser's account and information related to a user's account.  When a new object of a particular type is created, the social networking system 630 initializes a new data structure of the corresponding type, assigns a unique object identifier to it, and\nbegins to add data to the object as needed.  This might occur, for example, when a user becomes a user of the social networking system 630, the social networking system 630 generates a new instance of a user profile in the user profile store 636, assigns\na unique identifier to the user account, and begins to populate the fields of the user account with information provided by the user.\nThe connection store 638 includes data structures suitable for describing a user's connections to other users, connections to external systems 620 or connections to other entities.  The connection store 638 may also associate a connection type\nwith a user's connections, which may be used in conjunction with the user's privacy setting to regulate access to information about the user.  In an embodiment of the invention, the user profile store 636 and the connection store 638 may be implemented\nas a federated database.\nData stored in the connection store 638, the user profile store 636, and the activity log 642 enables the social networking system 630 to generate the social graph that uses nodes to identify various objects and edges connecting nodes to\nidentify relationships between different objects.  For example, if a first user establishes a connection with a second user in the social networking system 630, user accounts of the first user and the second user from the user profile store 636 may act\nas nodes in the social graph.  The connection between the first user and the second user stored by the connection store 638 is an edge between the nodes associated with the first user and the second user.  Continuing this example, the second user may\nthen send the first user a message within the social networking system 630.  The action of sending the message, which may be stored, is another edge between the two nodes in the social graph representing the first user and the second user.  Additionally,\nthe message itself may be identified and included in the social graph as another node connected to the nodes representing the first user and the second user.\nIn another example, a first user may tag a second user in an image that is maintained by the social networking system 630 (or, alternatively, in an image maintained by another system outside of the social networking system 630).  The image may\nitself be represented as a node in the social networking system 630.  This tagging action may create edges between the first user and the second user as well as create an edge between each of the users and the image, which is also a node in the social\ngraph.  In yet another example, if a user confirms attending an event, the user and the event are nodes obtained from the user profile store 636, where the attendance of the event is an edge between the nodes that may be retrieved from the activity log\n642.  By generating and maintaining the social graph, the social networking system 630 includes data describing many different types of objects and the interactions and connections among those objects, providing a rich source of socially relevant\ninformation.\nThe web server 632 links the social networking system 630 to one or more user devices 610 and/or one or more external systems 620 via the network 650.  The web server 632 serves web pages, as well as other web-related content, such as Java,\nJavaScript, Flash, XML, and so forth.  The web server 632 may include a mail server or other messaging functionality for receiving and routing messages between the social networking system 630 and one or more user devices 610.  The messages can be\ninstant messages, queued messages (e.g., email), text and SMS messages, or any other suitable messaging format.\nThe API request server 634 allows one or more external systems 620 and user devices 610 to call access information from the social networking system 630 by calling one or more API functions.  The API request server 634 may also allow external\nsystems 620 to send information to the social networking system 630 by calling APIs.  The external system 620, in one embodiment, sends an API request to the social networking system 630 via the network 650, and the API request server 634 receives the\nAPI request.  The API request server 634 processes the request by calling an API associated with the API request to generate an appropriate response, which the API request server 634 communicates to the external system 620 via the network 650.  For\nexample, responsive to an API request, the API request server 634 collects data associated with a user, such as the user's connections that have logged into the external system 620, and communicates the collected data to the external system 620.  In\nanother embodiment, the user device 610 communicates with the social networking system 630 via APIs in the same manner as external systems 620.\nThe action logger 640 is capable of receiving communications from the web server 632 about user actions on and/or off the social networking system 630.  The action logger 640 populates the activity log 642 with information about user actions,\nenabling the social networking system 630 to discover various actions taken by its users within the social networking system 630 and outside of the social networking system 630.  Any action that a particular user takes with respect to another node on the\nsocial networking system 630 may be associated with each user's account, through information maintained in the activity log 642 or in a similar database or other data repository.  Examples of actions taken by a user within the social networking system\n630 that are identified and stored may include, for example, adding a connection to another user, sending a message to another user, reading a message from another user, viewing content associated with another user, attending an event posted by another\nuser, posting an image, attempting to post an image, or other actions interacting with another user or another object.  When a user takes an action within the social networking system 630, the action is recorded in the activity log 642.  In one\nembodiment, the social networking system 630 maintains the activity log 642 as a database of entries.  When an action is taken within the social networking system 630, an entry for the action is added to the activity log 642.  The activity log 642 may be\nreferred to as an action log.\nAdditionally, user actions may be associated with concepts and actions that occur within an entity outside of the social networking system 630, such as an external system 620 that is separate from the social networking system 630.  For example,\nthe action logger 640 may receive data describing a user's interaction with an external system 620 from the web server 632.  In this example, the external system 620 reports a user's interaction according to structured actions and objects in the social\ngraph.\nOther examples of actions where a user interacts with an external system 620 include a user expressing an interest in an external system 620 or another entity, a user posting a comment to the social networking system 630 that discusses an\nexternal system 620 or a web page 622a within the external system 620, a user posting to the social networking system 630 a Uniform Resource Locator (URL) or other identifier associated with an external system 620, a user attending an event associated\nwith an external system 620, or any other action by a user that is related to an external system 620.  Thus, the activity log 642 may include actions describing interactions between a user of the social networking system 630 and an external system 620\nthat is separate from the social networking system 630.\nThe authorization server 644 enforces one or more privacy settings of the users of the social networking system 630.  A privacy setting of a user determines how particular information associated with a user can be shared.  The privacy setting\ncomprises the specification of particular information associated with a user and the specification of the entity or entities with whom the information can be shared.  Examples of entities with which information can be shared may include other users,\napplications, external systems 620, or any entity that can potentially access the information.  The information that can be shared by a user comprises user account information, such as profile photos, phone numbers associated with the user, user's\nconnections, actions taken by the user such as adding a connection, changing user profile information, and the like.\nThe privacy setting specification may be provided at different levels of granularity.  For example, the privacy setting may identify specific information to be shared with other users; the privacy setting identifies a work phone number or a\nspecific set of related information, such as, personal information including profile photo, home phone number, and status.  Alternatively, the privacy setting may apply to all the information associated with the user.  The specification of the set of\nentities that can access particular information can also be specified at various levels of granularity.  Various sets of entities with which information can be shared may include, for example, all friends of the user, all friends of friends, all\napplications, or all external systems 620.  One embodiment allows the specification of the set of entities to comprise an enumeration of entities.  For example, the user may provide a list of external systems 620 that are allowed to access certain\ninformation.  Another embodiment allows the specification to comprise a set of entities along with exceptions that are not allowed to access the information.  For example, a user may allow all external systems 620 to access the user's work information,\nbut specify a list of external systems 620 that are not allowed to access the work information.  Certain embodiments call the list of exceptions that are not allowed to access certain information a \"block list\".  External systems 620 belonging to a block\nlist specified by a user are blocked from accessing the information specified in the privacy setting.  Various combinations of granularity of specification of information, and granularity of specification of entities, with which information is shared are\npossible.  For example, all personal information may be shared with friends whereas all work information may be shared with friends of friends.\nThe authorization server 644 contains logic to determine if certain information associated with a user can be accessed by a user's friends, external systems 620, and/or other applications and entities.  The external system 620 may need\nauthorization from the authorization server 644 to access the user's more private and sensitive information, such as the user's work phone number.  Based on the user's privacy settings, the authorization server 644 determines if another user, the\nexternal system 620, an application, or another entity is allowed to access information associated with the user, including information about actions taken by the user.\nIn some embodiments, the social networking system 630 can include a clustering module 646.  The clustering module 646 can be implemented with the clustering module 102.\nHardware Implementation\nThe foregoing processes and features can be implemented by a wide variety of machine and computer system architectures and in a wide variety of network and computing environments, FIG. 7 illustrates an example of a computer system 700 that may\nbe used to implement one or more of the embodiments described herein in accordance with an embodiment of the invention.  The computer system 700 includes sets of instructions for causing the computer system 700 to perform the processes and features\ndiscussed herein.  The computer system 700 may be connected (e.g., networked) to other machines.  In a networked deployment, the computer system 700 may operate in the capacity of a server machine or a client machine in a client-server network\nenvironment, or as a peer machine in a peer-to-peer (or distributed) network environment.  In an embodiment of the invention, the computer system 700 may be the social networking system 630, the user device 610, and the external system 620 or a component\nthereof.  In an embodiment of the invention, the computer system 700 may be one server among many that constitutes all or part of the social networking system 630.\nThe computer system 700 includes a processor 702, a cache 704, and one or more executable modules and drivers, stored on a computer-readable medium, directed to the processes and features described herein.  Additionally, the computer system 700\nincludes a high performance input/output (I/O) bus 706 and a standard I/O bus 708.  A host bridge 710 couples processor 702 to high performance I/O bus 706, whereas I/O bus bridge 712 couples the two buses 706 and 708 to each other.  A system memory 714\nand one or more network interfaces 716 couple to high performance I/O bus 706.  The computer system 700 may further include video memory and a display device coupled to the video memory (not shown).  Mass storage 718 and I/O ports 720 couple to the\nstandard I/O bus 708.  The computer system 700 may optionally include a keyboard and pointing device, a display device, or other input/output devices (not shown) coupled to the standard I/O bus 708.  Collectively, these elements are intended to represent\na broad category of computer hardware systems, including but not limited to computer systems based on the x86-compatible processors manufactured by Intel Corporation of Santa Clara, Calif., and the x86-compatible processors manufactured by Advanced Micro\nDevices (AMD), Inc., of Sunnyvale, Calif., as well as any other suitable processor.\nAn operating system manages and controls the operation of the computer system 700, including the input and output of data to and from software applications (not shown).  The operating system provides an interface between the software\napplications being executed on the system and the hardware components of the system.  Any suitable operating system may be used, such as the LINUX Operating System, the Apple Macintosh Operating System, available from Apple Computer Inc.  of Cupertino,\nCalif., UNIX operating systems, Microsoft.RTM.  Windows.RTM.  operating systems, BSD operating systems, and the like.  Other implementations are possible.\nThe elements of the computer system 700 are described in greater detail below.  In particular, the network interface 716 provides communication between the computer system 700 and any of a wide range of networks, such as an Ethernet (e.g., IEEE\n802.3) network, a backplane, etc. The mass storage 718 provides permanent storage for the data and programming instructions to perform the above-described processes and features implemented by the respective computing systems identified above, whereas\nthe system memory 714 (e.g., DRAM) provides temporary storage for the data and programming instructions when executed by the processor 702.  The I/O ports 720 may be one or more serial and/or parallel communication ports that provide communication\nbetween additional peripheral devices, which may be coupled to the computer system 700.\nThe computer system 700 may include a variety of system architectures, and various components of the computer system 700 may be rearranged.  For example, the cache 704 may be on-chip with processor 702.  Alternatively, the cache 704 and the\nprocessor 702 may be packed together as a \"processor module\", with processor 702 being referred to as the \"processor core\".  Furthermore, certain embodiments of the invention may neither require nor include all of the above components.  For example,\nperipheral devices coupled to the standard I/O bus 708 may couple to the high performance I/O bus 706.  In addition, in some embodiments, only a single bus may exist, with the components of the computer system 700 being coupled to the single bus. \nMoreover, the computer system 700 may include additional components, such as additional processors, storage devices, or memories.\nIn general, the processes and features described herein may be implemented as part of an operating system or a specific application, component, program, object, module, or series of instructions referred to as \"programs\".  For example, one or\nmore programs may be used to execute specific processes described herein.  The programs typically comprise one or more instructions in various memory and storage devices in the computer system 700 that, when read and executed by one or more processors,\ncause the computer system 700 to perform operations to execute the processes and features described herein.  The processes and features described herein may be implemented in software, firmware, hardware (e.g., an application specific integrated\ncircuit), or any combination thereof.\nIn one implementation, the processes and features described herein are implemented as a series of executable modules run by the computer system 700, individually or collectively in a distributed computing environment.  The foregoing modules may\nbe realized by hardware, executable modules stored on a computer-readable medium (or machine-readable medium), or a combination of both.  For example, the modules may comprise a plurality or series of instructions to be executed by a processor in a\nhardware system, such as the processor 702.  Initially, the series of instructions may be stored on a storage device, such as the mass storage 718.  However, the series of instructions can be stored on any suitable computer readable storage medium. \nFurthermore, the series of instructions need not be stored locally, and could be received from a remote storage device, such as a server on a network, via the network interface 716.  The instructions are copied from the storage device, such as the mass\nstorage 718, into the system memory 714 and then accessed and executed by the processor 702.  In various implementations, a module or modules can be executed by a processor or multiple processors in one or multiple locations, such as multiple servers in\na parallel processing environment.\nExamples of computer-readable media include, but are not limited to, recordable type media such as volatile and non-volatile memory devices; solid state memories; floppy and other removable disks; hard disk drives; magnetic media; optical disks\n(e.g., Compact Disk Read-Only Memory (CD ROMS), Digital Versatile Disks (DVDs)); other similar non-transitory (or transitory), tangible (or non-tangible) storage medium; or any type of medium suitable for storing, encoding, or carrying a series of\ninstructions for execution by the computer system 700 to perform any one or more of the processes and features described herein.\nFor purposes of explanation, numerous specific details are set forth in order to provide a thorough understanding of the description.  It will be apparent, however, to one skilled in the art that embodiments of the disclosure can be practiced\nwithout these specific details.  In some instances, modules, structures, processes, features, and devices are shown in block diagram form in order to avoid obscuring the description.  In other instances, functional block diagrams and flow diagrams are\nshown to represent data and logic flows.  The components of block diagrams and flow diagrams (e.g., modules, blocks, structures, devices, features, etc.) may be variously combined, separated, removed, reordered, and replaced in a manner other than as\nexpressly described and depicted herein.\nReference in this specification to \"one embodiment\", \"an embodiment\", \"other embodiments\", \"one series of embodiments\", \"some embodiments\", \"various embodiments\", or the like means that a particular feature, design, structure, or characteristic\ndescribed in connection with the embodiment is included in at least one embodiment of the disclosure.  The appearances of, for example, the phrase \"in one embodiment\" or \"in an embodiment\" in various places in the specification are not necessarily all\nreferring to the same embodiment, nor are separate or alternative embodiments mutually exclusive of other embodiments.  Moreover, whether or not there is express reference to an \"embodiment\" or the like, various features are described, which may be\nvariously combined and included in some embodiments, but also variously omitted in other embodiments.  Similarly, various features are described that may be preferences or requirements for some embodiments, but not other embodiments.\nThe language used herein has been principally selected for readability and instructional purposes, and it may not have been selected to delineate or circumscribe the inventive subject matter.  It is therefore intended that the scope of the\ninvention be limited not by this detailed description, but rather by any claims that issue on an application based hereon.  Accordingly, the disclosure of the embodiments of the invention is intended to be illustrative, but not limiting, of the scope of\nthe invention, which is set forth in the following claims.", "application_number": "14585590", "abstract": " Systems, methods, and non-transitory computer readable media configured\n     to generate session information based on information regarding items of a\n     plurality of item types associated with interactions performed by active\n     users of a social networking system. A graph is generated based on the\n     session information. At least a first item of the items is assigned to a\n     cluster based on similarity between the item and the cluster. The cluster\n     is provided to a recommender system to facilitate selection of relevant\n     information for potential presentation to a user.\n", "citations": ["6247154", "6502091", "7653605", "7673340", "7693903", "8386495", "8515975", "8606787", "8626835", "8689108", "8751520", "8898150", "9026537", "9122758", "9165255", "9176639", "9286391", "9344390", "9361446", "9424668", "9672291", "9760609", "20030182612", "20050125276", "20050134587", "20050283487", "20060074870", "20060088095", "20060224898", "20070100623", "20070220037", "20070282785", "20080059521", "20080075280", "20080140643", "20080215416", "20080275902", "20090228296", "20100095215", "20100211588", "20100268830", "20100281029", "20110040768", "20110145093", "20110145226", "20110249572", "20110307321", "20110313844", "20120066243", "20120079020", "20120254080", "20120260205", "20120271860", "20130073979", "20130117261", "20130198203", "20140067439", "20140188992", "20140189525", "20140214936", "20140258187", "20140278896", "20140279618", "20140280143", "20150052135", "20150081656", "20150081725", "20150088911", "20150089424", "20150095185", "20150120432", "20150169758", "20150172854", "20150179166", "20150212922", "20150220530", "20150234939", "20150347543", "20160063506", "20160071162", "20160078148", "20160164982", "20160179835", "20160188713", "20160188725", "20170091537", "20170359584", "20180293607"], "related": []}, {"id": "20160217173", "patent_code": "10289712", "patent_name": "Method, system, and graphical user interface for alerting a computer user\n     to new results for a prior search", "year": "2019", "inventor_and_country_data": " Inventors: \nJeh; Glen M. (San Francisco, CA), Wong; Beverly Yang (San Francisco, CA)  ", "description": "<BR><BR>TECHNICAL FIELD\nThe disclosed embodiments relate generally to search engines.  More particularly, the disclosed embodiments relate to methods, systems, and user interfaces for alerting a computer user to new results for a prior search.\n<BR><BR>BACKGROUND\nSearch engines typically provide a source of indexed documents from the Internet (or an intranet) that can be rapidly scanned in response to a search query submitted by a user.  As the number of documents accessible via the Internet grows, the\nnumber of documents that match a particular query may also increase.  However, not every document matching the query is likely to be equally important from a user's perspective.  A user may be overwhelmed by an enormous number of documents returned by a\nsearch engine, unless the documents are ordered based on their relevance to the user's query.  One way to order documents is the PageRank algorithm more fully described in the article \"The Anatomy of a Large-Scale Hypertextual Search Engine\" by S. Brin\nand L. Page, 7.sup.th International World Wide Web Conference, Brisbane, Australia and U.S.  Pat.  No. 6,285,999, both of which are hereby incorporated by reference as background information.\nSome queries by a computer user may concern continuing interests of the user.  Some search engines, such as Google's Web Alerts, allow the user to explicitly specify such queries and receive alerts when a new web page in the top-ten search\nresults appears for the query.  However, it is too inconvenient for most users to explicitly register such queries.  Google is a trademark of Google Inc.  For example, in an internal study of 18 Google Search History users, out of 154 past queries that\nthe users expressed a medium to strong interest in seeing further results, none of these queries was actually registered as a web alert.  In addition, alerting the user to all changes to the search results for the query may cause too many uninteresting\nresults to be shown to the user, due to minor changes in the web or spurious changes in the ranking algorithm.\nThus, it would be highly desirable to find ways to automatically identify queries in a user's search history that concern continuing interests of the user.  In addition, it would be highly desirable to find ways to automatically identify\nuser-relevant results to prior searches by the user that have not been shown to the user and to alert the user to such results.\n<BR><BR>SUMMARY\nThe present invention overcomes the problems described above.\nOne aspect of the invention involves a computer-implemented method in which a search engine accesses Internet usage data for a computer user, wherein the usage data include a plurality of search queries by the user; using at least some of the\nInternet usage data, identifies search queries in the plurality of search queries that meet predefined query selection criteria for queries that correspond to continuing interests of the user; reruns at least some of the identified search queries;\nevaluates search results from the rerun queries to select search results that meet predefined search result selection criteria; and sends links corresponding to at least some of the selected search results to a computer associated with the user for\ndisplay.\nAnother aspect of the invention involves a computer-implemented method in which a search engine accesses Internet usage data for a computer user, wherein the usage data include a plurality of search queries by the user; using at least some of\nthe Internet usage data, identifies search queries in the plurality of search queries that meet predefined query selection criteria for queries that correspond to continuing interests of the user; and reruns at least some of the identified search\nqueries.\nAnother aspect of the invention involves a computer-implemented method in which a search engine produces search results by rerunning a plurality of search queries that have been performed previously for a computer user; evaluates the produced\nsearch results to select search results that meet predefined search result selection criteria, wherein at least one of the criteria is based on Internet usage data for the user; and sends links corresponding to at least some of the selected search\nresults to a computer associated with the user for display.\nAnother aspect of the invention involves a graphical user interface on a computer that includes a plurality of links recommended by a search engine for a computer user.  The plurality of links are determined by the search engine by: producing\nsearch results by rerunning a plurality of search queries that have been performed previously for the computer user; and evaluating the produced search results to select search results that meet predefined search result selection criteria, wherein at\nleast one of the criteria is based on Internet usage data for the user.\nAnother aspect of the invention involves a computer-implemented method in which a client computer sends Internet usage data for a computer user to a server computer, wherein the usage data include a plurality of search queries by the user.  The\nserver computer, using at least some of the Internet usage data, identifies search queries in the plurality of search queries that meet predefined query selection criteria for queries that correspond to continuing interests of the user; reruns at least\nsome of the identified search queries; and evaluates search results from the rerun queries to select search results that meet predefined search result selection criteria.  The client computer receives links corresponding to at least some of the selected\nsearch results from the server computer and displays at least some of the received links.\nAnother aspect of the invention involves a system that includes at least one server.  The at least one server is configured to access Internet usage data for a computer user, wherein the usage data include a plurality of search queries by the\nuser; using at least some of the Internet usage data, identify search queries in the plurality of search queries that meet predefined query selection criteria for queries that correspond to continuing interests of the user; and rerun at least some of the\nidentified search queries.\nAnother aspect of the invention involves a client computer that is configured to send Internet usage data for a computer user to a server computer, wherein the usage data include a plurality of search queries by the user.  The server computer,\nusing at least some of the Internet usage data, identifies search queries in the plurality of search queries that meet predefined query selection criteria for queries that correspond to continuing interests of the user; reruns at least some of the\nidentified search queries; and evaluates search results from the rerun queries to select search results that meet predefined search result selection criteria.  The client computer is configured to receive links corresponding to at least some of the\nselected search results from the server computer and display at least some of the received links.\nAnother aspect of the invention involves a computer-program product that includes a computer readable storage medium and a computer program mechanism embedded therein.  The computer program mechanism includes instructions, which when executed by\na server computer, cause the server computer to access Internet usage data for a computer user, wherein the usage data include a plurality of search queries by the user; using at least some of the Internet usage data, identify search queries in the\nplurality of search queries that meet predefined query selection criteria for queries that correspond to continuing interests of the user; and rerun at least some of the identified search queries.\nAnother aspect of the invention involves a computer-program product that includes a computer readable storage medium and a computer program mechanism embedded therein.  The computer program mechanism includes instructions, which when executed by\na client computer, cause the client computer to send Internet usage data for a computer user to a server computer, wherein the usage data include a plurality of search queries by the user.  The server computer, using at least some of the Internet usage\ndata, identifies search queries in the plurality of search queries that meet predefined query selection criteria for queries that correspond to continuing interests of the user; reruns at least some of the identified search queries; and evaluates search\nresults from the rerun queries to select search results that meet predefined search result selection criteria.  The computer program mechanism also includes instructions, which when executed by the client computer, cause the client computer to receive\nlinks corresponding to at least some of the selected search results from the server computer and display at least some of the received links.\nAnother aspect of the invention involves a server computer with means for accessing Internet usage data for a computer user, wherein the usage data include a plurality of search queries by the user; using at least some of the Internet usage\ndata, means for identifying search queries in the plurality of search queries that meet predefined query selection criteria for queries that correspond to continuing interests of the user; and means for rerunning at least some of the identified search\nqueries.\nAnother aspect of the invention involves a client computer with means for sending Internet usage data for a computer user to a server computer, wherein the usage data include a plurality of search queries by the user.  The server computer, using\nat least some of the Internet usage data, identifies search queries in the plurality of search queries that meet predefined query selection criteria for queries that correspond to continuing interests of the user; reruns at least some of the identified\nsearch queries; and evaluates search results from the rerun queries to select search results that meet predefined search result selection criteria.  The client computer also has means for receiving links corresponding to at least some of the selected\nsearch results from the server computer and means for displaying at least some of the received links.\nAnother aspect of the invention involves a system that includes at least one server.  The at least one server is configured to produce search results by rerunning a plurality of search queries that have been performed previously for a computer\nuser; evaluate the produced search results to select search results that meet predefined search result selection criteria, wherein at least one of the criteria is based on Internet usage data for the user; and send links corresponding to at least some of\nthe selected search results to a computer associated with the user for display.\nAnother aspect of the invention involves a computer-program product that includes a computer readable storage medium and a computer program mechanism embedded therein.  The computer program mechanism includes instructions, which when executed by\na server computer, cause the server computer to produce search results by rerunning a plurality of search queries that have been performed previously for a computer user; evaluate the produced search results to select search results that meet predefined\nsearch result selection criteria, wherein at least one of the criteria is based on Internet usage data for the user; and send links corresponding to at least some of the selected search results to a computer associated with the user for display.\nAnother aspect of the invention involves a server computer with means for producing search results by rerunning a plurality of search queries that have been performed previously for a computer user; means for evaluating the produced search\nresults to select search results that meet predefined search result selection criteria, wherein at least one of the criteria is based on Internet usage data for the user; and means for sending links corresponding to at least some of the selected search\nresults to a computer associated with the user for display.\nThus, the present invention provides improved methods, systems and user interfaces for alerting a computer user to new results for a prior search. <BR><BR>BRIEF DESCRIPTION OF THE DRAWINGS\nFor a better understanding of the aforementioned aspects of the invention as well as additional aspects and embodiments thereof, reference should be made to the Description of Embodiments below, in conjunction with the following drawings in\nwhich like reference numerals refer to corresponding parts throughout the figures.\nFIG. 1 is a block diagram illustrating an exemplary distributed computer system in accordance with one embodiment of the invention.\nFIG. 2 is a block diagram illustrating a search engine in accordance with one embodiment of the invention.\nFIG. 3 is a block diagram illustrating a client in accordance with one embodiment of the invention.\nFIG. 4 is an exemplary user record in the user information database in accordance with one embodiment of the invention.\nFIG. 5 is a flowchart representing a method of automatically identifying continuing interests of a computer user in accordance with one embodiment of the invention.\nFIG. 6 is a flowchart representing a method of alerting a computer user to new results for a prior search in accordance with one embodiment of the invention.\nFIG. 7 is a schematic screen shot of an exemplary graphical user interface for alerting a computer user to new results for a prior search in accordance with one embodiment of the invention.\nFIG. 8 is a flowchart representing a method of automatically identifying continuing interests of a computer user and alerting the user to new results for a prior search in accordance with one embodiment of the invention.\n<BR><BR>DESCRIPTION OF EMBODIMENTS\nMethods, systems, user interfaces, and other aspects of the invention are described.  Reference will be made to certain embodiments of the invention, examples of which are illustrated in the accompanying drawings.  While the invention will be\ndescribed in conjunction with the embodiments, it will be understood that it is not intended to limit the invention to these particular embodiments alone.  On the contrary, the invention is intended to cover alternatives, modifications and equivalents\nthat are within the spirit and scope of the invention as defined by the appended claims.\nMoreover, in the following description, numerous specific details are set forth to provide a thorough understanding of the present invention.  However, it will be apparent to one of ordinary skill in the art that the invention may be practiced\nwithout these particular details.  In other instances, methods, procedures, components, and networks that are well known to those of ordinary skill in the art are not described in detail to avoid obscuring aspects of the present invention.\nFIG. 1 is a block diagram illustrating an exemplary distributed computer system 100 according to one embodiment of the invention.  FIG. 1 shows various functional components that will be referred to in the detailed discussion that follows.  The\nsystem 100 may include one or more client computers 102.  Client computers 102 can be any of a number of computing devices (e.g., Internet kiosk, personal digital assistant, cell phone, gaming device, desktop computer, laptop computer, handheld computer,\nor combinations thereof) used to enable the activities described below.  Client 102 includes graphical user interface (GUI) 111.  Clients 102 are connected to a communications network 106.  The communications network 106 connects the clients 102 to a\nsearch engine system 112.  Search engine 112 includes a query server 114 connected to the communications network 106, a user information database 116, a query processing controller 118, and optionally other databases 117.\nSearch engine 112 generates search results in response to search queries from one or more clients 102 and also provides alerts to new results for some prior searches.  It should be appreciated that the layout of the search engine system 112 is\nmerely exemplary and may take on any other suitable layout or configuration.  The search engine system 112 is used to search an index of documents, such as billions of web pages or other documents indexed by modern search engines.\nNote that the search engine system 112 can be used as an Internet search engine, for locating documents on the WWW and/or as an intranet search engine, for locating documents stored on servers or other hosts within an intranet.  In addition, the\nmethodology described herein is applicable to implementations where only portions of documents, such as titles and abstracts, are stored in a database (e.g., 132) of the search engine system 112.\nThe search engine system 112 may include multiple data centers, each housing a backend.  The data centers are generally widely dispersed from one another, such as across the continental United States.  Search queries submitted by users at one of\nthe clients 102 to the search engine system 112 are routed to an appropriate backend as part of the Domain Name System (DNS), based on current load, geographic locality and/or whether that data center is operating.\nEach backend preferably includes multiple query servers, such as query server 114, coupled to a communications network 106 via a network communication module 120.  The communications network 106 may be the Internet, but may also be any local\narea network (LAN) and/or wide area network (WAN).  In some embodiments, each query server 114 is a Web server that receives search query requests and delivers search results and alerts to new results for some prior searches in the form of web pages or\nfeeds via HTTP, XML, RSS or similar protocols.  Alternatively, if the query server 114 is used within an intranet, it may be an intranet server.  In essence, the query servers, such as query server 114, are configured to control the search and alert\nprocesses, including searching a document index, analyzing and formatting the search results.\nThe query server 114 typically includes a network communications module 120, a query receipt, processing and response module 122, a user information processing module 124, and a history module 128, all interconnected.  The network communications\nmodule 120 connects the query server 114 to the communication network 106 and enables the receipt of communications from the communication network 106 and the provision of communications to the communication network 106 bound for the client 102 or other\ndestinations.  The query receipt, processing and response module 122 is primarily responsible for receiving search queries, processing them and returning responses and alerts to the client 102 via the network communications module 120.  In some\nembodiments, the history module 128 maintains a record of queries submitted by users.  In some embodiments, the history module maintains a record of search results sent to the users, independent of whether the users selected the results for viewing or\ndownloading.  In some embodiments, the history module also maintains a record of search results selected by the users for viewing or downloading, sometimes called click through information.  The click through information may include statistical\ninformation, including the number of times that each search result was clicked through and/or the number of times each search result was viewed by users for more than a threshold period of time (i.e., the number of times the users clicked through each\nsearch result without navigating away from the resulting page or document in less than the threshold period of time).\nThe user information processing module 124 assists in accessing, updating and modifying the user information database 116.  The user information database 116 stores various information about the user's activities in a user record (described\nbelow).  In addition, the user information database 116 may store derived information about the user based on the user's activities.  In some embodiments, the user information database 116 stores user profiles, a portion of which are the derived\ninformation.  The other databases 117 optionally include other databases with which the various modules in query server 114 may interact, such as a message database (electronic or otherwise), and user-created document databases (e.g., documents created\nfrom word processing programs, spreadsheet programs, or other various applications).\nThe query processing controller 118 is connected to an inverse document index 130, a document database 132 and a query cache 134.  The cache 134 is used to temporarily store search queries and search results, and is used to serve search results\nfor queries submitted multiple times (e.g., by multiple users).  The inverse document index 130 and document database 132 are sometimes collectively called the document database.  In some embodiments, \"searching the document database\" means searching the\ninverse document index 130 to identify documents matching a specified search query or term.\nSearch rank values for the documents in the search results are conveyed to the query processing controller 118 and/or the query server 114, and are used to construct various lists, such as a list of ordered search results, a personalized list of\nrecommended web pages, or a list of new results for one or more prior searches by a user.  Once the query processing controller 118 constructs the list, the query processing controller 118 may transmit to the document database 132 a request for snippets\nof an appropriate subset of the documents in the list.  For example, the query processing controller 118 may request snippets for the first fifteen or so of the documents in the list.  In some embodiments, the document database 132 constructs snippets\nbased on the search query, and returns the snippets to the query processing controller 118.  The query processing controller 118 then returns a list of located documents with their associated links (i.e., hyperlinks) and snippets back to the query server\n114.  In some embodiments, the snippets are stored in the cache server 134 along with the search results.  As a result, in these embodiments the query processing controller 118 may only request snippets for documents, if any, for which it is unable to\nobtain valid cached snippets from the cache server 134.\nIn some embodiments, fewer and/or additional modules, functions or databases are included in the search engine 112.  The modules shown in FIG. 1 as being part of search engine 112 represent functions performed in an exemplary embodiment.\nAlthough FIG. 1 portrays discrete blocks, the figure is intended more as a functional description of some embodiments of the invention rather than a structural description of the functional elements.  One of ordinary skill in the art will\nrecognize that an actual implementation might have the functional elements grouped or split among various components.  For example, the user information database 116 may be part of the query server 114.  In some embodiments the user information database\n116 may be implemented using one or more servers whose primary function is to store and process user information.  Similarly, the document database 132 may be implemented on one or more servers whose primary purpose is to store various documents. \nMoreover, one or more of the blocks in FIG. 1 may be implemented on one or more servers designed to provide the described functionality.  Although the description herein refers to certain features implemented in the client 102 and certain features\nimplemented in the search system 112, the embodiments of the invention are not limited to such distinctions.  For example, features described herein as being part of the search system 112 could be implemented in whole or in part in the client 102, and\nvice versa.\nFIG. 2 is a block diagram illustrating search engine 112 in accordance with one embodiment of the present invention.  Search engine 112 typically includes one or more processing units (CPU's) 202, one or more network or other communications\ninterfaces 204, memory 206, and one or more communication buses 208 for interconnecting these components.  The communication buses 208 may include circuitry (sometimes called a chipset) that interconnects and controls communications between system\ncomponents.  Search engine 112 optionally may include a user interface 210 comprising a display device 212 and a keyboard 214.  Memory 206 may include high speed random access memory and may also include non-volatile memory, such as one or more magnetic\nor optical disk storage devices.  Memory 206 may optionally include one or more storage devices remotely located from the CPU(s) 202.  In some embodiments, the memory 206 stores the following programs, modules and data structures, or a subset or superset\nthereof: an operating system 216 that includes procedures for handling various basic system services and for performing hardware dependent tasks; a network communication module (or instructions) 120 that is used for connecting search engine 112 to other\ncomputers (e.g., clients 102 and web sites 108) via one or more communication network interfaces 204 (wired or wireless) and one or more communication networks, such as the Internet, other wide area networks, local area networks, metropolitan area\nnetworks, and so on; a query server 114 for responding to and processing communications from the client 102 and for alerting a computer user to new results for one or more prior searches; a user information database 116 for storing information about\nusers as described in reference to FIG. 4; other databases 117 that the various modules in query server 114 may interact with, such as a message database (electronic or otherwise), and user-created document databases (e.g., documents created from word\nprocessing programs, spreadsheet programs, or other various applications); a query processing controller 118 for receiving requests from one of the query servers, such as the query server 114, and transmitting the requests to the cache 134, the inverse\ndocument index 130 and the document database 132; an inverse document index 130 for storing a set of words contained in document database 132 and, for each word, pointers to documents in document database 132 that contain the word; a document database\n132 for storing documents or portions of documents such as web pages; and a cache server 134 for increasing search efficiency by temporarily storing previously submitted search queries and corresponding search results.\nIn some embodiments, the query server 114 includes the following elements, or a subset of such elements: a query receipt, processing and response module 122 for receiving and responding to search queries, for providing alerts to new results for\none or more prior searches, and for managing the processing of search queries by one or more query processing controllers, such as query processing controller 118, that are coupled to the query server 114; a user information and processing module 124 for\naccessing and modifying the user information database 116, which includes one or more user records 400 (described in more detail in FIG. 4 below); and a history module 128 for processing and handling requests for searching a user's online history (e.g.,\nthe user's prior queries, sent URLs, query result click throughs and visited URLs).  In some embodiments, the query server 114 and/or the user information database 116 include additional modules.\nFIG. 3 is a block diagram illustrating client 102 in accordance with one embodiment of the invention.  Client 102 typically includes one or more processing units (CPUs) 302, one or more network or other communications interfaces 304, memory 306,\nand one or more communication buses 308 for interconnecting these components.  The communication buses 308 may include circuitry (sometimes called a chipset) that interconnects and controls communications between system components.  The client system 102\nmay include a user interface 310, for instance a display 312 with GUI 111 and a keyboard 314.  Memory 306 may include high speed random access memory and may also include non-volatile memory, such as one or more magnetic or optical storage disks.  Memory\n306 may include mass storage that is remotely located from CPUs 302.  Memory 306 may store the following elements, or a subset or superset of such elements: an operating system 316 that includes procedures for handling various basic system services and\nfor performing hardware dependent tasks; a network communication module (or instructions) 318 that is used for connecting the client system 102 to other computers via the one or more communications interfaces 304 (wired or wireless) and one or more\ncommunication networks, such as the Internet, other wide area networks, local area networks, metropolitan area networks, and so on; a client application 320 such as a browser application; a client assistant 322 (e.g., a toolbar, iframe (inline frame), or\nbrowser plug-in), which includes a monitoring module 324 for monitoring the activities of a user, and a transmission module 326 for transmitting information about the user's activities to and receiving information from the search system 112; and client\nstorage 328 for storing data and documents, including web pages or feeds with search results received in response to a search query and alerts to new results for one or more prior searches.\nEach of the above identified modules and applications in FIGS. 2-3 correspond to a set of instructions for performing a function described above.  These modules (i.e., sets of instructions) need not be implemented as separate software programs,\nprocedures or modules, and thus various subsets of these modules may be combined or otherwise re-arranged in various embodiments.  In some embodiments, memories 206 and 306 may store a subset of the modules and data structures identified above. \nFurthermore, memories 206 and 306 may store additional modules and data structures not described above.\nAlthough FIGS. 2-3 show search engine 112 and client 102 as a number of discrete items, FIGS. 2-3 are intended more as a functional description of the various features which may be present in search engine 112 and client 102 rather than as a\nstructural schematic of the embodiments described herein.  In practice, and as recognized by those of ordinary skill in the art, items shown separately could be combined and some items could be separated.  For example, some items shown separately in FIG.\n2 could be implemented on single servers and single items could be implemented by one or more servers.  The actual number of servers in search engine 112 and how features are allocated among them will vary from one implementation to another, and may\ndepend in part on the amount of data traffic that the system must handle during peak usage periods as well as during average usage periods.\nFIG. 4 is an exemplary user record 400 from the user information database 116 (FIG. 1) in accordance with one embodiment of the invention.  In some embodiments, user record 400 contains a subset or a superset of the elements depicted in FIG. 4. \nUser record 400 contains a user identifier 402 that associates the information in user record 400 to a particular user or user identifier.  In some embodiments, the user identifier 402 is associated with a particular instance of a client application 320. In some embodiments, the user identifier is associated with a computer user (e.g., when the user logs in with a username and password).  Some of the information that can be associated with a user includes event-based data 404, derived data 406, and\nadditional data 408.  Event-based data 404 includes one or more events, each of which has a data type associated with it.  In some embodiments, event-based data includes: one or more queries 410; one or more result clicks 412 (i.e., the results presented\nin a set of search results on which the user has clicked); and one or more browsing data 416 (e.g., URLs visited, URL visit duration data, etc.).  Event-based data 404 includes one or more elements relevant to the event.  For example, in some embodiments\nthe events in the event-based data 404 includes either or both an eventID 418 and a timestamp 420.  The eventID 418 is a unique identifier associated with the particular event which may be assigned by the search system in some embodiments (e.g., a 64-bit\nbinary number).  The timestamp 420 is a value (e.g., a 64-bit binary number) representing the date and/or time at which the particular event record in event-based data 404 was created or at which the particular event occurred.\nIn some embodiments, one or more of the query events 410, and one or more of the result clicks 412, include a query portion 421 which includes zero or more query terms associated with the recorded event.  In some embodiments, the query portion\nindicates the query string to which the event is associated (e.g., what query produced the results that the user clicked-though).  In some embodiments, the query portion 421 includes a pointer or identifier to the query event 410 associated with the\nresult click (e.g., an eventID).  In some embodiments, the query portion 421 may additionally identify a \"related query\".  For example, the related query may be a query related to an initial query that contains a misspelling.  In some instances is it\nmore desirable to associate the event with the corrected query rather than the query containing the spelling mistake.  In some embodiments, the search system 112 may generate \"related queries\" automatically based on the user's entered query.\nIn some embodiments, one or more of the queries 410, result clicks 412, and/or browsing data 416 include one or more contentIDs 422 that identify content associated with the particular event.  For a query 410, the contentIDs 422 can represent\nthe URLs or URIs (Uniform Resource Identifier) of search results that have been sent to the user.  For a result click 412, the contentID 422 can represent the URL or URI that has been clicked on by the user.  For browsing event 416, the contentID 422 can\nbe the content identifier used to identify the location of the browse event (e.g., URL, data location, or other similar identifier).  In some embodiments, the contentID 422 may be a document identifier that identifies a document in a document repository.\nIn some embodiments, the event-based data has a history score 425.  An event's history score 425 may be calculated in any of a number of different ways or combinations of ways.  For example, the history score 425 may be a time-based ranking\nvalue that may be periodically modified based on a length of time that has passed since the event was recorded.  In some embodiments, the value of the history score decreases as the time from the recordation increases.  In some embodiments, event data\nhaving a time-based ranking value below a threshold may be deleted.  The values can be determined and re-determined periodically at various points in time.  In some cases, removal of one or more events triggers a re-determination of one or more derived\nvalues as described above.  In some embodiments, the history score 425 is determined in response to a request instead of being determined during batch or off-line processing.\nIn some embodiments, a browsing event 416 indicates a particular browsing event not associated with a query, but instead, with some other user activity (e.g., user selection of a link in a web page, or an email message, or a word processing\ndocument).  This other user activity can be identified in an information field 426.  In some embodiments, the information field 426 stores ranking values associated with the event.  Such ranking values can be system generated, user created, or user\nmodified (e.g., PageRank for URLs, or a value assigned to the event by the user).  Other examples of user activity include, but are not limited to web browsing, emailing, instant messaging, word processing, participation in chat rooms, software\napplication execution and Internet telephone calls.\nIn some embodiments, derived data 406 includes one or more information fields 428 containing information derived from the event-based data 404.  For example, in some embodiments, the information field 428 represents a user profile which is\ngenerated from one or more of the user's query events 410, results click events 412, and browsing events 416.  For example, by examining one or more of the various events a user profile may be created indicating levels of interest in various topic\ncategories (e.g., a weighted set of Open Directory Project (\"http://dmoz.org) topics\").\nIn some embodiments, the derived data 406 includes one or more pairs of a score 432 associated with particular contentID 434.  The score 432 represents a derived score assigned to the content associated with the contentID 434 (e.g., a web page). The score 432 can be based on one or more of a number of different factors.  In some embodiments, the score 432 incorporates the number of times that a user has clicked on the contentID over a period of time (which may include click throughs as a result\nof search queries and/or browsing activities).  In some embodiments, the score 432 incorporates a time duration that the user is estimated to have been looking at the content (a stay-time).  In some embodiments, the score 432 incorporates a time since\nthe user last viewed the content.  In some embodiments, the score 432 may be modified based on user activities.  In some embodiments, the score 432 is negatively affected if the user is presented the content in a series of search results, but fails to\nselect the content from the results page.  In some embodiments, the score 432 is positively affected when the user visits locations or pages or clicks on results that are similar to the content.  Similarity can be determined by a number of well-known\ntechniques (e.g., text classifier, ODP categorization, link structure, URL, edit distance, etc.).  In some embodiments, a site is defined as a logically related group of pages, or physically related pages such as pages belonging to the same URL or\nrelated URLs.  In some embodiments, the score 432 incorporates the number of past queries of the user for which the content was presented (e.g., a higher number of times certain content is presented to the user correlates with a higher score 432).  In\nsome embodiments, the score 432 incorporates the number of past queries of the user for which related content was presented (e.g., a higher number of times related content is presented to the user as a result of the user's queries correlates with a\nhigher score 432).  In some embodiments, derived data 406 includes aggregate scores.  For example, the same query may be generated by the user multiple times and in some embodiments each occurrence will have a different eventID.  Accordingly, in some\nembodiments, an aggregate score is maintained for events that occur multiple times.  The aggregate score can be computed by any of a number of different methods.  A reference to the multiple events and to the aggregate score can be maintained in the\nderived data 406.\nFIG. 5 is a flowchart representing a method of automatically identifying continuing interests of a computer user in accordance with one embodiment of the invention.  FIG. 5 shows processes performed by search engine 112.  It will be appreciated\nby those of ordinary skill in the art that one or more of the acts described may be performed by hardware, software, or a combination thereof, as may be embodied in one or more computing systems.\nIn some embodiments, prior to sending Internet usage data for a computer user, client 102 receives login information for the user, such as a username and password, and sends the information to search engine 112 via communications network 106. \nSearch engine 112 receives and verifies the login information, thereby enabling search engine 112 to associate subsequent data received from client 102 (e.g., Internet usage data such as event-based data 404) with a particular user record 400 in user\ninformation database 116.  In some embodiments, the user may be identified using a cookie stored on the client 102, or by a user identifier that is stored by and associated with a browser toolbar or browser extension.  In some embodiments, the user may\npre-approve the use of the user's Internet usage data.\nQuery server 114 in search engine 112 accesses (502) Internet usage data for a computer user (e.g., data in user record 400).  The usage data include a plurality of search queries by the user (e.g., queries 421 in query events 410).  In some\nembodiments, the Internet usage data are grouped into query sessions, as described below.\nUsing at least some of the Internet usage data, query server 114 identifies (504) search queries in the plurality of search queries that meet predefined query selection criteria for queries that correspond to continuing interests of the user. \nIn some embodiments, the identifying of search queries is performed without explicit input from the user identifying search queries that are continuing interests of the user.  In some embodiments, the predefined query selection criteria include a score\nderived from a combination of at least some of the Internet usage data.\nTo see how the user's Internet usage data can be used to identify the user's continuing interests, consider the sample query session in Table 1.\nTABLE-US-00001 TABLE 1 Sample Query Session html encode java (8 s) * RESULTCLICK (91.00 s) -- 2.  \"http://www.java2html.de/docs/api/de/java2html/util/HTMLTools.  html\" * RESULTCLICK (247.00 s) -- 1.  \"http://www.javapractices.com/ Topic96.cjp\" *\nRESULTCLICK (12.00 s) -- 8.  \"http://www.trialfiles.com/program- 16687.html\" * NEXTPAGE (5.00 s) -- start = 10 o RESULTCLICK (1019.00 s) -- 12.  \"http://forum.java.sun.com/thread/jspa?threadID=562942...\" o REFINEMENT (21.00 s) -- html encode java utility\n+ RESULTCLICK (32.00 s) -- 7.  \"http://www.javapractices.com/Topic96.cjp\" o NEXTPAGE (8.00 s) -- start = 10 * NEXTPAGE (30.00 s) -- start = 20 (Total time: 1473.00 s)\nThe user initially submitted the query \"html encode java\"--presumably to find out how to encode html in a java program.  After 8 seconds of browsing the search results, she clicks on the second result presented, and remains viewing that page for\n91 seconds.  She then returns to the results page and views the first result for 247 seconds.  Finally, she views the 8th result for 12 seconds.  She then performs a next page navigation, meaning that she views the next page of results, starting at\nposition 11.  She views the 12th result for a long time--1019 seconds.  However, perhaps because she is still unable to find a satisfactory result, she submits the query refinement \"html encode java utility\"--she is explicitly looking for an existing\njava utility that will allow her to encode html.  After a single result click for 32 seconds, the user looks at the next page of results ranked 11-20, and immediately looks at the following page of results ranked 21-30.  She then ends the query session.\nHow can query server 114 determine whether the user found what she was looking for, and how interested she is in seeing new results? First, it would appear that the user was interested in finding an answer, since she spent a considerable amount\nof time in the session, viewed a number of pages, and performed a large number of refinements (query refinements, next pages, etc.).  Second, query server 114 might also guess that the user did not find what she was looking for, because the session ended\nwith her looking at a number of search results pages, but not actually clicking on anything.  Finally, it is not as clear what the duration of the user's information need is.  However, because this query topic seems to address a work-related need, query\nserver 114 might guess that the user needs to find a solution immediately, or in the near future.  Thus, from this example we can see how query server 114 might determine search queries that correspond to continuing interests with signals such as\nduration of the session, number of actions, ordering of actions, and so on.\nIn some embodiments, rather than focusing on individual queries, which may be related to one another, query server 114 evaluates a \"query session\", i.e., all actions associated with a given initial query.  Such actions can include result clicks,\nspelling corrections, viewing additional pages of results, and query refinements.  A query is a \"query refinement\" of the previous query if both queries contain at least one common term.  Here, we will use the term refinement to more broadly refer to\nspelling corrections, next pages, and query refinements.\nIf query server 114 evaluates a user's continuing interest in a query session, rather than a specific query, it needs to determine the actual query to make recommendations for.  A session may consist of many query refinements, so which should be\nused? In some embodiments, query server 114 uses the query refinement that is directly followed by the largest number of result clicks.  If two or more query refinements are tied (with respect to number of result clicks), then query server 114 chooses\nthe refinement for which the total duration of clicks is longest.  For example, in the query session shown in Table 1, query server 114 will register the query \"html encode java\" because it has four result clicks, while \"html encode java utility\" has\nonly one.\nQuery selection criteria that query server 114 can use to identify queries that correspond to continuing interests of the user include, without limitation, the following Internet usage data of the user: Number of query terms--A larger number of\nterms tends to indicate a more specific need, which in turn might correlate with shorter interest duration and lower likelihood of prior fulfillment.  Number of clicks and number of refinements--The more actions a user takes on behalf of a query (e.g.,\nclicks on query results), the more interested she is likely to be in the query.  In addition, a high number of refinements probably implies low likelihood of prior fulfillment.  History match score--If a query matches the interests displayed by a user\nthrough past queries and clicks, then interest level is probably high.  A history match score may be generated in a number of ways, such as that described by Sugiyama, Hatano, and Yoshikawa in \"Adaptive web search based on user profile constructed\nwithout any effort from users\" in Proc.  of WWW, 2004.  Navigational queries--A navigational query is one in which the user is looking for a specific web site, rather than information from a web page.  In some embodiments, it is assumed that if the user\nclicks on only a single result and makes no subsequent refinements, the query is either navigational, or answerable by a single good website.  In this case, there is a high likelihood of prior fulfillment and low interest level.  Repeated\nnon-navigational queries--If a user repeats a query over time, she is likely to be interested in seeing further results.  Note, however, that navigational queries which are often repeated, but for which the user does not care to see additional results,\nshould be eliminated.  In some embodiments, query server 114 only considers a query that has been repeated, and for which the user has clicked on multiple or different clicks the most recent two times the query was submitted.  Session duration--Longer\nsessions might imply higher interest.  Query topic--Leisure-related topics such as sports and travel might be more interesting than work-related topics.  Number of \"long clicks\"--A user might quickly click through many results on a query she is not\ninterested in, so the number of long clicks--where the user views a page for many seconds--may be a better indicator than the number of any kind of click.  Whether the session ended with a refinement--Sessions that end with a refinement may be indicative\nof queries for which the user would want to see further results.\nIn some embodiments, an interest score for query sessions is defined that correlates with the continuing interest the user has in a query session.  In some embodiments, the interest score is given by: i.sub.score=a\nlog(#clicks+#refinements)+blog(#repetitions)+c(history match score) where a, b, and c are constants.  It should be clear that this score is merely exemplary.  Other scores can be constructed where higher score values correlate with higher continuing user\ninterest.  In some embodiments, the predefined query selection criteria for queries that correspond to continuing interests of the user may require that the interest score be above a threshold value.\nIn some embodiments, Boolean criteria (e.g., threshold conditions) are not incorporated into the interest score, but can still be used as part of the query selection criteria.\nQuery server 114 reruns (506) at least some of the identified search queries.  In some embodiments, the rerunning is performed automatically by search engine 112 at predefined times.  In some embodiments, the predefined times include the times\nof periodic events (e.g., monthly, weekly, daily, twice per day, hourly, or the like) or the times of episodic events (e.g., in response to the occurrence of any one of a predefined set of trigger conditions, such as when the user logs in to the search\nengine or to another server or service).\nFIG. 6 is a flowchart representing a method of alerting a computer user to new results for a prior search in accordance with one embodiment of the invention.  FIG. 6 shows processes performed by search engine 112.  It will be appreciated by\nthose of ordinary skill in the art that one or more of the acts described may be performed by hardware, software, or a combination thereof, as may be embodied in one or more computing systems.\nPrior to sending Internet usage data for a computer user, client 102 receives login information for the user, such as a username and password, and sends the information to search engine 112 via communications network 106.  Search engine 112\nreceives and verifies the login information, thereby enabling search engine 112 to associate subsequent data received from client 102 (e.g., Internet usage data such as event-based data 404) with a particular user record 400 in user information database\n116.  In some embodiments, the user may pre-approve the use of the user's Internet usage data.\nQuery server 114 in search engine 112 produces (602) search results by rerunning a plurality of search queries that have been performed previously for a computer user (e.g., one or more of the queries 421 in query events 410 in user record 400).\nQuery server 114 evaluates (604) the produced search results to select search results that meet predefined search result selection criteria.  At least one of the criteria is based on Internet usage data for the user (e.g., data such as\nevent-based data 404 for the user).  In some embodiments, the criteria include a requirement that selected search results are not present in query event data 410 for the user.  In some embodiments, the criteria include a requirement that selected search\nresults are not present in the Internet usage data for the user.  In some embodiments, the predefined search result selection criteria identify search results deemed likely to be relevant to the computer user.\nExemplary search result selection criteria may include, without limitation: History presence--In some embodiments, some or all the URLs sent to a user for her past queries are stored, for example in user record 400.  If a page appears in this\nhistory, it is not selected.  In some embodiments, if a page appears anywhere in the user record (e.g., as a contentID 422 in user record 400), it is not selected.  In some embodiments, to err on the side of high precision but low recall, a URL from any\ndomain the user has seen is not recommended.  Rank--If a result R is ranked very highly by a search engine, it may be concluded that R is a good page relative to other results for the query.  In addition, if it is also a new result, this indicates that\nthe result R is new or was recently promoted.  Popularity and relevance (PR) score--Results for keyword queries are assigned relevance scores based on the relevance of the document to the query--for example, by term frequency inverse document frequency\n(TFxIDF) analysis, anchor text analysis, etc. In addition, major search engines utilize static scores, such as PageRank, that reflect the query-independent popularity of the page.  The higher the absolute values of these scores, the better a result\nshould be.  Above Dropoff--If the PR scores of a few results are much higher than the scores of all remaining results, these top results might be authoritative with respect to this query.  In some embodiments, a result R is \"above the dropoff\" if there\nis a 30% PR score dropoff between two consecutive results in the top 5, and if R is ranked above this dropoff point.  This dropoff formula is merely exemplary.  Analogous formulas can be used to create other dropoff criteria.  Days elapsed since query\nsubmission--This selection criterion is based on the hypothesis that the more days that have elapsed since the query was submitted, the more likely it is for interesting new results to exist.  However, to date this criterion has not effected the\nrecommendation quality.  Sole changed result--This criterion refers to a result that is the only new result in the top N results, where N is an integer (e.g., N=6).  This selection criterion is based on the hypothesis that such results are not a product\nof rank fluctuation.  However, to date this criterion has been inversely correlated with recommendation quality.  All poor signal--This criterion refers to when all top N results (e.g., N=10) for a query have PR scores below a threshold value.  This\nselection criterion is based on the hypothesis that if every result for a query has low score, then the query has no good pages to recommend.\nIn some embodiments, a quality score for the search results is defined that correlates with search results deemed likely to be relevant to the computer user.  In some embodiments, the quality score is given by: q.sub.score=a(PR score)+b(rank)\nwhere a and b are constants\nIn some embodiments, because initial data indicated that rank may be inversely correlated with relevance to the user, the quality score is given by: q.sub.score*=c(PR score)+d(1/rank) where c and d are constants,\nIt should be clear that these quality scores are merely exemplary.  Other scores can be constructed where higher score values correlate with higher likelihood of relevance to the user.  In some embodiments, the predefined result selection\ncriteria for results that correspond to relevant new pages to the user may require that the quality score be above a threshold value.\nIn some embodiments, Boolean criterion (e.g., \"above dropoff\", whether the PR scores were above a threshold value, and/or whether the new result appeared in the top N (e.g., N=3)) are not incorporated into the quality score, but can still be\nused as part of the result selection criteria.\nQuery server 114 sends (608) links corresponding to at least some of the selected search results to a computer associated with the user for display, such as the client 102 that the user has used for login.  In some embodiments, the links are\nsent without explicit input from the user requesting the selected search results.\nFIG. 7 is a schematic screen shot of an exemplary graphical user interface 700 for alerting a computer user to new results for a prior search in accordance with one embodiment of the invention.  In some embodiments, GUI 700 includes a plurality\n704 of links 702 recommended by a search engine for a computer user.  The plurality 704 of links 702 are determined by the search engine by: producing search results by rerunning a plurality of search queries that have been performed previously for the\ncomputer user; and evaluating the produced search results to select search results that meet predefined search result selection criteria.  At least one of the criteria is based on Internet usage data for the user.\nIn some embodiments, the links 702 are displayed in a web page that is separate from a search result web page.  In some embodiments, the links 702 are displayed in a search result history web page.  In some embodiments, the links 702 are\ndisplayed in a web page (e.g., a home web page, login splash page or other web page) personalized to the user.  In some embodiments, the links 702 are part of an RSS feed and are displayed using an RSS reader or other compatible interface.  In some\nembodiments, information about the previous query (e.g., the query terms 706 and the date of the previous query 708) is displayed near the corresponding recommended link 702 so that the user can recognize the context for the recommendation.  In some\nembodiments, there is a link (e.g., one or more of query terms 706) that the user can click on to re-run the corresponding previous query.  In some embodiments, additional information about the new search result, such as a snippet 710 of text from the\nnew result, is displayed near the corresponding recommended link 702 to help the user decide whether to click on the link.\nQuery server 114 will also receive implicit user feedback in the form of clicks on recommended links.  Such data can be incorporated into a feedback loop to refine and adjust subsequent recommendations.\nFIG. 8 is a flowchart representing a method of automatically identifying continuing interests of a computer user and alerting the user to new results for a prior search in accordance with one embodiment of the invention.  FIG. 8 shows processes\nperformed by search engine 112 and client 102.  It will be appreciated by those of ordinary skill in the art that one or more of the acts described may be performed by hardware, software, or a combination thereof, as may be embodied in one or more\ncomputing systems.  In some embodiments, portions of the processes performed by search engine 112 can be performed by client 102 using components analogous to those shown for search engine 112 in FIG. 2.\nPrior to sending Internet usage data for a computer user, client 102 receives login information for the user, such as a username and password, and sends the information to search engine 112 via communications network 106.  Search engine 112\nreceives and verifies the login information, thereby enabling search engine 112 to associate subsequent data received from client 102 (e.g., Internet usage data such as event-based data 404) with a particular user record 400 in user information database\n116.  In some embodiments, the user may pre-approve the use of the user's Internet usage data.\nClient 102 sends (802) Internet usage data for a computer user to a server computer, such as query server 114 in search engine 112, via communications network 106.  The Internet usage data include a plurality of search queries by the user (e.g.,\nqueries 421 in query events 410).  In some embodiments, the Internet usage data include one or more of: the top N search results produced in response to each search query, and click data indicating users selections (clicks) of search results and URL\nvisit duration times of the user on each user selected search result.  In some embodiments, the Internet usage data are grouped into query sessions.  In some embodiments, client 102 is the computer used by the user to enter login information for the\nsearch engine 112.  In some embodiments, the user has previously registered with the search engine 112.\nAccessing and using at least some of the Internet usage data, query server 114 identifies (804) search queries in the plurality of search queries that meet predefined query selection criteria for queries that correspond to continuing interests\nof the user.  In some embodiments, the identifying of search queries is performed without explicit input from the user identifying search queries that are continuing interests of the user.  In some embodiments, the predefined query selection criteria\ninclude a score derived from a combination of at least some of the Internet usage data.\nQuery server 114 reruns (806) at least some of the identified search queries.  In some embodiments, the rerunning is performed automatically by search engine 112 at predefined times.  In some embodiments, the predefined times include the times\nof periodic events (e.g., monthly, weekly, daily, twice per day, hourly, or the like) or the times of episodic events (e.g., in response to the occurrence of any one of a predefined set of trigger conditions, such as when the user logs in).\nQuery server 114 evaluates (808) search results from the rerun queries to select search results that meet predefined search result selection criteria.  In some embodiments, the predefined search result selection criteria identify search results\ndeemed likely to be relevant to the computer user.\nQuery server 114 sends (810) links corresponding to at least some of the selected search results to a computer associated with the user for display, such as the client 102 that the user has used for login.  In some embodiments, the links are\nsent without explicit input from the user requesting the selected search results.  In some instances, only the X highest ranked links are sent, where X is an integer (e.g., a number between 1 and 10) that is either predefined or chosen based on various\nsystem features (e.g., the type of client device, or the size of the display or display region in which the response is to be shown) or user preferences.\nClient 102 receives (812) links corresponding to at least some of the selected search results from query server 114 and displays (814) at least some of the received links (e.g., as shown in FIG. 7).  In some embodiments, the links 702 are\ndisplayed in a web page that is separate from a search result web page.  In some embodiments, the links 702 are displayed in a search result history web page.  In some embodiments, the links 702 are displayed in a web page (e.g., a home web page, login\nsplash page or other web page) personalized to the user.  In some embodiments, the links 702 are part of an RSS feed and are displayed using an RSS reader or other compatible interface.  In some embodiments, information about the previous query (e.g.,\nthe query terms 706 and the date of the previous query 708) is displayed near the corresponding recommended link 702 so that the user can recognize the context for the recommendation.  In some embodiments, additional information about the new search\nresult, such as a snippet 710 of text from the new result, is displayed near the corresponding recommended link 702 to help the user decide whether to click on the link.\nQuery server 114 will also receive implicit user feedback in the form of clicks on recommended links.  Such data can be incorporated into a feedback loop to refine and adjust subsequent recommendations.\nThe foregoing description, for purpose of explanation, has been described with reference to specific embodiments.  However, the illustrative discussions above are not intended to be exhaustive or to limit the invention to the precise forms\ndisclosed.  Many modifications and variations are possible in view of the above teachings.  The embodiments were chosen and described in order to best explain the principles of the invention and its practical applications, to thereby enable others\nskilled in the art to best utilize the invention and various embodiments with various modifications as are suited to the particular use contemplated.", "application_number": "15093351", "abstract": " A method, system, and graphical user interface for alerting a computer\n     user to new results for a prior search are disclosed. One aspect of the\n     invention involves a graphical user interface on a computer that includes\n     a plurality of links recommended by a search engine for a computer user.\n     The plurality of links are determined by the search engine by: producing\n     search results by rerunning a plurality of search queries that have been\n     performed previously for the computer user; and evaluating the produced\n     search results to select search results that meet predefined search\n     result selection criteria. At least one of the criteria is based on\n     Internet usage data for the user.\n", "citations": ["5724567", "5754939", "6018733", "6038574", "6131110", "6175824", "6182091", "6202058", "6285999", "6349307", "6356922", "6381594", "6385619", "6411950", "6460029", "6484161", "6510424", "6513026", "6549941", "6643661", "6658623", "6665659", "6678694", "6691106", "6745193", "6804675", "6853982", "6871140", "6873990", "6912505", "6941321", "6981040", "7162473", "7464086", "7765178", "20020024532", "20020095621", "20020184095", "20020198882", "20030014399", "20030069877", "20030126136", "20030195877", "20030233345", "20040044571", "20040078252", "20040088286", "20040186827", "20040205516", "20040210661", "20040215608", "20040236736", "20040249808", "20040260621", "20050027694", "20050027742", "20050033657", "20050033803", "20050055281", "20050060311", "20050071328", "20050080786", "20050120003", "20050144067", "20050210024", "20050216434", "20050222987", "20050222989", "20050228780", "20050240580", "20050246324", "20050278633", "20060026147", "20060212265", "20060230035", "20060248078", "20060259861", "20070043706", "20070050339", "20070100798", "20070100836", "20070214115", "20070239680", "20070266025"], "related": ["14179721", "13043400", "11323096"]}, {"id": "20160275416", "patent_code": "10304008", "patent_name": "Fast distributed nonnegative matrix factorization and completion for big\n     data analytics", "year": "2019", "inventor_and_country_data": " Inventors: \nMin; Renqiang (Princeton, NJ), Song; Dongjin (San Diego, CA)  ", "description": "<BR><BR>BACKGROUND\nThe present system is related to learning systems and big data analytic engines.\nNonnegative matrix factorization and completion (NMFC), which aims to approximate a (partially) observed data matrix with two nonnegative low rank matrix factors, has been successfully applied in a wide range of machine learning applications,\nsuch as dimensionality reduction, collaborative filtering, compressed sensing.  Nevertheless, due to the non-convex formulation and the underlying inverse problem, many existing solutions are not accurate and not scalable to handle large problems.\n<BR><BR>SUMMARY\nIn one aspect, systems and methods are disclosed for operating a machine, by receiving training data from one or more sensors; training a machine learning module with the training data by: partitioning a data matrix into smaller submatrices to\nprocess in parallel and optimized for each processing node; for each submatrix, performing a greedy search for rank-one solutions; using alternating direction method of multipliers (ADMM) to ensure consistency over different data blocks; and controlling\none or more actuators using live data and the learned module during operation.\nIn another aspect, an efficient greedy and distributed process for nonnegative matrix factorization and completion (GD-NMFC) is disclosed.  The system first partitions a large-scale data matrix into smaller submatrices in appropriate manners\n(e.g., random, rank-one SVD, and rank-one ADMM).  Next, for each submatrix, the system searches for rank-one solutions of NMFC based upon ADMM in a greedy manner and concatenate them to form the low rank matrix factors.  Finally, the solutions of each\nsubproblem are concatenated to form the final solution and we show both the convergence of the algorithm and its error bound.\nAdvantages of the system may include one or more of the following.  The matrix inverse problem is eliminated and the engine load is only linearly proportional to the matrix ranker, and the system is much faster than other methods for NMFC.  The\nsystem can use a warm start technique for dividing large-scale datasets and perform distributed optimization in parallel.  Therefore, it is scalable for big data analytics. <BR><BR>BRIEF DESCRIPTION OF THE DRAWINGS\nFIG. 1 shows an efficient greedy and distributed engine for nonnegative matrix factorization and completion (GD-NMFC).\nFIG. 2 shows an exemplary processing system to which the present principles may be applied, in accordance with an embodiment of the present principles.\nFIG. 3 shows a high level diagram of an exemplary physical system including an aging profiling engine, in accordance with an embodiment of the present principles.\n<BR><BR>DESCRIPTION\nAn efficient greedy and distributed engine for nonnegative matrix factorization and completion (GD-NMFC) is detailed.\nIn FIG. 1, an input data matrix is received (10).  A non-negative initialization of matrices U and V is done (12).  The process performs iterative multiplicative updates until convergence is achieved (14).  Alternatively, from 10, the process\nperforms least square minimization followed by a non-negative projection (16).  In another alternative from 10, the process partitions the data matrix using truncated SVD or rank-one ADMM (30).  Next, for all data partitions, the process greedily\nsearches for rank-one U&V in parallel, and uses ADMM to ensure consistency over different data blocks (32) and then loops until convergence is achieved.  From 14, 16, or 32, the process selects the final low-rank matrix factors U& V as the result (40).\nNonnegative matrix factorization and completion (NMFC) has been used to address scalability issues in machine learning by looking for two nonnegative low rank matrix factors, U.di-elect cons.R.sup.n.times.r and V.di-elect cons.R.sup.r.times.d to\nrecover a partially (fully) observed data matrix X.di-elect cons.R.sup.n.times.d of n samples and d features, i.e.,\n.times..times..times..OMEGA..function..times..gtoreq..gtoreq.  ##EQU00001## where r denotes rank, .parallel.  .parallel..sub.F is the Frobenius norm, the inequalities are element-wise, and P.sub..OMEGA.  is a projection operator such that the\n(i, j)-th entry of P.sub..OMEGA.(X) is X.sub.i,j if (i,j).di-elect cons..OMEGA.  and zero otherwise.\nGD-NMFC partitions a large-scale data matrix into smaller submatrices with appropriate techniques (e.g., random, rank-one SVD, and rank-one ADMM) such that each submatrix is parallelly optimized over a single node.  Then, for each submatrix, we\nconduct greedy search for rank-one solutions based upon ADMM.  The matrix inverse problem is eliminated and the optimization of NMFC can be dramatically accelerated, especially when r is large.\nGD-NMFC avoids the possible failures caused by biased rank estimation and is SVD-free since it relies on optimizing over U and V, iteratively.  Meanwhile, greedy searching for the optimal directions based upon rank-one approximation from 1 to r\nis more efficient than updating r directions in all iterates.  In addition, the lower rank solution before each rank increment can be seen as a \"warm start\" of the next higher rank minimization and thus speed up convergence.\nOur empirical studies over several real-world large scale datasets verify that GD-NMFC is more efficient than state-of-the-art methods while achieving similar or better performance.\nGiven a matrix X.di-elect cons.R.sup.n.times.d of n rows and d columns, we use x.sub.j.di-elect cons.R.sup.n to denote its j-th column, use x.sup.i.di-elect cons.R.sup.l.times.d to denote its i-th row, and use X.sub.ij to denote the entry in\ni-th row and j-th column of X. The Frobenius norm of X is defined as .parallel.X.parallel..sub.F= {square root over (Tr(X.sup.T X))} where Tr( ) denote the trace of a square matrix.  P.sub..OMEGA.  is a projection operator such that the (i, j)-th entry\nof P.sub..OMEGA.(X) is X.sub.i,j if (i,j).di-elect cons..OMEGA.  and zero otherwise.  The inner product of two matrices X and Y is defined as &lt;X,Y&gt;=Tr(X.sup.TY).\nNMF aims to reconstruct a fully observed data matrix with two nonnegative low rank matrix factors and has been widely applied for face recognition, object classification, and clustering.  To optimize NMF, multiplicative update rule (MUR) can be\nused.  MUR is the most popular method for NMF and it can be derived based upon Karush-Kuhn-Tucker (KKT) optimality condition, i.e.,\n.rarw..times..rarw..times..times..times.  ##EQU00002##\nWith nonnegative initializations of U and V, both U and V will remain nonnegative in each iteration.  Since MUR converges slowly in many practical applications, ALS and projected gradient method can be utilized as the substitutions.  ALS\nminimizes the least square cost function .parallel.X-UV.parallel..sub.F.sup.2 with respect to U and V, iteratively.  The procedure is based upon two closed form solutions, iteratively, i.e., U=P.sub.+(XV.sup.T(VV.sup.T)*) (4) and\nV=P.sub.+((U.sup.TU)*U.sup.TX), (5) where * denotes pseudo-inverse and P.sub.+ projects the matrix onto a nonnegative set, i.e., P.sub.+(U)=max(U,0).  Instead of calculating pseudo-inverse in ALS, projected gradient method first derive the gradient of\nPX-UVP.sub.F.sup.2 with respect to U (or V) and then update U (or V) based upon projected gradient update.  Fast HALS [9] is a coordinate descent approach which optimize the i-th row of U and i-th column of V when i iterates from 1 to r until convergence\nis achieved.\nAn alternative to ALS is called alternating direction method of multiplier (ADMM).  ADMM introduces two auxiliary variables A and B and considers the following optimization problem:\n.times..times..times..times..gtoreq..gtoreq.  ##EQU00003##\nTo solve this problem, the augmented Lagrangian function of 6 can be derived as:\n.function..LAMBDA..PI..times..LAMBDA..PI..rho..times..rho..times.  ##EQU00004## where .LAMBDA..di-elect cons.R.sup.n.times.r and .PI..di-elect cons.R.sup.r.times.d are Lagrange multipliers, &lt; &gt; is the matrix inner product, and .rho.&gt;0\nis the penalty parameter for the constraints.  By minimizing L with respect to U, V, A, B, .LAMBDA., and .PI., we can update each parameter iteratively until convergence.\nSince ADMM involves matrix inverse problems which are computationally expensive when the matrix rank r is relatively large, it may not be scalable to large scale matrices as they are more likely to contain a large r. Therefore, an efficient\ngreedy and distributed algorithm for nonnegative matrix factorization and completion (GD-NMFC) is developed.\nMatrix completion aims to recover the whole data matrix X from partially observed entries or undersampled linear measurements by leveraging the interaction between different instances which can be well captured with low-rank structure.  In the\npast few years, matrix completion has been applied various applications, such as collaborative filtering in recommender system and link recommendation in social network analysis.\nSince it is intractable to minimize the matrix rank exactly in general case, the trace norm or nuclear norm is widely utilized as a convex surrogate of rank.  Nevertheless, it is computationally expensive to solve the standard low rank or trace\nnorm problem as it involves computing SVD.  In recent years, many approaches have been developed to tackle this problem.  Most of these methods, however, still involve the computation of SVD or truncated SVD in each iteration and thus cannot be scalable\nto large-scale problems.  Several methods approximate the trace norm with UV and proceed by alternatively optimizing U and V. It has been shown that linear convergence rate can be established theoretically with properly designed optimization procedure\nand appropriate initialization (Jain et. al. 2013).  The computational complexity of these approaches, however, is quadratically proportional to the rank of the estimated matrix and thus cannot be scalable for large matrices.\nWe sequentially detail greedy distributed NMFC with three steps.  We first describe how to partition a large data matrix X into smaller submatrices.  Next, we introduce rank-one ADMM for NMFC based upon a submatrix.  Finally, we show how to\naggregate the solutions of all submatrices.\nData Partition\nWhen the number of samples n is extremely large in a data matrix X, solving NMFC over a single node will be infeasible.  In this case, we can partition X into smaller submatrices, i.e., X=[X(1).di-elect cons.R.sup.r.sup.1.sup..times.d;\nX(2).di-elect cons.R.sup.r.sup.2.sup..times.d; .  . . ; X(C).di-elect cons.R.sup.r.sup.c.sup..times.d] where .SIGMA..sub.i r.sub.i=r such that each one of them can be optimized parallelly.\nIn practical applications, three different partition methods could be utilized: uniformly sample a number of samples (i.e., r.sub.i) from X for the i-th node; first perform truncated SVD by setting r=1, project its eigenvector over nonnegative\nset, and then conduct k-means clustering over the eigenvector; first perform ADMM for NMFC by setting r=1 and then conduct k-means clustering over the eigenvector.\nThe second and third ways of partition can be seen as a \"warm start\" for the the second rank optimization and are expected to speed up convergence.\nRank-One ADMM for NMFC\nGiven each submatrix X(i) where i is the index of submatrices, rank-one ADMM can be used to optimize NMFC over this node.  In rank-one ADMM, we greedy search for rank-one solutions based upon ADMM.  In this way, the matrix inverse problem is\neliminated and the optimization of NMFC can be dramatically accelerated, especially when r is large.\nIn the first step (k=1) of rank-one ADMM, we set {circumflex over (X)}(i)=X(i).  For k.gtoreq.2, we set {circumflex over (X)}(i)={circumflex over (X)}((i)-u(i).sub.k-1.sup.Tv(i).sup.k-1.  Therefore, rank-one ADMM for the k-th rank can be\nformulated as:\n.function..function..function..function..times..function..function..times- ..function..function..function..function..function..function..gtoreq..func- tion..gtoreq..function..function..A-inverted..noteq.  ##EQU00005## where the first three\nconstraints are over this node and the last constraint is the communication between different nodes used to ensure that v(i).sup.k on each node is consistent.\nThe augmented Lagrangian of Eq.  8 can be written as:\n.function..function..function..function..function..times..function..funct- ion..times..function..function..function..function..function..noteq..times- ..function..function..times..times..rho..times..function..function..rho..t-\nimes..function..function..noteq..times..rho..times..function..function.  ##EQU00006##\nwhere .rho..di-elect cons.R.sup.n, q.di-elect cons.R.sup.l.times.d, and t.di-elect cons.R.sup.t.times.d are Lagrangian multipliers, and .rho.&gt;0 is the penalty parameter for the constraints.  By minimizing L with respect to u(i).sub.k,\nv(i).sup.k, a(i).sub.k, b(i).sup.k, p, q, and s, iteratively, we can obtain the closed form solution of each parameter as follows:\n.function..rarw..function..times..function..rho..times..times..function..- function..times..function..rho..function..rarw..function..times..function.- .rho..times..times..function..noteq..times..rho..times..times..function..t-\nimes..function..times..function..rho..function..rarw..function..function..- rho..function..rarw..function..function..rho..rarw..rho..function..functio- n..function..rarw..rho..function..function..function..rarw..rho..times..no-\nteq..times..function..function.  ##EQU00007##\nIn one embodiment, Technique 1 is executed by the processor 104 of FIG. 2 as follows:\nTABLE-US-00001 Technique 1 Greedy Distributed NMFC Input: X .di-elect cons.  .sup.n.times.d, u(i).sub.k, v(i).sup.k, a(i).sub.k, b(i).sup.k, p, q, s, .rho.  Output: U and V 1: Partition X into submatrices, i.e. X = [X (1) .di-elect cons. \n.sup.r.sup.1.sup..times.d; X(2) .di-elect cons.  .sup.r.sup.2.sup..times.d; .  . . ; X(c) .di-elect cons.  .sup.r.sup.c.sup..times.d] 2: For i-th node 3: For k = 1 to r, 4: Repeat: 5: Update u(i).sub.k based upon Eq.  10; 6: Update v(i).sup.k based upon\nEq.  10; 7: Update a(i).sub.k based upon Eq.  10; 8: Update b(i).sup.k based upon Eq.  10; 9: Update p based upon Eq.  10; 10: Update q based upon Eq.  10; 11: k = k + 1 12: Until convergence.  13: U(i) = [U(i); u(i).sub.k], V(i) = [V(i), v(i).sup.k],\nA(i) = [A(i); a(i).sub.k], B(i) = [B(i), b(i).sup.k].  14: End for.  15: End for i-th node.  16: U = [U; U(i)], V = V(i), S = [S; S(i)], T = T(i)\nIn another embodiment, Technique 2 is executed by the processor 104 of FIG. 2.  In Technique 2, U and V are randomly initialized and the matrices are set to zero matrices of appropriate sizes.  The stopping criterion for ADMM is met if the\nobjective in Eq.  6 does not improve relative to a tolerance value.  In each step, the main computation are U(k+1) updating and V(k+1) updating.\nTABLE-US-00002 Technique 2 ADMM for NMF 1: Input: X .di-elect cons.  .sup.n.times.d, U .di-elect cons.  .sup.n.times.r, V .di-elect cons.  .sup.r.times.d, S .di-elect cons.  .sup.  .sup.n.times.r, T .di-elect cons.  .sup.r.times.d, .rho.  2:\nOutput: U and V 3: Set k = 0 (index of iteration) 4: Repeat: 5: U (k + 1) = (XV(k).sup.T + .rho.S(k) - .LAMBDA.(k)) (V(k)V(k).sup.T + .rho.I).sup.-1 6: V(k + 1) = (U(k + 1).sup.T U(k + 1) + .rho.I).sup.-1 (U(k + 1).sup.T X + .rho.T(k) - .PI.(k)) 7: S(k +\n1) = P.sub.+ (U(k + 1) + .LAMBDA.(k)/.rho.) 8: T(k + 1) = P.sub.+ (V(k + 1) + .PI.(k)/.rho.) 9: .LAMBDA.(k + 1) = .LAMBDA.(k) + .rho.(U(k + 1) - S(k + 1)) 10: .PI.(k + 1) = .PI.(k) + .rho.(V(k + 1) - T(k + 1)) 11: k = k + 1.  12: Until convergence.\nThe foregoing details a rank-one alternating direction method of multiplier (ADMM) for nonnegative matrix factorization (NMF).  In each step, rank-one ADMM seeks for a rank-one solution of NMF based upon ADMM and utilizes greedy search to obtain\nlow rank matrix factors.  In this way, rank-one ADMM avoids the underlying matrix inverse problem and the computation is only linearly proportional to the rank r. Thorough empirical studies over several real-world large scale datasets demonstrate that\nthe present system improves computer performance and is more efficient than conventional systems while achieving similar or better learning performance.\nWe conducted empirical studies based upon two publicly available datasets, i.e., UMIST and Coil20.  Our results demonstrated that rank-one ADMM is more efficient and effective than MUR, ALS, and traditional ADMM.\nFIG. 2 with an exemplary processing system 100, to which the present principles may be applied, is illustratively depicted in accordance with an embodiment of the present principles, for operating a machine, by receiving training data from one\nor more sensors; training a machine learning module with the training data by: partitioning a data matrix into smaller submatrices to process in parallel and optimized for each processing node; for each submatrix, performing a greedy search for rank-one\nsolutions; using alternating direction method of multipliers (ADMM) to ensure consistency over different data blocks; and controlling one or more actuators using live data and the learned module during operation.\nThe processing system 100 includes at least one processor (CPU) 104 operatively coupled to other components via a system bus 102.  A cache 106, a Read Only Memory (ROM) 108, a Random Access Memory (RAM) 110, an input/output (I/O) adapter 120, a\nsound adapter 130, a network adapter 140, a user interface adapter 150, and a display adapter 160, are operatively coupled to the system bus 102.\nA first storage device 122 and a second storage device 124 are operatively coupled to system bus 102 by the I/O adapter 120.  The storage devices 122 and 124 can be any of a disk storage device (e.g., a magnetic or optical disk storage device),\na solid state magnetic device, and so forth.  The storage devices 122 and 124 can be the same type of storage device or different types of storage devices.\nA speaker 132 is operatively coupled to system bus 102 by the sound adapter 130.  A transceiver 142 is operatively coupled to system bus 102 by network adapter 140.  A display device 162 is operatively coupled to system bus 102 by display\nadapter 160.\nA first user input device 152, a second user input device 154, and a third user input device 156 are operatively coupled to system bus 102 by user interface adapter 150.  The user input devices 152, 154, and 156 can be any of a keyboard, a\nmouse, a keypad, an image capture device, a motion sensing device, a microphone, a device incorporating the functionality of at least two of the preceding devices, and so forth.  Of course, other types of input devices can also be used, while maintaining\nthe spirit of the present principles.  The user input devices 152, 154, and 156 can be the same type of user input device or different types of user input devices.  The user input devices 152, 154, and 156 are used to input and output information to and\nfrom system 100.\nOf course, the processing system 100 may also include other elements (not shown), as readily contemplated by one of skill in the art, as well as omit certain elements.  For example, various other input devices and/or output devices can be\nincluded in processing system 100, depending upon the particular implementation of the same, as readily understood by one of ordinary skill in the art.  For example, various types of wireless and/or wired input and/or output devices can be used. \nMoreover, additional processors, controllers, memories, and so forth, in various configurations can also be utilized as readily appreciated by one of ordinary skill in the art.  These and other variations of the processing system 100 are readily\ncontemplated by one of ordinary skill in the art given the teachings of the present principles provided herein.\nReferring now to FIG. 3, a high level schematic 200 of an exemplary physical system including an NMFC engine 212 is illustratively depicted in accordance with an embodiment of the present principles.  In one embodiment, one or more components of\nphysical systems 202 may be controlled and/or monitored using an engine 212 according to the present principles.  The physical systems may include a plurality of components 204, 206, 208.  210 (e.g., Components 1, 2, 3, .  . . n), for performing various\nsystem processes, although the components may also include data regarding, for example, financial transactions and the like according to various embodiments.\nIn one embodiment, components 204, 206, 208, and 210 may include any components now known or known in the future for performing operations in physical (or virtual) systems (e.g., temperature sensors, deposition devices, key performance indicator\n(KPI), pH sensors, financial data, etc.), and data collected from various components (or received (e.g., as time series)) may be employed as input to the engine 212 according to the present principles.  The engine/controller 212 may be directly connected\nto the physical system or may be employed to remotely monitor and/or control the quality and/or components of the system according to various embodiments of the present principles.\nWhile the machine-readable storage medium is shown in an exemplary embodiment to be a single medium, the term \"machine-readable storage medium\" should be taken to include a single medium or multiple media (e.g., a centralized or distributed\ndatabase, and/or associated caches and servers) that store the one or more sets of instructions.  The term \"machine-readable storage medium\" shall also be taken to include any medium that is capable of storing or encoding a set of instructions for\nexecution by the machine and that cause the machine to perform any one or more of the methodologies of the present invention.  The term \"machine-readable storage medium\" shall accordingly be taken to include, but not be limited to, solid-state memories,\nand optical and magnetic media.\nIt is to be understood that the above description is intended to be illustrative, and not restrictive.  Many other embodiments will be apparent to those of skill in the art upon reading and understanding the above description.  Although the\npresent invention has been described with reference to specific exemplary embodiments, it will be recognized that the invention is not limited to the embodiments described, but can be practiced with modification and alteration within the spirit and scope\nof the appended claims.  Accordingly, the specification and drawings are to be regarded in an illustrative sense rather than a restrictive sense.  The scope of the invention should, therefore, be determined with reference to the appended claims.", "application_number": "15063236", "abstract": " Systems and methods are disclosed for operating a machine, by receiving\n     training data from one or more sensors; training a machine learning\n     module with the training data by: partitioning a data matrix into smaller\n     submatrices to process in parallel and optimized for each processing\n     node; for each submatrix, performing a greedy search for rank-one\n     solutions; using alternating direction method of multipliers (ADMM) to\n     ensure consistency over different data blocks; and controlling one or\n     more actuators using live data and the learned module during operation.\n", "citations": ["5422836", "8452718", "20080275862"], "related": ["62135751"]}, {"id": "20170031576", "patent_code": "10311384", "patent_name": "Automatic creation and maintenance of a taskline", "year": "2019", "inventor_and_country_data": " Inventors: \nSaoji; Govind (Hyderabad, IN), Mani; Rohit (Hyderabad, IN), Kamdar; Nirav Ashwin (Hyderabad, IN), George; Justin Varacheril (Hyderabad, IN)  ", "description": "<BR><BR>BACKGROUND\nDigital assistants on client devices have traditionally provided information that can be used by a user to perform a small task, such as a route to a destination location, a movie recommendation, etc. The provided information is typically\ngeneric and is not customized to a particular user.  These types of systems used by digital assistants are unable to determine information that would be particularly useful to a user, and as such, the user is forced to search multiple sources, such as\nwebsites, e-mail systems, calendars, etc., to gather all information that could be used to perform a particular task.  Even further, the user would need to continually search these sources to determine if anything has changed in relation to completion of\na particular task.  This is time consuming to the user and extremely inconvenient.\n<BR><BR>SUMMARY\nThis summary is provided to introduce a selection of concepts in a simplified form that are further described below in the detailed description.  This summary is not intended to identify key features or essential features of the claimed subject\nmatter, nor is it intended to be used in isolation as an aid in determining the scope of the claimed subject matter.\nEmbodiments provided herein provide relevant and useful information to a user that can be used by the user to complete a task.  The information may be provided to the user by a personalized digital assistant, for example, by way of a taskline. \nThe taskline is generated based on a user task and subtasks that are related to the user task.  Both the user task and the subtasks may be determined based on contextual information associated with the user.  For instance, contextual information may\ninclude e-mails, calendar entries, social media interactions, browser history, etc., all of which can be used to infer what the user is trying to accomplish and what the user is interested in. The tasklines generated using embodiments provided herein are\ndynamic in nature, and thus are dynamically modified based on a number of factors, including contextual information, a user's current location, which subtasks a user has accomplished, and the like. <BR><BR>BRIEF DESCRIPTION OF THE DRAWINGS\nThe embodiments described herein are described in detail below with reference to the attached drawing figures, wherein:\nFIG. 1 is a block diagram of an exemplary operating environment in which embodiments described herein may be employed;\nFIG. 2 is a diagram of an exemplary flowchart for generating a dynamic taskline, in accordance with embodiments described herein;\nFIG. 3 is a screenshot of a mini taskline, in accordance with embodiments described herein;\nFIG. 4 is a screenshot of a dynamic taskline displayed in response to a user selection on the screenshot of FIG. 3, in accordance with embodiments described herein;\nFIG. 5 is a screenshot of a dynamic taskline displayed in response to a user selection on the screenshot of FIG. 5, in accordance with embodiments described herein;\nFIGS. 6-8 are screenshots of dynamic tasklines having contents based on a current location of a user, in accordance with embodiments described herein;\nFIG. 9 is a screenshot of a dynamic taskline, in accordance with embodiments described herein;\nFIG. 10 a screenshot of details corresponding to the dynamic taskline of FIG. 9, in accordance with embodiments described herein;\nFIG. 11 is a flow diagram showing an exemplary method for generating a dynamic taskline, in accordance with embodiments described herein;\nFIG. 12 is another flow diagram showing an exemplary method for generating a dynamic taskline, in accordance with embodiments described herein; and\nFIG. 13 is a block diagram of an exemplary computing environment suitable for use in implementing embodiments described herein.\n<BR><BR>DETAILED DESCRIPTION\nThe subject matter of embodiments of the invention is described with specificity herein to meet statutory requirements.  However, the description itself is not intended to limit the scope of this patent.  Rather, the inventors have contemplated\nthat the claimed subject matter might also be embodied in other ways, to include different steps or combinations of steps similar to the ones described in this document, in conjunction with other present or future technologies.  Moreover, although the\nterms \"step\" and/or \"block\" may be used herein to connote different elements of methods employed, the terms should not be interpreted as implying any particular order among, or between, various steps herein disclosed unless, and except, when the order of\nindividual steps is explicitly described.\nFor purposes of this disclosure, the word \"including\" has the same broad meaning as the word \"comprising.\" In addition, words such as \"a\" and \"an,\" unless otherwise indicated to the contrary, include the plural as well as the singular.  Thus,\nfor example, the constraint of \"a feature\" is satisfied where one or more features are present.  Also, the term \"or\" includes the conjunctive, the disjunctive, and both (a or b thus includes either a or b, as well as a and b).\nEmbodiments provided herein enable the generation of a dynamic taskline that assists the user in managing various tasks.  The dynamic taskline may be presented to the user on a device by way of a personalized digital assistant, which is able to\naccess contextual information associated with the user to infer what the user may be interested in at that time.  In embodiments, contextual information associated with a user is used to infer a task that the user would like to accomplish, which could be\nplanning an upcoming trip, managing the user's taxes, managing the user's finances, making a purchase, managing the user's health, and the like.  Included in the taskline may be multiple subtasks that are provided to assist the user in accomplishing the\ntask.  Contextual information may originate from one or more sources, such as e-mail systems, browser history, selections made by a user of search results, digital calendars, social media sites, photographs taken and/or stored on the computing device,\netc. While termed a subtask, not every subtask is something the user has to do in order to complete the task.  For instance, for an upcoming trip, some exemplary subtasks include flight information, hotel reservations, car rental reservations, suggested\nrestaurants in the destination city, etc. The user may not actually visit any of the restaurants that are suggested, but having the suggested restaurants that were determined based on the user's contextual information could assist the user in determining\nwhere to eat while on the trip.\nIn embodiments, subtasks that are identified by the system may be ranked before being presented to the user.  The ranking could be accomplished based on contextual information associated with the user, including the user's current location.  The\ncontextual information may be continuously updated and stored in a data store that is accessible to the personalized digital assistant that is used to generate the dynamic taskline.  The dynamic taskline is customized to a particular user, and as such,\nthe taskline includes information that is more personalized than generic information that could be provided to any user.  The user's interests, likes, dislikes, etc. can be inferred from contextual information, and may then be used to provide relevant\ninformation on the dynamic tasklines.  Even further, third party data can be plugged into the system architecture to create subtasks and additional information that may be relevant to the user's task.\nAdvantages of embodiments presented herein include the user having all associated information for a particular task in one location on the user's device.  Instead of the user having to search through e-mails, the web, calendar entries, etc., all\nof this information is located in one place.  The user may even have the opportunity to add information in the form of a subtask to the taskline.  Importantly, the taskline may be available to the user even when the user's device is offline.  Another\nadvantage of embodiments described herein is that the tasklines are dynamically modified based on current information.  For instance, for a trip that the user is taking, the information provided in the taskline may be modified based on the user's current\nlocation or the subtask that the user is currently performing.  As such, the user may not be interested in the layout of the destination airport or which baggage claim his/her luggage will be at one week before the user departs on the trip.  However, the\nuser could be interested in flight changes/delays, transportation to/from the airport, etc. before the user even leaves on the trip.  Additionally, the dynamic tasklines may be available to the user across multiple client devices.  For instance, if the\nuser has a laptop, a mobile device, and a tablet, the tasklines generated for that user could be viewable on all devices.  Additionally, if changes are made to a particular taskline on one of the user's devices, those changes would by synced across all\nof the user's devices.  For instance, the user may make changes to a taskline, such as adding a subtask.  This subtask would be synced across all devices.\nAccording to a first embodiment, a system is provided for automatically generating a dynamic taskline.  The system comprises a taskline generation engine having one or more processors and one or more computer-readable storage media.  The\ntaskline generation engine is configured to access one or more sources to retrieve contextual information associated with a user and based, at least in part, on the contextual information, detect a user task corresponding to the user.  The user task is a\nlong running task that comprises a plurality of subtasks that, when completed, contribute to a completion of the user task.  The taskline generation engine is further configured to identify one or more subtasks that are associated with the user task, and\nto generate a taskline that is customized to the user.  The taskline comprises the user task and the one or more subtasks.  Additionally, the taskline generation engine is configured to, for a duration of time corresponding to the user completing the one\nor more subtasks, continually monitor the contextual information for updated contextual information, and to dynamically modify the taskline based on the updated contextual information.\nAccording to a second embodiment, one or more computer storage media having computer-executable instructions embodied thereon are provided that, when executed by one or more processors, causes the one or more processors to perform a method for\nautomatically generating a dynamic taskline.  The method comprises accessing one or more sources to retrieve contextual information associated with a user, and from at least the contextual information, detecting a user task that comprises a plurality of\nsubtasks.  The method further comprises identifying one or more subtasks associated with the user task and ranking the one or more subtasks based, in part, on the contextual information, automatically generating a taskline based on the ranking of the one\nor more subtasks, and dynamically modifying the taskline based on a particular point in time in which the user is viewing the taskline or updated contextual information associated with the user.\nAccording to a third embodiment, a computer-implemented method is provided for automatically generating a dynamic taskline.  The method includes, based, at least in part, on contextual information associated with a user, detecting a user task\ncorresponding to the user.  The user task is a long running task that comprises a plurality of subtasks that, when completed, contribute to a completion of the user task.  The method further includes identifying one or more subtasks that are associated\nwith the user task, generating a taskline that comprises the user task and the one or more subtasks, and for a duration of time corresponding to the user completing the one or more subtasks, continually monitoring the contextual information for updated\ncontextual information.  Additionally, the method includes dynamically modifying the taskline based on the updated contextual information.\nTurning now to FIG. 1, a block diagram 100 is illustrated of an exemplary operating environment in which embodiments described herein may be employed.  As shown here, multiple client devices (items 102A, 102B, and 102C) may be utilized by a user\nto view the tasklines generated by embodiments described herein.  For instance, a particular user may have a mobile device, a laptop, and a desktop computing device that the user uses in different circumstances, such as where the user is located or what\nthe user is doing at a particular time.  Each of these client devices could be any type of computing device, such as computing device 1300 described herein in relation to FIG. 13.  Additional examples of computing devices include bands, glasses, watches,\ntelevisions, and any other device capable of communications with the Internet.  Using client device 102A as an example, client device 102A may include code that can be used to run a personal digital assistant program.  A personal digital assistant\nprogram, also termed herein a digital assistant, is a program that provides services traditionally provided by a human assistant.  Exemplary services include updating a calendar, providing reminders, tracking activities, suggesting tasks and subtasks for\nthe user based on information known about the user, etc. Digital assistants may respond to voice commands or typed commands, and may provide typed or audible responses.  In embodiments herein, a digital assistant is able to generate a taskline that\nrepresents a long running task having a plurality of subtasks associated therewith.  At least a portion of the long running task and the subtasks may be determined by the digital assistant program using user-specific information and contextual\ninformation associated with the user.  Using this information, tasklines are generated.\nBlock diagram 100 further includes a user context data store 104, a third party service 106, and a taskline generation engine 108.  Block diagram 100 further includes network 110, which may be wired, wireless, or both.  In embodiments the client\ndevices 102A, 102B, and 102C, the user context data store 104, the third party service 106, and the taskline generation engine 108 communicate and share data with one another by way of network 110.  Network 110 may include multiple networks, or a network\nof networks, but is shown in simple form so as not to obscure aspects of the present disclosure.  By way of example, network 110 can include one or more wide area networks (WANs), one or more local area networks (LANs), one or more public networks, such\nas the Internet, and/or one or more private networks.  Where network 110 includes a wireless telecommunications network, components such as a base station, a communications tower, or even access points (as well as other components) may provide wireless\nconnectivity.  Networking environments are commonplace in offices, enterprise-wide computer networks, intranets, and the Internet.  Accordingly, network 110 is not described in significant detail.\nInitially, a user of one or more of client devices 102A, 102B, or 102C may provide various types of information, termed contextual information herein, which can be used by the taskline generation engine 108 to generate tasklines that are\npersonalized for the user.  The information provided by the user may include e-mails sent and received, browser history, search results selected by the user, calendar entries, social media interactions, and other information that the system is\ncollecting, such as the user's geolocation.  It is noted that while embodiments described herein use user-specific information and contextual information to generate personalized tasklines, the user may have the option to opt-in or opt-out of the use of\ntheir personal information.  As such, for users who choose to opt-out, the taskline generation engine 108 may still present tasklines to the user by way of a digital assistant on the user's device, but the tasklines may be generic instead of being\npersonalized.\nThe user-specific information and contextual information may be stored in the user context data store 104 for a plurality of users.  As users further interact with services and websites on their devices, contextual information corresponding to\nthat user may also change, and thus the data stored in the user context data store 104 may dynamically change, and is thus updated periodically.  When it is determined that a taskline is to be generated for a particular user, the taskline generation\nengine 108 accesses the user content data store 104 for contextual information of the user, which is then used to generate a personalized taskline, as further described herein.\nThe taskline generation engine 108 comprises a contextual information component 112, a task identification component 114, a subtask identification component 116, a ranking component 118, a subtask organization component 120, and a dynamic\nmodification component 122.  Once it is determined that a taskline is to be generated for a particular user, the contextual information component 112 accesses one or more sources to retrieve contextual information corresponding to the user.  In one\ninstance, the user context data store 104 stores information from a variety of sources (e.g., e-mail system, calendar, social media sites, browser history), and thus the user context data store 104 is the only source that may be accessed.  In other\nembodiments, without a data store such as the user context data store 104, the contextual information component 112 may actually access an e-mail system, a calendar, social media sites, browser history, etc., to retrieve the relevant contextual\ninformation.  As mentioned, contextual information may continuously be updated, and thus, the sources from which contextual information can be retrieved may be periodically accessed to determine whether there is any updated contextual information.\nThe task identification component 114 is generally configured to infer a task that is specific to a user.  For example, task identification component 114 may use the contextual information retrieved by the contextual information component 112\n(e.g., received e-mails, browsing history) to determine that the user is currently planning a trip to Hawaii.  The task, in this example, would be planning a trip to Hawaii.  In another example, the task identification component 114 may determine from a\nuser's search history that the user would like to purchase a new camera.  The task in this case would be to purchase a new camera.  Other tasks that could be inferred from contextual information corresponding to a user other than planning a trip and a\nshopping journey include a user's personal finances, taxes, searching for a new home, searching for a college, or really any other task that requires multiple subtasks to complete.  In embodiments here, a task is referred to as a long running task.  A\nlong running task is a task that takes some time to complete.  It could take a couple of hours, a few days, weeks, months, years, etc. In some embodiments, a long running task is not a short task that can be completed in a single step.  For instance, a\ntaskline comprising multiple subtasks may not be helpful to a user or may not even be possible to generate when a task comprises just a single item.  The tasklines that are generated using embodiments described herein represent a task comprising multiple\nsubtasks, and that take some time to complete.\nThe subtask identification component 116 is configured to identify one or more subtasks that correspond to the task identified by the task identification component 114.  There are many ways that the subtask identification component 116 may\nidentify subtasks.  Many of these ways can be used in combination with one another.  One exemplary way to identify subtasks is to use a rules-based system where certain subtasks are stored in association with a particular task.  For example, for a task\nrelating to travel, some exemplary subtasks that may be identified in the early stages of the trip planning may include alternative destinations, reviews from other travelers, deals and discounts, rental car options, hotel options, etc. Some exemplary\nsubtasks that may be identified and presented to the user once the user has booked travel include flight status, visa requirements, weather, attractions, restaurant suggestions, travel time from one location to another along the user's route, currency\nconversion, emergency numbers, etc. As mentioned, some of these subtasks may be suggested based on a rules-based system that pre-populates subtasks as being associated with a particular task.\nAlternatively, subtasks may be identified by the subtask identification component 116 based on the user's contextual information.  For instance, the subtask identification component 116 may have the intelligence to determine if something found\nin the user's contextual information is related to the identified task.  For instance, if the task is determined to be the user planning a vacation, the subtask identification component 116 may search through contextual information to determine that the\nuser has a strong preference for a particular car rental company, and that the user strongly dislikes a certain airline.  In this case, the subtask identification component 116 would have the intelligence to learn this information not only for this task\nbut for future asks, and would provide recommendations for the car rental company preferred by the user, when possible, and would not provide airline recommendations for the airline disliked by the user, when possible.\nThe ranking component 118 is generally configured to rank the subtasks identified by the subtask identification component 116, discussed above.  The ranking of subtasks could be based on multiple factors.  For instance, the ranking system may\ntake into consideration a current time, the current location of the user, other subtasks that have already been performed by the user or otherwise crossed off of the list of potential subtasks, other contextual information, etc. As will be described\nfurther herein, the ranking component 118 may continuously rank the subtasks that have not yet been performed so that the taskline can be dynamically updated.\nThe subtask organization component 120 is configured to determine an order of the subtasks after they have been ranked by the ranking component 118.  For instance, as mentioned above, the ranking could be based on one or more factors.  Once\nranked, the subtask organization component 120 may determine which order is most appropriate for the given task, for example.  If the task is a trip out of town, the order of the subtasks may different than the order of subtasks for an item purchase\ntask.  The subtask organization component 120 may recommend a particular order of subtasks to the dynamic modification component 122.\nThe dynamic modification component 122 is generally configured to determine when a taskline should be modified, such as when the subtasks in a taskline are to be reordered or changed (e.g., added, removed).  The dynamic nature of the tasklines\ndescribed herein allows the tasklines to constantly be relevant and useful to the user.  As will be shown herein in various figures of exemplary screenshots, a taskline may be dynamically modified based on a user's location, such as whether a user is\nleaving for the airport, has arrived at the airport for a flight, or has reached the destination.  As mentioned herein, not only is the system able to dynamically modify the taskline with updated information and also based on the user's whereabouts,\netc., but the user may modify the taskline to add/edit/remove a subtask or to add details to a subtask (e.g., marking it as completed) or to edit properties of the task itself, such as changing the name from \"Trip to Hawaii\" to \"Paradise in Pacific.\"\nFIG. 2 is a diagram of an exemplary flowchart, generally represented as item 200, for generating a dynamic taskline, in accordance with embodiments described herein.  At block 202, contextual information is determined.  This could include\nlocations, times, calendar entries, meetings, browser history, social media information, and the like.  At block 204, the contextual information determined at block 202 is ordered, such as in order of time.  At block 206, next possible tasks are\nidentified from the contextual information, determined based on what may be important to the user at that time.  For instance, if browser history indicates the user has been performing extensive searches for a camera, the next task could be \"purchase a\ncamera.\" One or more subtasks processors labeled 208, 210, 212, and 214 are then responsible for determining which subtasks are appropriate for the task.  These subtask processors process the contextual information gathered at block 202 to determine\nroutes, weather, best prices on items, transportation options, traffic conditions, restaurants to recommend based on what the user likes, etc. While four processors are illustrated in FIG. 2, it should be noted that processor 214 is termed \"subtask N\nprocessor,\" and therefore any number of processors may be used to identify relevant subtasks to present to the user, where the subtasks correspond to the task that is the subject of the taskline.\nThe subtasks are then sent to the subtask ranker 216, which, as described above, is configured to rank the subtasks in one of many ways.  Subtasks may be ranked by a current user location, other subtasks that have been performed or completed by\nthe user, etc. The block 218, the taskline is organized and an order for the subtasks in the taskline is recommended.  The taskline may then be presented to the user on a user device.\nTurning now to FIG. 3, a screenshot is depicted of a mini taskline 300, in accordance with embodiments described herein.  Mini taskline 300 comprises subtasks 302, 304, 306, and 308, all of which correspond to the task, which is an upcoming\ntrip.  These subtasks include flight information, check-in information, time to drive to the airport, and weather in the destination city.  As shown by item 310, a user selection, indicated by item 312, of \"open my trip plan,\" can open a full taskline,\nshown in FIG. 4, corresponding to mini taskline 300.\nAs mentioned, FIG. 4 is a screenshot of a dynamic taskline 400 displayed in response to a user selection on the screenshot of FIG. 3.  This dynamic taskline, in one embodiment, could be stored in its current form on the user's device and thus be\navailable to the user even when the user's device is not online.  When the device is online and the dynamic taskline is modified, the modified taskline could be stored on the device for future offline use.  Multiple subtasks are illustrated in FIG. 4,\neach of which is associated with the same task, which here, is a Seattle trip on April 5.  As shown, subtask 402 is the user's flight information, showing two legs of the trip from Hyderabad to Seattle.  Subtask 404 is the user's route to the airport. \nSubtask 406 is information regarding Hyderabad Airport, where the user initiates the trip to Seattle.  Subtask 408 is currency information between Indian and U.S.  currency, and subtask 410 is restaurant recommendations for the user once the user arrives\nin the destination city of Seattle.  As mentioned, the subtasks are identified based on contextual information associated with the user.  While some systems use solely the user's location, such as Seattle in this example, this system determines which\nrestaurants to present to the user based on much more than just a location.  For instance, the user's past restaurant choices, as inferred from social media postings and other interactions, browser history, etc., can be used to determine which\nrestaurants the user would like.\nFIG. 5 is a screenshot of another dynamic taskline 500, in accordance with embodiments described herein.  Taskline 500 includes a plurality of subtasks, identified by item 502 for simplicity.  The task is a user's trip to Bangkok, and the\nrelated subtasks include flight scheduling, a hotel booking, a car booking, weather information for the destination location, a currency converter, and events and restaurant recommendations in the destination cities.  It should be noted that the subtasks\nillustrated in the figures herein are provided solely as examples of subtasks, and that these particular subtasks are not limiting to embodiments described herein.  Other subtasks could be identified and presented for the user based on many factors,\nincluding contextual information associated with the user and what the task is.\nFIGS. 6-8 are screenshots of dynamic tasklines having contents based on a current location of a user, in accordance with embodiments described herein.  These figures illustrate the dynamic nature of the dynamic tasklines, as described herein. \nInitially, FIG. 6 depicts a screenshot of a dynamic taskline 600 having subtasks that were identified and ordered based on the user being either at home or on his/her way to the airport, as indicated by the subtasks shown here.  These subtasks include\nsubtask 602 of the flight information and subtask 604 of the time it takes to get to the airport, including traffic conditions.  At the bottom of this taskline 600 could be an image of the destination location, and an indication of the task, which is the\nuser's trip to Bangkok on March 8.\nFIG. 7 illustrates a screenshot of a dynamic taskline 700 having the same task of dynamic taskline 600, but has been dynamically modified based on the user not being located at the JFK airport for the first leg of the flight to Bangkok, with the\nfirst leg being a route from New York City to Seattle.  Subtasks in taskline 700 include subtask 702 of the flight information, and subtask 704 of a map of JFK airport.  Importantly, subtask 704 illustrates the personalized nature of the tasklines\ndescribed herein.  For instance, subtask 704 provides an indication to the user that the user's favorite donut shop is located in the JFK airport.  This was provided to the user based on contextual information gathered for that particular user.  For\ninstance, this could have been determined by the user posting about that donut shop on a social media site, or by accessing the user's browsing history, where the user may have searched for that donut shop in multiple locations.  Similarly, dynamic\ntaskline 800 has been dynamically modified based on the user being located in the destination city, which here, is Bangkok.  Once in the destination city, the user's interest and priorities may change.  For instance, the subtasks shown in dynamic\ntaskline 800 include subtask 802 of the user's hotel booking, subtask 804 of the car booking, and subtask 806 of the traffic information from the airport to the user's hotel.\nReferring now to FIG. 9, a screenshot is depicted of another dynamic taskline 900, in accordance with embodiments described herein.  The dynamic taskline 900 of FIG. 9, the task is related to the user's finances for the year.  For instance,\nsubtasks related to the user's finances may include various checking/savings accounts, the user's debts, credit card balances and other information relating to credit card, budget information, and investment information, etc. This provides a single area\non the user's device where the user can check the status of the user's finances, instead of logging into multiple accounts, which is time intensive for the user.  The information illustrated in FIG. 9 may have been retrieved by way of contextual\ninformation, and may additionally require the user to input username/password information for each account, when required.  Similar to the other screenshots described herein, the information relating to the user's financial information in FIG. 9 may be\naccessible to the user even when the user's device is offline, and would then be updated the next time the user's device is online.  The screenshot 1000 of FIG. 10 illustrates more detailed information that can be accessed by way of a user selection on\nFIG. 9.  For example, if a user would like to view more detailed information about that user's investments, the user can access information, such as the information shown in screenshot 1000, to easily view this detailed information on the user's\ninvestments.\nFIG. 11 is a flow diagram showing an exemplary method 1100 for generating a dynamic taskline, in accordance with embodiments described herein.  At block 1110, sources are accessed to retrieve contextual information associated with a user.  As\nmentioned, contextual information can be retrieved from various sources, including an e-mail system, Internet/browser search history, search result selections, calendar entries, social media interactions, photographs taken, etc. Contextual information\nmay be stored in a data store, and may periodically be updated, such as at predetermined intervals of time, when new contextual information is detected, etc. At block 1112, a user task is detected, where the user task comprises a plurality of subtasks. \nThe user task is detected from the contextual information associated with the user.  In one embodiment, the user task may be determined based on a point in time that the user task is to occur.  For instance, multiple potential user tasks may be detected\nfrom the user's contextual information.  The one selected may be the task that the user needs to complete first.  For instance, a user task to purchase a new camera and a user task to plan the user's finances may both be detected.  But, it could be\ndetermined that the user is leaving on vacation in one week.  Thus, the user task to purchase a new camera that is to be used on that vacation may take precedence over the task to plan the user's finances.  In some embodiments, multiple user tasks are\nprovided to the user in the form of separate dynamic tasklines.  As described herein, in some embodiments, a user task is a long running task that comprises one or more subtasks.  As used herein, a long running task is a task that may take some time for\nthe user to complete it, and that includes subtasks that are all related to the task at hand.  While termed subtasks, a subtask may not necessarily be a task, but merely something that may be useful to the user.  For example, a subtask of the quickest\nroute to the airport associated with the user's task of an upcoming trip may not be something for user to actually do, but it is something for the user to consider when traveling to the airport.\nAt block 1114, subtasks that are associated with the user task are identified.  In one embodiment, subtasks are identified using the contextual information associated with the user.  For instance, subtasks may be determined based on how many\nsteps the user took in a day, a doctor's appointment that the user has on his/her calendar, etc. In another embodiment, subtasks may be determined using a rules-based system based on the task.  For instance, a task related to travel may have\npredetermined subtasks of car rental, hotel rental, airline information, airport information, travel information to the airport, suggested restaurants, etc. Even when subtasks are determined using a rules-based system, contextual information may\nadditionally be used to personalized the subtasks.  For example, providing restaurant suggestions may be a predetermined subtask to present to the user when the user task is an upcoming trip, but the actual suggestions may be determined based on\ncontextual information to determine what kind of food the user likes, where the user typically eats, etc. In one embodiment, the user may be able to contribute information to be added to an existing subtask, or to the creation of a new subtask.  For\ninstance, user input may be received associated with the user task.  This user input could be used to generate a user-created subtask, which could then be added to the taskline.  This allows the user to have some input as to the subtasks that the user\nfeels would help complete the user task.\nAt block 1116, the subtasks are ranked, in part, based on the user's contextual information.  The ranking of the subtasks could be based on a determination as to what is most important to the user at the particular time that the subtasks are\ndetermined.  As mentioned, contextual information may be continually updated in the system, and this updated contextual information may be used to infer what the user would be most interested in at that particular time.  As shown in FIGS. 6-8, different\nsubtasks are presented on the taskline based on the location of the user.  The determination as to which subtasks are presented on each taskline 600, 700, and 800, and the order in which the subtasks are displayed could be determined based on a ranking\nsystem.  As such, the ranking of the subtasks could be done using many factors, including contextual information, such as the location of the user at a particular time, an inference as to what would be the most useful to the user at the particular time,\nand the like.\nAt block 1118, a taskline is automatically generated based on the ranking of the subtasks.  As mentioned, the taskline generated is personalized to the user.  Instead of simply providing generic information to the user, such as restaurant\nsuggestions based on a location, restaurants are selected based on contextual information, which provides insight as to what the user actually likes and what types of restaurants the user typically visits.  In some embodiments, the taskline may be\navailable to the user even when the user's computing device is offline.  At block 1120, the taskline is dynamically modified based on a particular point in time in which the user is viewing the taskline or updated contextual information associated with\nthe user.\nFIG. 12 is another flow diagram showing an exemplary method 1200 for generating a dynamic taskline, in accordance with embodiments described herein.  At block 1210, a user task corresponding to the user is detected.  This detection of a user\ntask may be based, at least in part, on contextual information associated with a user, which indicates what is important to the user, the user's likes and dislikes, the user's interests, etc. The contextual information may be determined by accessing one\nor more sources, which may include an e-mail system, browser history, search result selections, a calendar, social media interactions, photographs taken or stored by the user, etc. In some embodiments, the user task is a long running task that comprises\na plurality of subtasks that, when completed, contribute to a completion of the user task.  At block 1212, subtasks that are associated with the user task are identified.  In embodiments, subtasks may be received or identified from a third party.  A\nthird party could simply provide information to the system that could be used to determine a subtask, or could provide the actual subtask.  As mentioned herein, the user may also provide input corresponding to the user task.  This input could be used to\ngenerate a subtask that is used in the generation of the taskline.  At block 1214, a taskline is generated that comprises the user task and the subtasks.  This taskline is personalized to the user based on the contextual information.  At block 1216, for\na duration of time corresponding to the user completing the subtasks, contextual information associated with the user is continually monitored for updated contextual information.  This updated contextual information is used to dynamically modify the\ntaskline at block 1218.  The dynamic modification of the task line may include modifying a display order of the subtasks in the taskline.  This could be done by a ranking system or by some other means.\nHaving briefly described an overview of embodiments of the present invention, an exemplary operating environment in which embodiments described herein may be implemented is described below in order to provide a general context for various\naspects of the present invention.  Referring initially to FIG. 13 in particular, an exemplary operating environment for implementing embodiments described herein is shown and designated generally as computing device 1300.  Computing device 1300 is but\none example of a suitable computing environment and is not intended to suggest any limitation as to the scope of use or functionality of the invention.  Neither should the computing device 1300 be interpreted as having any dependency or requirement\nrelating to any one or combination of components illustrated.\nThe invention may be described in the general context of computer code or machine-useable instructions, including computer-executable instructions such as program modules, being executed by a computer or other machine, such as a personal data\nassistant or other handheld device.  Generally, program modules including routines, programs, objects, components, data structures, etc., refer to code that perform particular tasks or implement particular abstract data types.  The invention may be\npracticed in a variety of system configurations, including hand-held devices, consumer electronics, general-purpose computers, more specialty computing devices, etc. The invention may also be practiced in distributed computing environments where tasks\nare performed by remote-processing devices that are linked through a communications network.\nWith reference to FIG. 13, computing device 1300 includes a bus 1310 that directly or indirectly couples the following devices: memory 1312, one or more processors 1314, one or more presentation components 1316, input/output ports 1318,\ninput/output components 1320, and an illustrative power supply 1322.  Bus 1310 represents what may be one or more busses (such as an address bus, data bus, or combination thereof).  Although the various blocks of FIG. 13 are shown with lines for the sake\nof clarity, in reality, delineating various components is not so clear, and metaphorically, the lines would more accurately be grey and fuzzy.  For example, one may consider a presentation component such as a display device to be an I/O component.  Also,\nprocessors have memory.  We recognize that such is the nature of the art, and reiterate that the diagram of FIG. 13 is merely illustrative of an exemplary computing device that can be used in connection with one or more embodiments of the present\ninvention.  Distinction is not made between such categories as \"workstation,\" \"server,\" \"laptop,\" \"hand-held device,\" etc., as all are contemplated within the scope of FIG. 13 and reference to \"computing device.\"\nComputing device 1300 typically includes a variety of computer-readable media.  Computer-readable media can be any available media that can be accessed by computing device 1300 and includes both volatile and nonvolatile media, removable and\nnon-removable media.  By way of example, and not limitation, computer-readable media may comprise computer storage media and communication media.\nComputer storage media include volatile and nonvolatile, removable and non-removable media implemented in any method or technology for storage of information such as computer-readable instructions, data structures, program modules or other data. Computer storage media includes, but is not limited to, RAM, ROM, EEPROM, flash memory or other memory technology, CD-ROM, digital versatile disks (DVD) or other optical disk storage, magnetic cassettes, magnetic tape, magnetic disk storage or other\nmagnetic storage devices, or any other medium which can be used to store the desired information and which can be accessed by computing device 1300.  Computer storage media excludes signals per se.\nCommunication media typically embodies computer-readable instructions, data structures, program modules or other data in a modulated data signal such as a carrier wave or other transport mechanism and includes any information delivery media. \nThe term \"modulated data signal\" means a signal that has one or more of its characteristics set or changed in such a manner as to encode information in the signal.  By way of example, and not limitation, communication media includes wired media such as a\nwired network or direct-wired connection, and wireless media such as acoustic, RF, infrared and other wireless media.  Combinations of any of the above should also be included within the scope of computer-readable media.\nMemory 1312 includes computer storage media in the form of volatile and/or nonvolatile memory.  The memory may be removable, non-removable, or a combination thereof.  Exemplary hardware devices include solid-state memory, hard drives,\noptical-disc drives, etc. Computing device 1300 includes one or more processors 1314 that read data from various entities such as memory 1312 or I/O components 1320.  Presentation component(s) 1316 present data indications to a user or other device. \nExemplary presentation components include a display device, speaker, printing component, vibrating component, etc.\nI/O ports 1318 allow computing device 1300 to be logically coupled to other devices including I/O components 1320, some of which may be built in. Illustrative components include a microphone, joystick, game pad, satellite dish, scanner, printer,\nwireless device, etc.\nIllustrative I/O components include a microphone, joystick, game pad, satellite dish, scanner, printer, display device, wireless device, a controller (such as a stylus, a keyboard, and a mouse), a natural user interface (NUI), and the like.  In\nembodiments, a pen digitizer (not shown) and accompanying input instrument (also not shown but which may include, by way of example only, a pen or a stylus) are provided in order to digitally capture freehand user input.  The connection between the pen\ndigitizer and processor(s) 1314 may be direct or via a coupling utilizing a serial port, parallel port, and/or other interface and/or system bus known in the art.  Furthermore, the digitizer input component may be a component separated from an output\ncomponent such as a display device, or in some embodiments, the usable input area of a digitizer may coexist with the display area of a display device, be integrated with the display device, or may exist as a separate device overlaying or otherwise\nappended to a display device.  Any and all such variations, and any combination thereof, are contemplated to be within the scope of embodiments of the technology described herein.\nAn NUI processes air gestures, voice, or other physiological inputs generated by a user.  Appropriate NUI inputs may be interpreted as ink strokes for presentation in association with the computing device 1300.  These requests may be transmitted\nto the appropriate network element for further processing.  An NUI implements any combination of speech recognition, touch and stylus recognition, facial recognition, biometric recognition, gesture recognition both on screen and adjacent to the screen,\nair gestures, head and eye tracking, and touch recognition associated with displays on the computing device 1300.  The computing device 1300 may be equipped with depth cameras, such as stereoscopic camera systems, infrared camera systems, RGB camera\nsystems, and combinations of these, for gesture detection and recognition.  Additionally, the computing device 1300 may be equipped with accelerometers or gyroscopes that enable detection of motion.  The output of the accelerometers or gyroscopes may be\nprovided to the display of the computing device 1300 to render immersive augmented reality or virtual reality.\nEmbodiments presented herein have been described in relation to particular embodiments which are intended in all respects to be illustrative rather than restrictive.  It will be understood that certain features and sub-combinations are of\nutility and may be employed without reference to other features or sub-combinations.  This is contemplated by and is within the scope of the claims.", "application_number": "14812912", "abstract": " Methods and systems are provided for automatically generating a dynamic\n     taskline. Initially, sources are accessed to retrieve contextual\n     information associated with a user. From this contextual information, a\n     user task is detected that comprises subtasks. Subtasks are identified,\n     where the subtasks are associated with the user task. The subtasks are\n     ranked based, in part, on the contextual information associated with the\n     user. A taskline is automatically generated based on the ranking of the\n     subtasks. The taskline is dynamically modified based on a particular\n     point in time or updated contextual information associated with the user,\n     to constantly provide the user with relevant and useful information.\n", "citations": ["8069422", "8326859", "8412716", "8694350", "8694355", "8751472", "9009592", "20040019603", "20080178105", "20110119068", "20110126123", "20110145761", "20120030227", "20120036137", "20120036510", "20120259852", "20120303792", "20120311447", "20130091453", "20130283211", "20140033071", "20140046590", "20140074545", "20140115464", "20140253455", "20150005009", "20150006564", "20150134393", "20160065521", "20160077674"], "related": []}, {"id": "20170075994", "patent_code": "10372759", "patent_name": "Profile based content retrieval for recommender systems", "year": "2019", "inventor_and_country_data": " Inventors: \nBarbieri; Mauro (Eindhoven, NL), Pronk; Serverius Petrus Paulus (Vught, NL), Korst; Jan (Eindhoven, NL)  ", "description": "<BR><BR>FIELD OF THE INVENTION\nThe present invention relates to an apparatus, a method, and a computer program product for controlling a recommender system for content retrieval.\n<BR><BR>BACKGROUND OF THE INVENTION\nHard-disk drives and digital video compression technologies have created the possibility of time-shifting live television (TV) and recording a large number of TV shows in high quality without having to worry about the availability of tapes or\nother removable storage media.  At the same time, digitalization of audiovisual signals has multiplied the number of content sources for an average user.  Hundreds of channels are available using a simple parabolic antenna and a TV receiver.  Huge\namounts of video clips are published daily on the Internet across various services, and all major content producers are already making their entire content libraries available online.  As a consequence, thousands of potentially interesting programs are\nmade available every day and can be recorded and stored locally for later access.\nHowever, in view of this enormous amount of offered content items, individual content selection becomes an important issue.  Information that does not fit to a user profile should be filtered out and the right content item that matches a user's\nneeds and preferences (e.g. a user profile) should be selected.\nRecommender systems: address these problems by estimating a like-degree of a certain content item for a certain user profile and automatically ranking the content item.  This can be done by comparing a content item's characteristics (e.g.\nfeatures, metadata, etc.) with a user profile or with similar profiles of other users.  Thus, recommender systems can be seen as tools for filtering out unwanted content and bringing interesting content to the attention of the user.\nThe use of recommender technology is steadily being introduced into the market.  Among various examples, websites offer a recommender to support users in finding content items (e.g. movies) they like, and electronics devices (e.g. personal video\nrecorders) use recommender for automatic filtering of content items.  Recommender systems are increasingly being applied to individualize or personalize services and products by learning a user profile, wherein machine learning techniques can be used to\ninfer the ratings of new content items.\nRecommenders are typically offered as stand-alone services or units, or as add-ons (e.g. plug-ins) to existing services or units.  They increasingly appear in consumer devices, such as TV sets or video recorders.  Recommenders typically require\nuser feedback to learn a user's preferences.  Implicit learning frees the user from having to explicitly rate items, and may by derived by observing user actions such as purchases, downloads, selections of items for play back or deletion, etc. Detected\nuser actions can be interpreted by the recommender and translated into a rating.  For example, a recommender may interpret a purchase action as positive rating, or in case of video items, a total viewing duration of more/less than 50% may imply a\npositive/negative rating.\nAn example of a recommender is presented in US 2008/0104127 A1.  There, a media guidance system is described which is capable of recommending content items to a user based on their relevancy.  For retrieving content items, the system generates\nsearch criteria first, which are derived from personalisation data that have been generated by so monitoring user behaviour and/or by receiving explicit user preferences.  For instance, the search criteria can be the string: \"Silvester Stalone\", if the\npersonalisation data yield that the user likes this actor.  Such search criterion is sent to a media information data base for retrieving matching content items.  Matching content items are rated and, if the rated items are relevant, are eventually\nrecommended to the user.\nGrossly speaking, there are two types of recommender systems, those based on a community of users and those based on metadata.\nThe first type is known as collaborative filtering, where either (i) members of the community are characterized by the ratings they give to items or (ii) items are characterized by the ratings they receive from the members of the community. \nThese characterizations are next used to define similarity among users or items, respectively.  For a specific member of the community and a specific item that has not yet been rated by this member, these similarities are used to infer for this member a\nrating for this item by combining ratings of similar users or similar items, respectively.\nThe second type of recommender systems uses available metadata about items, which typically cornea in the form of features and associated values or lists of values.  The rating history of a user is exploited to build a profile of this user in\nterms of feature-value pairs, indicating for these pairs a like-degree.  For a new item that has not yet been rated by this user, its metadata used, and the like-degrees of each feature-value pair present are combined to obtain an overall rating.  A\nsimple, but popular algorithm in this context is called naive Bayes, and it employs Bayesian classification.\nUsers of personal video recorders would like to have access to any content available, independently of its source.  No matter whether the content will be broadcast (and thus listed in an electronic program guide (EPG)), or is available in a\nvideo-on-demand library or somewhere else on the Internet, users would like to have access to it and a recommender system should be able to provide recommendations for videos independently from its location or source.  Independently of its type, whether\nit is based on collaborative filtering or is content-based, a recommender system needs to have access to all the items for which a recommendation has to be generated.  For example, a recommender for a video-on-demand library needs to access all the items\nof the video-on-demand library to be able to calculate for each item the probability that a given user would like it, and ultimately to select a list of top rated items.\nHowever, filtering entire databases and rating all items based on a user profile does not work for very large distributed databases, not only because it is inefficient and not scalable, but especially because it requires access to all the items\nof all the databases for which recommendations have to be generated.\n<BR><BR>SUMMARY OF THE INVENTION\nIt is an object of the present invention to provide an efficient control for recommender systems, which enables recommendations for items of remote databases without having to access all items of the database.\nThis object is achieved by an apparatus as claimed in claim 1, a method as claimed in claim 6, and a computer program product as claimed in claim 7.\nAccordingly, the user profile normally used by the recommender to predict user ratings is employed to generate a targeted query for the content sources yielding a set of results that can be scored or rated by the recommender and provided as\nsuggestions to the user.  The feature-value pairs extracted from the user profile are used to compose a targeted query to be sent to the content sources.  The results are merged and rated by the recommender to provide a list of recommended, highly\nrelevant items.  Consequently, the recommender system does not need to have complete access to entire databases or other types of content sources to produce relevant recommendations.\nA feature selector is provided for selecting from the feature-value pairs extracted by the feature-value extractor those feature-value pairs which are most discriminative for said user profile.  Thereby, the query can be restricted to most\ndiscriminative feature-value pairs.\nThe feature selector is adapted to use a Relief algorithm, e.g. the Relief algorithm described in by Kira, K., & Rendell, L. (1992): The feature selection problem: Traditional methods and a new algorithm, Proceedings of the 10th National\nConference on Artificial Intelligence, San Jose, Calif., July 12-16, 129-134 or a variation thereof for selecting the most discriminative feature-value pairs.  Thereby, an efficient selection procedure can be provided.\nAccording to a second aspect, which can be combined with the above first aspect, the composing of the query and the rating of the results may be iterated until a predetermined number of relevant content items has been obtained.\nAccording to a third aspect, which can be combined with the above first or second aspect, if there are several discriminating values associated to a single feature, then this provides the advantage that different features can be turned on and\noff during query composition, so that, in an iterative fashion, the resulting set of items can be controlled.  This can be generalized to multiple features and the system can keep track of which values of the same or different features lead to the best\nresults and prioritize them to improve the query composition step and reduce the number of iterations required.\nAccording to a fourth aspect, which can be combined with any one of the above first to third aspects, the feature-value extractor may be adapted to extract feature-value pairs based on at least one of positive and negative user ratings. \nThereby, queries that include and/or exclude feature values can be composed.\nAccording to a fifth aspect, which can be combined with any one of the above first to fourth aspects, the query composer may be adapted to expand the query using a thesaurus or an ontology.\nAccording to a sixth aspect, which can be combined with any one of the above first to fifth aspects, the query composer may be adapted to extend the query to categories other than those of the user profile.  Thus, cross-domain recommendations\ncan be provided.\nAccording to a seventh aspect, which can be combined with any one of the above first to sixth: aspects, the user profile may have been derived from the recommender system.\nAccording to an eighth aspect, which can be combined with any one of the above first to seventh aspects, co-occurrences of feature-value pairs may be counted and only those feature-value pairs with a sufficient co-occurrence count may be\ncombined in the query.  Thereby, the number of unsuccessful query attempts can be reduced.\nIt is noted that the above apparatus can be implemented as discrete hardware circuitry with discrete hardware components, as an integrated chip, as an arrangement of chip modules, or as a signal processing device or computer device or chip\ncontrolled by a software routine or program stored in a memory. <BR><BR>BRIEF DESCRIPTION OF THE DRAWINGS\nThe invention will now be described, by way of example, based on embodiments with reference to the accompanying drawings, wherein:\nFIG. 1 shows a schematic block diagram of a recommender system according to an embodiment of the present invention;\nFIG. 2 shows a schematic flow diagram of a procedure for profile based content retrieval according to an embodiment of the present invention; and\nFIG. 3 shows a table with a feature-value excerpt of an exemplary user profile.\n<BR><BR>DESCRIPTION OF EMBODIMENTS\nEmbodiments of the present invention will now be described based on an exemplary recommender system which generates ratings on content items, such as books, TV programs, movies, etc.\nFIG. 1 shows a schematic block diagram of a recommender system according to a first embodiment which is configured to retrieve content items from various content sources 103.  The content sources 103 provide for example at least audio/video\ninformation in a broadcasting or on-demand fashion.  In addition, the content sources 103 may provide information data, e.g., EPG information inside a vertical blanking interval of the video signal, or MPEG-7 metadata on segments of a particular content\nitem (e.g. the scene boundaries of a movie).  An electronic program guide (EPG) service on the Internet may for example provide information data on TV programs.  Such information data retrieved from the content sources or Internet services may be\nsupplied to at least one pre-selection filter (F) 105 which is associated with a personalized content channel and filters content items accordingly, e.g. by means of logic rules.  It is noted that any number of personalized content channels could be\nprovided.  The output of the pre-selection filter 105 is connected to a recommender engine (RE) 107.  Thus, each personalized content channel may have an own recommender engine 107 associated therewith.  The recommender engine 107 and hence personalized\ncontent channel has a user profile (P) 109 associated therewith.  The output of the recommender engine 107 is connected to a scheduler (SCH) 111.  The scheduler 111 is connected to a storage device 113 (e.g. a set of hard-disk drives), and to a selector\n(SEL) 115.  The content source 103 can be connected to the selector 115 which may comprise at least one set of content isolation means (e.g. a tuner or the like) which allows to isolate one or more content items for recording on the storage device 113. \nThe output of the selector 115 is connected to the storage device 113.\nAdditionally, the first embodiment is adapted to provide recommendations for items of the content sources 103 (e.g. remote databases) without having to access all the items of the database, provided that a respective database of the content\nsources 103 has a query interface.  The basic idea is that the user profile 109 normally used by the recommender engine 107 to predict user ratings is employed to generate a targeted query for the content sources 103 yielding a set of results that can be\nscored by the recommender engine 107 and provided as suggestions to the user.\nFor example, for a user who likes martial arts movies, the system automatically extracts from the user profile feature values that stand out, i.e., have a high like-degree.  In case keywords are used as desired features, then such feature values\nmay be \"martial arts\", \"karate\", or cast names like \"Bruce Lee\", or \"Chuck Norris\".  The feature-value pairs are then used to compose a query to be sent to an entire list of the content sources 103 (e.g. video search engines and video-on-demand\nlibraries).  The results are merged and rated by the recommender engine 107 to provide a top N list of recommended relevant items.\nTo achieve this, the recommender system according to the first embodiment comprises a feature-value extractor or extraction function (FVE) 116 which is configured to access and analyze the user profile 109 to extract feature-value pair\ncombinations that stand out, e.g. that have high positive or negative ratings.  Optionally, an additional feature selector or selection function (FS) 117 may be provided so as to use only a top number of feature values of the set of results, which are\nmost discriminative for a certain user profile.  Here, high negative ratings may be employed as well to select feature values to be excluded in the query.\nThe user profile analysis performed by the feature-value extractor 116 and optional feature selector 117 is followed by a query composer or composing function 118 which receives the extracted feature-value pairs and composes a query using the\ngiven feature-value pairs obtained from the user profile analysis.  The composed query is then submitted to the content sources 103.\nThe operation of the apparatus of FIG. 1 will now be described.  Information data of a current content item to be played out on a personalized content channel is gathered from the content sources 103 or via other means, e.g., via transmission in\nthe vertical blanking interval of an analogue TV broadcast signal or via digital video broadcast (DVB) transport streams, or combinations of any of the above.  The content item may be a TV program, data stream containing video and/or audio data or a\nsegment of a program etc.\nThe information data may comprise a plurality of attributes and attribute values associated with the content item such as title, actors, director and genre.  Each profile 109 is based on the information data together with data indicating the\n\"like\" or \"dislike\" of the user.  The rating of a \"like\" and \"dislike\" can be based on feedback or content items that pass the associated pre-selection filter 105.  This feedback can be given as explicit rating by the users that use the particular\npersonalized content channel.  The ratings can be made in several ways.  For example, the user can, using a remote control device, indicate for a currently selected content item or a given attribute of the current content item his rating (\"like\" or\n\"dislike\") by pressing appropriate buttons on a user interface (e.g. the remote control device) whilst bearing the current content item.  Alternatively, the behaviour of the user can be observed.  For example, if the user watches a current content item\nfor more than a predefined time interval (for example, 20 minutes), this could, automatically indicate \"like\".  In a more advanced setting, a \"like\" degree on a discrete or continuous scale can be provided or calculated instead of just a binary \"like\" or\n\"dislike\" classification.\nWhen information data of a content item passes the filter 105, this information data is forwarded to the recommender engine 107 which calculates a biased \"like\" degree or rating, based on its associated user profile 109, for this subsequent\ncontent item.  The information data associated to the subsequent content item is then forwarded, along with the computed rating, to the scheduler 111, which subsequently computes recording schedule that will be used to schedule the recording of content\nitems offered by the recommender engine 107 onto the storage device 113.  In particular, the scheduler 111 may primarily consider the content items of high like degree or rating while still considering sufficient new content for each personalized content\nchannel.  To this end, the recording schedule computed by the scheduler 111 is used to instruct the scheduler 115 to select the content items available from a respective one of the content sources 103 to record them on the storage device 113.\nUse or user profiles can be derived using three basic methods: implicit profiling; explicit profiling; and feedback profiling.  Implicit profiling methods derive content use profiles unobtrusively from the user's use histories, e.g., sets of TV\nshows watched and not watched.  Explicit profiling methods derive content use profiles from user's answered questions as that include explicit questions about what the user likes and dislikes.  Feedback profiling methods derive use profiles from content\nitems for which a user has provided ratings of the degree of like or dislike.\nFIG. 2 shows a schematic flow diagram of a profile based content retrieval procedure which can be applied in the first embodiment.\nThe first step \"user profile analysis\" consists of analyzing the user profile to extract feature-value pair combinations that stand out most.  These can be feature-value pairs with a high number of positive ratings when compared with other\nfeature-value combinations, and can be achieved by the feature-value extractor 116 and optional feature selector 117 of FIG. 1.\nFIG. 3 shows a table with a feature-value excerpt of an exemplary user profile for the feature `keyword`.  In FIG. 3, the keywords \"Japan\", \"Karate\", \"Martial arts\", and \"Tokyo\" stand out with respect to the rest of the keywords in terms of\nnumber of positive ratings.  The use has given a positive rating to ten items having such feature values.  These four feature-value pairs are passed on to the second step of FIG. 2, \"query composition\".  In this step a query is composed using the given\nfeature-value pairs, which can be achieved by the query composer 118 of FIG. 1.  The exact form of the query depends on the search engine or database of the content sources 103 to query.  For free-text search engines, the query can consist of the list,\nof values of the feature-value pairs.  In the example above, it would be: [\"Japan\" \"Karate\" \"Martial arts\" \"Tokyo\"]. For databases or search engines that allow specifying different fields in a query, the example above could lead to the query:\n[keyword:\"Japan\" keyword:\"karate\" keyword:\"martial arts\" keyword:\"Tokyo\"].\nIn the third step the query is submitted to a set of search engines or databases that contain possibly relevant items.  It is noted that different queries can be submitted to different search engines or databases of the content sources 103 to\ncomply with different formats and application programming interfaces (APIs).  The results are then retrieved and merged to form one list of related items.  From this list, items that the user has already seen or has previously black-listed can be\nremoved.  The remaining items are then rated in the fourth step by the recommender engine 107 from which the first user profile 109 was derived.  The result is a sorted list of related items with those items at the top that have a high probability of\nbeing liked by the user.  The list of rated items is then ready to be presented to the user in the fifth step of the procedure.\nThe steps \"query composition\", \"query submission and retrieval of results\", and \"rating of items according to user profile\" may be iterated until a sufficient number of highly rated relevant items has been obtained.  At each iteration, a\ndifferent set of feature-value pairs could be used starting with a rich set defining a very specific query that may lead to too few results and removing feature-value pairs, thus making the query less specific, to obtain more results.  In the example\nabove, a first query [\"Japan\" \"Karate\" \"Martial arts\" \"Tokyo\"] may return 164 results on a video database, a second query, [\"Japan\" \"Karate\" \"Martial arts\"], without the keyword \"Tokyo\" may returns 1180 results, and a third query, [\"Japan\" \"Karate\"],\nwithout the keywords \"Tokyo\" and \"Martial arts\" may return 5760 results.\nAlternatively, it is possible to keep track of co-occurrences of feature-values (feature values that appear in the same item) and preferably make only those combinations where the co-occurrence count is sufficiently high to reduce the number of\nunsuccessful query attempts.\nWhen multiple feature-value pairs corresponding to the same feature are used, as in the examples above, where the feature-value pairs all correspond to the feature \"keyword\", at each iteration, the query composition can turn on and off different\nfeatures.  For example, one query could be generated using \"keyword\" feature values and another one using e.g. \"cast\" feature values.  The system can keep track of which features lead to the best results and prioritize them to improve the query\ncomposition step and reduce the number of iterations required.\nAccording to a second embodiment, the recommender system may be modified to use only the top N features discovered by using a feature selection procedure which may be performed at the optional feature selector 117 of FIG. 1.  The top N features\nmay be the features that are the most discriminative for a certain profile.\nAn example of such a feature selection procedure may be the Relief algorithm which is based on feature weighting.  The diagonal elements of a projection matrix are allowed to take real-valued numbers, instead of binary ones.  This enables the\nemployment of some well-established optimization techniques and allows for efficient algorithm implementation.  Among the existing feature weighting algorithms, the Relief algorithm, as described for example in K. Kira and L. A. Rendell, A practical\napproach to feature selection, Proc.  9th Int.  Conf.  Mach.  Learn., (1992), pp.  249-256, is considered one of the most successful ones due to its simplicity and effectiveness.  It has been recently shown that the Relief algorithm is an online\nalgorithm that solves a convex optimization problem aimed at maximizing a margin-based objective function.  The margin is defined based on the one-nearest-neighbour classifier.  Compared with filter methods, the Relief algorithm usually performs better\ndue to the performance feedback of a nonlinear classifier when searching for useful features.  Compared with conventional wrapper methods, by optimizing a convex problem, the Relief algorithm avoids any exhaustive or heuristic combinatorial search, and\nthus can be implemented efficiently.  As an extension of the first and second embodiments, also negative ratings of the user profile can be employed to create queries that exclude results with feature values corresponding to the negative ratings (e.g.\n[\"Japan\" \"Karate\" \"Martial arts\" \"Tokyo\" exclude:\"India\"]).\nThe query composition step performed by the query composer 118 of FIG. 1 can also include an optional \"query expansion\" operation that expands the query based on the given feature-value pairs using e.g. a thesaurus or an ontology.  This can be\nemployed also to prevent terminology mismatches among databases.\nIt is noted that the search can be extended to items of different categories than the original profile.  For example, information on books can be retrieved from e.g. from an online store and suggested based on a TV viewing profile (cross-domain\nrecommendation).\nIt is noted that the present invention can be applied to any recommender system for set-top boxes, TV sets, mobile phones, personal digital assistants (PDAs), personal computers (PCs), personal video recorders (PVRs), audio systems (including\nportable audio), Internet services (including audio and video services), and all devices where recommenders are used to collect, filter, and present content items from multiple sources to their users.  The invention is thus not restricted to recommenders\nof television or film content, but can be applied to music, theatre shows, books and all types of products and services for which recommenders can be built.\nIn summary, an apparatus, a method and a computer program product for controlling a recommender system have been described, wherein a user profile normally used by a recommender to predict user ratings is employed to generate a targeted query\nfor the remote database yielding a set of results that can be scored by the recommender and provided as suggestions to the user.\nWhile the invention has been illustrated and described in detail in the drawings and the foregoing description, such illustration and description are to be considered illustrative or exemplary and not restrictive.  The invention is not limited\nto the disclosed embodiments.  From reading the present disclosure, other modifications will be apparent to persons skilled in the art.  Such modifications may involve other features which are already known in the art and which may be used instead of or\nin addition to features already described herein.\nVariations to the disclosed embodiments can be understood and effected by those skilled in the art, from a study of the drawings, the disclosure and the appended claims.  In the claims, the word \"comprising\" does not exclude other elements or\nsteps, and the indefinite article \"a\" or \"an\" does not exclude a plurality of elements or steps.  A single processor or other unit may fulfil at least the functions of FIGS. 1 and 2 based on corresponding software routines.  The computer program may be\nstored/distributed on a suitable medium, such as an optical storage medium or a solid-state medium supplied together with or as part of other hardware, but may also be distributed in other forms, such as via the Internet or other wired or wireless\ntelecommunication systems.  The mere fact that certain measures are recited in mutually different dependent claims does not indicate that a combination of these measures cannot be used to advantage.  Any reference signs in the claims should not be\nconstrued as limiting the scope thereof.", "application_number": "15274190", "abstract": " The present invention relates to an apparatus, a method and a computer\n     program product for controlling a recommender system, wherein a user\n     profile normally used by a recommender to predict user ratings is\n     employed to generate a targeted query for the remote database yielding a\n     set of results that can be scored by the recommender and provided as\n     suggestions to the user.\n", "citations": ["6353810", "7937725", "9477783", "20030066067", "20030066068", "20080104127"], "related": ["13704496", "2011059885"]}, {"id": "20170109787", "patent_code": "10360590", "patent_name": "Auto recognition of acquirable entities", "year": "2019", "inventor_and_country_data": " Inventors: \nKumar; Dileep R. (Redmond, WA), Blais; Philippe (Monroe, WA), Shah; Shrey Nitin (Redmond, WA)  ", "description": "<BR><BR>BACKGROUND\nLarge portions of the world's population use computing devices on a frequent basis.  Indeed, many individuals may spend the majority of their waking hours working and/or recreating with computing devices.  Individuals may use computing devices\nfor work, research, recreation, shopping for (and ultimately purchasing) goods and services, etc.\nData has shown that one of the important blockers for any purchase on a computing device is the number of steps involved in the purchase flow.  People drop off at each step along the way of making a purchase and the more the number of steps, the\nmore the possibility for drop off.  Also, there is a significant percentage of people who come to know about items that they may like to purchase from sources other than an e-commerce website.  For example, a user may obtain information about items from\nan article while browsing the web, a retailer promoting their apps on their home page, someone posting a link in social media sites, a friend sending links to items that he/she recommends etc.\nWhile targeted advertising has been performed using web browser functionality, such as cookies, to monitor e-commerce sites that a user might visit, users using apps other than web browsers or not visiting e-commerce sites may have additional\ninconvenience when attempting to purchase items that they are researching or may otherwise be interested in.\nThe subject matter claimed herein is not limited to embodiments that solve any disadvantages or that operate only in environments such as those described above.  Rather, this background is only provided to illustrate one exemplary technology\narea where some embodiments described herein may be practiced.\n<BR><BR>BRIEF SUMMARY\nOne embodiment illustrated herein includes a method of identifying, to a user, acquirable entities that the user may be interested in. The method includes at a component configured to analyze information across a plurality of applications,\nanalyzing in one or more of the applications being used by a user, content in the one or more applications.  The method further includes based on the content, identifying one or more acquirable entities from the content.  The method further includes\nidentifying to the user the identified acquirable entities.\nThis Summary is provided to introduce a selection of concepts in a simplified form that are further described below in the Detailed Description.  This Summary is not intended to identify key features or essential features of the claimed subject\nmatter, nor is it intended to be used as an aid in determining the scope of the claimed subject matter.\nAdditional features and advantages will be set forth in the description which follows, and in part will be obvious from the description, or may be learned by the practice of the teachings herein.  Features and advantages of the invention may be\nrealized and obtained by means of the instruments and combinations particularly pointed out in the appended claims.  Features of the present invention will become more fully apparent from the following description and appended claims, or may be learned\nby the practice of the invention as set forth hereinafter. <BR><BR>BRIEF DESCRIPTION OF THE DRAWINGS\nIn order to describe the manner in which the above-recited and other advantages and features can be obtained, a more particular description of the subject matter briefly described above will be rendered by reference to specific embodiments which\nare illustrated in the appended drawings.  Understanding that these drawings depict only typical embodiments and are not therefore to be considered to be limiting in scope, embodiments will be described and explained with additional specificity and\ndetail through the use of the accompanying drawings in which:\nFIG. 1 illustrates devices that user may use to view content related to acquirable entities;\nFIG. 2 illustrates a device interacting with a database;\nFIG. 3 illustrates an operating system that includes functionality for identifying acquirable entities;\nFIG. 4 illustrates an application framework with functionality for identifying acquirable entities;\nFIG. 5 illustrates various user interface elements that may be used to access additional information about acquirable entitles; and\nFIG. 6 illustrates a method of identifying to a user acquirable entities that the user may be interested in.\n<BR><BR>DETAILED DESCRIPTION\nEmbodiments described herein may include functionality for discovering various acquirable entities described or depicted on several different user interfaces used by a user.  Such acquirable entities may include, for example, items that can be\npurchased, sampled, obtained through free distribution, etc. Such acquirable entities may be obtained through physical delivery or pick-up for physical items, by download for various digital items, or otherwise appropriately acquired.  Acquirable\nentities may also include services.  For example, an acquirable entity may include a taxi cab ride, house cleaning, yard work, or virtually any other service.\nAs noted, embodiments may be able to identify acquirable entities across a number of different user interfaces used by a particular user.  Examples are now illustrated with reference to FIG. 1.  FIG. 1 illustrates a device 102.  The device 102\nmay be, for example, a mobile phone, tablet or other device.  The device may have a number of apps (short for application and typically used to describe applications on a mobile device, but may be used herein to describe any appropriate application)\ninstalled on the device.  For example, the device may have a browser app, an e-commerce interface app, a word-processor app, a game app, an app marketplace app, a mapping app, or any one of a number of different apps.  Any or all of these different apps,\nor other appropriate apps, may be used to identify acquirable entities.\nA user may select one of the apps 104-1 which causes an interface 106 (see FIG. 2) to be opened to the user.  The interface 106 may include various pieces of text 108, images 110, links 112, videos, music, metadata, etc. that describe or depict\nacquirable entities.  These acquirable entities can be identified and stored in a database 114 for later identification to a user.  The database 114 may be stored directly on the device 102 and/or may be stored in remote storage at a service provider.\nAs noted, a user may select other apps on the device 102.  For example, the user may select the app 104-2 for use.  A different user interface for that app 104-2 may be displayed with various depictions and/or descriptions of acquirable\nentities.  Notably, in some embodiments, the user may manually create the depictions and/or descriptions of acquirable entities.  For example, using a word processing app, the user may create a description of an acquirable entity.  Using a camera app, a\nuser may take a picture of an acquirable entity.  Virtually any app can have depictions and/or descriptions of acquirable entities that can be identified by embodiments of the invention.\nThe database 114 may store acquirable entities across multiple apps.  Indeed, the database 114 may store acquirable entities across multiple devices.  Thus, as illustrated in FIG. 1, a user may use a device 102 with various apps, but may also\nuse a laptop computer 116 which provides access to various applications and interfaces.  Embodiments can identify acquirable entities across the multiple apps and/or devices to provide an encompassing representation of acquirable entities that a user is\ninterested in in a variety of different contexts.\nThis cross-app and/or cross device functionality may be accomplished in a number of different ways.  For example, in one example illustrated in FIG. 3, an operating system 118 on the device 102 may include the functionality for identifying\nacquirable entities.  Thus any apps 104 installed on top of the operating system 118 may be searched by the operating system for identification of acquirable entities.  Further, a user account 120 may be installed in the context of the operating system. \nThis user account may allow for linking between devices which also allow the user to establish the user account 120.  The operating systems on different devices may have the ability to collaborate based on a user account basis.\nIn an alternative example illustrated in FIG. 4, the device 102 may include an application framework 122.  Apps 104 are implemented within the context of the application framework 122.  The application framework 122 may include functionality for\nidentifying acquirable entities for any apps used within the context of the application framework 122.  Again, in this example, a user account 120 may be implemented in the context of the application framework 122 which allows for cross-device entity\ntracking.\nEmbodiments may be able to identify acquirable entities in a number of different ways.  For example, in any user interface of any application, embodiments may be able to identify textual names for acquirable entities, images of acquirable\nentities, link to acquirable entities, metadata describing acquirable entities, etc. For example, in some embodiments, text, images, videos, music, links, etc. could be put through an entity recognition search engine 124 (see FIG. 42), such as Bing\nEntity recognition available from Microsoft Corporation of Redmond Wash.  to determine whether or not a particular user interface lists, describes, or depicts acquirable entities.  This could be done by identifying textual names of acquirable entities,\nidentifying images that depict acquirable entities, identifying a page being viewed in an interface that includes a URL that identifies acquirable entities, or identifying content in a user interface that includes acquirable entities or descriptions or\ndepictions of acquirable entities, etc. For example, the operating system can take a copy of any of the following from any arbitrary app and send it across to Bing or similar services that can translate them to a known entity: (a) screenshot/rendering of\nwhat the app is showing (e.g. an image); (b) text/URLs on what the app is showing; (c) audio/video snippets from what the app is playing; (d) etc. The service can the provide entity information.  This information can then be used to automatically build a\ndatabase 114 of acquirable entities that the user is interested in, and the extent of the interest.\nThere are a number of different ways for determining the extent of interest.  For example, embodiments may determine the amount of time a user spends in a user interface.  For example, in a browser interface, embodiments may determine the amount\nof time spent on a webpage for an entity.  Alternatively or additionally, embodiments may determine the number of times the entity is viewed or detected across multiple different interfaces.  Alternatively or additionally embodiments may determine the\nprominence of an entity in an interface.  For example, within an interface, embodiments may determine the number of times an entity is mentioned.  Alternatively or additionally, embodiments may identify the context within which entities are described or\ndepicted to determine extensive related treatment of the entity.  When an image is displayed, embodiments may be able to identify the prominence of an entity within the image.  For example, if an entity is more in focus than other entities, displayed\nlarger, displayed more in the forefront, etc., the entity may be given a higher weight when determining likelihood of user interest.  Alternatively or additionally, embodiments may determine how recently an entity is viewed by a user.  Entities that are\nviewed more recently and/or with more frequency may be of high interest to a user who wishes to acquire those entities.\nEmbodiments can determine which of the discovered acquirable entities are of particular interest, which are of most interest to the user, or identify a ranking of probable interest in acquirable entities.  Embodiments may additionally provide a\nsimple mechanism for users to access an enumeration or identification of acquirable entities and a simple interface for requesting acquisition of the acquirable entities.\nNotably, identifying acquirable entities can be done on a real time basis and/or based on a user's history.  Thus, acquirable entities may be determined by examining what a user is currently viewing or consuming in applications and/or may be\nbased on a past history of what a user has viewed or otherwise consumed in various applications.\nEmbodiments can use the preceding techniques to both identify acquirable entities of interest and also to identify the level of interest.  For example, embodiments may maintain a database 114 of identified entities.  The database 114 may have a\nranking or rating system that is able to rank or determine probable interest in an entity based on various factors such as those identified above (e.g. frequency of viewing descriptions or depictions, how recent descriptions or depictions are views,\nprominence of descriptions or depictions in an interface, number of different interfaces in which an acquirable entity is viewed, etc.).\nThe ranking or rating can be used to determine if and/or how acquirable entities are presented to a user.  For example, in some embodiments, once an acquirable entity is determined to be of sufficient interest to a user, a user interface element\nmay indicate the acquirable entity to the user.  Such interface elements may be pop-up windows, charms, pull-down menu alerts, user selectable elements, etc. Various scenarios will be illustrated in more detail below.  The list may be presented in\nvarious ways.  For example, the list may simply be an enumeration of acquirable entities.  Alternatively, the list may be presented with links to various sources where entities may be acquired.  Alternatively, the list may be presented in the context of\na web store or other e-commerce portal.  In yet another alternative, embodiments may present contextual ads not based on search, but based on user behavior.\nIn some embodiments, information about entitles may be used to identify other related entities.  For example, if a user has been researching printers, embodiments may identify ink cartridges that could be used with the printers being researched. Alternatively or additionally, different printers with similar specifications or in similar price categories may be identified even though the user has not researched those specific printers.\nA user may be alerted to, and able to access a listing of acquirable entities in a number of different ways.  FIG. 5 illustrates a number of different examples in the context of device 102 and the laptop 116.  While a number of examples are\nshown, it should be appreciated that other elements may be used to accomplish functionality within the scope of embodiments of the invention.\nFIG. 5 illustrates that in some embodiments, a charm 126 may allow a user to access a list of acquirable entities created by embodiments of the invention.  The charm can be accessed from a charms bar 128 that may be constantly or selectively\ndisplayed on a device screen.  The user can select the charm 126 which will cause a user interface to display the list of acquirable entities.\nIn an alternative or additional embodiment, a keyboard key 130 or other hardware key may be configured to provide access to a list of acquirable entities.  In some such embodiments, a soft button 132 may be assigned functionality for opening a\nlist of acquirable entities.\nIn some embodiments, a notification may be issued.  For example, in some embodiments a toast notification 134 may alert a user that acquirable entities are available.  For example, this may occur when embodiments have determined that a user has\nshown sufficient interest in an entity or that some other threshold for an entity has been reached.  In some embodiments, the user can select the notification to obtain access to the list, or can pull down on a notification bar 136 to obtain the list or\nother user interface element giving access to the list of acquirable entities.\nIn some embodiments, an application and associated icon 138 can be used to alert a user regarding identified acquirable entities and/or provide access to a user to a list of acquirable entities.  For example, a user may be able to select the\nicon 138 which causes an application interface to open, which can then be used to display a list of acquirable entities and/or an interface that facilitates a user acquiring an entity, such as a store interface or other appropriate interface.\nIn the example illustrated in FIG. 5, the icon 138 includes a badge counter 140.  The badge counter 140 indicates a number of new or un-reviewed acquirable entities.  Badge counter values may indicate a number of newly identified acquirable\nentities that meet some threshold requirement.  For example, embodiments may identify some threshold level of interest or other threshold level that warrants alerting a user.  The alert may be in the form of an increased badge counter number.  Alerts may\nbe built into the operating system itself.\nIn some embodiments, alerting a user to identified acquirable entities may be based on various external factors.  For example, embodiments can identify that a user is in the proximity of geographical location where entities can be acquired.  For\nexample, if a user has hammers in their list of acquirable entities, and the user walks into or drives near a hardware store, an alert may be issued to the user indicating that entities on their list of acquirable entities could be easily obtained.\nSimilarly, in some embodiments, the list of acquirable entities may be reordered based on location such that entities that can be obtained more easily in a given location are prioritized in a more prominent location in the list.  Alternatively,\nthe entities may be listed more prominently in a displayed list of acquirable entities.  Thus, for example, the list may be reordered, entities that can be obtained in a location can be highlighted, bolded, underlined, colored, or otherwise made more\nprominent.\nLocation may be determined in a number of different ways.  For example, location may be identified based on GPS modules in a device, network triangulation, beacons at locations, etc.\nSimilarly, embodiments may present acquirable entities based on \"digital location.\" Thus, for example, when a user navigates to some e-commerce site, the list may be arranged or entities made prominent (e.g. in the fashion described above for\nphysical locations) if entities are acquirable at the particular e-commerce site.  This differs from what is presently being done in that some e-commerce sites may offer acquirable entities that a user has looked at on the particular site.  In contrast,\nembodiments can present users with a list or identification of acquirable entities identified as relevant based on a user's navigation to a plurality of different sites or use of a plurality of different apps.  Indeed, the user may never have previously\nnavigated to an acquirable entity on an e-commerce site, and yet be presented with a list and/or link on that e-commerce site based on other activities with other web pages and/or other apps.\nIn some embodiments, the entities could be made available from a store for a one-click purchase experience right within the browser/app or any other surface that the user is in. For example, a user may be able to select an entity from a webpage\nin a browser app (or even a word processor app) and purchase that entity directly from interaction within the app based on an underlying store being able to receive the interaction from the app to complete the transaction.\nThe list and potentially the order of the list of acquirable entities can be used for various other purposes.  For example, the list may be used to implement highly targeted advertisements, provide price tracking in an interface, provide alerts\nto users, enable merchants to bid to make an offer on specific entities etc.\nThe following discussion now refers to a number of methods and method acts that may be performed.  Although the method acts may be discussed in a certain order or illustrated in a flow chart as occurring in a particular order, no particular\nordering is required unless specifically stated, or required because an act is dependent on another act being completed prior to the act being performed.\nReferring now to FIG. 6, a method 600 is illustrated.  The method 600 includes acts for identifying to a user, acquirable entities that the user may be interested in. For example, the method may identify purchasable or free items.  Such items\nmay be physically delivered.  Alternatively the items may be electronically delivered such as through download.\nThe method 600 includes, at a component configured to analyze information across a plurality of applications, analyzing in one or more of the applications being used by a user, content in the one or more applications (act 602).  For example, as\nillustrated in FIG. 3, the operating system 118 may include functionality for analyzing applications being used by a user.  As illustrated in FIG. 4, an application framework 122 may include such functionality.\nThe method 600 further includes, based on the content, identifying one or more acquirable entities from the content (act 604).\nThe method 600 further includes identifying to the user the identified acquirable entities (act 606).\nThe method 600 may be practiced where the content comprises at least one of text, video, music, images, metadata, links (such as hyperlinks), etc. The description above and FIG. 2 illustrate examples of how such content may be used.\nThe method 600 may be practiced where identifying to a user the identified acquirable entities is performed as a result of one or more of providing a charm and receiving user input, providing a keyboard key and receiving user input, providing a\nsetting button and receiving user input, providing an icon and receiving user input, providing a toast notification and receiving user input, or providing a soft button and receiving user input, etc. Various such examples are illustrated above and in\nFIG. 5.\nThe method 600 may be practiced where identifying to a user the identified acquirable entities comprises providing a shopping list.\nThe method 600 may be practiced where identifying to a user the identified acquirable entities is performed after detecting that a user is in a location where the user may purchase one or more of the acquirable entities.  As described above,\nthis may be a physical location or a digital location.\nThe method 600 may be practiced where identifying to a user the identified acquirable entities comprises providing price comparisons, price tracking, and the like.  Thus, for example, embodiments may identify to a user where they can acquire\nentities at different costs.  Alternatively or additionally, embodiments may identify to a user the change in cost of an entity over time.\nThe method 600 may be practiced where identifying one or more acquirable entities in the content is performed based on a history of content from one or more applications to identify at least one of relevance, or frequency or pattern of content\nuse, etc. Alternatively or additionally, the method 600 may be practiced where identifying one or more acquirable entities in the content is performed by use real time context.  Thus, entities can be identified based on history, in real time, or a\ncombination of the two.\nThe method 600 may be practiced where the acquirable entities are specifically identified in the content.  Thus for example, the content may include a description or identification of an entity specifically.  Alternatively, the method 600 may be\npracticed where the acquirable entities are derived from entities specifically identified in the content.  Thus, for example, comparable or related entities to those specifically identified in content may be identified.  For example, if a printer is\nidentified in the content, embodiments may identify compatible printer toner cartridges or comparable printers to those specifically identified in the content.\nThe method 600 may be practiced where identifying one or more acquirable entities from the content is performed by analyzing content across user devices and/or accounts for the user.\nThe method 600 may further include providing an in-place purchase interface to allow the user to acquire one or more of the entities.  Thus, for example, a user may be able to purchase or acquire entities directly from an application from which\nthe content is obtained.  Thus, for example, embodiments may provide an interface in a web application, word processing application, or other application that allows the user to purchase identified entities.\nFurther, the methods may be practiced by a computer system including one or more processors and computer readable media such as computer memory.  In particular, the computer memory may store computer executable instructions that when executed by\none or more processors cause various functions to be performed, such as the acts recited in the embodiments.\nEmbodiments of the present invention may comprise or utilize a special purpose or general-purpose computer including computer hardware, as discussed in greater detail below.  Embodiments within the scope of the present invention also include\nphysical and other computer-readable media for carrying or storing computer-executable instructions and/or data structures.  Such computer-readable media can be any available media that can be accessed by a general purpose or special purpose computer\nsystem.  Computer-readable media that store computer-executable instructions are physical storage media.  Computer-readable media that carry computer-executable instructions are transmission media.  Thus, by way of example, and not limitation,\nembodiments of the invention can comprise at least two distinctly different kinds of computer-readable media: physical computer readable storage media and transmission computer readable media.\nPhysical computer readable storage media includes RAM, ROM, EEPROM, CD-ROM or other optical disk storage (such as CDs, DVDs, etc.), magnetic disk storage or other magnetic storage devices, or any other medium which can be used to store desired\nprogram code means in the form of computer-executable instructions or data structures and which can be accessed by a general purpose or special purpose computer.\nA \"network\" is defined as one or more data links that enable the transport of electronic data between computer systems and/or modules and/or other electronic devices.  When information is transferred or provided over a network or another\ncommunications connection (either hardwired, wireless, or a combination of hardwired or wireless) to a computer, the computer properly views the connection as a transmission medium.  Transmissions media can include a network and/or data links which can\nbe used to carry or desired program code means in the form of computer-executable instructions or data structures and which can be accessed by a general purpose or special purpose computer.  Combinations of the above are also included within the scope of\ncomputer-readable media.\nFurther, upon reaching various computer system components, program code means in the form of computer-executable instructions or data structures can be transferred automatically from transmission computer readable media to physical computer\nreadable storage media (or vice versa).  For example, computer-executable instructions or data structures received over a network or data link can be buffered in RAM within a network interface module (e.g., a \"NIC\"), and then eventually transferred to\ncomputer system RAM and/or to less volatile computer readable physical storage media at a computer system.  Thus, computer readable physical storage media can be included in computer system components that also (or even primarily) utilize transmission\nmedia.\nComputer-executable instructions comprise, for example, instructions and data which cause a general purpose computer, special purpose computer, or special purpose processing device to perform a certain function or group of functions.  The\ncomputer executable instructions may be, for example, binaries, intermediate format instructions such as assembly language, or even source code.  Although the subject matter has been described in language specific to structural features and/or\nmethodological acts, it is to be understood that the subject matter defined in the appended claims is not necessarily limited to the described features or acts described above.  Rather, the described features and acts are disclosed as example forms of\nimplementing the claims.\nThose skilled in the art will appreciate that the invention may be practiced in network computing environments with many types of computer system configurations, including, personal computers, desktop computers, laptop computers, message\nprocessors, hand-held devices, multi-processor systems, microprocessor-based or programmable consumer electronics, wearable devices (such as headsets, watches, fitness trackers, etc.), network PCs, minicomputers, mainframe computers, mobile telephones,\nPDAs, pagers, routers, switches, and the like.  The invention may also be practiced in distributed system environments where local and remote computer systems, which are linked (either by hardwired data links, wireless data links, or by a combination of\nhardwired and wireless data links) through a network, both perform tasks.  In a distributed system environment, program modules may be located in both local and remote memory storage devices.\nAlternatively, or in addition, the functionally described herein can be performed, at least in part, by one or more hardware logic components.  For example, and without limitation, illustrative types of hardware logic components that can be used\ninclude Field-programmable Gate Arrays (FPGAs), Program-specific Integrated Circuits (ASICs), Program-specific Standard Products (ASSPs), System-on-a-chip systems (SOCs), Complex Programmable Logic Devices (CPLDs), etc.\nThe present invention may be embodied in other specific forms without departing from its spirit or characteristics.  The described embodiments are to be considered in all respects only as illustrative and not restrictive.  The scope of the\ninvention is, therefore, indicated by the appended claims rather than by the foregoing description.  All changes which come within the meaning and range of equivalency of the claims are to be embraced within their scope.", "application_number": "15392801", "abstract": " A method of identifying, to a user, acquirable entities that the user may\n     be interested in is disclosed. The method includes at a component\n     configured to analyze information across a plurality of applications,\n     analyzing in one or more of the applications being used by a user,\n     content in the one or more applications. The method further includes\n     based on the content, identifying one or more acquirable entities from\n     the content. The method further includes identifying to the user the\n     identified acquirable entities.\n", "citations": ["6981040", "7444319", "8620767", "20060200556", "20070299817", "20090297045", "20120084828", "20120317482", "20130006904", "20140229248", "20140244762", "20140358882", "20150186381", "20150186538", "20150220979"], "related": ["14460498"]}, {"id": "20170124092", "patent_code": "10318647", "patent_name": "User input-based play-list generation and streaming media playback system", "year": "2019", "inventor_and_country_data": " Inventors: \nEyal; Aviv (New York, NY), Aposporos; George (Rockville, MD)  ", "description": "<BR><BR>CROSS REFERENCE TO RELATED APPLICATION\nThis application is a Continuation of U.S. patent application Ser. No.\n     14/508,665 filed Oct. 7, 2014, now U.S. Pat. No. 9,547,650, which is a\n     continuation of U.S. patent application Ser. No. 14/327,789, filed Jul.\n     10, 2014, which is a Continuation of U.S. patent application Ser. No.\n     13/355,867, filed Jan. 23, 2012, now U.S. Pat. No. 8,782,194, which is a\n     Continuation of U.S. patent application Ser. No. 12/255,615, filed Oct.\n     21, 2008, now abandoned, which is a Continuation of U.S. patent\n     application Ser. No. 10/828,124, filed Apr. 19, 2004, now U.S. Pat. No.\n     7,469,283, which is a continuation of U.S. patent application Ser. No.\n     10/251,307, filed on Sep. 20, 2002, now U.S. Pat. No. 6,735,628, which is\n     a continuation of Ser. No. 10/104,792, filed on Mar. 22, 2002, now U.S.\n     Pat. No. 6,484,199, which is a continuation of U.S. patent application\n     Ser. No. 09/563,250, filed May 2, 2000, now U.S. Pat. No. 6,389,467,\n     which claims priority to U.S. Provisional Patent Application Ser. No.\n     60/177,786, filed Jan. 24, 2000, entitled \"Streaming Media Search and\n     Playback System\" each of which are incorporated herein by reference in\n     their entirety.\n         <HR>\n<CENTER><b><i>Claims</b></i></CENTER> <HR> <BR><BR>The invention claimed is: 1.  A system architecture comprising: a first client application executing on a first multimedia computing platform with internet access, the first client application\nincluding: a first media player that plays media resources delivered over the Internet from one or more remote servers in communication with the first media player, and a streaming media clips rating system that receives a rating when a first user enters\na rating selection by using one or more of an icon or display feature of the first client application, and signals, via the Internet, the rating to a rating component, and a messaging component;  and a second client application executing on a second\nmultimedia computing platform with internet access, the second client application including a second media player that plays media resources being delivered over the Internet from one or more remote servers in communication with the second media player; \nand a rating system including: a database management component that maintains an organizational data structure that describes rating information for the media resources, the rating component that receives, via the Internet, ratings from the streaming\nmedia clips rating system and modifies rating information in the organizational data structure at least based on the ratings;  a play-list generator located at least partially on one or more remote servers adapted to automatically generate at least one\nplay-list based on the rating information, wherein a play-list generated by the play-list generator comprises identifiers of at least one or more media resources selected based on the rating information;  and wherein the messaging component allows the\nfirst user to select an action to send a message that includes a selectable link, the selection of which allows the second media player to playback the media resources in a play-list selected to be sent by the first user.\n2.  The system architecture of claim 1, the second client application further comprising a second streaming media clips rating system that receives a rating when the second user enters a rating selection by using one or more of an icon or\ndisplay feature of the second client application, and signals, via the Internet, the rating to the rating component, and wherein the second client application allows the second user to enter a rating selection for one or more of the media resources of\nthe play-list selected to be sent by the first user.\n3.  The system of claim 1, wherein the selectable link contains an identifier that is packaged with arguments or other coding.\n4.  The system of claim 3, wherein the arguments or other coding identify a play-list, a specific media resource, or a search request or criteria used by the first user.\n5.  The system of claim 1, wherein the identifiers are one or more of a URL (Uniform Resource Locator), a URL link, or a URI (Uniform Resource Identifier).\n6.  The system of claim 1, wherein the play-list selected to be sent by the first user further comprises one or more of metadata information and identifiers of metadata information about the one or more media resources included in the play-list.\n7.  A system for receiving user input regarding media resources from a playback interface installed and executing on an internet enabled multimedia computing platform, the playback interface including a media player, the system comprising: a\ndatabase management component that maintains an organizational data structure that describes rating information for the media resources, and the rating component adapted to receive, via the internet, the user input from the playback interface, to\ndetermine a rating from the user input, and to modify the rating information in the organizational data structure at least based on the rating, and a play-list generator adapted to generate at least one play-list based on the rating information in the\norganizational data structure, wherein the play-list comprises identifiers of at least one or more media resources selected based on the rating information, and wherein the playlist is delivered over the internet to the internet enabled multimedia\nplatform and the media resources are capable of being played back on the media player.\n8.  The system of claim 7, wherein the user input regarding the media resources includes the selection of one or more of a play feature and a skip feature of the playback interface.\n9.  The system of claim 7, wherein the user input regarding the media resources includes the entry of a rating selection by selection of one or more of an icon and a display feature of the playback interface.\n10.  The system of claim 7, wherein the user input is a selection of one or more of a genre, category, or organizational information on the playback interface.\n11.  The system of claim 7, wherein the play-list is a new playlist created for a current genre or category, and wherein the new playlist replaces the previous playlist for that genre or category.\n12.  The system of claim 7, wherein the playlist is dynamically generated.\n13.  A system for receiving a plurality of user inputs regarding media resources from a plurality of playback interfaces installed and executing on internet enabled multimedia computing platforms, each respective playback interface including a\nmedia player, the system comprising: a database management component that maintains an organizational data structure that describes rating information for the media resources, and the rating component adapted to receive, via the internet, the plurality\nof user inputs from the plurality of playback interfaces, to determine a plurality of ratings from the plurality of user inputs, and to modify rating information in the organizational data structure based on the plurality of ratings, and a play-list\ngenerator adapted to generate at least one play-list based on the rating information in the organizational data structure, wherein the play-list comprises identifiers of at least one or more media resources selected based on the rating information, and\nwherein the playlist is delivered over the internet to at least one playback interface and the media resources are capable of being played back on the media player of that playback interface.\n14.  The system of claim 13, wherein the plurality of user inputs regarding the media resources includes the selection of one or more of a play feature and a skip feature on at least some of the plurality of playback interfaces.\n15.  The system of claim 13, wherein the plurality of user inputs regarding the media resources includes the entry of a rating selection by selection of one or more of an icon and a display feature on at least some of the plurality of playback\ninterfaces.\n16.  The system of claim 13, wherein the plurality of user inputs regarding the media resources includes a selection of one or more of a genre, category, or organizational information on at least some of the plurality of playback interfaces.\n17.  The system of claim 13, wherein the play-list is a new playlist created for a current genre or category, and wherein the new playlist replaces the previous playlist for that genre or category.\n18.  The system of claim 13, wherein the playlist is dynamically generated.\n19.  The system of claim 13, wherein at least some of the plurality of ratings are tallied at least based on a rating formula and the play-list generator generates at least one play-list for at least one user organized in an order at least based\non the tally of the plurality of ratings.\n20.  The system of claim 18, wherein the dynamically generated play-list starts playing automatically.\n21.  A system comprising: An internet enabled multimedia computing platform including: a playback interface adapted to receive at least one user's initial selection for streaming media based on at least one item of metadata, including at least\ngenre, category, or other organizational information, at least one user selection for controlling the playback of streaming media, and rating information;  wherein the playback interface is adapted to signal, via the Internet, the user's initial\nselection based on at least one item of metadata to at least one rating component of the streaming media rating system, user selection for controlling the playback of streaming media, and rating information;  and a streaming media rating system\nincluding: a database management component that maintains an organizational data structure that describes rating information for a media resource;  the rating component adapted to receive, via the Internet, a rating from the streaming media rating system\nand modify the rating information in the organizational data structure at least based on the rating information;  and a play-list generator adapted to generate at least one playlist based on at least a user's initial selection via the user interface of\none or more user selections for streaming media based on at least one item of metadata, including at least one of a genre, category, or organizational information selected by the user and the rating information in the organizational data structure; \nwherein the play-list is provided, via the Internet, to the playback interface, and wherein the play-list comprised of media resources is capable of being played back on the multimedia computing platform.\n22.  The system of claim 21, wherein an initial playlist is generated by user's selection of a genre, artist, or other media resource attribute through the playback interface.\n23.  The system of claim 21, wherein the streaming media rating system is further adapted to receive a plurality of ratings from a plurality of users, with the play-list being dynamically generated based on the plurality of ratings.\n24.  The system of claim 21, wherein the playback interface allows the user to select an action to send a signal to a second internet enabled multimedia computing platform that allow a user to playback the play-list of media resources on the\nsecond internet enabled multimedia computing platform. <HR> <CENTER><b><i>Description</b></i></CENTER> <HR> <BR><BR>BACKGROUND OF THE INVENTION\nField of the Invention\nThis invention relates to the field of streaming media content search and playback over a network.  In particular, the invention relates to a computer system that enables a continuous streaming media playback from a distribution of sites\navailable over a network such as the Internet.\nDescription of the Related Art\nComputers currently can access streaming media on the Internet.  Streaming media available on the Internet include, for example, music, video clips such as movie trailers, home movies, and animation.\nUsers locate streaming media on the Internet by manually selecting links.  Typically, users browse the media sites that contain numerous sub-links Users sometimes select through a chain of links to locate a desired media on a media link.  Once\nlocated, the desired media link may or may not contain the desired media.\nSome services provide media search engine capabilities.  Users may enter a search request for selected media creations by an artist.  The media search engine then displays links to categories and/or sub-links of media that are determined to\nmatch one or more criteria in the search request set forth by the user.  The determination of which links should be displayed in response to the search request is dependent on the algorithm used in by the search engine.  Typically, links displayed to\nusers of current search engines are not subject to a determination of the quality or availability of the media associated with the media links.  Further, the search results are outputted to the user as a display of links for the user's selection.\nMany Internet streaming media outlets provide a limited number of source nodes.  The sites can be unreliable when the number of users accessing the site become congested.\n<BR><BR>SUMMARY OF THE INVENTION\nAn embodiment of the invention includes a method for playing back media from network.  The method comprises receiving a search criteria from a network enabled device.  The method further includes accessing a database comprising a plurality of\nnetwork addresses, where the database associating each address with one or more classes of information.  Each address accesses a media network resource.  The method further includes selecting at least one address in the database using the search\ncriteria, signaling the selected address to the network enabled device, and controlling the network enabled device so as to automatically access and play back the media resource of the selected address.\nAnother embodiment includes a method for playing back media from a network.  The method includes receiving a request for media playback from a network enabled device.  Further, accessing a database comprising a plurality of network addresses,\nwhere each address accessing a media network resource.  The method also includes identifying at least two addresses from the database, signaling each identified address to the network enabled device, and controlling the network enabled device to access\nand automatically play back the media network resources of each of the signaled addresses.\nIn another embodiment, a computer system is provided for playing back media from a network.  The computer system comprises a network enabled device comprising a media playback component.  A database is included that comprises a plurality of\naddresses, where each address locates a media network resource on the network.  The database includes one or more classes of information associated with each address in the plurality of addresses.  The system also includes a network server module that is\ncoupleable to the network enabled device and to the database.  The network server module is able to receive a search request from the terminal that specifies one or more criterias.  The network server module selects an address from the database that is\nassociated with a class of information that matches the search criteria.  The network server module signals the address to the network enabled device to cause the device to access the media network resource, and to signal media playback component to load\nthe media network resource after the device accesses the media network resource.\nIn another embodiment, a computer system is provided for playing back media from a network.  The computer system includes a network enabled platform comprising a media playback component.  A database includes a plurality of addresses, where each\naddress locates a media network resource on the network.  Each address accesses a media network resource.  The embodiment further includes a network server module coupleable to the network enabled device and to the database.  The network server receives\na request for media playback from the network enabled device, selects multiple addresses from the database, and signal the multiple addresses to the network enabled device.  The network server module control a media playback component on the network\nenabled device to use the addresses to automatically access and play back the media network resource associated with the addresses.\nIn another embodiment, a network enabled device is configured to playback media from a network.  The network enabled device is coupleable over the network to a database that includes a plurality of addresses.  Each address locates a media\nnetwork resource on the network.  The network enabled device includes a user-interface to prompt for a search request.  The network interface signals the request to a network server module that is communicatable with the database, and receives one or\nmore addresses in the database that match the search request.  The network enabled device includes a media playback component that is configured to be programmatically controlled by the network server module to automatically load the media network\nresources located by the addresses that match the search request.\nIn another embodiment, a network enabled device is configured to playback media from a network.  The network enabled device is coupleable over the network to a database comprising a plurality of addresses.  Each address locates a media network\nresource on the network.  The network enabled device comprises a user-interface including a plurality of user-interactive features, including a first user-interactive feature that prompts to receive a search request for media playback.  A network\ninterface signals the request to a network server module upon the first user-interactive feature receiving the search request for media playback.  The network interface is communicatable with the database to receive one or more addresses in the database\nthat match the search request.  A network playback component is configured to be programmatically controllable by the network server module to automatically load the media network resource associated with each address signaled to the network enabled\ndevice upon accessing the media network resource.  A playback of the media playback component being controllable by one or more control user-interactive features.\nAn embodiment includes a system that provides media from a network to a terminal having a media playback component.  The system includes a first network site and a second network site, where each network site locates one or more media network\nresources.  Each media network resource is locatable on the network by a corresponding address that accesses the media network resource.  A network server module is coupleable to the terminal through the network.  The network server module identifies a\nfirst media network resource from the first network site and a second media network resource from the second network site.  The network server module signals the corresponding address of the first media network resource to the terminal with control\nsignals to cause the playback component to automatically load the first media network resource.  The network server module automatically signals the corresponding address of the second media network resource to the terminal with control signals to cause\nthe playback component to automatically load the second media network resource.\nAnother embodiment provides a media playback system for the Internet.  The system includes an end terminal having a media playback component.  A web server module is coupleable to the end terminal through the Internet.  The web server module has\naccess to one or more media web resources on a first web site, and to one or more media web resources on a second web site.  The web server module signals a first link to a first media web resource on the first web site, and a second link to a second\nmedia web resource on the second web site.  The web server module provides control signals to the end terminal to cause the end terminal to access and load the first media web resource and the second media web resource into the media playback component.\nOne or more of the embodiments may include a database that stores links to each of the plurality of media web resources, the web server module identifying the first link and the second link from the database.\nAnother embodiment includes a media playback system for the Internet.  The system includes a terminal having a media playback component and a user-interface.  A web server module is coupleable to the user terminal through the Internet.  The web\nserver module has access to a plurality of links, where each link locates a media web resource.  The plurality of links are accessible on a plurality of web sites.  The web server module signals the plurality of links to the user terminal in a designated\norder to cause the terminal to load the media web resource located by each of the plurality of links into the media playback component.  The embodiment also includes a database that stores the plurality of links.  The database is accessible to signal the\nplurality of links to the web server module in the designated order.  The user-interface signals one or more inputs from a user to the web server module.  The one or more inputs direct the web server to alter the designated order in which the database\nsignals the plurality of links to the web server module.\nAnother embodiment includes a system that provides media play-back on a network.  The system includes a terminal that is coupleable to the network.  A play-list module is coupleable to the terminal.  The play-list module stores a first play-list\nsignaled from the terminal.  The first play-list includes a plurality of network addresses.  A first network address locates a first media network resource on a first network site, and a second network address locates a second media network resource on a\nsecond network site.  A network server module is coupleable to the terminal and to the play-list module.  The network server module signals the first play-list to the terminal.  The network server module controls the terminal to cause the terminal to\naccess the media network resource associated with each network address in the first play-list, and to automatically load each respective media network resources into the media playback component.\nAnother embodiment includes a method for providing media to a terminal coupled to a network, where the terminal includes a media playback component.  A terminal is programmatically directed to access a first network site in the plurality of\nnetwork sites.  The media playback component on the terminal is caused to automatically load a first media web resource located at the first network site to playback a first media.  The terminal is programmatically directed to access a second network\nsite in the plurality of network sites.  The media playback component on the terminal is caused to automatically load a second media web resource located at the second network site to playback a second media.\nAnother embodiment includes a method to provide media to a terminal coupled to the Internet.  A database is accessed that stores a plurality of links, where each link opening a corresponding media web resource.  A first link is selected from the\ndatabase, the first link being located on a first network site.  Next, a second link is selected from the database, the second link being located in a second network site.  The second network site is external to the first network site.  Then, the\nselected links are signaled to a media playback component on the terminal to sequentially access the media web resources associated with the selected links.  The media playback component on the terminal is automatically signaled to load each of the media\nweb resource accessed from the selected links so as to playback a media corresponding to each media web resource.\nAnother embodiment includes a system to share media playback from a network between a plurality of terminals.  The plurality of terminals include a first terminal and a second terminal.  The system includes a play-list component locatable on the\nnetwork by a selectable link.  The play-list component identifies a plurality of links to form a play-list, where each link in the play-list locating a media file on the network.  The system includes a network server module that signals the plurality of\nlinks that form the play-list to the first terminal.  The network server module receives a signal to transmit the selectable link to a second terminal to enable the second terminal to locate the play-list module.\nIn another embodiment, a method is provided to locate web resources on the Internet.  A web site is accessed to identify a plurality of links using a web browser component.  The web site can be automatically or programmatically accessed.  Each\nof the plurality of links are selectable to open a corresponding web resource of a specified data type on the web site.  The plurality of links are made available to a plurality of Internet enabled devices that select one or more of the links.\nAnother embodiment includes a system to locating web resources on the Internet.  The system includes a web browser component, and a database.  A search module controls the web browser component to access at least one web site.  The search module\ncontrols the web browser component to identify a plurality of links to media web resources at the web site.  Each of the plurality of links are selectable to open a media web resource.  The search module stores the plurality of links in the database.\nAnother embodiment includes a method to locate web resources on the Internet.  A database that stores a plurality of links is accessed, the plurality of links being selectable to open a corresponding web media resources.  Metadata information is\nprogrammatically identified about the web media resource corresponding to each of the plurality of links.  The plurality of links are made accessible to a plurality of Internet enabled devices.  The plurality of Internet enabled devices elect one or more\nof the links to open the corresponding media web resource.\nAnother embodiment includes a method to locate web resources on the Internet.  A database is accessed that includes a plurality of links to media web resources.  Each of the plurality of links are programmatically verified to open a\ncorresponding web media resource.  Each verified link is accessible to a plurality of Internet enabled devices that select one or more of the links to open the corresponding media web resource.\nAnother embodiment includes a system to locate web resources on the Internet.  The system includes a first indexed data structure comprising a plurality of links.  A media playback component is coupleable to the database.  The media playback\ncomponent loads each of the plurality of links to verify whether the link is selectable to open a media web resource.  A second indexed data structure stores each verified link in the plurality of links.  The second indexed data structure is available to\nthe plurality of Internet enabled devices.\nAnother embodiment includes a method to providing links for use in a media search engine.  A plurality of internal links on a network site are identified.  The network site makes a network resource of a specific data type accessible for a\nnetwork enabled device.  The internal links that are selectable to open the network resource of the specific data type are extracted.  The external link is stored in a database.  One or more of the links are automatically signaled to a media playback\ncomponent in response to receiving a search requests from the network enabled device.\nAnother embodiment includes a method to provide links for use in a media search engine.  The method includes a) receiving from a first indexed data structure a first external link to a first network site; b) initializing a second data structure\nto be empty;\nc) determining if the first network site contains at least one internal link; d) storing the at least one internal link contained on the first network site that is not in the first indexed data structure and not in the second indexed data\nstructure as another external link in the first indexed data structure; e) identifying the internal links contained on the first network site that are selectable to open a network resource of a specific data type or types; f) moving the first external\nlink from the first indexed data structure to the second indexed data structure; and g) repeating steps a) through f) until the first indexed data structure is empty.\nAnother embodiment includes a computer system to search for links to streaming media playback on a network, the network being accessible to a network enabled device.  The system includes a metacrawler to locate one or more media sites in\ndirectories containing streaming media.  A media search module coupled to be signaled the one or more directories from the metacrawler.  The media search module identifies a plurality of media links for the media sites.  Each of the plurality of media\nlinks are selectable to open streaming media network resource.  A metadata extraction module accesses each media link identified by the media search engine to extract metadata about the identified media link.  A database comprising the plurality of media\nlinks identified by the media search engine, and the metadata is extracted about each identified media link.  The database enables the network enabled device to access the plurality of media links.\nAn embodiment includes a rating system for rating media network resources on a network that is coupleable to a plurality of terminals.  The rating system includes a database having a plurality of addresses.  Each address locates a corresponding\nmedia network resource on the network.  A network server module is coupleable to the plurality of terminals.  The network server module accesses the database to signal one or more addresses from the database to the plurality of terminals.  A rating\nmodule is coupleable to the plurality of terminals.  The rating module receives a rating input from each of the plurality of terminals.  The rating module associates the rating input with a selected address in the database.\nIn another embodiment, a rating system is provided to rate media network resources on a network.  The rating system includes a database comprising a plurality of addresses that each locate a corresponding media network resource on the network. \nThe database includes one or more classes of information associated with each of the plurality of addresses.  A network server module is coupleable to the plurality of terminals.  The network server module communicates with each of the plurality of\nterminals to receive a search request.  The network server module signals the database to retrieve one or more addresses from the database in response to the search request.  The retrieved addresses are associated with a class of information matching the\nsearch request.  A rating module is coupleable to the plurality of terminals.  The rating module receives a rating input from each of the plurality of terminals.  The rating module associates the rating input with a selected address in the database.\nAnother embodiment includes a rating system for rating media network resources available over a network.  The media network resources are located on the network by a plurality of terminals.  The rating system includes a database that stores a\nplurality of addresses.  Each address locates a corresponding media network resource on the network.  The database includes a rating associated with each of the plurality of addresses.  A network server module is coupleable to each of the plurality of\nterminals.  The network server module accesses the database to signal one or more addresses from the database to the plurality of terminals.  A rating module is coupleable to each of the plurality of terminals.  The rating module receives a rating input\nfrom one of the terminals for each of the plurality of addresses in the database.  In response to receiving the rating input from one of the plurality of terminals for a selected address in the database, the rating module accesses the database and\nreconfigures the rating associated with the selected address.  A play-list module accesses the addresses to select one or more combinations of addresses.  The play-list module signals the play-list to the network server module as addresses to be signaled\nto one or more of the plurality of terminals.\nIn a variation, the address may be selected by the play-list module based on a criteria stored with the address in the database.  Examples of criterias include rankings, reflecting preferences of users on terminals after playing back media\nlocated by the respective addresses.  Other criterias that can be used to select addresses include metadata information, such as artist name and media title.  For example, the search request may specify a ranking as one of the criterias.  The play-list\nmodule then sorts the database for the ranking in selecting the addresses.\nAnother embodiment includes a method for ranking media sources on a network.  The method includes accessing a database that stores a plurality of addresses.  Each address locates a media resource on the network and each address is associated\nwith a rating.  A selected address from the database is signaled to a terminal coupled to the network.  A rating input is received from the terminal after signaling the selected address to the terminal.  The rating is associated for the selected address\nis adjusted in response to receiving the rating input.\nAnother embodiment includes a method for ranking media sources on a network.  A database is accessed that stores a plurality of addresses.  Each address locates a media resource on the network and each address is associated with a rating.  A\ncombination of addresses are selected to form a play-list.  The play-list is signaled to a terminal coupled to the network.  A ranking is received from the terminal after signaling the addresses in the play-list to the terminal.  The rating is adjusted\nfor each address signaled to the terminal from the play-list in response to receiving the ranking.\nAnother embodiment includes a method that ranks media sources on a network.  A database that stores a plurality of addresses is accessed.  Each address locates a media resource on the network, and each address is associated with a rating.  A\nselected address is signaled from the database to a terminal coupled to the network.  A ranking is received from the terminal after the selected address is signaled to the terminal.  The rating associated for the selected address is adjusted in response\nto receiving the ranking.\nAnother embodiment includes a network enabled device that comprises a media playback component.  The media playback component is configured to communicate with a network-side module to receive a first plurality of links.  Each of the first\nplurality of links locate a media file on a network.  A web browser component is configured to receive a second plurality of links.  Each of the second plurality of links hosts a media file located by one of the first plurality of links.  The web browser\ncomponent displays the web site for each of the second plurality of links when the media playback component plays back media from the media file being hosted by web site being displayed. <BR><BR>BRIEF DESCRIPTION OF THE DRAWINGS\nFIG. 1 is a flow process describing an embodiment of the invention.\nFIG. 2 is a block diagram illustrating an architecture for use with an embodiment of the invention.\nFIG. 3 is a block diagram illustrating a back end architecture, under an embodiment of the invention.\nFIG. 4 is a block diagram illustrating a media search and playback system, under an embodiment of the invention.\nFIG. 5 is a block diagram illustrating components on an end terminal receiving control information from a server-side module, under an embodiment of the invention.\nFIG. 6 is a flow chart illustrating a system for forming a search database of media resources accessible on a network, under an embodiment of the invention.\nFIG. 7 is a flow chart illustrating a system for forming a search database of media resources accessible on a network, under an embodiment of the invention.\nFIG. 8 is a flow chart for verifying records in a search database of media resources, under an embodiment of the invention.\nFIG. 9 is a flow chart for extracting metadata about a media resource associated with a site on a network, under an embodiment of the invention.\nFIG. 10 is a flow chart for forming play-lists for end users of a system under an embodiment of the invention.\nFIG. 11 is a flow chart for receiving user input in response to playing back media resources from a search database, under an embodiment of the invention.\nFIG. 12 is a block diagram of a media playback system including a rating feature, under an embodiment of the invention.\nFIG. 13 is a flow chart describing user input to a user interface for a media playback system, under an embodiment of the invention.\nFIG. 14 is a flow chart describing a rating system, under an embodiment of the invention.\nFIG. 15 illustrates an exemplary structure for a database to maintain updated records on ratings for addresses containing media resources, under an embodiment of the invention.\nFIG. 16 is a flow chart for creating play-lists using rating information, under an embodiment of the invention.\nFIG. 17 is a flow chart for programmatically categorizing media files, under an embodiment of the invention.\nFIG. 18 is a flow chart for creating personalized play-lists of streaming media files available in a network, under an embodiment of the invention.\nFIG. 19 illustrates a distributed playback architecture, under an embodiment of the invention.\nFIG. 20 illustrates a block diagram of a messaging application, under an embodiment of the invention.\nFIG. 21 illustrates a user-interface for use with a media search and playback system, under an embodiment of the invention.\nFIG. 22 includes another user-interface displaying an instance of the web browser while media is being played back, under an embodiment of the invention.\n<BR><BR>DETAILED DESCRIPTION\n<BR><BR>A. System Overview\nAccording to an embodiment, a system is provided comprising a media search engine.  The media search engine may be used to create a database of links to media files.  The links may be structured according to predefined categories and/or\nuser-defined search criteria.  A client terminal includes a media player to automatically access one or more media files using the corresponding links.  The media player then plays back media contained on the media files.\nAmong other advantages of the invention, the user terminal accesses media files at various sites on a network, without requiring users to manually select media links.  For example, user-terminals may output music to a user by automatically\naccessing one or more Internet sites containing media files.  The music is outputted without requiring users' to view and select links to sites containing the media.\nIn contrast to embodiments of the invention, using other systems to search for Internet files containing media can be a distracting and time-consuming experience for an end user.  In many instances, such a search will yield a series of links on\na directory or web search page.  A user may have to click on each individual link, one at a time, to play each individual media file.  The selected media file may be broken and unavailable to deliver media content.  Even if the number of broken links is\nnot high, the user must still click on the links one at a time to activate each media file, providing at best a stop-and-go experience.\nIn one embodiment of the invention, a user terminal is able to receive continuous media streaming from multiple sites on the Internet.  Multiple sites may be accessible to enable the user terminal to receive streaming media without any\ninteraction required from an end user other than signaling a request to receive streaming media.  The user terminal automatically accesses media links containing media using a media playback component.\nThe media playback component may be controlled by one or more server-side modules.  In one embodiment, the media playback component on the user terminal interacts with one or more play-lists generated by server side modules.  The play-lists\ncontain media links for the media playback application.  The media links may be structured or ordered in the play-lists.  The play-lists may be generated automatically by back-end modules and/or manually by editors.  The play-lists may also be generated\nby end users.\nThe media playback component may also interact with one or more server side search modules to access media links on the network.  The media links may be automatically selected based on, for example, a search criteria from the end user.\nEmbodiments of the invention provide a system to search and playback media accessible over a network.  In one embodiment, a media search engine is provided to enable users to request media output based on a criteria set forth in a search\nrequest.  The media search engine is able to efficiently locate streaming media on the network that matches criteria set forth in a search request.  The system provides continuous playback of media found on multiple sites of the network.  For example, a\nuser may specify a search based on a specified artist.  The system locates one or more sites on the Internet containing media files from the specified artist.  The system enables the user terminal to automatically and continuously play back media\ncreations available on the Internet sites.\nFurther, a backend system under an embodiment of the invention minimizes possibilities of broken links and mismatched search results.  The backend system may also be used to perform manual and/or programmatic quality check of the media\nassociated with each link.\nFurther, a search engine under an embodiment of the invention employs an Internet web browser software component on the back-end to perform searches and indexing of web resources.  The Internet web browser component may be a configured or\nmodified commercially available web browser component.  Server-side modules may combine to control the browser in locating media links and media sites containing media content.  As a result, the media search engine under this embodiment is efficiently\nimplemented, using existing resources on the back-end system.\nAmong other advantages, embodiments of the invention enable streaming media from multiple media links to be automatically played to users.  Embodiments of the invention also employ a scalable and distributed architecture.  Scalability in this\nsense means that the service is available to a large (thousands or more) audience of simultaneous listeners or viewers while minimizing bottlenecks caused by congestion.  Another advantage of a distributed architecture is that the unavailability of one\nmedia site, or of one or more media on the media site, does not preclude the user terminal from receiving media from another site.  As a result, users are ensured a continuous listening or viewing experience.\nFurther, streaming media may be continuously outputted to users from multiple sites on the Internet based on personalized criteria set forth by users.  The criteria may be set forth in one or more requests by an end user.  The end user may\nexperience media continuously outputted from multiple sites, based on only one request from the end user.  This allows a user to request media through actions such as clicking requests through a user-interface.\nAn embodiment of the invention enables users to share streaming media experiences with other end users.  For example, users may share play-lists containing links to multiple Internet sites.  This enables individuals to create media programs of\nstreaming media using multiple sites on the Internet.  For example, play-lists may be shared among end users using a host web site, or e-mails.\n<BR><BR>B. Search and Playback System\nA user terminal may transmit a search request from an end user to one or more modules on a server.  A client side playback module, one or more server-side modules, or a combination of client and server side modules combine to access the user\nterminal to a site on the Internet that contains media content immediately available for loading and playback.  The response to the search request is media output through the user terminal.  The media content is outputted from the user terminal without\nany additional action on the part of the end user after the initial search request.  Once media from one site is completed, the playback module automatically enables the user terminal to access and playback media located on another Internet site.  As a\nresult, an embodiment enables the user terminal to output continuous streaming media to an end user, where the media outputted is accessed from multiple Internet sites.\nEmbodiments of the invention may be implemented on the Internet.  Other embodiments may be implemented on any network that carries digital information, such as local-area networks (LANs), Wide Area Networks (WAN), Extranets, Intranets, Internet,\nand wireless networks, or networks utilizing wireless transmissions.  An example of a network for use with an embodiment of the invention includes a network operating under a transmission control protocol/Internet protocol (TCP/IP).  Embodiments of the\ninvention may also be employed on proprietary WANs, such as America Online.TM..  Thus, discussion of embodiments employed on the Internet are exemplary, and equally applicable to other types of networks described above.\nA system for use with an embodiment includes a network enabled device, a network server module and a database.  The network enabled device includes a device having components to couple to a network such as the Internet.  The network enabled\ndevice includes a communication port and processor, and may also include memory and a display.  The communication port may be a physical port, such as a connector extending a modem connection.  The communication port may also be a wireless port, such as\nthose configured to transmit and receive radio frequency data communications.  Examples of network enabled devices include personal computers, handheld devices such as those operating Windows CE.TM.  or Palm.TM.  operating systems, and cellular phones\nwith Internet capabilities such as Sprint PCS.TM.  systems.  Other examples of network enabled devices include smart appliances, such as systems including speakers and a processor to receive communications from the network.\nThe network enabled device may include a media playback component.  The media playback component includes an application that plays back streaming media files.  Examples of commercially available media playback components include Real Network\nPlayer.TM., Apple Quicktime Player.TM., and Microsoft Windows Media Player.TM..\nIn an embodiment, network server module includes server-side modules that communicate to the network enabled device through the communication port.  The network modules may be coupleable to the network enabled device through a network such as\nthe Internet.  Alternatively, the network server module may exist on the terminal.  The network server module may, for example, access a database on the network from the terminal.  Still further, the network server module may exist on both the terminal\nand on a server on the network.  Specifically, the network server module may comprise network-side code, executed on the terminal through a client application.  For example, the network server module may includes applets or Java script delivered to the\nuser terminal for execution of processes and functions, as disclosed herein.\nThe database stores a plurality of addresses.  Each address locates a media network resource.  The media network resource includes files that can be loaded into the media playback component to output media.  As used herein, media refers to a\ncombination of audio and/or video.  Video media may include a collection of images assembled together in an animated fashion to resemble motion or action.  Examples of video media include movie clips, recordings from video recorders, and animation such\nas cartoons.  Still further, media may include a collection of still images and graphic presentations that are combined with audio media.  Other examples of media include dynamic or animated pictures or text on a web page.\nIn one implementation, the media files may be loaded and played back to output music or music videos.  As another example, media files may include video or animation with story-lines, plots, characters and resemble conventional television or\nradio programming.  Other examples include movie clips, home movies, movie trailers, or highlights from sporting events.\nAs used herein, a module includes a program, a subroutine, a portion of a program, a software component or a hardware component capable of performing a stated task or function.  A module can exist on a hardware component such as a server\nindependently of other modules, or a module can exist with other modules on the same server or client terminal, or within the same program.\nThe network server module is coupleable to the network enabled device to exchange communications, and to access the database.  The network enabled device provides a search request, including a search criteria.  The search criteria includes any\ncondition specified by the user to identify some of media files from other media files in the database.  Examples of search criterias include titles, artist names, data types, user preferential ratings, quality, and duration.\nThe network server module selects at least one address from the database based on the search criteria.  The identified addresses are signaled to the network enabled device.  The network server module may communicate with the media playback\ncomponent to cause the media playback component to playback the media resource located by the address.\nFIG. 1 illustrates a process for use with a system to search for and playback Internet streaming media, under an embodiment of the invention.  In one application, the process is performed on architectures described and illustrated with FIGS. 2\nand 3.  While the process is described with reference to an integral system, one or more steps described with FIG. 1 may be performed independently of other steps.  Similarly, components and modules used to perform steps in FIG. 1 may also be implemented\nin different systems and architectures.  Further, steps mentioned with FIG. 1 may be performed concurrently with one other, or in an order different than shown in FIG. 1.\nIn step 110, a system builds a database of addresses.  An address may include a Universal Resource Locations (URL) for network and Internet sites.  A media site include, for example, a web site that allows web users to access streaming media. \nIn other embodiments, the media site may locate network media resources on other types of networks.  The media sites may be located through a media search engine, as described elsewhere in this application.  An exemplary process for identifying media\nsites under an embodiment of the invention is provided with FIG. 4.\nEach media site may provide access to media through one or more media links available at the site or through other means.  The media links identify web resources having media content.  These web resources may include a file of arbitrary type. \nExamples of file types include Multipurpose Internet Mail Extension (MIME) types such as MOV, JPEG, or RAM.  The file is available for loading, browsing or playback on the World Wide web.  Each media link may be either an internal or external link\nrelatively to that particular media sites.  An internal media link on a web-site may correspond to a URL that identifies a web resource located on the web domain, host, property or server of that site.  An external media link on a media site identifies a\nweb resource that is not located on web domain, host, property or server of that media site.\nIn step 120, the system identifies and stores in a database media links (URLs) for each media site.  An exemplary process for identifying and storing media links on individual media site stored in a database of media site is provided with FIG.\n5.\nIn step 130, each media link is verified.  The media link is verified to contain media that is available for playback for users.  Thus, broken links, inoperational or unavailable media are precluded from being verified.\nIn step 140, metadata information is extracted from each media link.  Preferably, metadata information is extracted from each verified media link.  In an embodiment, metadata may also be added to a list or database of extracted metadata. \nAdditional metadata may be added using, for example, manual interactive editing and an editor interface (see for example, editor interface module 275 in FIG. 2).  Examples of metadata information include (with an exemplary data structure type associated\nwith each media link in parenthetical): identification (Integer), author (String), duration (String), media URL (URL), source web site (URL), media type (Integer), rating (Real number), number of votes (Integer), verification status (Boolean), edited\nstatus (Boolean), genre type (Index into a genre database table), play-list genre status (Boolean), mix (index into mixes database table), play-list mix status (Boolean), mood (index into moods database table), description (String), clip broadcast\nquality (integer), image size for videos (integer, integer), and play-list mood status (Boolean).  One or more of these types of metadata may be extracted from the media links or from the actual media file.  For example, a media link to a web resource\nmay be extracted for identification, duration, author, and source web site.  Similarly, one or more of these types of metadata may be added to the extracted metadata information.  For example, genre type and description information may be added to the\nextracted metadata information.\nIn step 150, the system creates media play-lists using media database for predefined categories.  In an embodiment, verified media links are structured into play-lists, such as described with FIG. 10.\nIn some embodiments, links to streaming media commercials may be inserted into the play-lists in various locations between media clips.  These commercials are targeted to the audience likely to listen to the media available on the play-list. \nThe commercial may be produced and broadcast from distributed sources, or from web server module.  Other examples of streaming media that can be included with play-lists includes news items and weather reports.\nIn step 160, a playback interface is provided.  The playback interface causes the media player component on the user terminal to play media associated with media links in each play-list.  The playback interface may include features to manipulate\nplay-lists, or to switch between play-lists.  For example, the playback interface may allow for a user to skip media or web resources until a preferred media or web resource is located.  The playback interface is a software or hardware application that\nis executed on the user terminal.  The playback interface may be packaged as a web application, dynamically accessible through a web server module, or be packaged as a desktop software application.\nIn an embodiment, a playback interface module includes a streaming media clips rating system that allows users to rate each clip as it is played back.  The back-end module rating system uses these votes to generate rated play-lists that are\navailable through the playback Interface for playback.\nFurther, the playback interface module may include a system to allow users to send Internet e-mail notifications to one or more e-mail addressees regarding a media clip, or to send continuous streaming media programs containing multiple media\nclips from multiple network sources.  Recipients may initiate the playback module by selecting one or more links contained in the e-mail.  Selecting a link from the e-mail initiates the play back module on that recipient's terminal, causing the play back\nmodule to play back the media clip or the programming referred to by the sender.\nThe playback interface includes user interface elements that allow users to define and execute search criteria for media playback.\nFIG. 2 is a block diagram illustrating an architecture of a system 200, under an embodiment of the invention.  The system is shown to link a user terminal 210 with media that is accessible on the Internet 220, including the World Wide web 215. \nOther embodiments of the invention may operate with different types of networks.\nThe user terminal 210 includes any network enabled multimedia computing platform.  In particular, user terminal 210 includes any Internet enabled multimedia computing platform.  Examples of computing systems for user terminal 210 include\npersonal computers (PC), personal digital assistants (PDA), smart phones, and Internet enabled televisions and radios, and other devices.  The multimedia capability is manifested in the availability of a steaming multimedia playback software and or\nhardware component.  Internet enabling means that the platform can access information over the Internet.  In an embodiment, user terminal 210 runs the media location and playback interface module 270 that is accessible over the Internet.  A communication\nchannel 212, such as a phone line, wireless medium, or DSL line, is used to couple the user terminal 210 to the Internet.  Alternatively, the playback module may be preinstalled on the client terminal.  Under both configurations the playback module\naccess media play-lists that are stored on an Internet web server.\nA back-end database management system 245 is provided to maintain information used in providing media searching and playback to user terminal 210.  The database management system 245 receives information from modules, including server-side\nmodules that communicate with user terminal 210.  In an embodiment, modules used to provide media search and playback capabilities to user terminal 210 include a media search module 230, an automatic verification and extraction module 255, an editor\nmodule 250, a play-list generator module 260, and a web server module 270.  The modules may communicate with an interface of user terminal 210.\nUnder an embodiment, this communication is implemented using media play-lists on the web server module 270.\nThe modules may also communicate with software applications or components on the user terminal, such as a web browser application or a Streaming Media player component in a manner that will be described below.\nIn an embodiment, media search module 230 includes a media directories meta-crawler module 234 and a media search engine 238.  The meta-crawler module 234 and the media search engine 238 may be operated independently and concurrently of one\nanother.  The meta-crawler module 234 conducts a general search of the Internet 220 to locate media sites.  Media sites may include web pages that are likely to contain web resources, media links to web resources, or links to other web pages that have\nsuch media links and/or web resources.  The meta-crawler module 234 adds the address or location of each found media site to a media site table 243 maintained by database management system 245.  The media site table 243 may list media sites that identify\na URL for each web page located by meta-crawler 234.\nIn one embodiment, the entire media site table 243 is programmatically generated by meta-crawler module 234, without any manual or interactive human input.  In other embodiments, an editor module 232 may interface with database management system\n245 to manually input a URL for one or more of the media sites into the media site table 243.  Another embodiment may substitute editor module 232 for meta-crawler 234, so that the media subdirectory manually receives a URL for each media site.\nThe media search engine 238 accesses the media site table 243 maintained by database management system 245.  The media search engine 238 identifies media links to web resources on each media site provided in the media site table 243.  In an\nembodiment, media search engine 238 contacts each site in the media site table 243 to locate media links.  The media search engine 238 then stores the addresses of each media link in the database management system 245.  In an embodiment, a URL of each\nmedia link is stored in a portion of a media and metadata table 247.\nAn automatic media verification and metadata extraction (AMVME) module 240 accesses the portion of media and metadata table 247 that contains URLs to the media or media links.  The AMVME module 240 verifies each media link in media and metadata\ntable 247.  The media links are verified to contain web resources matching a criteria defining media.  For example, each media link may be verified to contain a combination of audio or video, rather than be only a text document.  In addition, the media\nlinks are verified as available for playback by users, to avoid broken or old links being maintained by database management system 245.\nThe AMVME module 240 also extracts metadata from the web resource associated with each media link in the media and metadata table 247.  Preferably, AMVME module 240 extracts metadata from verified media links.  The AMVME module 240 may\nautomatically visit each media link on the Internet to extract metadata information, as well as verification information.  The metadata extracted pertains to information available from the web resource or about the web resource on the media link. \nExamples of metadata that may be extracted by media extraction module 255 include information such as the author, duration, name, description text, broadcasting and playback quality of the media content and frame size and display resolution for images,\nvideo and home movie clips.  For example, a media link may be associated with a web resource that is an audio media.  Metadata that may be extracted from the media creation may include the artist name, the name of the media creation, length and\naudio/video quality.  In an embodiment, media extraction module 255 also verifies that the media is available for playback from the media site.  The AMVME module 240 may accesses database management system 245 to store verification and metadata\ninformation in media and metadata table 247.\nIn an embodiment, a metadata editor interface 275 is included in the system 200.  The metadata interface 275 accepts manual entry from an editor pertaining to metadata of the web resource associated with each media link.  The metadata interface\nmodule 275 may access one or more media links in the media and metadata table 247 to allow manual inspection of each web resource for metadata information.  An editor operating metadata interface module 275 transmits a media streaming request to have the\nmedia of the web resource replayed for inspection on a terminal.  The metadata editor interface 275 then allows for additional metadata to be stored in media and metadata table 247.  Preferably, the additional metadata information includes metadata that\nis not programmatically available from the media link containing the web resource.  For example, metadata editor interface 275 may be used to add information to media and metadata table 247 information such as genre of the web resource, description of\nthe web resource, and system predefined information, such as mood and mix, that are found applicable by the editor to the web resource.\nA play-list generator module 260 generates a plurality of play-lists based on information in the database management system 245.  In an embodiment, play-list generator 260 accesses media and metadata list 247 for URLs to media contained on\nstored media links.  The play-list generator module 260 may create play-lists 284 from predefined categories characterized by information stored in the database system for media links and metadata stored in table 247.  Play-lists 284 are stored on web\nserver module 270.\nUnder one embodiment, the web server module 270 includes a media location and playback application.  The user terminal 210 interfaces with the media location and playback application through the Internet.  For example, web server module 270\nmakes the media location and playback application available on a web site.  The user can launch the media location and playback application by clicking a link on the web site.  Under another embodiment, the playback application is pre-installed on the\nuser terminal.\nThe playback application accesses the web server module 270 to load media play-lists that are stored on it.  In an embodiment, the playback application reads Media URLs and Metadata stored in one or more play-lists.  This information is used to\nplayback continuous media from the play-lists to the user.  A web page or network site hosting the media file being played back may also be displayed as an instance of a web browser on the network enabled device.  For example, audio media may be played\nback while the user is presented with a web page hosting the audio playback (see FIG. 22 and accompanying disclosure).\nThe media location and playback application may output or playback media processed by the back-end system and stored in the media and metadata table 247 upon receiving a request from user terminal 210.  For example, under an embodiment, music\nmay be outputted from user terminal 210 continuously in a manner that resembles a jukebox, Disk Jockey Mix or a radio station.\nAn interface of the user terminal 210 enables users to skip playback of media clips, or to switch categories.  For example, a user on user terminal 210 may select to hear Jazz programming, and then switch to a genre of classical music.  One or\nmore features of a user-interface may be used to enable users to make selections (see FIG. 21 and accompanying text).  The user may also control playback settings such as volume, pause, seek and retrieve additional media clip information, skip songs, or\nreplay certain songs being automatically played.  The user may also control and/or customize the creation of play-lists using the interface.  For example, one musical play-list may include a combination of genres, such jazz and classical songs.\nIn an embodiment, the media location and playback application programmatically controls a streaming media multimedia software or hardware component to perform the actual streaming of the media digital bits to the user terminal's multimedia\noutput device (such as video display and speakers hardware).  The media location and playback application contains functionality that responds to software events generated by the streaming media component.  For example, a playback error generated by the\nstreaming component may result in the application instructing the component to play another media file.  In another example, the application determines and initiates playback of a media clip in response to the component reporting that the currently\nplaying media has finished.  The application may contain user interface elements that allow users to issue media playback commands.  These commands are dispatched by the application to the component that implements the playback command for the currently\nplayed media.\nIn an embodiment, the media location and playback application works in combination with functional commands provided to the user via a web based software application.  A user-interface may be provided to enable the user to select the function\ncommands at the software application.  An example of a user-interface is provided below, with FIG. 21 and accompanying text.\nIn an embodiment, a categorization module 290 accesses media and metadata table 247 to add metadata and to categorize media associated with media links in media and metadata table 247.  The automatic process generates metadata such as music\ngenre by consulting with information stored in other records in media and metadata table 247.  For example, the module can automatically set the genre metadata information for all media creations available in the table, for a given artists, according to\ngenre metadata entered for one or more media creations by the same artists.  This process greatly contributes the efficiency and scalability of the back-end system.\nFIG. 3 is high-level system software components diagram for the system 300, under an embodiment of the invention.  The diagram shows how software components may be written, deployed and interact to provide the functionality described by system\n200.  The components of system 200 may be described as a three-tier architecture.  Components are written to spec and deployed to a backend tier, a middle tier, and a front tier.  The backend tier includes the database management system 245.  The\ndatabase management system 245 includes a database 345 and a backend interface module 355.  The backend interface module 355 may be provided with, for example, a Microsoft SQL Server system (MS SQL).\nThe middle tier includes modules that communicate with backend interface module 355.  The middle tier may include a media sites manager 360 and a media manager 365 software components.  The media sites manager 360 and the media manager 365 each\nindependently communicate with backend interface module 355.  The media sites manager 360 components exposes a programmatic interface 362 to communicate with modules and components in the front tier.  The media manager 365 includes a first media manager\ninterface 366 and a second media manager interface 368.\nThe front tier includes a media site module 330 and a media module 340.  The media site module 330 communicates with site interface 362.  The media site module 340 communicates with the first and second media manager interfaces 366 and 368.  The\nfirst and second media manager interfaces 366 and 368 communicate with the media module 340.  The media site module 330 includes a front-end interface 332 to a directory meta-crawler 310 and a media search engine 312 modules.  The media site module 340\nincludes a front-end interface 342 to the media search engine 312, an editor interface module 314, and an automatic verification module 316.  The directory meta-crawler 310 crawls Internet media directories web sites.  The links to media web sites are\nhanded over to the MediaSite module 330 for storage in the database.  The media search engine 312 searches for media links on web sites provided by the MediaSite module 330, these links are transferred through Interface 342 on the Media module 340 for\nstorage in the database module 345.\nThe editor interface module 314 obtains media link for editing from the Media module 340, using Interface 342 and loads the media for editorial playback from the Internet.  The editors provide metadata for media that are added to the database by\nthe Media module 340.\nThe verification module 316 examines media files or web resources accessed through each media link and updates metadata regarding media availability in the database using Media module 340.  This module also extracts metadata from Internet media\nand updates this in the database using Media module 340.  The module queries the database for a batch of media records using the Media module 340 and automatically verifies and extracts metadata for the Internet media represented by these records.\nWith respect to communications from the backend tier to the front-end tier, database management system 345 of the backend tier provides records to the system 300.  Each record or record set is disconnected from tables or databases of record(s). \nDisconnected records are transmitted from the backend tier to the front-end tier as active database objects (ADO) Disconnected record sets.\nWith respect to communications from the front-end tier to the backend tier, each disconnected record can be updated in the database by any components on any tier.  Updated records are transmitted to the database management system 345 in the form\nof record set update operations.  In an embodiment, directory meta-crawler 310 sends URLs to be added to records in database 345 to media site module 330 using an asynchronous method calls.  The media search engine 312 transmits to media site module 330\nusing a get search method call for batch sites of URLs.  The media search engine 312 uses an asynchronous method call to add media links and metadata associated with media links.\nThe components and all tiers expose programmatic interfaces that contain callable methods using the MS DCOM (distributed component object model) software component technology.  Communication between the tiers is also implemented using method\ncalls on these components.  The components are deployed in front, middle and back tier hardware systems.  Alternatively, The components may be developed and deployed using the MS COM+ components technology.  Using this technology, a COM+ In Memory\nDatabase system (IMDB) proxies and caches tables of the back-end database module 245.  This process speeds up the search and editorial process.  COM+ services such Queued Components may used to implement asynchronous method calls exposed on Interfaces\n362 and 366.\n<BR><BR>C. Media Search Engine\nEmbodiments of the invention locate web resources on a network such as the Internet.  In one embodiment, a network browser identifies a plurality of links to one or more network sites.  The links are each selectable to open a network resource of\na specified data type.  The identified links are then made available to network enabled devices that can select one or more of the links.\nAs used herein, a network browser is software that performs core functions that include (i) loading network resources; (ii) parsing, translating and laying out network resources, and (iii) displaying the network resources.  The network browser\nincludes an application programmable interface (API).  An embodiment of the invention employs the network browser on a back end to locate the network resources of the specified data type.  One advantage of this embodiment is that the web browser is\nemployed on the back end programmatically, rather than through manual interaction with an editor or other user.\nA network browser may include a shell, an API, and a processing module.  A component of the network browser includes the API and the processing module.  For Internet applications, the processing module may include, for example, a MSH.TM.  or DLL\nmodule.  The network browser component performs functions that include loading a network resource, as well as parsing, translating, and laying out the network resource.\nIn an Internet application, a web browser component may be used to locate resources of a specified data type.  The web browser component may be a portion of a commercially available browser.  For example, the web browser component for use with\nan embodiment of the invention may be a reconfigured Netscape Navigator.TM.  or Internet Explorer.TM.  browser.\nIn an embodiment, the web browser component is programmatically controlled through the API of the web browser to access the web resource for the plurality of links.  The web browser may be programmatically controlled to bypass the shell of the\nweb browser.  For example, the API may be used to instruct the web browser to ignore the shell, or to detach the functionality of the shell.  The remaining web browser component then identifies the links to the specified data types.  The result is that\nthe web browser component accesses the web resources of the plurality of links to identify the data types of the resources on the links while ignoring data such as images and sound.\nIn another embodiment, a search module controls the web browser component to access a web site.  The search module controls the web browser component to identify a plurality of links to media web resources at the web site.  Each of the plurality\nof links identified by the web browser component are selectable to open a media web resource.  The search module stores the plurality of links in the database.\nIn another embodiment, a database includes a plurality of links to media web resources.  The plurality of links are programmatically verified to determine whether each link opens a corresponding media web resource.  The verified link are made\navailable to a plurality of Internet enabled devices that select one or more of the links to open the corresponding media web resource.\nThe links may be verified on the back end using a media player, including a commercially available media player.  For example, each link that needs to be verified may be programmatically loaded through an API of the media player.  The response\nprovided by the media player to the link determines whether the links are verified.\nIn another embodiment, the media player may be programmed to identify metadata from the media web resource of each link.  The metadata may then be stored in a database associated with the link.\nAmong other advantages, embodiments enable network links to files of a particular data type to be rapidly accumulated and stored in a database.  Each of the links are selectable to open a file on the network.  The files may enable a terminal to\nplay back media.  In an embodiment, the addresses access media files that can be loaded into the media playback component of the user terminal.  The files can be stored in the database with information that characterizes the files associated with the\nlinks.  Thus, the links may be characterized by, for example, metadata information, and one or more classes of information.\nIn addition, embodiments enable each link in the database to be programmatically verified, so that there are no broken or unavailable links in the database.  Still further, some metadata information may be programmatically identified from each\nmedia file.  In contrast, existing systems verify links manually, employing interactive users to perform the manual functions.  Existing systems also extract metadata information manually.\nFIG. 4 illustrates a block diagram in which system 200 receives a search request 203 and provides a response 209.  In an embodiment, system 200 processes the search request 203 using the web server module 270 and the media and metadata database\n247.  The end terminal 210 signals the search request 203 to web server module 270.  The web server module 270 accesses the media and metadata database 247 to retrieve one or more URLs matching the search request.  The web server module 270 signals the\nresponse containing the retrieved URLs to the media playback component 211 of end terminal 210.\nIn an embodiment, the search request 203 includes one or more criterias that specify a selection of URLs from media and metadata database 247.  The criterias may correspond to parameters in media and metadata database 247.  The table 249\nillustrates a data structure of media and metadata database 247.  The table 249 includes a URL list comprising a plurality of URLs.  Each URL provides direct access to a web resource containing media.  Each URL is characterized by one or more parameters\nthat correspond to metadata information about the web resource associated with the URL.  As an example, table 249 provides parameters as being genre (G), data type (DT), category (C), web resource identity, and one or more play-lists (PLAY1, PLAY2,\nPLAY3).\nThe genre data is a broad class identifier of the media creation comprising the web resource of the respective URL.  For music, the genre may include rock, classical, and jazz.  For movies, the genre may correspond to romance, comedy, horror\netc. The genre may be identified either programmatically, or through an editor interface.  One genre may be associated with one or more URLs in table 249.  In the example provided, URL1-URL7 are in either one of three genres, G1, G2, and G3. \nAlternatively, several genres may be associated with one URL.\nThe data type parameter corresponds to the MIME characteristic of the web resource associated with the URL.  The category parameter may correspond to a sub-class of a genre.  For example, in music, a category may correspond to soft rock.  In\nmovies, a category may correspond to the time-period of the movie.  The table 249 illustrates an example in which the category is unique to the genre.  Thus, a web resource of one genre is not in the same category as a web resource of another genre.  As\nan example, URL1 and URL3 are in the same category, as are URL2 and URL5.  However, no other URLs are in the same category.\nOther metadata information that may be included in media and metadata database 247 include identifier information.  The identifier information identifies the web-resource.  The identifier may provide name of a specific media creation, as well as\nan artist or author of the media creation.\nIn an embodiment, media and metadata database 247 includes play-list information as parameters of metadata information.  The play-lists may be identified in any one of several ways.  For example, the play-lists may be identified by a unique name\nor other identifier.  The play-lists may be identified by another parameters, such as genre or category type.  A Boolean data type may be associated between each URL and each play-lists.\nThe criterias of the search request 203 specify one or more parameters to media and metadata database 247.  For example, search request 203 may include criterias corresponding to one or more of a genre, category, play-list, or identifier.  In an\nembodiment, web server module 270 accesses media and metadata database 247 for URLs that have all of the parameters set forth in the search criteria.\nThe web server module 270 retrieves the URLs matching the criterias of the search request.  The response 209 is signaled to the media play-back component 211.  The response includes one or more URLs.  It is noted that when play-lists are\nrequested, additional URLs multiple play-lists are provided.  The response 209 may also include metadata information.  For example, the response 209 may signal to end terminal 210 the duration of the web resource for each URL, the artist, the history,\netc.\nThe web server module 270 further signals control information 207 to access the URL provided in the response 209.  The control information 207 causes end terminal 210 to load the web resource for the media playback component 211.  Thus, the\nmedia playback component automatically loads the web resources associated with each URL included in response 209.  The experience provided to end user 210 is that media is outputted in response to inputting a search request.  This is in contrast to other\nsystems in which the user is provided links to media sites containing web resources matching the search criteria.\nAs an example, a user may specify a media creation from a specific category.  For example, the user may input a search request for \"nature sounds\".  The web server module 210 accesses media and metadata database 247 for parameters that match\n\"nature sounds\".  In one application, a play-list is located that is pre-programmed to provide URLs to web resources containing nature sounds.  The response 209 then comprises one or more play-lists, each containing multiple URLs to web resources\ncontaining nature sounds.  In another application, a category parameter or sub-parameter is searched for \"nature sounds\".  The response 209 may include one or more URLs that are not pre-programmed into play-lists.  The response 209 may provide URLs to\nmedia playback component 211 one at a time, in groups (such as in play-lists), or all at once.\nIn an embodiment, categorization module 280 may be used to programmatically create one or more parameters such as illustrated by table 249.  The parameters may be determined, by for example, identifying metadata information on the media site\nhosting the URL.\nFIG. 5 is a block diagram illustrating the media playback component 211 being controlled by one or more modules of system 200, under an embodiment of the invention.  The web server module 270 signals control information to an application program\ninterface 276 of the media playback component 211.  The control information may be provided by the media locator and playback application of the web server module 270.  The web server module 270 signals commands, with one or more URLs corresponding to\nmedia resources selected to be signaled to the user terminal 210.  As an example, commands from web server module 270 may be instructions that use each URL as an arguments.  Examples of commands that control the media playback component include play\n(URL) and pause (URL).\nAs an optional feature, web server module 270 may also signal control information to a web browser component 213 of user terminal 210.  The control information may be in the form of commands to access and display a web site associated with the\nmedia resource.  The commands may be provided to an application program interface 279 of the web browser component 213.  This allows the system 200 to display the web site associated with the media resource selected to be played back on user terminal\n210.  Thus, user terminal 210 may play back media from the media resource while displaying the web site where the media resource is located.  One advantage of this embodiment is that it allows users to receive media playback from the media resource in\none medium, such as audio, while providing images, audio text, or media not associated with the media resource.  Thus, users can listen to songs from media resources signaled to user terminal 210, while viewing banner ads on the web site where the media\nresource is located.\nEach URL signaled from web server module 270 has a network protocol.  For media resources, and specifically audio files, types of protocols include \"HTTP\" protocol, \"PNM\" protocol (RealNetworks, having .RM extensions), or \"RTSP\" protocol (having\n.RAM extensions).  The URLs signaled by web server module 270 include the protocol at an initial portion of the string forming the URL.  Preferably, for HTTP protocol files, the string portion corresponding to \"HTTP\" is replaced with \"PNM\".  This\nadjustment prevents playback component 211 from failing as a result of a bug in the media playback component, particularly if the playback component 211 is a RealNetworks Player.TM..\nThe web server module 270 may be either a network-side module, client side module, or a combination of both.  In either embodiment, web server module 270 may access the database directly or indirectly.\nFIG. 6 illustrates a process for a component of an Internet media search module, under an embodiment of the invention.  A process such as described with FIG. 6 may be used to build a database of media sites, where each media site includes media\nlinks and/or links to other media sites.  In an embodiment, the process of FIG. 6 is applicable to meta-crawler module 234 in system 200 (FIG. 2).\nThe process of FIG. 6 is a backend operation that is unobservable to a user of the user terminal.  Preferably, the flow process of FIG. 6 is an automatic or programmatically controlled process, conducted periodically.  For example, media links\nmay be identified and stored under a flow process such as shown by FIG. 6 every few days or weeks.  The duration between executions of the flow process of FIG. 6 maybe referred to as an idle period.\nThe process of FIG. 6 provides for extracting URLs of media sites from a web pages directory.  Examples of a web directory for use with an embodiment of the invention includes directories on web sites such as Yahoo.com.RTM.  and Lycos.com.RTM.. \nThe flow process of FIG. 6 is a backend operation that is unobservable to a user of user terminal 210.  Preferably, the flow process of FIG. 6 is an automatic or programmatically controlled process that does not require human interaction.\nIn step 410, a directory home page is added to a searched-pages data structure.  The searched-pages data structure maintains.  A similarly structured parsed-pages data structure is also maintained to hold URL of pages already processed by the\nmodule.  The parsed-pages data structure indicates whether a home page web directory was previously parsed by the process.  The searched-pages and parsed-pages data structures are keyed or indexed by URL and they support querying for existence of a given\nURL in them.  Examples of keyed or indexed data structures include database tables and hashtables.\nIn step 410, the parsed-pages data structure is empty, indicating that the directory home pages in the searched-page data structure have not been parsed.\nIn step 420, a determination is made as to whether the searched-pages data structure is empty.  If the determination is affirmative, the flow process is done.  This occurs when the process has parsed all the Internal web pages in the directory. \nIf the determination is negative, a current page link is called from the searched-pages data structure in step 430.  The current page is then loaded into memory and parsed.  Parsing means loading and reading the HTML source (or equivalent) code of the\nweb page so its content is accessible and in a machine-readable format.\nIn an embodiment, the page is parsed using an HTML parser component.  An example of an HTML parser is a web browser.  Thus, the current page may be parsed using a web Browser component.  Specifically, step 440 of the process may be implemented\nusing an application program interface (API) that is exposed by the web Browser component.  In this context, the web Browser component is configured and used in a back-end server process with no visible presentation area or end user.  It is configured\nnot to load or render media at the web page so that the loading is more efficient.  The configuration may occur through the API.\nIn an embodiment, the web browser is configured to parse web pages efficiently by, for example, automatically excluding a presentation layer from being displayed.  Further, the web browser may be programmatically configured to not load or parse\ninformation that is not critical to the search function.  For example, the web browser component can be configured to not load media data found on web pages.\nIn step 440, all links to media sites on the currently parsed-page are determined using the parser.  The HTML parser API allows access to the page document object model.  In step 450, all new external page links are added to the media sites\ndatabase.  An example of a web-page data structure is provided with media site database table 243 (FIG. 2).  The database stores the URL of the media sites and not the sites themselves.  New external page links implies media sites that are not already\nindexed or present in the media site database.\nIn step 460, all URLs also link to internal links found on the currently parsed page are added to the web pages data structure, provided that the URL in question is (i) not already existing in the searched pages data structure and (ii) not\nalready existing in the parsed pages data structure.  In step 470, the currently parsed page is moved to the parsed pages data structure, and the flow process returns to step 420.  This process adds the URL of all the media sites indexed by the directory\nto the media sites database.\nFIG. 7 illustrates another component of an Internet media search module, under an embodiment of the invention.  A process such as described with FIG. 7 may be used to identify and store media links to web resources that are accessible from one\nor more web site.  The process of FIG. 7 may be used in conjunction with a process such as described with FIG. 4.  In an embodiment, the process of FIG. 7 is applicable to media search engine 238 in system 200 (FIG. 2).\nIn an embodiment, the flow process of FIG. 7 is a backend operation that is unobservable to a user of the user terminal.  Preferably, the flow process of FIG. 7 is an automatic or programmatically controlled process, conducted periodically.  For\nexample, media links may be identified and stored under a flow process such as shown by FIG. 7 every few days or weeks.  The duration between executions of the flow process of FIG. 7 maybe referred to as an idle period.\nThe flow process of FIG. 7 assumes access to a media sites database store.  The database includes URLs to each media site.  An exemplary database of media sites includes media sites and metadata table 243, described with FIG. 2.  Each record\ncontains a URL field for media site and a field indicating the last date, if any that the process described in FIG. 5 lastly processed the web site at the URL in the URL field.  Reference to a media site that is parsed implies that the media site was\nprogrammatically examined for media links to web resources, and for links to other media sites using a process such as the one described in FIG. 5.\nIn step 510, MIME types are determined for web resources.  Examples of MIME types that can be selected for step 510 include JPEG, MOV, RAM and WAVE.\nIn step 515, a record for a media site is fetched or received from the database.  A condition of the media site received is that the media site was not parsed by the process described here during the idle period.  This condition may be specified\nby checking, for example, the date field associated with the record.  For example, a date field may indicate when the media site was previously parsed.\nA determination is made in step 520 as to whether a record and a URL was received in step 515.  If no URL was received, the system interprets that all media sites in the database have already been parsed during the idle period.  If a URL is\nreceived, the system in step 525 adds the URL of the media site to a URLs data structure of media sites to be processed.  The URL data structure of unparsed media sites may be indexed or keyed.  For example, the URL data structure may be a list, or a\nhashtable software data-structure.\nIn step 526, the last search field of the record fetched in step 515 is updated with the current date to indicate that the media site is parsed.  In an embodiment, the field corresponds to a date in which the last parsing occurred.\nIn step 530, a URL in the date structure of unparsed media sites is fetched or received.  If in step 535, a determination is made that the URL data structure is empty, the system returns to step 515.  As will be further described, the flow\nprocess returns to step 515 only when step 570 is completed.  If a determination is made that the URL data structure is not empty.  Thus, steps 510-545 allow the flow process to distinguish between when a media site is being parsed for the first time, or\nhas been previously parsed by the process during the idle period.\nIn step 545, media links on the media site fetched in step 530 are extracted from the HTML code of the page fetched in step 530.  The media links are associated with web resources on that media site.  In step 545, the media resources may be in\nany MIME format recognizable as media.  In an embodiment, the currently parsed page is parsed using an HTML parser.  An example of an HTML parser is a web browser.  Thus, the media links may be extracted using a web browser.  Specifically, the media\nlinks may be extracted using an application program interface (API) provided by a web browser software or hardware component.  The web browser may be configured to perform this task efficiently by, for example, excluding a presentation layer.  Further,\nthe web browser may be programmatically configured to not load or parse information that is not critical to the search function.  For example, the browser component may be configured to not load media data found on web pages.\nIn step 550, new media links on each media site that match the MIME format specified in step 510 are added to a database.  New media links refers to media links that do not already existing in the database from, for example, a previous execution\nof the flow process.  In step 555, metadata is extracted from each new media link found in step 550.  The metadata may also be stored in the database, with a reference to the URL the media that the metadata refers to.  An exemplary database is provided\nwith media and metadata table 247 (FIG. 2).  An example of metadata is the URL of the web Page that provided a link for each media URL.\nIn step 560, the URLs of all new internal media site links on the media site currently being parsed are added to the URL data structure.  New internal media site links refers to URLs of media sites that do not already exit in the URL data\nstructure and that are not in the parsed URL data structure.\nIn step 570, the currently parsed page is removed from the URL data structure and added to the parsed URL data structure.  The flow process returns to step 530.\n<BR><BR>D. Verification and Extraction Flow Processes\nFIG. 8 illustrates a flow process that verifies and extracts metadata from Internet streaming media files.  While media links are specified, other embodiments of the invention may employ the flow process of FIG. 8 within a system that\nincorporates verification and extraction of any content or resource associated with links stored in a database.  A specific application employs a process such as described with FIG. 4 in the system 200.  In the system 200, flow process of FIG. 8 may be\nperformed by the AMVME module 240.\nIn step 610, a module operating the flow process of FIG. 8 fetches or receives an unverified URL from a database.  An example of such a database is provided by media and metadata table 247 (FIG. 2).  The unverified URL corresponds to a media\nlink on a media site stored in a database such as the media site database 243 (FIG. 2).\nIn step 620, a determination is made as to whether a URL for a media link is present.  If the URL to the media link is not present, the module assumes all media links have been determined as being verified, and the process is done.\nIf a URL exists, the module in step 630 loads the URL into an Internet multimedia playback software component and programmatically control the component to provide metadata embedded in the media file.  In response to this request, the component\nloads some or the entire file over the Internet and provides the process with this information.  In step 640, a determination is made as to whether the media or web resource associated with the URL was successfully loaded over the Internet by the module. If the determination is that media was not loaded, then in step 650 the URL associated with the media link is marked as unavailable and verified.  The media is marked as verified to prevent the process from revisiting it once it already extracted\nmetadata for it and verified it.  The availability mark assists the flow processes described in FIG. 9 and FIG. 10.  The determination may be in the negative if, for example, the media link is old and no longer contains a media file that is available for\nplayback through its URL, or if the media link contains content other than what is designated as media.\nIn an embodiment, the process may use an availability rating for each media.  Under such schema, each media is assumed to have the maximum availability score.  For media that are currently not available for playback, step 650 may lower the score\nby one.  The system may consider the media as unavailable if its score is below a predefined threshold.  This process is useful since Internet streaming media availability may vary according to factors such as web server load and the time of day or year.\nIf the media is loaded, then in step 660 the media metadata is extracted from the playback component.  Examples of metadata that can be extracted in this step include-artist name, playback duration, playback quality, frame size etc.\nIn step 670, extracted metadata is stored in a database with the associated URL of the media link that was presently verified.  In step 680, the URL of the media link presently verified is marked as verified in the database.  The flow process\nthen returns to step 610.\nFIG. 9 illustrates a process for interactively adding metadata to URLs of media stored in a database.  In an embodiment, the database may correspond to verified URLs of media links determined in FIG. 8.  For example, a process such as shown by\nFIG. 9 may be performed on information stored by AMVME module 240 in media and metadata table 243.  The process of FIG. 9 may be performed by a module interface, such as editor interface 275 (FIG. 2).\nIn step 710, an unedited media record is fetched or received by an interface module from a database.  The unedited record may be one or more categories of metadata and other information about a media link, media site, or web resource.  In an\nembodiment, the unedited media information includes a URL to a media link, as well as metadata extracted programmatically, such as described with FIG. 8.  In step 720, a determination is made as to whether a record was received.  If no record is received\nin step 720, the flow process assumes there are no unedited records remaining in the database, and the process is done.  If a record is received, the in step 730 the interface module is updated with the record received.  This may correspond to displaying\nthe record fields to the editor operating the editor interface.\nIn step 740, the web resource associated with the record received is loaded into an Internet multimedia playback software component.  Preferably, the software component is programmatically constructed and controlled by the module interface.  The\nsoftware component plays back the media to the editor.  The editor is able to experience the media played back from the web resource associated with the media link.  The editor is able to determine metadata information regarding the web resource.  For\nexample, the editor may determine mood, genre, quality, appropriate mix name, and description of a web resource such as an audio media creation or a home movie clip.  In an embodiment, the editor controls playback of media located by the search engine on\nthe network side, such as by pausing and playing media back through an editor interface.\nIn step 745, a determination is made as to whether the record received also includes previously determined metadata.  The previously determined metadata may be extracted programmatically in another process, such as described with FIG. 8.  If the\ndetermination is made that the record received does not contain extracted metadata information, then in step 750 the editor interface automatically extract metadata from the web resource associated with the URL of the record.  To accomplish this step,\nthe editor interface may access another module that automatically extracts certain types of metadata information.  For example, the editor interface may forward the record to AMVME module 240 (FIG. 3) that performs a flow process such as shown by FIG. 8.\nOnce metadata is included with the record, then a determination is made in step 760 that the editor operating the interface module may choose to save the auto-extracted metadata already included with the record in the database.  If the\ndetermination to step 760 is negative, then in step 765 the editor updates media information with editor provided metadata using input elements on the editorial software user interface.  Once the determination in step 760 is positive, the record is\nmarked as edited and updated in step 770.  Then, all the newly added metadata for the media record is updated to the database.  The process then continues from step 710 for the next unedited media.  The media is marked as edited so it won't be included\nfor editing in the process.\nFIG. 10 illustrates a process for generating a play-list.  The flow process of FIG. 10 assumes that play-lists names are predetermined and stored in a database.  Each play-list is identifiable by its name.  For example, classic music, jazz and\nrock.  The play-lists include records of media links.  In an embodiment, a record includes at least a URL to a streaming media that is categorized in a database as belonging to the play-list name.  In step 810, a play-list name is received from\nthe-play-lists database.  In step 820, a determination is made as to whether a play-list name was received.  If the determination is negative, the system assumes it produced play-lists for all play-lists names, and the flow process is done.  This process\nis routinely executed to add all newly added media to the appropriate play-lists.\nIn step 830, media records that match search criteria are fetched from the media database.  The criteria is that each record play-list record field must match the current play list name obtained in step 810 and that the `in-play-list` record\nfield for the play list name has False value.  In step 840, a play-list is generated to include all media stored at the records fetched is step 830.  The new play-list contains one record entry for each fetched media record.  Preferably, each play list\nrecord includes media URL and metadata information that is obtained from the media database record.\nIn step 850, the media records called in step 840 are labeled as being in the \"in-play-list\" for the current play-list name.  This is achieved by setting the \"in-play-list\" value for the media database record to true for the appropriate\nplay-list name.\nIn step 860, the generated play-list is made available to a server-side module, such as web server module 270 (FIG. 2).  As an example, the play-lists may be stored, copied or appended to be made available on the web server module.  Once the\nplay-lists are available on a server-side module, media URLs and metadata stored in the play-lists is made available to the user terminal so that the user terminal may customize media output available from the play-list.  Specifically, one or more\nplayback applications that run on the user terminal may read the play-lists, access media links on the play-lists, continually play-back streaming media from media URLs in the play-list and present media metadata to users for further interaction.  The\nplay-list may also be configured to provide access to a client-side media player component that uses a URL of a media link to load and play the media associated through it.  Additionally, users may further modify and edit play-lists to create\npersonalized media programming.  Further, play-lists may be dynamically generated by a web application in response to a request for media playback made on the user terminal.\nFIG. 11 is a flow process for software or hardware application that enables a user terminal to playback streaming media programming determined by play-lists.\nAn embodiment described below assumes that play-lists are available for the process, and that play-lists are identifiable by play-list names.  For example, the play-lists may be dynamically generated by the play-list module, in response to a\nsearch criteria signaled from a user terminal.  The play-lists may also be manually generated by editors on the network side.  The play-lists may be predetermined by, for example, a process described with FIG. 10.  The playback component can access the\nplay-list without any direct interaction with server side modules.\nIn an embodiment, the flow process employs a streaming media player component installed on the user terminal.  The media player may be preexisting on the user terminal.  Examples of media players for use with an embodiment include RealNetwork\nPlayer.TM., Microsoft Windows Media Player.TM., and Apple QuickTime.TM..  The application described in the process may be web based or installed on the user terminal.\nIn step 910, an application interface for a media player on the user terminal is provided.\nIn step 920, a default play-list name is selected from a list of play-lists.  In an embodiment, a database of play-lists is stored on or accessible through the web server module 270.  The play-list generator module creates and stores play-list\non the web server module to provide the interface with the user terminal 210 and media player stored thereon.  Each play-list may store two or more media links, and preferably a plurality of media links.\nIn step 930, one or more play-lists for the current play-list name are loaded.  In step 940, media is presented and played-back on the user terminal.  To playback media, server-side modules may provide the media player with URLs to media links\nthat are stored in each play-list.  Each play-list may include one or more media link URLs and media metadata.  The user terminal then accesses the URL and loads the web resource associated with that media link into a streaming media playback component\non the user terminal.  Media playback on the user terminal includes outputting, for example, audio and/or video stored in digital format on web resources associated with a media link.  In embodiments where the web resources include video media, the step\ndescribed may dynamically adjust the interface size and the playback component that will handle the actual playback according to the media clip metadata.\nUnder an embodiment of the invention, the media playback component continuously plays back media by (i) accessing a first site on the network and playing back media from the first site, (ii) then automatically accessing a second site and playing\nback media from the second site.  The media sites may be provided by play-lists which that are made accessible to the media playback component.  The sequence for automatically and continuously playing back media may be repeated for each media link\nincluded in the play-list.  The play-lists may include hundreds of media links, thus allowing the media play back component to automatically and continuously play back media using numerous sites on a network.  As a result, a user is able to experience\ncontinuous media play back for hours at a time.\nThe user terminal also includes an interactive interface to affect the media being played back.  An end user on the user terminal may choose to manipulate media playback through one or more commands that may be inputted through the application\ninteractive interface or presentation layer.\nIn step 945, a determination is made as to whether an event occurred.  If an event occurred, the flow process determines the event.  The flow process may determine the event that occurred sequentially or concurrently.  Preferably, the flow\nprocess is configured to receive media playback event from the streaming media playback component.  If the event is to skip the currently played media, then a determination in step 960 causes a corresponding action of the media being skipped, and the\nprocess step returning to step 940.  If the process received a playback error event, or an playback error event, then a determination in step 965 causes the flow process to return to step 940 to playback media from the next web resource of the play-list\nor play-list name.\nIf a user quits the application, or signals to quit, then a determination in step 970 causes the flow process to be done.  In step 975, a user may choose to view a new media web site while media is being played back on the user terminal.  Then\nin step 980, the media web site is opened in a new Internet window, preferably using the client side web browser.\nIn step 982, a determination is made as to whether the action selected by the user on the user terminal is to send an e-mail message to one or more e-mail addresses that allow the receiver(s) to playback the current media and the current\nplay-list played by the sender at the time of the event.  A user may send either an e-mail containing the URL, the play-list, the play-list name or a URL link.  When the message receiver clicks on the link, his terminal will execute the media playback\napplication and will start playing back the media and the play-lists played at the time of the message-sending event.  If the determination is positive, then in step 984 the user terminal prompts the user for an one or more e-mail addresses, and then\nprompts the user to transmit the e-mail.  The user need not have an e-mail client software application for the operation to succeed.  The e-mail may be directed to terminals having a streaming media playback component and Internet access.\nPreferably, the e-mail message is directed to a user having a user terminal that communicates with server-side modules so that the recipient user terminal is automatically plays back media from the transmitted media link received upon the e-mail\nbeing opened.  Thus, server side modules may receive addresses from the terminal and act as the source of the email addressed to one or more recipients.\nIn step 986, a determination is made as to whether a user wishes to rate a media played back from the media links.  If the determination is positive, then the user is prompted to rate the media in step 988.  A rating value is transmitted to a\nbackend web rating system application using the Internet.  This operation is part of the service rating system that includes server side modules that produce, in combination with this operation, top and bottom rating media in each media category.\nStep 990 illustrates other exemplary actions that may be received from a user on the user terminal interfacing with the playback application.  For example, user actions may correspond to pausing media playback, adjusting volume, picture\ncontrols, size, seeking within the media, etc. In step 992, playback settings are changed according to user input.  In an embodiment, the flow process returns to step 945 to check for another event if any of the determinations in step 982-992 are\nnegative.\n<BR><BR>E. Rating System for Media Play Back\nAn embodiment of the invention includes a rating system with a media search and playback system.  The rating system allows users to listen or view media segments available over the Internet according to a rating.  In addition, users participate\nin determining rating media segments by providing a rating input after listening or viewing a media clip.  The ratings may be used as a category, similar to other categories such as genres or categories.\nFIG. 12 illustrates an architecture for use with the rating system, under an embodiment of the invention.  The rating system 1000 may be employed with, for example, the system 200 (FIG. 2).  The rating system 1000 may include or cooperate with\ncomponents of a system such as described with FIG. 2 to enable the user view and/or select media clips from play-lists.  The generated play-lists may contain a list of links to media on the Internet.  Selection of media clips by the user causes media to\nbe played back to the user over the user terminal.\nThe rating system 1000 includes a backend database management component 1045.  The database management component 1045 maintains organizational data structures such as tables that describe rating information for media clips.  The media clips\ninclude Internet streaming audio or video.  The rating information may be in the form of values such as, for example, total votes counted.  In an embodiment, database management component 1045 maintains records that comprise meta information on each\nmedia clip including the URL to the media clip, the current rating of the media clip, and the total votes for that media clip.\nA user 1010 on a user terminal interacts with a web-based playback interface 1020.  As an example, play-back interface 1020 outputs play-lists 1018, 1022 to the user.  The media clips in each play-lists may be outputted automatically, or\ndisplayed for the selection of the user.  The play-back interface 1020 may also display to the user genre field 1016 or category field 1014 of the selected media clip, or play-list 1018, 1022.  The playback interface 1020 includes features to enable a\nuser on the user terminal to make entries or selections regarding preferences and opinions, as well as other types of information.  The user may also view ratings stored on backend database 1045.  The user may enter selections by, for example, using\nicons or other display features.  The user may make entries by, for example, inputting text or voice.  FIG. 12 illustrates a rating selection component 1012 as a feature of play-back interface 1020.  As an example, the rating selection component 1012\nallows users to rate a media output between a scale of 1 to 5.\nA user 1010 may input a rating to play-back interface 1020.  The rating is signaled from play-back module 1020 to a rating module 1030.  In an embodiment, rating module 1030 maintains a tally for each media clip.  The tally compiles ratings\nreceived from play-back module 1020.  The ratings may be received from more than one user and/or user terminal.  The tally may be implemented through a protocol that enables the rating module 1030 to organize media clips according to an order.  The\norganization of the media clips may correspond to a user preferential list, where preferred media clips are, for example, listed together or listed before less preferred clips.  The rating module 1030 may also determine a genre, category, or other\norganization information through selections or entries received from the play-back module 1020.  The selections may be tallied through any protocol, such as summation, averages, weighted averages and moving averages.  In another embodiment, the rating\nmodule 1030 may maintain a text field to store user comments regarding each media clip.\nIn an embodiment, the rating component 1030 updates the rating information maintained in the database management component 1045.  For example, the rating component 1030 may update values of the current rating and total votes for each media link.\nA play-list generator 1040 generates play-lists based on rating information maintained in the database management component 1045.  The play-list generator 1040 may signal to retrieve or receive records for each media clip.  The play-list\ngenerator 1040 then automatically generates one or more play-list 1042.  As previously discussed, each play-list is a list of media links.  In an embodiment, the play-lists 1042 are generated according to the current rating and/or rating for each media\nclip.  The generated play-lists are provided by the play-list generator 1040 for the play-back interface 1030.\nThe user 1010 may choose to listen to play-lists containing media clips rated according to one or more criteria.  The play-lists may also be organized according to other factors, such as genre and category.\nFIG. 13 is a flow chart that allows a user to listen to media clips that are rated according to one or more criteria.  In step 1110, the user is provided a user-interface that allows users to receive media sorted according to one or more\ncategories.  The categories correspond to genres, such as type of music etc.\nIn step 1120, the user selects a category from the options presented by the user-interface.  In response to the selection, the user terminal is provided one or more play-list in step 1130.  The play-list received by the user-terminal matches the\ncategory or genre selected by the user.  Further, play-lists contain predetermined media links to media clips.  The media clips in each of the play-lists are determined according to a rating system, using a system such as described by FIG. 12.  The\npredetermined play-list may correspond to a play-list generated by play-list generator 1040 (FIG. 12).  Once the play-list is received by the user terminal, the flow process returns to step 1120.\nIn step 1140, media clips are played back on the user terminal.  The media clips are played back consecutively and automatically, so that the user experiences continuous media playback.  For example, the play-lists may contain numerous media\ncreations from a selected genre.  The media creations may be determined for the play-list according to a rating formula.  The user is provided the media creations of the selected genre continuously, so that the user's media experience resembles listening\nto an album.\nFIG. 14 illustrates a flow process for updating a rating of a media clip, under an embodiment of the invention.  In step 1210, a module is provided a rating event.  The rating event is a rating for a particular media clip, having an associated\nURL.  The rating from the user is predefined from a closed set.  For example, the user may provide a rating from 1 to 5.\nIn step 1220, a record is located for the media clip that was currently rated.  The record may be stored in a database, and include the media link for the media clip, the current rating of the media clip, and the votes received for that media\nclip.  In an embodiment, the record may include more than one URL associated with the media clip that was rated.  In an embodiment, the record is maintained in database management component 1045 (FIG. 12).\nIn step 1230, a rating field for the media record is updated.  The rating field may correspond to the current rating of a media clip.  A module such as the rating module 1030 may update the rating field in database management component 1045\n(FIG. 12).  The media record is updated to determine a new rating.  In one embodiment, the new rating is an averaged based formula.  The formula may also be weighted.  An example of a formula to determine a rating, under an embodiment of the invention\nis: Newrating=1/(n+1)(N*(old rating)+user provided rating) N is the total number of votes received, and newrating ranges between 0 and a maximum value.\nIn step 1240, record for the media clip rated is further updated to add an additional vote to the field for votes received.  The flow process then returns to step 1210.\nFIG. 15 illustrates an exemplary structure for a database to maintain updated records on ratings and votes tallied.  The table may associate values corresponding number of votes, rating, and other information to a media link containing a media\nclip.\nFIG. 16 illustrates a flow process for generating media clips into play-lists according to a rating criteria.  Play-lists including a rating criteria are referred to as rated play-lists.  The flow process assumes known categories for media\nclips.  The flow process also assumes a rating for rated media clips, and the number of media clips in a rated play-list.  The flow process may be used with any of the aforementioned embodiments.\nIn step 1410, a next category may be fetched from a database containing the different categories of media clips.  In step 1420, the system makes a determination as to whether a category was received.  If no category is received, the system\nassumes that there are no more media categories to be rated.\nIn step 1430, a new play-list is created for a current category.  In step 1440, up to N rated media clips from a database of rated media clips are added to the play-list.  Preferably, N is a constant in the flow process.  Then in step 1450, an\nold play-list is deleted, and the new play-list is saved.  The new play-list may be saved in a format that follows predefined protocol so that the play-list and its contents are accessible to a streaming media play back interface.  The flow process then\nreturns to step 1410.\nFIG. 17 illustrates a flow process for programmatically categorizing media files.  The process assumes a database containing metadata associated with media clips.  The metadata includes metadata provided by a human editor.  For example, the\nmetadata may pertain to categories such as genre, mood and atmosphere.\nIn step 1510, a record is retrieved from the database.  The record is retrieved with metadata information containing a first type of metadata information and a second type of metadata information.  As an example, the first type of metadata\ninformation may correspond to a genre of music, and the second type of metadata information may correspond to an artist.  In step 1520, a determination is made as to whether a record was received.  If the determination is negative, then the process\nassumes that all media clips have been categorized.\nIf the determination in step 1520 is positive, then all records in the database having the first type of metadata information are retrieved in step 1530.  In step 1540, all records retrieved in step 1530 are updated to include the second type of\nmetadata information.  As an example, all records belonging to a particular artist (first type of metadata information) or given additional metadata information of a particular genre (second type of metadata information).  The process then returns to\nstep 1510 to retrieve another record.\nIn one embodiment, the second type of metadata information is a genus category, and the first type of metadata information is a species of the first type of metadata information.  Once the first record is known to have the a particular species\nand genus, the genus may be determined and stored for all records having the same species.\n<BR><BR>F. Personalized Media Playback\nFIG. 18 is a flow process to create personalized play-lists of streaming media files available on the Internet (or other networks).  The play-lists may be personalized by users on user-terminals.\nIn step 1610, a user chooses to add a URL of a selected media clip to a personal favorite play-list.  In step 1620, the flow process adds the URL (and metadata) of the selected media clip to a user terminal store for user persistent information,\nsuch as an Internet cookie.  The persistent data store is then accessible for the web-based play back application on the user terminal.\nIn step 1630, the user selects to play back media clips from that user's favorite play-list.  In step 1640, the system reads back the media clips from the persisted data store.  In step 1650, the system plays media clips using a URL associated\nwith each media clip.  The cookie may also provide additional URLs.  Thus, multiple media clips may be played continuously from different sites on the Internet.\nThe user may edit the play-list, change an order of the play-list, or delete selections from the play-list.  The user may designate certain play-lists as personal, so as to identify the play-list with that user's terminal.  Alternatively, the\nplay-list may be stored on a network server and accessed using the media location and playback module.  Users may access their personal play-lists from any one of a plurality of terminals that have access to the system.\n<BR><BR>G. Distributed Architecture\nAn implementation under an embodiment provides a distributed architecture in which a user terminal accesses media resources from a plurality of network sites.  In a network such as the Internet, the user terminal accesses multiple web sites to\nplayback media locates as files on those web sites.\nA network site includes any network location having internal links.  Embodiments of the invention access network sites providing links to media files and/or other network sites.  A web site refers to a network site on the Internet.  Examples of\nweb sites include web pages, including web pages with HTML links to other web sites, to media files, and to other types of files.\nThe distributed architecture inverts conventional media distribution paradigms.  Numerous streaming media files can be streamed to an individual user terminal continuously from throughout the Internet using the embodiment of the distributed\nplayback architecture.  The distribution architecture is scalable to provide thousands or millions of streaming media files to user terminals.  The users can then play media files located throughout the Internet in a continuous manner from the numerous\nInternet sites.\nFIG. 19 illustrates a distributed playback architecture, under an embodiment of the invention.  A user terminal 1710 has access to N network sites that provide access to media, also referred to here as media sites.  The N media sites 1722 via\nweb server module 1770.  The media sites 1722 each have one or more links to media web resources.  The links are represented by URLs 1-N. The web server module 1770 can load the media resources onto a media playback component of user terminal 1710.  Once\nloaded, the media resources are played back by a media playback component on user terminal 1710.\nIn an embodiment, the media sites 1722 correspond to different locations on a network such as the Internet.  For example, media sites may have different Internet addresses, including different domains.  Each media site provides direct access to\na media network resource.  This implies that a URL (or link) to one of the media sites accesses the media network resource for playback without accessing another internal URL (or link).\nIn an embodiment, web server module 1770 signals multiple URL links to user terminal 1710.  The media playback component of user terminal 1710 accesses each link to playback the media resource.  The URLs are selected for media playback so as to\noutput media from user terminal 1710 according to a predetermined program.\nIn an embodiment, the program is selected or defined from a search request of user.  For example, a search request may designate a category for media output, such as a genre and artist.  All URLs containing media from that artist and genre may\nbe gathered and signaled from web server module 1770 to user terminal 1710.  The URLs may be provided in any order, such as random, etc. or a chronological order of the artist.\nIn another embodiment, a program may be provided by one or more play-lists.  Each play-list in the program may be generated by, for example, a play-list generator 1040 (FIG. 12).  The play-lists may be personalized for the user of the end\nterminal 1710.  For example, play-lists may be generated for preferences and profiles specified by the user of user terminal 1710.  As another example, a user may couple to the Internet, prompting web server module 1770 to automatically signal one or\nmore play-lists containing the URLs to user terminal 1710.  Still, other embodiments provide for URLs to web resources, or play-lists containing the URLs to be randomly provided to user terminal 1710.\nAmong other advantages, the distributed architecture permits simultaneous playback of, for example, thousands or millions of multiple streams which do not congregate on a single point.  This avoids congestion arising under examples of the\ncurrent media paradigms.  This ensures that the embodiment of our distributed architecture may \"scale,\" or permit the simultaneous playback of, for example, thousands or millions of simultaneous streams.  Further, the quality of the user experience is\nnot affected by scaling a system under the distributed architecture embodiment.\nIn contrast, conventional broadcasting employs one radio or television signal to broadcast to listeners or viewers.  Media files disseminated over the Internet today may be distributed in a manner which is somewhat similar in that the media file\nis located on a single server (or small group of servers) which is accessed by potentially large number of Internet users.  As a result, the experience of the users may diminish due to the limited ability of current systems to scale.\nThis distributed playback architecture, the delivery of streaming media through this playback architecture, in combination with the search functionality performed by the back-end module, and the rating and personalization features of the\nplayback client terminal module permits the creation of a broadcasting system that is personalized by an end user.  A personal broadcasting system permits each individual user to create media programs which can be sent to, for example, thousands or\nmillions or other users who can simultaneously play different programming combinations using a distribution of Internet (or other network) sites.\nAn example of a distributed architecture playback system includes wireless devices that are communicatable to a network containing media resources.  For example, media playback component 1710 may be loaded onto a wireless access protocol (WAP)\nenabled device.  Examples of WAP enabled devices include handheld computes and cell phones.  The WAP enabled device may use a wireless communication network to access network server module 1770.  The WAP enabled device may also include output features,\nsuch as speakers or a display screen.  The WAP enabled device accesses media sites 1722 by control of network server module 1770.  The WAP enabled device then plays back media from the media sites 1722.  The WAP enabled device may then be used to\nsimulate a portable radio.\nAs another example, an automobile may be equipped with a wireless device.  The wireless device accesses multiple media sites on a network such as the Internet to and provide playback of media clips.  For example, the user may select to hear\nmusic from a favorite play-list using the WAP enabled device in the automobile.\n<BR><BR>H. Messaging Applications\nFIG. 20 is a diagram illustrating a messaging application, under an embodiment of the invention.  The messaging application enables the user to share a media playback experience with other users having access to the network.\nFIG. 20 assumes the messaging application is operated on a network such as the Internet.  In the embodiment, a network interface or network-side module is used to enable messaging, rather than a client messaging applications.  Examples of\nmessaging applications for use with embodiments include e-mails, which are delivered to a folder on a recipient's terminal.  Other types of electronic messages include instant messages, which can be displayed or heard on the recipients terminal\nautomatically upon arrival.\nA messaging module 2080 receives a messaging request from a first user terminal (sender) 2010.  The messaging module 2080 may be an application or portion of network server module 2070.  The messaging request is entered by the user through the\nuser-interface 1900, using for example, an e-mail selection field 1990.\nThe messaging module 2080 receives addresses to deliver messages to recipient terminals (recipient) 2020.  The sender 2010 may manually signal the recipients address using entry methods such as keyboards, graphic user selection features, or\naudio commands.  Alternatively, messaging module 2080 has access to network stored addresses for the specific user.  The network stored messages are then selectable from a terminal by the user on the sender terminal 2010.\nIn response to a request from sender 2010, messaging module 2080 generates a message 2085 for the recipient.  The request may also include the address of the intended recipient(s).  The message 2085 is sent to all recipients 2020 specified by\nsender 2010.  The contents of the message 2085 include a URL to the network server module 2070.  In an embodiment, the URL in the message is packaged with arguments or other coding to identify a play-list maintained on the network server module 2070. \nThe URL may also be packaged with arguments to identify the specific song being played when the sender causes the message to be transmitted to the recipient.  Alternatively, the URL may identify to the recipient the search request or criteria used by the\nsender.\nThe recipient may choose to return a message 2082 to signal messaging module 2080.  In one embodiment, the content of the message is constructed so that once the message is opened, the user can select a link to a module that stores or maintains\nthe play-list 2075.  For Internet applications, the link is HTML formatted to include the URL of network server module 2070, and arguments to identify the play-list selected by sender 2010.  Once network server module 2070 is accessed by the recipient\n2020, arguments 2088 contained with the link identify the specific play-list 2075 experienced by sender 2010 when the request to send the message was made.\nIf the message is instant, the recipient 2020 can respond immediately to simultaneously share the experience of sender 2010.  Alternatively, the recipient 2020 can be made to respond automatically upon the recipient 2020 receiving the message\n2085, so as to enable sender 2010 and 2020 to simultaneously or concurrently share the same media playback.\nThe argument 2088 that is packaged with the link may also identify individual media clips, and/or an entire play-lists.  The recipient 2020 is able to experience media playback from individual media clips selected by sender 2010.\nIn another embodiment, message 2085 is constructed so that once the message is opened, the user is automatically connected to network server module 2070.  The message may be an e-mail, stored in a designated folder of recipient 2020.  The e-mail\nmay include an HTML formatted URL to cause the recipient's terminal to access and communicate with network server module 2070.  The HTML formatted URL may also include code that causes the user terminal to automatically access network server module 2070\nupon the e-mail being opened.  The HTML formatted link may also include arguments to specify the play-list 2088 and/or media clip identified by the sender, as well as other parameters of the URL.  Once the play-list or media clip is identified by network\nserver module 2070, the recipient 2020 is able to share the media playback experience of the sender 2010.  The sender 2010 can experience the media playback at the time sender 2010 requests the message to be sent.\nIn the embodiments shown, sender 2010 can select a media program that is signaled transmitted to recipient 2020 by messaging module 2080.  The program may correspond to one or more play-lists, playing back multiple media resources.  While sender\n2010 is being played back the program, the sender 2010 can specify the address of recipient 2020 to messaging module 2080.  The messaging module 2080 generate a message that includes a selectable link to enable the recipient to access the network server\nmodule 2070.  Arguments or scripting contained with the URL identify the particular play-list being signaled to the sender 2010.  Since the play-list is updated after every media resource is played back to sender 2010, recipient 2020 accesses the\nplay-list at the selection being played back to the sender 2010.  The play-list is then signaled to the sender 2010 and recipient 2020 simultaneously, or approximately thereabout.  Alternatively, recipient 2020 accesses the play-list beginning with the\nmedia clip played back to sender 2010 when the sender 2010 selected to transmit the message to recipient 2020.\nAs an example, sender 2010 transmits a search request causing media, based on search criterias of a specific artist and a ranking.  The network server module 2070 identifies URLs matching the search request and forms play-list 2075 for sender\n2010.  After reviewing the play-list 2075, the sender 2010 decides to share the media playback with a friend, recipient 2020, whom the sender believes would appreciate play-list 2075.  The sender 2010 requests messaging module 2080 to transmit message\n2085 to recipient 2020 by submitting the recipient's e-mail address to the messaging module 2080.  The message 2085 sits on the recipient's terminal until accessed.  The recipient 2020 selects message 2085 to access play-list 2075.  Unless the messaging\nis nearly instantaneous, the recipient experiences media playback from the play-list 2075 when sender 2010 request message 2085 to be sent.  Alternatively, sender 2010 may request the entire play-list 2075 to be transmitted to recipient 2020.  In this\nway, sender 2010 and recipient 2020 may share a common interest in certain genres, category, artists etc. of media playback.\n<BR><BR>I. User-Interface\nFIG. 21 illustrates a user-interface 1900, under an embodiment of the invention.  The user-interface 1900 may correspond to the play-back interface 1020, described with FIG. 10.  Alternatively, the user-interface may be a terminal side component\nin communication with one or more server-side modules, such as for example web server module 1070 (FIG. 12).\nIn an embodiment such as shown by FIG. 12, user-interface 1900 includes a plurality of user-interactive features.  The user-interactive features enable users to interact with the system 200 from the user terminal 210.  Some of the plurality of\nuser-interactive features allow users to submit search requests and other media requests for playback.  Other control user-interactive features allow users to affect the play back of the media resources.\nThe user-interface 1900 may output to the user information, images, and/or audio that is different than the media resource being played back.  For example, user-interface 1900 displays metadata information to the users about the media resource\nbeing played back.  In addition, the user-interface 1900 enables users to, for example, view advertisement, receive electronic messages, and create and manage play-lists.\nIn an embodiment such as shown by FIG. 21, the user-interface 1900 includes a first menu field 1910, a second menu field 1920, and a third menu field 1930.  The first menu field 1910 allows the user to select a first criteria for media resources\nthat are to be played back.  The second menu field 1920 allows the user to select a second criteria from a set of media resources matching the first criteria.  The third menu field 1930 allows the user to select a third criteria from the a set of media\nresources matching both the first and second criteria.  Each of the menu fields 1910-1930 may be in the form of click and drag-down menus.\nThe user-interface 1900 may also include a text field 1940.  The text field 1940 allows users to enter a search criteria.  The search criteria entered in text field 1940 may be combined with the search criterias of one or more menu fields\n1910-1930 using a Boolean operation.  Preferably, all search criterias are AND together into a single search criteria.  For example, the search criteria entered in text field 1940 may correspond to an artist name, or a title of a media creation.\nIn an embodiment, the user-interface 1900 provides features that prompt a user for input, such as for one more search criterias.  The web server module 270 receives the search criteria(s) signaled from user terminal 210, and access media and\nmetadata table 247.  Each of the menu field 1910-1930 may also allow users to enter text field as the search criterias.  The search criteria(s) are matched to URLs containing metadata having the same (or equivalent) criterias.  For example, the search\nrequest may specify a genre, and a first name of an artist.  Then, web access server 270 locates URLs to media resources having associated metadata information that identifies the media resource as being of the same genre, and as containing the same\nfirst name in the artist name metadata indexed data structure.\nThe web server module includes a feedback display portion 1950.  The feedback display portion 1950 may signal information, messages, advertisement etc. to the end user.  In an embodiment, feedback display portion 1950 displays metadata\ninformation about the media resource being played back.  For example, a song of a particular genre and category may be played back.  The display screen portion 1950 may display the title of the song, the artist name, a play-list associated with the song,\na rating component of the song, and the song's duration.  Information is read when the media playback component loads the media resource.\nOther user-interactive features may also be included in user-interface 1900.  In an embodiment, user-interface 1900 includes a play-list feature 1960.  The play-list feature 1960 enables users to add a media creation to a play-list.  The\nplay-list feature 1960 may, as an example, be a selectable icon.  Upon selecting the play-list feature 1960, a pop-up window (not shown) may be displayed allowing a user to name or select the play-list that will include the media resource being played. \nIn this way, a user of user terminal 210 can provide input to create and manage play-lists, using systems such as described with FIGS. 12 and 19.\nThe user-interface 1900 may include one or more control user-interactive features.  The control user-interactive features may be in the form of selectable icons.  A skip feature 1972 causes, for example, web server module 270 to signal a URL of\nanother media creation to the media playback component.  This causes the media playback component to start playing back a new media creation.  A pause feature 1974 enables users to pause the media playback component from playing back the media resource. \nThe pause feature 1974 may signal the media playback component directly, or cause the web server module to signal the command to the media playback component.  Reselecting the pause feature 1974 then causes the media creation to be played back from the\nportion where playback was paused.  Similarly, a seek feature 1976 may signal to seek or move to a specific instance of playback on the media resource.  A volume feature 1978 signals the application program interface 276 (FIG. 5) to raise the volume of\nthe media resource being played back.\nThe user-interface 1900 may also include a rating feature 1980.  The rating feature 1980 may be in the form of multiple selectable icons, where the icons are arranged to correspond to a rating.  For example, five icons may be provided to\nrepresent best to worst ratings.  In an embodiment, the rating feature 1980 enables a user to rate a media resource during or after it is played back on the user terminal 210.  With reference to an embodiment such as described with FIG. 12, the rating\nfeature 1980 is used to prompt a user to signal a rating to rating component 1030 (FIG. 12).  The rating feature 1980 may be a user response to a media clip played back on user terminal 210.  The rating component 1030 receives the rating and modifies\nrating information associated with the URL that is stored in 1045.  The rating information may then be provided to other users or user terminals.  For example, the rating information may then be signaled to display portions 1950 of other user terminals\n210 who select that media clip for playback.\nThe user-interface 1900 also includes a personal play-list feature 1985.  The personal play-list feature includes iconic selection features, including an add icon 1987 to add a URL to a play-list, and a play icon 1989 to play a personal\nplay-list.  The add icon 1987 enables a user to signal play-list generator 1040 (FIG. 12) to add a URL to the personal play-list.  The URL being added to the play-list may correspond to a media resource being played back on user terminal 210.  The play\nicon 1989 may be selected to cause web server module 1070 (FIG. 12) to signal URLs from the personal play-list to the media playback component of user terminal 210.  In this way, user terminal 210 may select to have continuous media output from resources\npreviously selected to be on a play-list.\nThe user-interface 1900 may also include an e-mail selection feature 1990.  The e-mail selection feature 1990 may be iconic, to allow selection by the user upon the media playback.  Once selected, an e-mail program on user terminal 210 may be\nlaunched.  The e-mail program may be directed to open a new message, and attach the URL of the selected media resource.\nFIG. 22 illustrates an embodiment in which user-interface 1900 is displayed on the desktop along a second window 2210 showing a web site 2212.  The web site 2212 hosts the media file being played back.  In this embodiment, web server module 1070\nsignals a media file URL to the media player component of the terminal.  The web server module 1070 concurrently signals the web browser component 213 on the terminal another URL to the hosting web site.  The web browser 213 opens the second window 2210\nto display the web site while the media from the media file is being played back on the terminal.  In this way, users are displayed the web site hosting the media file while media from the media file is played back.  This allows the user to view, for\nexample, banner ads, artist name and titles, and copyright information while media from the web site is being played back.\nAfter the playback is complete for one media file, a URL to a next media file is signaled to the media player component on the terminal.  The next URL may be determined by a sequence of a play-list, or by a result to a search term inputted from\nthe user.  If the URL of the next media file is hosted on a web site that is different than the preceding web site, then web server module 270 signals the URL of the next hosting web site to the web browser.  The second window 2210 then displays a second\nweb site 2212' that hosts the media file being played back.  In this way, the second window 2210 displays only web sites hosting the media files being played back.\n<BR><BR>J. Conclusion\nThe foregoing description of various embodiments of the invention has been presented for purposes of illustration and description.  It is not intended to limit the invention to the precise forms disclosed.  Many modifications and equivalent\narrangements will be apparent.\n<BR><BR><CENTER><b>* * * * *</b></CENTER>\n<HR>\n   <CENTER>\n   <a href=http://pdfpiw.uspto.gov/.piw?Docid=10318647&homeurl=http%3A%2F%2Fpatft.uspto.gov%2Fnetacgi%2Fnph-Parser%3FSect1%3DPTO2%2526Sect2%3DHITOFF%2526p%3D1%2526u%3D%25252Fnetahtml%25252FPTO%25252Fsearch-bool.html%2526r%3D1%2526f%3DG%2526l%3D50%2526co1%3DAND%2526d%3DPTXT%2526s1%3D20170124092%2526OS%3D%2526RS%3D&PageNum=&Rtype=&SectionNum=&idkey=NONE&Input=View+first+page><img src=\"/netaicon/PTO/image.gif\" alt=\"[Image]\" border=\"0\" valign=\"middle\"></A>\n   <TABLE>\n   <TR><TD align=\"center\"><A href=\"https://certifiedcopycenter.uspto.gov/other/patft/view.html?backUrl1=http%3A//patft.uspto.gov/netacgi/nph-Parser?Sect1%3DPTO2%26Sect2%3DHITOFF%26p%3D1%26u%3D%25252Fnetahtml%25252FPTO%25252Fsearch-bool.html%26r%3D1%26f%3DG%26l%3D50%26co1%3DAND%26d%3DPTXT%26s1%3D20170124092%26OS%3D&backLabel1=Back%20to%20Document%3A%2010318647\"><IMG border=\"0\" src=\"/netaicon/PTO/cart.gif\" border=\"0\" valign=\"m\niddle\" alt=\"[View Shopping Cart]\"></A>\n   <A href=\"https://certifiedcopycenter.uspto.gov/other/patft/order.html?docNumber=10318647&backUrl1=http%3A//patft.uspto.gov/netacgi/nph-Parser?Sect1%3DPTO2%26Sect2%3DHITOFF%26p%3D1%26u%3D%25252Fnetahtml%25252FPTO%25252Fsearch-bool.html%26r%3D1%26f%3DG%26l%3D50%26co1%3DAND%26d%3DPTXT%26s1%3D20170124092%26OS%3D&backLabel1=Back%20to%20Document%3A%2010318647\">\n   <IMG border=\"0\" src=\"/netaicon/PTO/order.gif\" valign=\"middle\" alt=\"[Add to Shopping Cart]\"></A>\n   </TD></TR>\n   <TR><TD align=\"center\">\n   <A href=\"#top\"><IMG valign=\"middle\" src=\"/netaicon/PTO/top.gif\" border=\"0\" alt=\"[Top]\"></A>\n   </TD></TR>\n   </TABLE>\n   <A name=\"bottom\"></A>\n   <A href=\"/netahtml/PTO/index.html\"><IMG src=\"/netaicon/PTO/home.gif\" alt=\"[Home]\" border=\"0\" valign=\"middle\"></A>\n   <A href=\"/netahtml/PTO/search-bool.html\"><IMG src=\"/netaicon/PTO/boolean.gif\" alt=\"[Boolean Search]\" border=\"0\" valign=\"middle\"></A>\n   <A href=\"/netahtml/PTO/search-adv.htm\"><IMG border=\"0\" src=\"/netaicon/PTO/manual.gif\" alt=\"[Manual Search]\" valign=\"middle\"></A>\n   <A href=\"/netahtml/PTO/srchnum.htm\"><IMG src=\"/netaicon/PTO/number.gif\" alt=\"[Number Search]\" border=\"0\" valign=\"middle\"></A>\n   <A href=\"/netahtml/PTO/help/help.htm\"><IMG border=\"0\" src=\"/netaicon/PTO/help.gif\" alt=\"[Help]\" valign=\"middle\"></A>\n   </CENTER>\n</BODY>\n</HTML", "application_number": "15407548", "abstract": " Systems are provided to enable users of a streaming media playback system\n     to access play-lists generated automatically based on input of a\n     plurality of users regarding previously played media resources, and to\n     provide user input regarding the media resources of the play-lists. The\n     user input regarding media resources may be received from a plurality of\n     users using a plurality of playback interfaces executing on a plurality\n     of internet enabled multimedia computing platforms. A rating component\n     determines rating information from the user inputs provided by the\n     plurality of users and modifies the rating information in an\n     organizational data structure that describes rating information for the\n     media resources. The system further includes a play-list fenerator\n     adapted to generate and store or dynamically generate at least one\n     play-list at least based on the rating information in the organizational\n     data structure.\n", "citations": ["3568156", "4384329", "4739567", "4788675", "4833610", "4870579", "4992940", "4996642", "5062143", "5157643", "5182708", "5191573", "5235509", "5241674", "5287109", "5303150", "5303302", "5297042", "5341350", "5371807", "5392212", "5404505", "5408448", "5418951", "5442390", "5459306", "5497488", "5499046", "5539635", "5548507", "5548724", "5570138", "5583763", "5583868", "5592511", "5608622", "5612741", "5616876", "5633839", "5659732", "5661787", "5668788", "5668948", "5675734", "5675786", "5678054", "5696919", "5704017", "5706365", "5708709", "5713016", "5721827", "5726909", "5732398", "5734719", "5740134", "5745681", "5749081", "5751672", "5754938", "5758257", "5764235", "5774357", "5774670", "5778367", "5790423", "5790426", "5790935", "5793980", "5794207", "5794210", "5794233", "5797127", "5809246", "5815662", "5818510", "5819160", "5833469", "5842010", "5854887", "5854901", "5862220", "5862339", "5864863", "5864868", "5867799", "5872747", "5872850", "5872921", "5873080", "5878739", "5881234", "5883986", "5884282", "5884312", "5890152", "5892905", "5897620", "5898833", "5900564", "5905973", "5909023", "5909492", "5911043", "5911139", "5913040", "5913041", "5915094", "5918014", "5918223", "5920856", "5926207", "5930526", "5930768", "5931679", "5931901", "5931907", "5941951", "5945988", "5948061", "5950189", "5953005", "5956482", "5959945", "5960430", "5961603", "5963916", "5963957", "5966440", "5969283", "5974398", "5977964", "5980261", "5980262", "5983176", "5983214", "5986979", "5987454", "5987525", "5991374", "5996015", "6000008", "6005603", "6006225", "6006257", "6009382", "6009459", "6011537", "6012098", "6014665", "6016504", "6018738", "6020883", "6021203", "6021409", "6025838", "6026398", "6026439", "6029161", "6029195", "6031795", "6031797", "6032130", "6035055", "6035268", "6038527", "6038591", "6041311", "6041318", "6041360", "6044376", "6047251", "6047268", "6047320", "6047327", "6049777", "6049829", "6052717", "6058423", "6061680", "6064379", "6064980", "6065051", "6065058", "6070185", "6018768", "6073727", "6074215", "6075787", "6078916", "6085242", "6088722", "6092049", "6092204", "6097719", "6101510", "6102406", "6105022", "6112186", "6112239", "6118450", "6119163", "6125361", "6131082", "6134532", "6134596", "6134680", "6138142", "6144958", "6151624", "6154773", "6161132", "6161139", "6167369", "6182072", "6182142", "6185560", "6192340", "6195657", "6199076", "6199082", "6201176", "6202061", "6205126", "6216112", "6216672", "6222980", "6225546", "6226672", "6230192", "6230207", "6232539", "6240423", "6240459", "6246672", "6247069", "6247130", "6249773", "6249810", "6252988", "6256739", "6260064", "6263313", "6263332", "6266649", "6271840", "6272456", "6272495", "6275858", "6282548", "6292795", "6298446", "6314421", "6317722", "6317740", "6317761", "6321205", "6321221", "6321226", "6326982", "6330592", "6330593", "6334127", "6343317", "6349339", "6353849", "6353929", "6356971", "6362856", "6363434", "6370315", "6370513", "6370543", "6374404", "6377965", "6385596", "6389467", "6401084", "6404893", "6405203", "6408270", "6411992", "6415327", "6418421", "6421651", "6424998", "6425018", "6429863", "6430539", "6430573", "6430603", "6430605", "6434535", "6434550", "6438579", "6446080", "6452609", "6460029", "6460036", "6460060", "6463432", "6484148", "6484149", "6484156", "6484199", "6487598", "6490553", "6502194", "6505160", "6505203", "6512763", "6513031", "6513061", "6519648", "6522769", "6526411", "6526580", "6532477", "6535854", "6538996", "6539395", "6546421", "6557026", "6557042", "6560403", "6560704", "6563769", "6564213", "6584492", "6622826", "6587127", "6601066", "6611812", "6611813", "6614914", "6614987", "6615039", "6615208", "6629079", "6633874", "6638313", "6639610", "6655963", "6657117", "6658151", "6662826", "6675195", "6677894", "6678680", "6704727", "6721741", "6725275", "6725446", "6735628", "6738078", "6741869", "6741980", "6748395", "6751606", "6757740", "6766357", "6769028", "6772113", "6772139", "6772150", "6782370", "6792573", "6807632", "6813745", "6859213", "6873982", "6879963", "6883163", "6889383", "6925441", "6925489", "6931451", "6952523", "6961897", "6963850", "6963899", "6970886", "6981245", "6986132", "6993590", "7000007", "7003515", "7010537", "7022905", "7024681", "7031931", "7043433", "7058694", "7072846", "7076561", "7080153", "7081579", "7085845", "7107548", "7115808", "7133924", "7136870", "7136945", "7146627", "7155734", "7158531", "7158993", "7167895", "7170999", "7188352", "7206775", "7209892", "7228305", "7233948", "7243129", "7246109", "7263497", "7277955", "7279629", "7281034", "7321923", "7330826", "7363314", "7396990", "7448062", "7464112", "7469283", "7505959", "7555539", "7640560", "7711838", "7725912", "7788339", "7992176", "8005724", "8036418", "8230343", "8352543", "44298", "8463780", "8782194", "9405753", "9547650", "9779095", "20010005823", "20010013061", "20010013123", "20010042107", "20010042109", "20010044855", "20010052028", "20010053944", "20010055276", "20020002039", "20020002562", "20020004839", "20020007418", "20020010621", "20020010714", "20020010789", "20020013852", "20020013947", "20020016839", "20020019858", "20020026499", "20020035561", "20020045717", "20020049717", "20020054087", "20020056004", "20020056100", "20020065857", "20020077988", "20020082901", "20020095387", "20020099696", "20020099737", "20020103998", "20020111912", "20020116082", "20020120518", "20020129123", "20020152204", "20020157034", "20020175941", "20020194260", "20030002608", "20030007507", "20030028796", "20030046283", "20030083871", "20030088463", "20030093476", "20030095660", "20030103644", "20030133453", "20030135513", "20030139989", "20030140160", "20030165200", "20030182139", "20030190077", "20030206558", "20030233650", "20030236894", "20040059826", "20040078269", "20040090462", "20040103372", "20040167890", "20040177096", "20050149759", "20050188370", "20050198020", "20050216942", "20050256909", "20050273827", "20060031240", "20060050012", "20060080741", "20060149813", "20060206478", "20060212442", "20060212444", "20060282544", "20070162398", "20070177586", "20080016531", "20080016538", "20080162573", "20090049045", "20090077041", "20090240732", "20100010971", "20100010997", "20100146084", "20120303604", "20140337298"], "related": ["14508665", "14327789", "13355867", "12255615", "10828124", "10251307", "10104792", "09563250", "60177786"]}, {"id": "20170124628", "patent_code": "10296961", "patent_name": "Hybrid recommendation system", "year": "2019", "inventor_and_country_data": " Inventors: \nKirkby; Stephen Denis (Unley Park, AU), Chew; Theam Yong (Adelaide, AU), Boukis; Christos (Attiki, GR), Passalis; Georgios (Athens, GR)  ", "description": "<BR><BR>BACKGROUND\nOnline shopping and online purchases have increased dramatically over the years.  Competition between online retailers has become fierce and these online retailers try to provide the best user experience and also try to implement techniques to\nincrease sales.  One such technique is through recommendations.  It is not uncommon for an online retailer to provide a recommendation to a user viewing a web page for a particular product.  Typically, the recommendation identifies other products that\nwere purchased by other users in combination with the product currently being viewed by the user.  However, in many instances, the recommendations are outdated or duplicative or do not further specific goals of the retailer. <BR><BR>BRIEF DESCRIPTION OF\nDRAWINGS\nThe embodiments are described in detail in the following description with reference to the following figures.  The figures illustrate examples of the embodiments.\nFIG. 1 illustrates a hybrid recommendation system.\nFIG. 2 illustrates a recommendation engine.\nFIG. 3 illustrates a computer system that may be used for the methods and systems described herein.\nFIG. 4 illustrates a method that may be performed by the hybrid recommendation system.\nFIG. 5 illustrates examples of factors to consider for determining recommendation functions.\nFIG. 6 illustrates examples of detailed steps and factors for determining recommendations.\nFIG. 7 illustrates an example of a summary of a summary of a process for selecting recommendations.\nFIG. 8 illustrates an example of a specific use case for coupons.\nFIG. 9 illustrates an example for providing a real-time recommendations and factors that may be considered to select the recommendation.\n<BR><BR>DETAILED DESCRIPTION OF EMBODIMENTS\nFor simplicity and illustrative purposes, the embodiments of the invention are described by referring mainly to examples thereof.  Also, numerous specific details are set forth in order to provide a thorough understanding of the embodiments.  It\nwill be apparent however, to one of ordinary skill in the art, that the embodiments may be practiced without limitation to one or more of these specific details.  In some instances, well known methods and structures have not been described in detail so\nas not to unnecessarily obscure the description of the embodiments.\nAccording to an embodiment, a hybrid recommendation system determines recommendations for product purchases based on offline and online testing.  The offline testing analyzes and adjusts a plurality of recommendation functions and the online\ntesting may be used to validate or further adjust the recommendation functions that maximize one or more performance metrics.  These recommendation functions may be used to create recommendation indices representing recommendations for different products\nand users.  The indices are then used to determine candidate recommendations in a real-time environment to provide to users viewing product web pages.  A scoring function may be applied to select candidate recommendations to display to the user.\nFIG. 1 discloses a hybrid recommendation system 100, according to an embodiment.  The system 100 includes a hybrid recommendation core 110 and a recommendation provider subsystem 120.  The hybrid recommendation core 110 generates recommendation\nindices of recommendations and the recommendation provider subsystem 120 determines recommendations from the indices to provide to a user.\nThe hybrid recommendation core 110 includes an offline testing module 111, online testing module 112, recommendation function optimizer 113 and a recommendation engine 115.  Recommendation functions 102 may be input by a user or another system\nto the system 100.  A recommendation function is a function for determining a recommendation based on one or more parameters.  The recommendation functions 102 may include at least one of statistical models, commentary, adjustable parameters, test plan,\nenhancement steps, applicable recommendation scenarios, variations needed for different scenarios, etc. Different functions may be tested and their parameters periodically adjusted to optimize the recommendation functions.  The recommendation functions\n102 may identify purchase patterns, identify peers or pairs of products purchased together, analyze bundles, consider merging baskets from different purchases and time periods, etc. A basket may be an online shopping cart where user selections for\nproducts to purchase are placed prior to conducting the transaction to purchase the products.\nThe offline testing module 111 simulates results of providing a recommendation on a test dataset to measure effectiveness of a recommendation function based on one or more performance metrics.  In one example, the performance metrics include\nrecall (e.g., the ratio of the items in a basket of a consumer that are matching our recommendations) and precision (e.g., the percentage of the recommendations that turned out to be successful (e.g., resulted in purchases of the recommended products))\nbut other performance metrics may be used.  An item or product item for example is a product for purchase.  A product may be a good or service.  In one embodiment, data from data 101 includes historic purchase data and user profiles.  The historic\npurchase data includes any data related to online sales, offline sales, transactions, dates, browsing history, etc. A training dataset and a test dataset may be generated from the data 101.  The training dataset may be used to create recommendation\nfunctions.  For example, machine learning techniques may be used to generate classifiers that identify purchase patterns and determine relationships between users and their purchase patterns.  These relationships may be used to generate the\nrecommendation functions 102 from the training set.  Bayesian networks, neural networks, singular value decomposition (SVD), classifiers may be applied to the training set to determine recommendation functions.  Hill climbing or other mathematical\noptimization techniques may be used to optimize the recommendation functions 102.\nThe test dataset is used to test the performance of recommendations generated by the recommendation functions 102.  For example, the test dataset is evaluated to determine the number of conversions of the recommended products or to determine\nother performance metrics.  The recommendation functions 102 may include adjustable parameters that are adjusted to try to improve the functions 102 and they can be retested in an iterative process.\nThe online testing module 112 evaluates performance of the recommendation functions 102 that are tested by an online testing system 104.  The online testing system 104 may try different recommendation functions or different variations of a\nrecommendation function on different users and captures the online behavior, including transactions.  For example, the online testing system 104, to assess the performance of the recommendation engine 115, performs online tests by comparing the\nperformance of a group of customers to whom recommendations have been provided to that of a control group to whom no recommendations are given.  The effect of the recommendations can be evaluated by the offline testing module 111 at a macro level, by\ncomparing performance metrics like the average basket size per customer, the average sales per basket, and the average sales per customer.  These metrics may also be analyzed at a finer level, for example at the product category level, or customer\nsegment level.  Alternatively the effectiveness of recommendations can be assessed at a micro level by matching the items recommended to a customer with the items finally placed in their shopping cart, or by the click-through rates for those items. \nOther examples of performance metrics and key performance indicators to evaluate recommendations include: baseline analysis metrics, such as number of occurrences or whether number of visits exceed a threshold; funnel analysis metrics for each\nrecommended item, such as number of clicks, number of items added to a cart, number of purchases; basket metrics, such as percentage of baskets that contain a recommended item, percentage of sales that are driven by a recommendation; customer analysis\nmetrics, such as repeat visits, customer life time value; and system performance metrics at run-time.\nThe recommendation function optimizer 113 may suggest adjustments to adjustable parameters in the recommendation functions based on the performance metrics and may allow a user to make adjustments.  Then, the functions can be re-tested.  A data\nstore 116 may store the recommendation functions 102, different data sets, performance metrics and any other information used by the core 110 to generate recommendation indices.  The data store 116 and the data store 125 may be databases or other types\nof storage systems.\nThe recommendation engine 115 generates recommendation indices based on the optimized recommendation functions.  The recommendation indices identify by SKU or other product identifiers, one or more products to be recommended for each product\noffered for sale online or offline.  These indices are stored for example in data store 125 and are used by the recommendation provider subsystem 120 to provide recommendations in real-time for users.  The data store 125 to store the recommendation\nindices may be a low-latency data store that provides the recommendations to users without incurring an unsatisfactory delay.  The data store may include additional filters or rules that are applied to make final recommendation selections. \nRecommendation selection module 121 selects products to recommend, for example, by performing index lookups.  Dynamic data 103 may identify a product a user is currently viewing and other user information so the lookups can be performed.  Filter module\n122 applies filters, such as determining whether a product is out of stock or complies with the retailers goals, to determine final product recommendations.  The processing speed for determining and providing recommendations is improved by use of lookups\non the recommendation indices, minimal amount of computation (filters) to post-process recommendations, fast append, filter, and sort lists of recommendations.\nInterface service layer 130 may expose the providing of recommendations as a web service to web browsers 140 or applications 141.  The web service may include a method or protocol for communication between two devices over the Internet.  For\nexample, the interface service layer 130 may provide web services compatible with PHP (Hypertext Preprocessor, which is an open source general-purpose scripting language that is suited for web development), JAVA, .NET, etc. Thus, the recommendations may\nbe sent to users via a network.\nFIG. 2 shows a more detailed block diagram for the recommendation engine 115.  The recommendation engine 115 may include a core 201, customer clustering component 202, macro-personalization component 203, micro-personalization component 204,\ntime effects component 205, predictive filtering component 206 and business rules component 207.  The core 201 generate the recommendation indices that identify products to recommend for example based on recommendation functions implemented by one or\nmore of the components of the recommendation engine 115.  Item-to-item, customer-to-item, and other associations determined by the purchase behaviors of items, purchase behaviors of customer segments and purchase behaviors of a specific user.  Lookups\nmay be performed on the indices to identify one or more items to recommend.\nExamples of information provided by data sources are shown on the left side of FIG. 2.  The recommendation engine 115 determines targeted product or service recommendations for users, for example, by processing several sources of data using the\ncomponents shown in FIG. 2.  The data sources may provide information regarding transactions, customer preferences, product taxonomy, product attributes, demographics, etc.\nFor example, the data sources may provide information related to customer demographics, such as age, gender, location, etc. Customer demographics, along with other data like user preferences, may be used in identifying the similarity between\ncustomers for collaborative filtering.  Customer demographics can be used also to post filter a recommendation by applying for instance gender, age and marital status information.\nTransaction data may include transaction files that include among others the time, the price and the quantity at which an item has been purchased from a specific user.  The transaction data may identify customer baskets and items that belong to\nthe same basket are traced.  This type of information may be used to determine hidden associations among products by analyzing baskets to generate recommendations of the type \"Customers who bought this also bought that\".  From transaction files the\npurchase history of every user may be identified and used as input to collaborative filtering techniques that address the question \"customers like you also bought this\".  The transaction data may be used to estimate the significance of key performance\nindicators that relate to customer value and customer preferences.  For instance, from transaction files, a time of day is identified when a user visits a store and which days of the week or month he/she performs his/her purchases.  The value of\ncustomers to the retailer and the customer's preferred payment method (if this is recorded properly) may also be determined.  Also preferred categories shopped by every user and also their product or service usage and product-related preferences may be\ndetermined.  Also, from point of sale data, sales, customers' counts, and purchase times can be determined.\nThe data sources may provide information related to product hierarchy which may include various levels of the product hierarchy.  For example, for retailers with a large product range that may have a \"long tailed\" purchasing pattern or where the\nuser to item association index is sparse, product taxonomy can be used to apply association analysis at various levels of the product hierarchy and thus enrich the recommended items list.  This method can be also used to tackle the \"cold start\" problem\nwhere recommendations are needed for items that have not been sold yet.\nThe data sources may provide information related to product attributes to identify similarities among products within a specific product category.  This type of information can contribute toward assessing the similarity of products within the\nsame category.  Product attributes along with product ratings (if available) or sales can be used to perform attribute weight analysis and estimate the importance of every attribute to the revenue of the retailer.  Product descriptions may be used when\nproduct attributes are unavailable to identify the similarity of products for example by applying text similarity functions.\nProduct ratings, when available, can be processed to generate useful recommendations as well.  Products that are estimated to be rated high from a user can be recommended for another user in a similar demographic.  Store characteristics may be\nused to account for the location where a purchase is placed in the generated recommendations and for the store size and other store characteristics.\nThe data from the data sources can also be used to generate customer analytic records (CARs) that provide information related to the behavior and the characteristics of a customer.  A CAR may include customer related KPIs like the number of\npurchases by a customer, his/her average basket size, the time (the days of week, time of day) and locations at which his/her purchases were made, the average number of trips to the store, the product categories purchased, the preferred payment method\nand so on.  CARs can be used to perform micro- or macro-segmentation and to assist the performance of personalization of recommendations.\nThe customer clustering component 202 identifies clusters of users that have similar purchase-related behavior and have similar demographics.  The macro-personalization component 203 may use the clusters to determine that a user of a cluster may\nbe recommended an item based on an item purchased by someone else in the same cluster.\nThe micro-personalization component 204 generates recommendations based on information personal to the user.\nThe time effects component 205 generates recommendations based on seasonality and recentness of transaction data.  For example, transaction data that is more recent is weighted heavier and transaction data relevant to a seasonal purchase may be\nweighted heavier.\nThe predictive filtering component 206 identifies future purchase interests for users based on their historical purchases.  The predictive filtering component 206 may use Hidden Markov models to make user-to-item recommendations.\nThe business rules component 207 may be applied to a set of recommendations generated by the recommendation core 201 to select final recommendations to be presented to the user.  For example, a business rule may indicate that whenever displaying\nbooks, only recommend books.  In another example, instead of providing normal recommendations, give top 5 promotion items.\nThe final recommendations may be provided to the testing platform which may include the offline testing module 111 and/or the online testing module 112 working with the online testing system 104 shown in FIG. 1 to optimize the recommendation\nfunctions.\nThe components of the recommendation engine 115 shown in FIG. 2 perform association analysis to determine item-to-item associations.  For example, the transaction data, since it provides information related to who purchased what, when, and\nwhere, is used to identify baskets and recognize item groups that are frequently purchased together.  This can be the basis of association analysis.  Using this information, item-to-item (whereby an item can be a product or service) recommendations are\ngenerated.  For example, for every product within a basket, products that are usually purchased together with that one are recommended.  Therefore recommendations of the type \"customers who bought this also bought that\" are generated.  Thus a set of\nrecommendations for every product and every basket can be generated.  In particular, associations between pairs or even sets of products that are purchased together are determined for the recommendations.\nTo determine these associations, the recommendation functions may include scoring functions to analyze customer baskets and the significance of each item set in the baskets is estimated.  Examples of scoring functions that may be used as\nrecommendation functions include support count, support, confidence, and a cosine metric.  Formulas for calculating values for these scoring functions are described below.\nSupport count of an item set is the number of transactions that contain this particular item set.  Mathematically the support count of an item set X is defined as .sigma.(X)=|{t.sub.i|Xt,t.sub.i.di-elect cons.T}|, where the operator | | denotes\nthe number of elements in a set, t.sub.i is a transaction that consists of several items i.sub.k, T={t.sub.1, t.sub.2, .  . . , t.sub.N} is the set of all transactions and I={i.sub.1, i.sub.2, .  . . , i.sub.d} is the set of all available items.\nSupport, which determines how often an association rule of the form i.sub.k.fwdarw.i.sub.m is applicable in a given dataset consisting of N transactions\n.function..fwdarw..sigma..function..fwdarw.  ##EQU00001##\nConfidence that measures how often item i.sub.m appears in transactions that contain item i.sub.k\n.function..fwdarw..sigma..function..fwdarw..sigma..function.  ##EQU00002##\nCosine metric, which is defined as\n.function..function..function..times..function.  ##EQU00003##\nValues for these scoring functions are computed and their performance is evaluated.  The values may be compared to predetermined benchmarks to determine whether there is an association between items.  The values may be combined and weighted to\ncompare to benchmarks.  Other metrics may also be used, such as Mutual Information and Pearson Correlation.\nOther factors may be used in the scoring functions.  For example, recentness of transaction data may be considered, price of items and geography may be considered.  For example, a scoring function may include the following:\n.function..fwdarw..times..times..function..times..times..times.  ##EQU00004## with w.sub.price and w.sub.geo being nonlinear weighting factors that take into account the relative price of items i.sub.k and i.sub.m and also the relative distance\nbetween the place where the purchase of the pair takes place and the location where the recommendations are going to be provided.  Also, in this scoring function, t is the time parameter designating the time a transaction was performed.  t.sub.0 is the\ntime of the first transaction in the dataset of transaction; t.sub.1 is the time of the most recent transaction; and t.sub.m is the time the m-th transaction was done.  M is the total number of transactions in the dataset.  n is an exponential that\ndetermines the effect of a timeliness of a transaction.  This is an adjustable parameter that may be adjusted in an iterative process by a user or by predetermined amounts to improve the outcome of the scoring function.  Typical values may be 2, 3, 4, . \n. . . The larger the value of n, the less important historical transactions become.  The function UniqueUser (i.sub.k,i.sub.m) is the number of distinct users that have purchased the items and is a metric measuring popularity of the items.\nCollaborative filtering may be performed by one or more of the components shown in FIG. 2 to determine customer-to-item associations.  Full transaction histories of every customer can be extracted from transaction data.  This can then be used\nfor the application of collaborative filtering techniques.  These techniques attempt to find for every customer, customers with similar purchasing behavior, characteristics and purchasing patterns, and preferences.  Then recommendations for a customer\nare generated by identifying the most frequent purchases of similar customers.  The recommendations generated with this approach are of the form \"customers like you also bought this\".\nThe similarity among customers can be defined in several fashions.  One approach is to compare the record of every customer to the records of the other customers based on their CARs and to generate a similarity index.  This index may be\nfrequently updated as customers are dynamic entities that continuously purchase new items and thus continuously alter their preferences and behavior as this is recorded in the CARs.  Another approach is to apply micro-clustering techniques to group\ncustomers into segments of users with like behavior and to generate recommendations for a customer using the purchases of his peers within the same group.  This approach is less computation intense but may be less accurate than the former one.\nFIG. 3 illustrates a computer system 300 that may be used to implement the system 100.  The computer system 300 may include additional components not shown and that some of the components described may be removed and/or modified.  The computer\nsystem 300 may be a server or the system 100 may be implemented in a distributed computing system on a plurality of servers.  Each server may include the components of the computer system 300.\nThe computer system 300 includes processor(s) 301, such as a central processing unit, ASIC or other type of processing circuit, input/output devices 302, such as a display, mouse keyboard, etc., a network interface 303, such as a Local Area\nNetwork (LAN), a wireless 802.11x LAN, a 3G or 4G mobile WAN or a WiMax WAN, and a computer-readable medium 304.  Each of these components may be operatively coupled to a bus 308.  The computer readable medium 304 may be any suitable medium which\nparticipates in providing instructions to the processor(s) 301 for execution.  For example, the computer readable medium 304 may be non-transitory or non-volatile medium, such as a magnetic disk or solid-state non-volatile memory or volatile medium such\nas RAM.  The instructions stored on the computer readable medium 304 may include machine readable instructions executed by the processor(s) 301 to perform the methods and functions of the system 100.\nThe system 100 may be implemented as software stored on a non-transitory computer readable medium and executed by one or more processors.  For example, the computer readable medium 304 may store an operating system 305, such as MAC OS, MS\nWINDOWS, UNIX, or LINUX, and code for the core 110/subsystem 120.  The operating system 305 may be multi-user, multiprocessing, multitasking, multithreading, real-time and the like.  For example, during runtime, the operating system 305 is running and\nthe code for the core 110/subsystem 120 is executed by the processor(s) 301.\nThe computer system 300 may include a data storage 307, which may include non-volatile data storage.  The data storage 307 stores any data used by the system 100.  The data storage 307 may be used for one or more of the data stores 116 or 125\nshown in FIG. 1 or the data stores 116 or 125 may be hosted by separate database servers.\nThe network interface 303 connects the computer system 300 to internal systems for example, via a LAN.  Also, the network interface 303 may connect the computer system 300 to the Internet.  For example, the computer system 300 may connect to web\nbrowsers and other external applications and systems, including the online testing system 104, via the network interface 303 and the Internet.\nThe recommendation functions of the hybrid recommendation system 100 process a diverse range of data sources as described above and creating several types of outputs in the process.  An important class of outputs is the different recommendation\nindices produced by the recommendation engine 115 and the test recommendation indices created at intermediate stages used for offline testing.  The creation of indices trades off storage space for faster computational time, whether for serving\nrecommendations or for offline testing.  Hence, the hybrid recommendation system 100 may impose certain resource requirements on the data store and processors.  In one example, the hybrid recommendation system 100 may be implemented in a distributed\ncomputing environment, such as a cluster of machines (e.g., servers) as well as network bandwidth on the connections linking the machines together.\nIn one example, the operations performed by the hybrid recommendation system 100 may be implemented in a map-reduce programming style for running parallel programs.  Mapper and reducer programs are written as side-effect free functions that can\nbe executed separately and in parallel on separate fragments of data.  They are isolated threads of computation that provide computational speedups.  In order to achieve this parallelism, the operations performed by the hybrid recommendation system 100\nare framed as sequences of map and reduce tasks that can be executed in parallel.\nThe operations on the indices performed by the recommendation engine 115 may be effectively reduced to a variation of self-join operations.  For example, individual transactional orders are separately processed in association-pair mapper tasks\nthat output primary items as keys, and secondary/recommended items and their weights as values.  The map-reduce framework shuffles and re-arranges the outputs by their keys (primary items) for feeding into reducer tasks.  The reducers then calculate and\nsort the final pairwise associations in the form of an item-item association or similarity index.\nEach mapper may be small enough that the total associations computed or the resources required are limited to the total counts of all product pairs in the data split, or sum (basket_size^2).  Each row of the item-item similarity index may be\nsorted to rank the recommendations by a pre-specified metric.  This means that the size of a reducer process depends on the product range offered, and the sparseness of the index.  Larger product ranges and denser associations may have larger reducer\ntasks or more reducers.\nFIG. 4 illustrates a method 400 according to an embodiment.  The method 400 may be performed by the system 100.  At 401, performance metrics are selected for evaluating recommendation functions.  Examples of the performance metrics may include\nprecision, recall, diversity of product category, diversity of users, time, etc. Other examples of performance metrics are described herein.  Different performance metrics may be used for different purchase phases.\nAt 402, recommendation functions 102 are determined and stored, and at 403 the recommendation functions 102 are optimized through offline testing.  Optimizing may be performed to achieve an object, such as to increase the revenues of retailers\nby providing targeted product or service recommendations.  The offline testing may be performed by the offline testing module 111 at 402 and 403.  For example, training data sets are generated from historic purchase data and user profiles and are used to\nidentify patterns and relationships between a performance metric and other variables.  In one example, the historical transaction data is split into training and testing datasets whereby 80% of the data may be used for training and 20% may be used for\ntesting.  As newer data arrives, the datasets (i.e., training and testing) may be redefined at periodic intervals to maintain freshness.  Also the datasets may be non-overlapping with respect to time.  Additionally, given several datasets with\nwell-defined time separation between the training and test sets, the recentness effect in recommendations may be quantified.  The performance of the recommendations over time provides an additional indication of the sales trends of products or services\nand provides an indication of the suitable frequency for processing the data to provide timely recommendations.\nThe training dataset may be used to generate recommendations using conventional machine learning techniques, such as Naive Bayes.  The recommendations are then evaluated on the test dataset.  Offline testing is performed by comparing the set of\nrecommended items to the items in the baskets of the customers in the testing period.  The more these two sets are alike the more successful the recommendations are.  The effectiveness of recommendations may be assessed using recall (e.g., the ratio of\nthe items in a basket of a consumer that are matching our recommendations) and precision (e.g., the percentage of the recommendations that turned out to be successful).  Recall evaluates how many of the items in the customer's basket were triggered by\nthe recommendations and it is estimated as the number of common items in the recommendations set and the basket divided by the number of items in the basket.  Therefore if in a basket the items p1, p2, p3, p4 and p5 were used and the recommendation\nengine 115 recommended the items p2, p4, p6, p8, p9 and p10, then recall is =40%.  Precision is a metric of the effectiveness of the provided recommendations and it is estimated as the number of the common items in the recommendation set and the basket,\ndivided by the number of provided recommendations.  Therefore, in the previous example the precision is 2/6=33.33%.  Precision may be a monotonically decreasing function regarding the number of provided recommendation, while recall may be a monotonically\nincreasing function of the number of provided recommendation.  Therefore, the more recommendation that are provided the higher the recall will be, since there are more chances to trigger a conversion but at the same time the lower the precision becomes.\nPrecision and recall may be used as performance metrics to optimize the recommendation functions.  For example, a recommendation function is applied to a test dataset to determine recommendations and precision and recall are measured.  The\nprecision and/or recall may be compared to thresholds to determine if they are satisfactory.  If not, adjustable parameters in the recommendation function may be adjusted and the recommendation function is re-tested to improve the performance metrics in\nan iterative process.  For example, when new transactions are placed from customers, the number of items that are purchased together change.  This change results in change in the support count (increase or reduction) scoring function which subsequently\nis reflected in the recommendations.  Also, the effect is determined by design parameters which are adjustable.  For example, a scoring function is described above that takes into consideration w.sub.price and w.sub.geo which are nonlinear weighting\nfactors that take into account the relative price of items and location.  As indicated above, this scoring function includes an exponential weighting parameter n which an adjustable parameter that may be adjusted in an iterative process to improve the\nresult of the scoring function.  Also, the length of the time window used to generate recommendations may be varied, e.g., the length may range from a few months to years, or even all historical transactions.\nAdditional metrics for the index size, product range coverage, and comprehensiveness may also be used to evaluate recommendations.  Cross-recommendation comparisons of overlap or similarity may also be used to aid the adjustment process during\noptimization.\nThe offline performance metrics can also be used to measure the effects of business rules on the performance of unconstrained recommendations.  This may provide a way to evaluate different what-if scenarios from post-processing recommendations\nusing different business rules or variations of business rules.  As an example, suppose a business rule proposing to \"limit recommendations for books to only books\" is introduced.  This eliminates non-book products from those recommendations.  This\nincreases the impressions for the recommended books and reduces impressions to non-book products (that are no longer being recommended).  The scores for the scoring functions might indicate that the overall conversion rate from the whole book category\nhas been reduced, as estimated from the reduction in the overall recall metric.  Conversely, the rule might provide an uplift within certain customer segments (e.g. the \"book lovers\" segment) especially if the base recommendation functions have not been\ntuned to recognize such customer segments.\nOffline and online testing are not mutually exclusive.  The offline testing may be used to initially calibrate the parameters of the recommendation function.  Online testing may then be to fine tune them.  Offline testing are estimates of the\nimpact that the provided recommendations will have, while online testing is an assessment of the actual impact of recommendations.\nAt 404, the optimized recommendation function is tested through online testing by the online testing module 112.  In one example, multiple recommendation functions are tested through online testing and the top K, where K is an integer greater\nthan 0, recommendation functions are selected based on the performance metrics.\nAt 405, recommendation indices are created, for example, from the top-performing recommendation functions by the recommendation engine 115.  The recommendation indices are stored in the low latency data store 125.  The indices identify macro or\npersonalized recommendations.  For example, for each product, an index identifies one or more other products to recommend, or for each product and user information for a user that purchased the product, an index identifies one or more other products to\nrecommend.  The indices may be supplemented with additional information, such as category of product, purchasing patterns of a product over time including periodicity, summary for product, etc.\nAfter the recommendation indices are created and stored, the indices may be used to provide recommendations to users.  For example, at 406, the dynamic data 103 is received which indicates the user's current behavior, such as product currently\nbeing viewed, products in a shopping cart, most recent web pages visited, geographic location, current time, recent purchases, demographics, etc. At 407, a product, user information or other information is identified from the dynamic data 103 to perform\na lookup on the recommendation indices.  At 408, the recommendation selection module 121 performs the lookup on a recommendation index to determine recommendations.  At 409, a filter or business rule is applied to select the recommendations, such as only\nproviding recommendations for other books or providing recommendations for long-tail products.  For example, a rule may indicate that whenever displaying books, only recommend books (remove anything that is not a book from index).  In another example,\ninstead of providing normal recommendations, give top 5 promotion items.  At 410, the selected recommendations are delivered to the user.  For example, the selected recommendations are displayed on a webpage the user is currently viewing.\nThe selected recommendations may be recommendations for other products to purchase.  The recommendations may include coupons or other promotions.  The recommendations may be shown on a web page being currently viewed or may be delivered via\nemail or another communication channel.\nFIG. 5 illustrates factors to consider for determining recommendation functions.  Also, FIG. 5 shows that indices may be created for item-to-item, customer-to-customer or personalized for a specific customer or demographic to determine\nrecommendations.  The factors to consider for determining recommendation functions may include purchase history, order data, product attributes, time of purchase, product reviews, navigation and search behavior (e.g., previously viewed web pages, click\npath, search terms), and customer feedback.  FIG. 5 also shows that the recommended function may become more sophisticated as a result of using multiple indices and as data volume is increased.  The recommendation function may include a statistical\nmodel.  Different recommended functions may be tested to find a balance between precision and a model complexity for the recommendation function.  A test plan may be associated with a recommendation function to test adjustable parameters.  Also,\ndifferent scenarios may be identified that are best for different recommendation functions.  Also, the scarcity treatment refers to the problem when there is not much data.  For example, when there is a new product or when there is little purchase\nhistory available for a product, product category level relationships may be used for a recommendation function if the indices cannot provide recommendations.  FIG. 6 illustrates some detailed steps and factors for determining recommendations.  FIG. 7\ngraphically shows steps for determining recommendations.  The recommendation functions identify products that are purchased together.  For example, they identify pairs of items purchased together frequently by multiple users and take into consideration\nthe recency of purchased pairs and the number of users that purchased each pair.  Multiple performance metrics may be used to assess and optimize the recommendation functions.  Also, recommendations may be shared among similar items.  For example, a\nproduct hierarchy may be determined having multiple levels, such as L0-L4, where L0 is the root.  A recommendation determined for one product in a level may be applied to other products in the level or a recommendation may be provided from a level higher\nup.  For example, if L4 does not have sufficient recommendations, then recommendations may be drawn from the L3 level.  Also, multiple recommendations may be determined and filtered based on rules or similarity control to determine final recommendations. For example, string similarity algorithms break down each L3 category to several L4 ones; recommendations are shared among the products of an L4 category to tackle the cold start problem; and if L4 does not provide sufficient recommendations, more are\ndrawn from the L3 level.\nFIG. 8 shows a specific use case whereby the recommendations are for coupons.  The data sources may include, in addition to information shown in FIG. 2, information related to coupons, such as impressions per coupon and a coupon list.  The\nrecommendation engine 115 generates recommendations and business rules may be applied to determine the final recommendations.  For example, the recommendations are coupons.  The coupons may be recommended based on items in a shopping basket.  The coupons\nmay be selected from a list of available coupons or new coupons not on the list are recommended.  Recommendations may be based on the user, such as based on the user's purchase history and/or preferences.  The coupons may be selected from a list of\navailable coupons or new coupons not on the list are recommended.  Performance metrics may be used to measure actual performance of the recommendations and perform fin-tuning and optimization of recommendation functions.\nFIG. 9 shows an example that illustrates filtering recommendations based on real-time information, such as location, time of day, real-time accepts/declines and other customer/user characteristics.  For example, a determination is made that a\nuser has accepted an offer for coffer or a transaction is recorded that a user has just purchased a coffee.  The real-time offer targeting can further refine the list of eligible offers by excluding high propensity offers that are not relevant in\nreal-time context.  Coupons or other recommendations for coffee may be suppressed for the user for the next hour even though the user is in the vicinity of other coffee shops.  In another example, real-time location exclusion may filter out offers that\nare not available in a subscriber's travel area.\nAs indicated above, different performance metrics may be considered to select and evaluate recommendation functions and recommendations.  The performance metrics may be combined to determine selections.  In addition to the examples described\nabove, other examples may include time and diversity.  For example, more recent purchases may be given more weight.  Diversity determines the number of different users that purchased a pair of products.  Also, in order to take into consideration the cold\nstart problem, which may be when there is a new product or when there is little purchase history available for a product, product category level relationships may be determined.  For example, if a person buys toothpaste, what other types of products do\nthey buy and how often.  Also, benchmarking may be performed for the metrics to determine whether offline or online testing results are satisfactory.\nSome examples for calculating the performance metrics are described below.  For example, recall and precision may be calculated.  For each rank, recall for each product p in basket is:\nif count(others)&gt;0, sum (count(intersection(recommendations, others))/count(others)/count(basket)).\nOthers is the rest of the basket not including p, and recommendations is the recommendation_function(p).\nFor precision, for each product p in the basket, if count(others)&gt;0 then sum count(intersection(recommendations, others))/count(basket)/count(recommendations).\nIn another example for calculating recall, let recommendations be an empty set and for each product p in basket:\nrecommendations=recommendations UNION recommendation_algorithm(p);\nrecall=count(intersect(recommendations,basket))/count(basket); and\nprecision=count(intersect(recommendations,basket))/count(recommendations)- .\nIn another example, an f-measure (which is 2*precision*recall/(precision+recall)) is used to combine both metrics, and then the time effects are considered.\nWhile the embodiments have been described with reference to examples, those skilled in the art will be able to make various modifications to the described embodiments without departing from the scope of the claimed embodiments.", "application_number": "15377432", "abstract": " A hybrid recommendation system uses offline testing and online testing to\n     generate and optimize recommendation functions. The functions generate\n     recommendations which may be presented online for product purchases.\n     Indices are created from the recommendations. Lookups may be performed on\n     the indices to select recommendations for a particular user. The selected\n     recommendations may be filtered before presenting to the user.\n", "citations": ["6266649", "7983952", "8326690", "8359227", "20040225509", "20050066350", "20070150369", "20070203790", "20090248494", "20100114692", "20110145051", "20110184806", "20110258085", "20110282821", "20120066087", "20120095863", "20120259729", "20120323682", "20120330778", "20130204737", "20130246216", "20130254065"], "related": ["13790854"]}, {"id": "20170132509", "patent_code": "10255628", "patent_name": "Item recommendations via deep collaborative filtering", "year": "2019", "inventor_and_country_data": " Inventors: \nLi; Sheng (Malden, AS), Kawale; Jaya (San Jose, CA)  ", "description": "<BR><BR>BACKGROUND\nRecommendation is a fundamental problem that has gained utmost importance in the modern era of information overload.  The goal of recommendation is to help a user find a potentially interesting item from a large repository of items. \nRecommendation systems are widely used in modern websites in various contexts to target customers and provide them with useful information (for example, Amazon, Google News, Netflix, Last.fm, etc.).  A widely used setting of recommendation systems is to\npredict how a user would rate an item (such as a movie) if only given the past rating history of the users.  Many classical recommendation methods have been proposed during the last decade, and the two broad categories of recommendation systems are\ncontent filtering approaches and collaborative filtering methods.  The collaborative filtering methods have attracted more attention due to their impressive performance.  Matrix factorization plays a crucial role in collaborative filtering methods and\nhas emerged as a powerful tool to perform recommendations in large datasets.\nLearning effective latent factors plays an important role in matrix factorization based collaborative filtering methods.  Traditional matrix factorization methods for collaborative filtering directly learn the latent factors from the user-item\nrating matrix (i.e., collection of item ratings given by users).  One of the main challenges faced by these systems is to provide a rating when a new user or new item arrives in the system, also known as the cold start problem.  The cold start problem is\ncircular in nature as the system will not recommend an item unless it has some ratings for it, and unless the system recommends the item, the system may not get ratings for the item.  Another practical challenge is learning the appropriate latent factors\nwhen the rating matrix is sparse, which is often the case in many real world scenarios.\nIn order to overcome these challenges, researchers have suggested incorporating additional sources of information about the users or items, also known as side information.  This side information can be obtained from user profiles and item\nprofiles, and may include any number of features regarding the users and items, such as, for example, demographics of a user, genre of a movie, etc. The user demographics could be used to infer the relationships between the users, and similarly, the item\nsimilarity can be used to automatically assign ratings to new items.  The use of side information to aid matrix factorization has been successfully applied by various prior works.  These methods, however, only utilize the side information as\nregularizations in the model, and the learned latent factors may not be very effective due to the sparse nature of the ratings and the side information.  In order to make matrix factorization based methods effective in such a setting, it is highly\ndesirable to learn and extract discriminative features from the datasets.\n<BR><BR>SUMMARY\nEmbodiments of the present invention generally relate to a deep collaborative filtering approach in a recommender system that tightly couples matrix factorization based collaborative filtering with deep feature learning.  The deep collaborative\nfiltering approach described herein addresses the cold-start problem, while being computationally efficient and scalable and providing improved performance when compared to prior state-of-art solutions.  In accordance with embodiments of the present\ninvention, a user-item rating matrix, user side information, and item side information are provided as input to a recommender system.  The recommender system learns user latent factors and item latent factors by jointly: (1) decomposing the user-item\nrating matrix to extract latent factors from the user-item rating matrix, and (2) extracting latent factors from hidden layers of deep learning models using the user side information and item side information as input layers.  Predicted item ratings are\ngenerated for missing ratings in the user-item rating matrix using the user latent factors and item latent factors.  The recommender system selects item recommendations for a user based on the predicted item ratings.  The item recommendations are then\nprovided to the user by communicating the item recommendations, via a communication network, to a user device associated to the user.\nThis summary is provided to introduce a selection of concepts in a simplified form that are further described below in the Detailed Description.  This summary is not intended to identify key features or essential features of the claimed subject\nmatter, nor is it intended to be used as an aid in determining the scope of the claimed subject matter. <BR><BR>BRIEF DESCRIPTION OF THE DRAWINGS\nThe present invention is described in detail below with reference to the attached drawing figures, wherein:\nFIG. 1 is a diagram illustrates the deep collaborative framework used by a recommender system in accordance with embodiments of the present invention;\nFIG. 2 is a flow diagram showing a method for utilizing the deep collaborative filtering framework in a recommender system to provide recommendations for a given user in accordance with an embodiment of the present invention;\nFIG. 3 is a flow diagram showing a method for determining user latent factors and item latent factors using a deep collaborative filtering approach combining probabilistic matrix factorization with marginalized denoising autoencoders in\naccordance with embodiments of the present invention;\nFIG. 4 is a flow diagram showing a method for determining user latent factors and item latent factors using a deep collaborative filtering approach combining probabilistic matrix factorization with marginalized stacked denoising autoencoders in\naccordance with embodiments of the present invention;\nFIG. 5 is a block diagram of an exemplary system architecture in which embodiments of the invention may be employed; and\nFIG. 6 is a block diagram of an exemplary computing environment suitable for use in implementing embodiments of the present invention.\n<BR><BR>DETAILED DESCRIPTION\nThe importance of accurate recommendation techniques motivated by wide ranging applications has fuelled a great amount of academic as well as industrial research in this area.  Currently, most recommender systems use matrix factorization based\ncollaborative filtering approaches.  However, matrix factorization methods suffer from the cold start problem (i.e., what recommendations to make when a new user/item arrives in the system).  Another issue often present in many real world applications is\nthe problem of data sparsity or reduced coverage.  Incorporating side information, such as user and item features, has helped to alleviate the cold start problem but these approaches still suffer when the side information is sparse.\nThe application of deep learning models to the task of collaborative filtering is very new and there are not many attempts in this direction.  As used herein, deep learning or deep learning models refer to neural networks with one or more hidden\nlayers.  Researchers have invested in modifying deep learning algorithms like Restricted Botzmann Machines or Convolutional Neural Networks or Deep Belief Networks directly for the task of collaborative filtering.  These approaches mainly modify the deep\nlearning algorithms for the task of collaborative filtering and do not directly couple matrix factorization with deep learning models.  More recently, researchers have proposed a hierarchical Bayesian model called collaborative deep learning (CDL) which\ntightly couples stacked denoising autoencoders (SDA) and collaborative topic regression (CTR).  However, the CDL approach is relatively computationally inefficient and not highly scalable.  Additionally, the CDL approach only extracts deep features for\nitems and does not learn deep features for both items and users.\nAccordingly, embodiments of the present disclosure address these technological problems of recommender systems by introducing a model for collaborative filtering, referred to herein as deep collaborative filtering (DCF), which tightly couples\nmatrix factorization based collaborative filtering with deep learning.  The DCF approach models the mappings between the latent factors used in collaborative filtering and the latent layers in deep learning models.  Particular embodiments combine\nprobabilistic matrix factorization (PMF) with marginalized denoising autoencoders (mDA).  The scalability and low computational cost of the mDA makes it a highly attractive deep learning tool.  However, mDA is a new method that has only been introduced\nfor specific applications (e.g., image classification), and there has been no work on how to combine mDA with matrix factorization or more generally combining matrix factorization and deep learning using a framework as described herein.  The combined\nframework leads to a parsimonious fit over the latent factors as indicated by its improved performance in comparison to prior state-of-art models.\nSome embodiments of the present invention provide a number of advantages over the CDL approach discussed above in a number of significant ways.  First, CDL utilizes a Bayesian formulation of SDA, while some embodiments herein employ a more\nefficient architecture, namely mDA.  One advantage of using mDA is computational efficiency.  Unlike SDA used in CDL that requires learning parameters (i.e., weights applied to hidden layers) through optimization, mDA computes its parameters (namely\nmapping functions) in closed form and is thus highly efficient and scalable.  Next, the generative process of CDL consists of drawing samples for CDL using an expectation maximization (EM)-style algorithm for obtaining the MAP estimates of Bayesian SDA\nand thus has to learn a large number of parameters.  Some embodiments herein use mDA for learning the features and stochastic gradient descent algorithm to learn the latent factors and hence this approach is computationally more efficient and highly\nscalable since, among other things, it uses a closed form solution as opposed to optimization as in CDL.  Further, CDL extracts deep features only for items, whereas embodiments herein learn deep features for both items and users, which provides better\nlatent factors that achieve higher prediction accuracy.\nAs previously explained, embodiments of the present invention are directed to a deep collaborative filtering (DCF) framework, which unifies deep learning models with matrix factorization based collaborative filtering.  Since a number of\nnotations will be used herein to describe the DCF framework, a summary of the notations is provided below in Table 1.\nTABLE-US-00001 TABLE 1 Summary of Notations Notation Description m Number of users n Number of items d Dimension of latent factors p Dimension of user features q Dimension of item features R .di-elect cons.  Rating matrix U .di-elect cons. \nLatent factors of users V .di-elect cons.  Latent factors of items X .di-elect cons.  Side information of users Y .di-elect cons.  Side information of items W .di-elect cons.  Mapping function in autoencoder P .di-elect cons.  Projection matrix\nFIG. 1 illustrates the DCF framework.  DCF is a hybrid model, which makes use of a user-item rating matrix R 102, user side information X 104, and item side information Y 106 and bridges together matrix factorization and feature learning.  The\nuser-item rating matrix R 102 comprises a matrix identifying item ratings given to various items by various users.  Each item rating provides an indication of a particular user's interest in or assessment of a particular item.  Item ratings may be\nprovided for any of a variety of different types of items, such as physical products, services, and digital content (e.g., digital music, digital movies, news content, advertisements).  In some embodiments, the item ratings are numerical representations,\nsuch as a rating on scale (e.g., 1-5).  In other embodiments, the item ratings are a binary indication of a user's assessment, such as an indication of a \"like\" or \"dislike.\" In still further embodiments, the item ratings represent whether a user\ninteracted with a particular item, such as clicking on a link for a news story or an advertisement.\nAs shown in FIG. 1, given the user-item rating matrix R 102, the user side information X 104 and the item side information Y 106, DCF jointly decomposes the user-item rating matrix R 102 and learns latent factors (i.e., U 108 and V 110) from the\nuser side information X 104 and the item side information Y 106.  In particular, the latent features U 108 and V 110 are extracted from the hidden layers 112 and 114 of deep learning models 116 and 118, respectively.  The following formulation provides a\ngeneral framework:\n.times..times..times..function..beta..function..gamma..times..times.L.fun- ction..delta.L.function..times..times.  ##EQU00001## where .beta., .gamma., and .delta.  are trade-off parameters.\nThere are two key components of the DCF framework: (i) the function l(R,U,V) for decomposing the rating matrix R into the two latent matrices; and (ii) the function L(X,U) and L(Y,V) that connects the user/item contextual features with the\nlatent factors.  The first component derived through matrix factorization extracts latent knowledge from the rating matrix.  The second component devised using deep learning models establishes connections of the side information with the latent factors.\nFIG. 2 provides a flow diagram illustrating a method 200 for utilizing the DCF framework in a recommender system to provide recommendations for a given user.  Each block of the method 200 and any other method discussed herein comprises a\ncomputing process that may be performed using any combination of hardware, firmware, and/or software.  For instance, various functions may be carried out by a processor executing instructions stored in memory.  The methods may also be embodied as\ncomputer-usable instructions stored on computer storage media.  The methods may be provided by a standalone application, a service or hosted service (standalone or in combination with another hosted service), or a plug-in to another product, to name a\nfew.  For example, the method 200 may be performed using a computing device, such as the computing device 600 of FIG. 6.\nAs shown at block 202, a user-item rating matrix, user side information, and item side information are received as inputs.  The process at block 204 then jointly decomposes the user-item rating matrix and learns user latent factors and item\nlatent factors from the user side information and item side information using a loss function (e.g., equation (1) above) that combines a matrix factorization loss function and mDA loss function.\nAs can be understood, the original user-item rating matrix received at block 202 has missing entries because not all users have rated all items in the matrix.  Predicted item ratings for missing entries are generated using the user latent\nfactors and the item latent factors, as shown at block 206.  As noted above, the item ratings in the input user-item rating matrix may take a variety of forms, such as, for instance, a numerical rating, binary rating, or indication of a user action (such\nas a click on a link).  As such, the predicted item ratings will be of the form of the item ratings of the input user-item rating matrix.  It should be understood that in the event the item ratings are an indication of a user action, the predicted item\nratings will comprise response predictions (i.e., a likelihood regarding whether that action will be performed for each item).\nItem recommendations are selected for a particular user based on at least some of the predicted item ratings for that particular user, as shown at block 208.  For instance, N items having the highest predicted item ratings for that user may be\nselected for recommendation.  The selected item recommendations are communicated over a communications network from the recommender system (e.g., which may reside on a server) to a user device associated with the user, as shown at block 210.\nSome embodiments of DCF are directed to combining probabilistic matrix factorization (PMF) with mDA.  The motivations of doing this are two-folds.  First, PMF is a widely applied collaborative filtering approach with excellent performance, and\nmDA is a powerful tool in extracting high-level features from raw inputs.  The combination of the two leverages their benefits for learning even richer models.\nLet X.di-elect cons.and Y.di-elect cons.denote the c-times repeated versions of X and Y respectively and let X and Y denote their corrupted versions.  The following loss function of PMF may be used to decompose the rating matrix R:\nl(R,U,V)=.parallel.A.circle-w/dot.(R-UV.sup.T).parallel..sub.F.sup.2 Equation (2) where A is the indicator matrix indicating the non-empty entries in R and .circle-w/dot.  denotes the Hadamard or point-wise product.  The objective function of mDA-CF is\nformulated as follows:\n.times..times.L.function.L.function..alpha..times..circle-w/dot.  .beta..function..times..times..times..times..times..times..times.L.functi- on..times..lamda..times..times.  .times.L.function..times..lamda..times..times.  .times..times..times. \n##EQU00002## and where W.sub.1.di-elect cons.  and W.sub.2.di-elect cons.  and are reconstruction mappings, P.sub.1.di-elect cons.  and P.sub.2.di-elect cons.  are projection matrices, .alpha., .beta., and .lamda.  are trade-off parameters.  Note that\n.gamma.  and .delta.  in equation (1) have been set to 1 in equation (3) for simplicity.\nThe first term in L.sub.U(W.sub.1,P.sub.1,U) denotes the learning process in the mDA.  It measures the reconstruction error between input user features X and the mapped features of corrupted inputs, i.e., W.sub.1 {tilde over (X)}.  W.sub.1 is\nthe learned mapping that is expected to minimize the loss.  The second term connects the hidden layer feature W.sub.1X and the latent factor U. Generally, the latent factor has much lower dimension than the raw features.  Therefore, a low-dimensional\nprojection P.sub.1 is added that maps latent factor to the feature space.\nAlthough the optimization problem in equation (3) is not jointly convex in all the variables, it is convex to each of them when fixing the others.  Hence, each of the variables in equation (3) can be alternately optimized.  The detailed\nprocedures are provided below.\nFirst, a solution is derived to solve W.sub.1 and W.sub.2.  By ignoring the variables irrelevant to W.sub.1, the objective function of equation (3) can be rewritten as:\n.times..times..times..times..lamda..times..times.  .times..times..times.  ##EQU00003##\nThe optimal solution below is obtained by considering the infinitely many copies of noisy data: W.sub.1=E[S.sub.1]E[Q.sub.1].sup.-1 Equation (5) where S.sub.1=X{tilde over (X)}.sup.T+.lamda.P.sub.1U.sup.TX.sup.T and Q.sub.1=X{tilde over\n(X)}.sup.T+.lamda.XX.sup.T.  An efficient solver for solving the expectations E[S.sub.1] and E[Q.sub.1] is provided in Minmin Chen et al., Marginalized Denoising Autoencoders for Domain Adaptation, in ICML, 2012.\nSimilarly, the closed-form solution of W.sub.2 is derived as: W.sub.2=E[S.sub.2]E[Q.sub.2].sup.-1 Equation (6) where S.sub.2=YY.sup.T+.lamda.P.sub.2V.sup.TY.sup.T and Q.sub.1=Y{tilde over (Y)}.sup.T+.lamda.YY.sup.T.\nNext, by dropping the irrelevant variables with respect to P.sub.1, the objective function becomes:\n.times..times..times..times..lamda..times..times.  .times..times..times.  ##EQU00004##\nThe closed-formed solution is obtained as: P.sub.1=W.sub.1XU(U.sup.TU).sup.-1 Equation (8)\nSimilarly, the optimal solution of P.sub.2 is: P.sub.2=W.sub.2YV(V.sup.TU).sup.-1 Equation (9)\nTo solve for the latent factors U and V, stochastic gradient descent is used.  In particular, when other variables irrelevant to U and V are fixed, we use f(U,V) to denote the objective in equation (3).  The update rules are:\n.gamma..times..differential..differential..times..function..times..times.- .gamma..times..differential..differential..times..function..times..times.  ##EQU00005## where .gamma.  is the learning rate, and the detailed derivatives are defined as:\n.differential..function..differential..lamda..function.  .function..times..times..beta..times..times..alpha..times..di-elect cons.  .times..times.  .times..times..times..differential..function..differential..lamda..functi- on. \n.function..times..times..beta..times..times..alpha..times..di-elect cons.  .times..times.  .times..times..times.  ##EQU00006##\nTurning now to FIG. 3, a flow diagram is provided illustrating a method 300 for determining user latent factors and item latent factors using a DCF approach combining PMF with mDA.  As shown at block 302, input is received that includes a\nuser-item rating matrix, user side information, and item side information.  Additionally, trade-off parameters may also be received at block 302.  User latent factors, item latent factors, a user projection matrix, and an item projection matrix are\ninitialized, as shown at block 304.\nAs shown in FIG. 3, the following steps are repeated until convergence.  Convergence is considered to occur when the difference between the output of the objective function from the current run and the output from a previous run satisfies a\ncertain threshold, which may be configurable (e.g., 10.sup.-6 could be used as the threshold in some embodiments).  A user mapping function is updated as a function of the user side information, the user latent factors, and the user projection matrix, as\nshown at block 306.  This may be performed using equation (5).  An item mapping function is updated at block 308 as a function of the item side information, the item latent factors, and the item projection matrix.  This may be performed using equation\n(6).  The user projection matrix is updated at block 310 as a function of the user side information, the user mapping function, and the user latent factors.  This may be performed using equation (8).  The item projection matrix is updated at block 312 as\na function of the item side information, the item mapping function, and the item latent factors.  This may performed using equation (9).  The user latent factors are updated at block 314 as a function of the user side information, the user projection\nmatrix, and the user mapping function.  This may be performed using equation (10).  The item latent factors are updated at block 316 as a function of the item side information, the item projection matrix, and the item mapping function.  This may be\nperformed using equation (11).\nUpon convergence being determined at block 318, learned user latent factors and learned item latent factors are outputted, as shown at block 320.  The learned user latent factors and learned item latent factors are then used to generate\npredicted item ratings for missing entries in the user-item rating matrix, as shown at block 322.\nThe above approach can be summarized in Algorithm 1 shown below:\nTABLE-US-00002 Algorithm 1: mDA-CF Algorithm Input: Rating matrix R, user side information X, item side information Y, trade-off parameters .lamda., .alpha., .beta.  Output: Latent factors U, V 1: Initialize U, V, P.sub.1, and P.sub.2; 2: while\nvalidation error decreases, do 3: Update W.sub.1 using equation (5) 4: Update W.sub.2 using equation (6) 5: Update P.sub.1 using equation (8) 6: Update P.sub.2 using equation (9) 7: for each observed R.sub.ij, do 8: Update u.sub.i using equation (10) 9:\nUpdate v.sub.j using equation (11) 10: end for 11: end while\nRegarding the complexity of Algorithm 1, the analytical solutions of steps 3-6 are efficient to compute.  The matrix multiplication and inversion used in Step 5 and Step 6 cost (p.sup.2m+pmd+d.sup.3) and (q.sup.2n+qnd+d.sup.3), respectively. \nSteps 8-9 are implemented in a batch-learning fashion, and cost (tN) to evaluate the gradients, where t is the number of iterations and N is the number of training ratings in R. Considering that N&gt;&gt;max{m,n,d}, the time complexity of Algorithm 1 is\nmainly determined by (tN).  Hence, this approach owns a good scalability.  To further reduce the computational cost, some advanced distributed optimization algorithms could be applied.\nThe above approach can be extended to multiple hidden layers using marginalized stacked denoising autoencoders (mSDA), which results in better performance in some instantiations.  In accordance with some embodiments, an assumption is made that\nonly one hidden layer should be close to the latent factor.  The reasons are two-fold.  First, latent factors are high-level representations, which should correspond to the deeper layers in deep learning models.  Secondly, latent factors should be\nunique, but different hidden layers have various representations.  Therefore, enforcing the similarity between multiple hidden layers and latent factors is unreasonable.\nIn accordance with the mSDA-CF model in some embodiments, an assumption is made that the latent factors are generated from the .left brkt-bot.(l+1)/2.right brkt-bot.  layer, given the total number of layers is l. When the model is trained for\nthe others layers, the parameters, .lamda., .alpha., and .beta.  are simply set to 0.  Only W.sub.1 and W.sub.2 need to be updated for these layers so the other steps from Algorithm 1 are ignored.  One benefit of such setting is time efficiency, as\ncomputational burden is not increased too much when adding multiple layers.  Moreover, another interesting problem is how to set the number of layers.  The number of layers implies the model complexity, which is usually related to the learning task and\nthe size of training data.\nFIG. 4 provides a flow diagram for determining user latent factors and item latent factors using a DCF approach combining PMF with mSDA.  As shown at block 402, input is received that includes a user-item rating matrix, user side information,\nand item side information.  Additionally, trade-off parameters may also be received at block 302.  The number of layers for the mSDAs may also be specified.\nAs shown in FIG. 4, the layers are looped through.  For each pass, a layer is selected at block 404.  If it is determined at block 406 that the currently selected layer is the .left brkt-bot.(l+1)/2.right brkt-bot.  layer, user latent factors\nand item latent factors are updated, as shown at block 408.  This may be performed, for instance, using the method 300 and Algorithm 1 discussed above.  Alternatively, if the currently selected layer is not the .left brkt-bot.(l+1)/2.right brkt-bot. \nlayer, the user mapping function and item mapping functions are updated, as shown at block 410.  This may be done, for instance, by setting tradeoff parameters (e.g., .lamda., .lamda., and .beta.) to zero.\nAfter all the layers have been processed at block 412, learned user latent factors and learned item latent factors are outputted, as shown at block 414.  The learned user latent factors and learned item latent factors are then used to generate\npredicted item ratings for missing entries in the user-item rating matrix, as shown at block 416.\nThe above approach can be summarized in Algorithm 2 shown below:\nTABLE-US-00003 Algorithm 2: mSDA-CF Algorithm Input: Rating matrix R, user side information X, item side information Y, trade-off parameters .lamda., .alpha., .beta., layers l. Output: Latent factors U, V 1: for loop 1 : l, do 2: if loop = .left\nbrkt-bot.(l+1)/2.right brkt-bot., do 3: Update U and V using Algorithm 1, by setting valid values to .lamda., .alpha., and .beta.; 4: otherwise 5: Update W.sub.1 and W.sub.2 using Algorithm 1, by setting .lamda.  = 0, .alpha.  = 0, and .beta.  = 0; 6:\nend if 7: end for\nWith reference now to FIG. 5, a block diagram is provided illustrating an exemplary system 500 in which some embodiments of the present invention may be employed.  It should be understood that this and other arrangements described herein are set\nforth only as examples.  Other arrangements and elements (e.g., machines, interfaces, functions, orders, and groupings of functions, etc.) can be used in addition to or instead of those shown, and some elements may be omitted altogether.  Further, many\nof the elements described herein are functional entities that may be implemented as discrete or distributed components or in conjunction with other components, and in any suitable combination and location.  Various functions described herein as being\nperformed by one or more entities may be carried out by hardware, firmware, and/or software.  For instance, various functions may be carried out by a processor executing instructions stored in memory.\nAmong other components not shown, the system 500 includes a recommender system 502 operable to select and send item recommendations to user devices.  For instance, FIG. 5 illustrates the recommender system 502 providing the user 1 item\nrecommendations 524 being delivered to the user device 526 of a first user, the user 2 item recommendations 528 being delivered to the user device 530 of a second user, and the user 3 item recommendations 532 being delivered to the user device 532.  It\nshould be understood that the recommender system 502 may provide item recommendations to any number of users, and the three shown in FIG. 5 are provided by way of example only.\nEach of the components shown in FIG. 5 may be implemented via any type of computing device, such as computing device 600 described with reference to FIG. 6, for example.  The components may communicate with each other via a network, which may\ninclude, without limitation, one or more local area networks (LANs) and/or wide area networks (WANs).  Such networking environments are commonplace in offices, enterprise-wide computer networks, intranets, and the Internet.  It should be understood that\nany number of user devices and recommender systems may be employed within the system 500 within the scope of the present invention.  Each may comprise a single device or multiple devices cooperating in a distributed environment.  For instance, the\nrecommender system 502 may be provided via multiple devices arranged in a distributed environment that collectively provide the functionality described herein.  Additionally, other components not shown may also be included within the network environment.\nThe recommender system 502 includes a DCF module 5004 that utilizes the DCF approach described herein to learn user latent factors 512 and item latent factors 514.  As shown in FIG. 5, the DCF module 504 receives input, including a user-item\nrating matrix 506, user side information 508, and item side information 510.  The DCF module 504 utilizes matrix factorization based collaborative filtering combined with mDA to derive the user latent factors 512 and the item latent factors 514.  For\ninstance, the DCF module may employ any of the methods 200, 300, or 400.\nThe user latent factors 512 and the item latent factors 514 are provided to a ratings generation module 516.  The ratings generation module employs the user latent factors 512 and the item latent factors to generate predicted item ratings 518\nfor at least a portion of the missing entries in the user-item rating matrix 506.  Predicting item ratings using user latent factors and item latent factors is well known and therefore will not be described in further detail herein.\nThe predicted item ratings 518 are provided to an item recommendation module 520.  The item recommendation module 520 selects item recommendations for a given user based on the predicted item ratings 518.  For instance, for the first user\nassociated with user device 526, the item recommendation module 520 retrieves predicted item ratings identified for the first user.  The item recommendation module 520 then selects the top N items having the highest predicted item ratings and provides\nrecommendations for those top N items.\nThe communications device 522 includes hardware (e.g., a network interface controller) operable to communicate item recommendations to a communications network, such as the Internet, in order to transmit the item recommendations to user devices. For instance, as shown in FIG. 5, the user 1 item recommendations 524 are delivered to the user device 526 of a first user, the user 2 item recommendations 528 are delivered to the user device 530 of a second user, and the user 3 item recommendations 532\nare delivered to the user device 532.\nHaving described embodiments of the present invention, an exemplary operating environment in which embodiments of the present invention may be implemented is described below in order to provide a general context for various aspects of the\npresent invention.  Referring initially to FIG. 6 in particular, an exemplary operating environment for implementing embodiments of the present invention is shown and designated generally as computing device 600.  Computing device 600 is but one example\nof a suitable computing environment and is not intended to suggest any limitation as to the scope of use or functionality of the invention.  Neither should the computing device 600 be interpreted as having any dependency or requirement relating to any\none or combination of components illustrated.\nThe invention may be described in the general context of computer code or machine-useable instructions, including computer-executable instructions such as program modules, being executed by a computer or other machine, such as a personal data\nassistant or other handheld device.  Generally, program modules including routines, programs, objects, components, data structures, etc., refer to code that perform particular tasks or implement particular abstract data types.  The invention may be\npracticed in a variety of system configurations, including hand-held devices, consumer electronics, general-purpose computers, more specialty computing devices, etc. The invention may also be practiced in distributed computing environments where tasks\nare performed by remote-processing devices that are linked through a communications network.\nWith reference to FIG. 6, computing device 600 includes a bus 610 that directly or indirectly couples the following devices: memory 612, one or more processors 614, one or more presentation components 616, input/output (I/O) ports 618,\ninput/output components 620, and an illustrative power supply 622.  Bus 610 represents what may be one or more busses (such as an address bus, data bus, or combination thereof).  Although the various blocks of FIG. 6 are shown with lines for the sake of\nclarity, in reality, delineating various components is not so clear, and metaphorically, the lines would more accurately be grey and fuzzy.  For example, one may consider a presentation component such as a display device to be an I/O component.  Also,\nprocessors have memory.  The inventors recognize that such is the nature of the art, and reiterate that the diagram of FIG. 6 is merely illustrative of an exemplary computing device that can be used in connection with one or more embodiments of the\npresent invention.  Distinction is not made between such categories as \"workstation,\" \"server,\" \"laptop,\" \"hand-held device,\" etc., as all are contemplated within the scope of FIG. 6 and reference to \"computing device.\"\nComputing device 600 typically includes a variety of computer-readable media.  Computer-readable media can be any available media that can be accessed by computing device 600 and includes both volatile and nonvolatile media, removable and\nnon-removable media.  By way of example, and not limitation, computer-readable media may comprise computer storage media and communication media.  Computer storage media includes both volatile and nonvolatile, removable and non-removable media\nimplemented in any method or technology for storage of information such as computer-readable instructions, data structures, program modules or other data.  Computer storage media includes, but is not limited to, RAM, ROM, EEPROM, flash memory or other\nmemory technology, CD-ROM, digital versatile disks (DVD) or other optical disk storage, magnetic cassettes, magnetic tape, magnetic disk storage or other magnetic storage devices, or any other medium which can be used to store the desired information and\nwhich can be accessed by computing device 600.  Computer storage media does not comprise signals per se.  Communication media typically embodies computer-readable instructions, data structures, program modules or other data in a modulated data signal\nsuch as a carrier wave or other transport mechanism and includes any information delivery media.  The term \"modulated data signal\" means a signal that has one or more of its characteristics set or changed in such a manner as to encode information in the\nsignal.  By way of example, and not limitation, communication media includes wired media such as a wired network or direct-wired connection, and wireless media such as acoustic, RF, infrared and other wireless media.  Combinations of any of the above\nshould also be included within the scope of computer-readable media.\nMemory 612 includes computer-storage media in the form of volatile and/or nonvolatile memory.  The memory may be removable, non-removable, or a combination thereof.  Exemplary hardware devices include solid-state memory, hard drives,\noptical-disc drives, etc. Computing device 600 includes one or more processors that read data from various entities such as memory 612 or I/O components 620.  Presentation component(s) 616 present data indications to a user or other device.  Exemplary\npresentation components include a display device, speaker, printing component, vibrating component, etc.\nI/O ports 618 allow computing device 600 to be logically coupled to other devices including I/O components 620, some of which may be built in. Illustrative components include a microphone, joystick, game pad, satellite dish, scanner, printer,\nwireless device, etc. The I/O components 620 may provide a natural user interface (NUI) that processes air gestures, voice, or other physiological inputs generated by a user.  In some instance, inputs may be transmitted to an appropriate network element\nfor further processing.  A NUI may implement any combination of speech recognition, touch and stylus recognition, facial recognition, biometric recognition, gesture recognition both on screen and adjacent to the screen, air gestures, head and eye\ntracking, and touch recognition associated with displays on the computing device 600.  The computing device 600 may be equipped with depth cameras, such as, stereoscopic camera systems, infrared camera systems, RGB camera systems, and combinations of\nthese for gesture detection and recognition.  Additionally, the computing device 600 may be equipped with accelerometers or gyroscopes that enable detection of motion.  The output of the accelerometers or gyroscopes may be provided to the display of the\ncomputing device 600 to render immersive augmented reality or virtual reality.\nAs can be understood, embodiments of the present invention are generally directed to providing item recommendations using a recommender system employing a deep collaborative filtering approach that combines deep learning models, namely\nmarginalized denoising autoencoders, with matrix factorization based collaborative filtering.  The present invention has been described in relation to particular embodiments, which are intended in all respects to be illustrative rather than restrictive. \nAlternative embodiments will become apparent to those of ordinary skill in the art to which the present invention pertains without departing from its scope.\nThe subject matter of the present invention has been described with specificity herein to meet statutory requirements.  However, the description itself is not intended to limit the scope of this patent.  Rather, the inventors have contemplated\nthat the claimed subject matter might also be embodied in other ways, to include different steps or combinations of steps similar to the ones described in this document, in conjunction with other present or future technologies.  Moreover, although the\nterms \"step\" and/or \"block\" may be used herein to connote different elements of methods employed, the terms should not be interpreted as implying any particular order among or between various steps herein disclosed unless and except when the order of\nindividual steps is explicitly described.\nFrom the foregoing, it will be seen that this invention is one well adapted to attain all the ends and objects set forth above, together with other advantages which are obvious and inherent to the system and method.  It will be understood that\ncertain features and subcombinations are of utility and may be employed without reference to other features and subcombinations.  This is contemplated by and is within the scope of the claims.", "application_number": "14934294", "abstract": " A deep collaborative filtering (DCF) approach is employed in a\n     recommender system to provide item recommendations to users. The DCF\n     approach combines deep learning models with matrix factorization based\n     collaborative filtering. To provide item recommendations, a user-item\n     rating matrix, user side information, and item side information are\n     provided as input to a recommender system. The recommender system learns\n     user latent factors and item latent factors by jointly: (1) decomposing\n     the user-item rating matrix to extract latent factors, and (2) extracting\n     latent factors from hidden layers of deep learning models using the user\n     side information and item side information. The learned user latent\n     factors and item latent factors are used to predict item ratings for\n     missing ratings in the user-item rating matrix. The predicted item\n     ratings are then used to select item recommendations for a given user,\n     which are then communicated to a user device of the user.\n", "citations": ["9202178", "9681250", "9798980", "9805098", "9990367", "20150012467", "20150055783", "20160148253", "20160180235", "20160180402", "20160203141", "20160350834", "20170132509", "20170140262", "20170140417", "20180075512"], "related": []}, {"id": "20170140409", "patent_code": "10311457", "patent_name": "Computerized method and system for automating rewards to customers", "year": "2019", "inventor_and_country_data": " Inventors: \nLiu; Siyuan (Singapore, SG), Han; Xiaogang (Singapore, SG), Shen; Zhiqi (Singapore, SG), Miao; Chunyan (Singapore, SG)  ", "description": "<BR><BR>FIELD OF THE INVENTION\nThe present invention relates to automated methods and systems for selecting which of a plurality of rewards to offer to a customer of at least one retailer, which may be an individual or a commercial organisation.\n<BR><BR>BACKGROUND OF THE INVENTION\nThere is a long tradition of retailers providing their customers with rewards to encourage them to place an order with the retailer, or encourage them use the retailer again.  One traditional reward mechanism is to allow customers to accumulate\npoints to earn goods.  A loyalty program is a typical example [1].  The customers are provided with a particular type of card (e.g., a loyalty card, a rewards card, a point card, an advantage card, or a club card), often with barcodes or magstripes on\nthem.  By presenting the cards, the customers can enjoy either a discount on the current purchase, or accumulate points that can be used for future purchases.  An alternative is to provide customers with \"one-time\" rewards, such as giving the customers\ngifts or vouchers, or entering the customers into a lucky draw\nFrom the retailer's point of view, the rewarding mechanisms can encourage the customers to conduct more shopping, and thus raise the retailer's profits.  For example, although the customers can use the points to redeem products, or enjoy\ndiscounts, the point accumulation needs a long-term shopping period, so it only will not have significant costs to the retailer if the customers use the retailers repeatedly over that period.  For the one-time rewards, e.g., a lucky draw, the customers\nneed to spend a minimum amount of money to get the reward.\nAlthough customers do benefit from a loyalty scheme, the behaviour needed to accumulate points requires behaviour which they have to passively accept.  For example, when they have become members of a program organised by a certain retailer, they\nwill only benefit if they go back to the same retailer for their shopping; or they have to redeem their points before a certain expiration date.  Therefore, customers are often incentivized to redeem their points as soon as possible.  On the other hand,\none-time rewards are often less than satisfactory.  The vouchers often carry conditions (e.g. they can only be used on certain products which the customers do not want to buy), or the gifts are not what they need, so customers do not feel happy when they\nreceive vouchers or gifts that do not match their personal needs.  An additional disadvantage of both reward mechanisms is that in order to participate users usually have to complete a registration process, and provide private information they may prefer\nnot to give, such as their name, IC number and contact number.\nTherefore, the existing rewarding mechanisms do not provide a great enough incentive to make existing customers more loyal, or attract new loyal customers.  The major reason for this is that the traditional rewarding mechanisms are not adapted\nto the customers' personal needs.  The uniform rewards applicable to one-time rewards do not benefit all customers, while loyalty programs make the customers feel that they are forced passively to accept behaviour dictated by the retailer, instead of\nbeing encouraged.\nWO 2011/1460554 [7] proposes an automated system to accumulated customer rewards, but the system requires that the user supplies a unique identifier.  The selection of a reward is made by the customer himself or herself.\n<BR><BR>SUMMARY OF THE INVENTION\nThe present invention aims to provide a customer rewarding mechanism which benefits the customers and encourages them to conduct more shopping.\nIn general terms, the invention proposes that a computerized reward mechanism system makes use both of presently collected data relating to the customer, and a database of historical data relating to the customer.  Using this information, the\nsystem performs a customer preference analysis, to select one or more rewards to offer the customer (from among a set of predefined reward possibilities), which are better adapted to the customers' personal needs.\nThe proposed mechanism can surprise the customers, making them feel that attention has been paid to them.  As a consequence, the rating for retailers may be increased and attract the customers to go back.\nA method which is an embodiment of the proposed mechanism may be performed automatically (e.g. upon automatically recognising that a certain customer arrives at a geographical location associate with at least one retailer, e.g. shopping center;\na surveillance system may be provided at the geographical location to do this), without an additional requirement of asking the customers to disclose their personal information, and this improves the convenience of the customers' shopping experience.\nThe presently collected data may include responses to questions put to the customer relating to his present shopping experience.  Customer honesty is considered in the step of determining which rewards to offer the consumer, to encourage the\nconsumers to express their feelings more clearly.\nThe benefits provided by preferred embodiments of the invention are bidirectional.  The customers can be rewarded in a way which is appropriate to their personal preferences.  Furthermore, since they are rewarded also for truthfully presenting\ntheir feelings and preferences, the retailers can improve their service through analyzing the truthfully presented feelings and preferences from the customers.  At the same time, more customers can be attracted through customer referral [2].\nThe term \"automatically\" is used in this document to mean a process substantially without human involvement, except with regards to setting up a system to perform the automatic process. <BR><BR>BRIEF DESCRIPTION OF THE DRAWINGS\nA non-limited example of the invention will now be described for the sake of example only with reference to the following figures, in which:\nFIG. 1 is a view of a system which is an embodiment of the method; and\nFIG. 2 is a flow diagram of the method performed by the embodiment.\n<BR><BR>DETAILED DESCRIPTION OF THE EMBODIMENT\nFIG. 1 shows schematically a system which is an embodiment of the invention.  FIG. 2 shows the steps of the method.  The system employs one or more security cameras 1 which are positioned at entrances to a shopping center.  When customers 2\nenter the shopping center, images of their faces are captured (step 21), and the images are sent to a computational system 10 having a processor 3 which is able to access a database 4 containing a plurality of customer records, each relating to a\nrespective previous customer.  Each customer record contains both one or more previously captured images of the customer and historical data relating to that customer 2, e.g. shopping records and a user profile.  Using the database, the processor 3\nperforms a facial recognition algorithm [3, 4] to try to identify the customers 2 among the previous customers (step 22), to associate one of the customer records with a customer 2 entering the shopping center.\nIf a customer 2 is not recognised in step 22, a new customer record is generated.  One or more images of the customer 2 captured by the camera 2 are entered into the customer records.  The historical data section of the customer record is\npopulated as the customer shops in the shopping center.\nConversely, if a customer 2 is recognised in step 22, the historical data relating to that customer is extracted from the database (step 23); during the rest of the method below any new information which is generated relating to the customer is\nadded to the historical data in the customer profile in the database 4.\nIn step 24, the historical data for the recognised customers 2 is used to select customers to reward.\nIn step 25, the system generates further data characterizing the current behaviour of the customers 2 (i.e. behaviour after the customer 2 has entered the geographical location).  For example, the security cameras 1 may record where in the\nshopping center the customers 2 go.  Furthermore, if the customers 2 make a purchase, the details of the purchase are collected.  Additionally, the customer 2 may be asked questions regarding their shopping experience, and that data input to the\nprocessor 3 using the interface 5.  Emotional information can be inferred from the customer's shopping experience.  The reward amount may be partially determined by the customer's emotion.  For example, when the customer is in a low emotion (i.e. a bad\nmood), a slightly higher reward can be provided to him.\nIn step 26, the data characterizing the current behaviour of the customers 2, and the historical data relating to those customers, is used to determine at least one reward to be offered to the customers 2 selected in step 24.  These reward(s)\nmay be selected from a predetermined database of rewards.  Optionally, a plurality of rewards may be selected and offered, from which the user can select at least one.  The rewards can be in a form such as personalized gifts or vouchers.  For example, if\na certain customer often buys cosmetics of a particular brand, then samples of the latest products from this brand can be provided to the customer as rewards.  If the data characterizing the current behaviour of the customer shows that the customer has\nspent time in an area of the shopping center where certain goods are sold, e.g. an area of where children's clothes are displayed, then some vouchers to buy children's clothes can be provided to the customer as rewards.  The techniques from the user\npreference analysis in recommendation systems [5][6] can be applied to make customers prefer the rewards.\nThe embodiment explained above can be applied in the environment of a real shopping center to provide the customers 2 with rewards matching their preferences.\nA second embodiment of the invention is adapted instead for use in an e-commerce environment, in which customers operating respective computer systems communicate (e.g. over the internet) with an e-Commerce website.  The method of this\nembodiment is that same as that of FIG. 2, except that steps 21 and 22 are replaced by a user login process.  In this embodiment, step 25 may include collating information about which webpages in the online store the user views, and/or which search terms\nhe or she uses.  It may further include asking the consumer questions about his or her shopping experience.\nBoth forms of the embodiment make it possible to provide rewards which depend upon customer preferences.  By providing such kind of rewards, the customers will feel surprised and be encouraged to go back more often.  Hence, such rewards will\nprovide customers with a more convenient and enjoyable shopping experience, as well as benefit the product providers by helping them to sell more products.\n<BR><BR>REFERENCES\nThe disclosure of the following references is incorporated herein in its entirety.  [1] Glossary L, \"Loyalty Program\".  Electronic Merchant Systems.  Aug.  18, 2011.  K. Merrick.  [2] Fred Reichheld, Loyalty Rules!, Harvard Business School\nPress, Boston, 2001.  [3] Pengcheng Wu, Steven C. H. Hoi, Hao Xia, Peilin Zhao, Dayong Wang, Chunyan Miao, \"Online Multimodal Deep Similarity Learning with Application to Image Retrieval\", in Proceedings of the 21st ACM international conference on\nMultimedia, pp.  153-162, 2013.  [4] Jialei Wang, Peilin Zhao, Steven C. H. Hoi, and Rong Jin, \"Online Feature Selection and Its Applications\", IEEE Transactions on Knowledge and Data Engineering (TKDE), 2013.  [5] Y. Koren.  \"Collaborative\nrecommendation\".  In Proceedings KDD'09, pp.  195-202, 2009.  [6] Y. Koren, R. Bell, and C. Volinsky.  Matrix factorization techniques for recommender system.  Computer, 42(8):30-37, 2009.  [7] WO 2011/146054, \"Improved customer reward systems and\nmethods\".", "application_number": "15128885", "abstract": " A computerized reward mechanism system is proposed which makes use both\n     of presently collected data relating to the customer, and a database of\n     historical data relating to the customer. Using this information, the\n     system performs a customer preference analysis, which results in\n     selecting rewards which are adapted to the customers' personal needs. In\n     one form, the system is positioned at a shopping center, and includes\n     cameras for recognising past customers by image processing. This may be\n     done without requiring customers to participate in a process of signing\n     up to use the system. The presently collected data include responses to\n     questions put to the customer relating to his present shopping\n     experience. Customer honesty is considered in the step of determining\n     which rewards to offer the consumer, to encourage the consumers to\n     express their feelings more clearly.\n", "citations": ["20040249712", "20070214037", "20090083122", "20090240571", "20120046044", "20120150606", "20120239504", "20120253905", "20120265637", "20120323662", "20130124361", "20130218721", "20140089399", "20150012426", "20150112826", "20170140409"], "related": ["61970019"]}, {"id": "20170206304", "patent_code": "10318701", "patent_name": "Resolving configuration conflicts using a multi-valued decision diagram", "year": "2019", "inventor_and_country_data": " Inventors: \nGoodman; Bryan Roger (Northville, MI), Hunsaker; Melinda Kaye (Canton, MI), Newton; David Mark (Cologne, DE), Liu; Yu-Ning (Ann Arbor, MI), Sabbagh; Essam Mahmoud (Dearborn Heights, MI), Sprague; Rickie Allan (Gladwin, MI), Fradkin; Yakov M. (Farmington Hills, MI)  ", "description": "<BR><BR>CROSS-REFERENCE TO RELATED APPLICATIONS\nThis application claims the benefit of U.S. provisional application Ser.\n     No. 62/280,609 filed Jan. 19, 2016 and U.S. provisional application Ser.\n     No. 62/352,463 filed Jun. 20, 2016, the disclosures of which are hereby\n     incorporated in their entirety by reference herein.\n         <HR>\n<CENTER><b><i>Claims</b></i></CENTER> <HR> <BR><BR>What is claimed is: 1.  A system comprising: a memory device adapted to store data representative of a multi-valued decision diagram (MDD) specifying a buildable space of all possible\nconfigurations of a vehicle, the MDD including a root node, a truth node, and at least one level of intervening nodes, each level of the MDD corresponding to a family of mutually-exclusive features represented by at least one node, each intervening node\nof a level connecting to nodes of a next adjacent level by outgoing edges having labels indicating valid features of the family and to nodes of a prior adjacent level by incoming edges that are outgoing edges of the prior adjacent level, such that a\ncomplete path from the root node through the outgoing edges to the truth node defines at least one of the valid configurations;  and a processor in communication with the memory, programmed to identify an invalid configuration, generate a restricted\nbuildable space, including to determine an edit distance of each complete path indicative of a number of features to change the invalid configuration of that path to one of the valid configurations, identify a minimum of the edit distances, and remove\nconfigurations having edit distances larger than the minimum;  and identify at least one feature to change the invalid configuration to at least one valid configuration based on the restricted buildable space;  and generate output indicative of the at\nleast one feature to change.\n2.  The system of claim 1, wherein the processor is further programmed to provide a message to a user indicative of the at least one feature to change.\n3.  The system of claim 1, wherein the processor is further programmed to: receive input indicative of a non-guided resolution;  and generate a further restricted buildable space having a single target configuration, including to determine a\nweight of each path in the restricted buildable space, indicative of a priority of its features, identify the maximum weight of all paths, and remove configurations having weights that are less than the maximum weight.\n4.  The system of claim 3, wherein each feature is assigned a weight such that each path is uniquely weighted.\n5.  The system of claim 1, wherein the processor is further programmed to: receive input indicative of a non-guided resolution;  and generate a further restricted buildable space having a single target configuration, including to determine a\nnumber of standard features of each path in the restricted buildable space, identify a maximum standard number of features of all paths, and remove configurations having less than the maximum standard number of features.\n6.  The system of claim 1, wherein the processor is further programmed to: receive input indicative of a non-guided resolution;  determine a first configuration corresponding to one of the valid configurations;  determine a second configuration\ncorresponding to the invalid configuration in response to receiving a selection of at least one feature;  determine a first feature state for each feature of the first configuration, including at least one of Selected, Included and Default feature\nstates;  generate a further restricted buildable space having a single target configuration, including to determine a second feature state for each feature of the second configuration, including at least one of Selected, Included and Default feature\nstates;  identify additions in the second configuration indicative of features present in the second configuration and not present in the first configuration, and the corresponding second feature state of each feature;  and identify subtractions in the\nsecond configuration indicative of features present in the first configuration and not present in the second configuration, and the corresponding first feature state of each feature.\n7.  The system of claim 6, wherein the processor is further programmed to: receive a return delta indicative of an amount of information provided to a user in response to an invalid configuration;  and provide a message to the user indicative of\nthe at least one feature to change to at least one valid configuration based on the further restricted buildable space and the return delta.\n8.  The system of claim 7, wherein the message is further indicative of all additions and subtractions in response to a return delta of true;  and wherein the message is further indicative of no additions or subtractions having Default feature\nstates in response to a return delta of false.\n9.  The system of claim 7, wherein the message is further indicative of only additions having Included feature states and only subtractions having Selected feature states in response to a return delta of false.\n10.  The system of claim 1, wherein the processor is further programmed to: receive input indicative of a guided resolution;  and generate a further restricted buildable space having at least one target configuration, including to determine a\nnode weight indicative of a weight of the node to the truth node along each path in the restricted buildable space, wherein a positive weight is assigned to each feature included in the configuration and a weight of zero is assigned to each feature that\nis not included in the configuration, identify a maximum node weight of all paths, and remove configurations having weights that are less than the maximum node weight, and thereby remove partial matches.\n11.  The system of claim 1, wherein the processor is further programmed to: receive input indicative of a guided resolution;  determine a first configuration corresponding to one of the valid configurations;  determine a second configuration\ncorresponding to the invalid configuration in response to receiving a second selection of at least one feature;  generate a further restricted buildable space having multiple target configurations, including to determine a bitset of the second\nconfiguration, determine a domain bitset of the restricted buildable space, calculate a bitwise conjunction of the second configuration bitset and the restricted buildable space bitset, and identify at least one family to change as a family having no\nactive bits in the bitwise conjunction;  and provide a message to a user that displays the at least one feature to change from each family to change, to resolve the at least one feature.\n12.  The system of claim 11, wherein the processor is further programmed to: determine a resolution object, including nested resolution objects, indicative of actions required to change the invalid configuration to one of the valid\nconfigurations in the restricted buildable space, wherein every family to change will have at least one action, and wherein there is more than one choice, including to identify a branch family as any family that leads to a divergent choice and the\nchoices for remaining families are unknown until the branch family choice is identified, identify a no-branch family as any family that does not lead to divergent choices for remaining families, and provide the message to the user that displays the\nfeatures from the no-branch families and no more than one branch family, and prompt the user to select from the displayed features.\n13.  A method comprising: storing, in a memory, data representative of a multi-valued decision diagram (MDD) specifying a buildable space of all possible configurations of a vehicle, the MDD including a root node, a truth node, and at least one\nlevel of intervening nodes, each level of the MDD corresponding to a family of mutually-exclusive features represented by at least one node, each intervening node of a level connecting to nodes of a next adjacent level by outgoing edges having labels\nindicating valid features of the family and to nodes of a prior adjacent level by incoming edges that are outgoing edges of the prior adjacent level, such that a complete path from the root node through the outgoing edges to the truth node defines at\nleast one of the valid configurations;  receiving input indicative of a non-guided resolution;  identifying an invalid configuration;  generating a restricted buildable space, including determining an edit distance of each complete path indicative of a\nnumber of features to change the invalid configuration of that path to one of the valid configurations, identifying a minimum of the edit distances, and removing configurations having edit distances larger than the minimum, generating a further\nrestricted buildable space having a single target configuration, including determining a weight of each path in the restricted buildable space, indicative of a priority of its features, identifying the maximum weight of all paths, and removing\nconfigurations having weights that are less than the maximum weight;  identifying at least one feature to change the invalid configuration to at least one valid configuration based on the further restricted buildable space;  and generating output\nindicative of the at least one feature to change.\n14.  The method of claim 13, further comprising: determining a first configuration corresponding to one of the invalid configurations;  determining a second configuration corresponding to the single target configuration;  determining a first\nfeature state for each feature of the first configuration, including at least one of Selected, Included and Default feature states;  determining a second feature state for each feature of the second configuration, including at least one of Selected,\nIncluded and Default feature states;  identifying additions in the second configuration indicative of features present in the second configuration and not present in the first configuration, and the corresponding second feature state of each feature; \nidentifying subtractions in the second configuration indicative of features present in the first configuration and not present in the second configuration, and the corresponding first feature state of each feature;  receiving a return delta indicative of\nan amount of information provided to a user in response to an invalid configuration;  and providing a message to the user that displays the at least one feature to change from each family to change to resolve the at least one feature.\n15.  The method of claim 14, wherein the message is indicative of all additions and subtractions in response to a return delta of true;  and wherein the message is further indicative of no additions or subtractions having Default feature states\nin response to a return delta of false.\n16.  The method of claim 14, wherein the message is indicative of only additions having Included feature states and only subtractions having Selected feature states in response to a return delta of false.\n17.  A method comprising: storing, in a memory, data representative of a multi-valued decision diagram (MDD) specifying a buildable space of all possible configurations of a vehicle, the MDD including a root node, a truth node, and at least one\nlevel of intervening nodes, each level of the MDD corresponding to a family of mutually-exclusive features represented by at least one node, each intervening node of a level connecting to nodes of a next adjacent level by outgoing edges having labels\nindicating valid features of the family and to nodes of a prior adjacent level by incoming edges that are outgoing edges of the prior adjacent level, such that a complete path from the root node through the outgoing edges to the truth node defines at\nleast one of the valid configurations;  receiving input indicative of a guided resolution;  identifying an invalid configuration;  generating a restricted buildable space having multiple target configurations, including determining an edit distance of\neach complete path indicative of a number of features to change the invalid configuration of that path to one of the valid configurations, identifying a minimum of the edit distances, and removing configurations having edit distances larger than the\nminimum, identifying at least one family to change, including determining a bitset of the invalid configuration, determining a domain bitset of the restricted bhuildable space, calculating a bitwise conjunction of the invalid configuration bitset and the\nrestricted buildable space bitset, and identifying the at least one family to change as a family having no active bits in the bitwise conjunction;  and providing a message to a user that displays at least one feature to change from each family to change,\nto resolve the at least one feature.\n18.  The method of claim 17, further comprising: determining a resolution object, including nested resolution objects, indicative of actions required to change the invalid configuration to one of the valid configurations in the restricted\nbuildable space, wherein every family to change will have at least one action, and wherein there is more than one choice, including identifying a branch family as any family that leads to a divergent choice and the choices for remaining families are\nunknown until the branch family choice is identified, identifying a no-branch family as any family as any family that does not lead to divergent choices for remaining families, and providing the message to the user that displays the features from the\nno-branch families and no more than one branch family, and prompt the user to select from the displayed features.\n19.  The method of claim 17, further comprising: determining a node weight indicative of a weight of the node to the truth node along each path in the restricted buildable space, wherein a positive weight is assigned to each feature included in\nthe configuration and a weight of zero is assigned to each feature that is not included in the configuration;  identifying a maximum node weight of all paths;  and removing configurations having weights that are less than the maximum node weight, and\nthereby remove partial matches.\n20.  The method of claim 17, further comprising receiving a user selection of a feature that resulted in the invalid configuration. <HR> <CENTER><b><i>Description</b></i></CENTER> <HR> <BR><BR>TECHNICAL FIELD\nOne or more embodiments generally relate to systems and methods for configuring a product.\n<BR><BR>BACKGROUND\nProduct configuration is an aspect of industries that offer customizable products with a wide variety of features.  The process of selecting a configuration, or features that include a configuration, is used in multiple aspects of marketing and\nsales, order management and production planning, and product development.  Examples include virtually constructing an ideal product (e.g., a vehicle) using a build-and-price application or selecting features for a prototype.\nThe product definition or product offering in the automotive industry is often of staggering dimensionality and size.  It is common for a vehicle to be offered with thirty or more optional feature categories, such as paint color, engine size,\nradio type, and wheel style.  Allowing a user to quickly explore a complex space that could include more than 10.sup.30 valid configurations is a challenging problem in constraints programming.\n<BR><BR>SUMMARY\nIn one embodiment, a system is provided with a memory device and a processor.  The memory device is adapted to store data representative of a multi-valued decision diagram (MDD) specifying a buildable space of all possible configurations of a\nvehicle.  The MDD includes a root node, a truth node, and at least one level of intervening nodes.  Each level of the MDD corresponds to a family of mutually-exclusive features represented by at least one node.  Each intervening node of a level connects\nto nodes of a next adjacent level by outgoing edges having labels indicating valid features of the family and to nodes of a prior adjacent level by incoming edges that are outgoing edges of the prior adjacent level, such that a complete path from the\nroot node through the outgoing edges to the truth node defines at least one of the valid configurations.  The processor is in communication with the memory and is programmed to identify an invalid configuration, and to generate a restricted buildable\nspace, including to determine an edit distance of each complete path indicative of a number of features to change the invalid configuration of that path to one of the valid configurations, identify a minimum of the edit distances, and remove\nconfigurations having edit distances larger than the minimum.  The processor is further programmed to identify at least one feature to change the invalid configuration to at least one valid configuration based on the restricted buildable space; and to\ngenerate output indicative of the at least one feature to change.\nIn another embodiment, a method is provided for storing, in a memory, data representative of a multi-valued decision diagram (MDD) specifying a buildable space of all possible configurations of a vehicle.  The MDD includes a root node, a truth\nnode, and at least one level of intervening nodes, each level of the MDD corresponding to a family of mutually-exclusive features represented by at least one node.  Each intervening node of a level connects to nodes of a next adjacent level by outgoing\nedges having labels indicating valid features of the family and to nodes of a prior adjacent level by incoming edges that are outgoing edges of the prior adjacent level, such that a complete path from the root node through the outgoing edges to the truth\nnode defines at least one of the valid configurations.  Input indicative of a non-guided resolution is received.  An invalid configuration is identified.  A restricted buildable space is generated, including: an edit distance of each complete path is\ndetermined that is indicative of a number of features to change the invalid configuration of that path to one of the valid configurations, a minimum of the edit distances is identified, and configurations having edit distances larger than the minimum are\nremoved.  A further restricted buildable space having a single target configuration is generated, including: a weight of each path in the restricted buildable space is determined that is indicative of a priority of its features, the maximum weight of all\npaths is identified, and configurations having weights that are less than the maximum weight are removed.  At least one feature to change the invalid configuration to at least one valid configuration is identified, based on the further restricted\nbuildable space.  And output indicative of the at least one feature to change is generated.\nIn yet another embodiment, a method is provided for storing, in a memory, data representative of a multi-valued decision diagram (MDD) that specifies a buildable space of all possible configurations of a vehicle.  The MDD includes a root node, a\ntruth node, and at least one level of intervening nodes.  Each level of the MDD corresponds to a family of mutually-exclusive features represented by at least one node.  Each intervening node of a level connecting to nodes of a next adjacent level by\noutgoing edges having labels indicating valid features of the family and to nodes of a prior adjacent level by incoming edges that are outgoing edges of the prior adjacent level, such that a complete path from the root node through the outgoing edges to\nthe truth node defines at least one of the valid configurations.  Input is received that is indicative of a guided resolution.  An invalid configuration is identified.  A restricted buildable space is generated that has multiple target configurations,\nincluding: an edit distance is determined of each complete path indicative of a number of features to change the invalid configuration of that path to one of the valid configurations, a minimum of the edit distances is identified, and configurations are\nremoved that have edit distances larger than the minimum.  At least one family to change is identified, including: a bitset of the invalid configuration is determined, a domain bitset of the restricted space is determined, a bitwise conjunction of the\ninvalid configuration bitset and the restricted space bitset is calculated, and the at least one family to change is identified, as a family having no active bits in the bitwise conjunction.  A message is provided to a user that displays at least one\nfeature to change from each family to change, to resolve the at least one feature. <BR><BR>BRIEF DESCRIPTION OF THE DRAWINGS\nFIG. 1 is a block diagram of a product configuration system, according to one or more embodiments;\nFIG. 2 is an application programming interface illustrating an application of the product configuration system of FIG. 1 including a configuration engine;\nFIG. 3 is a table illustrating configurations expressed in conjunctive normal form;\nFIG. 4 is a table illustrating configurations expressed in conjunctive normal form and in binary form;\nFIG. 5 is a table illustrating mappings of the configurations of FIG. 4;\nFIG. 6 is a table illustrating multiple configurations and a superconfiguration;\nFIG. 7 is a table illustrating multiple superconfigurations;\nFIG. 8 is a table illustrating the interaction of superconfigurations;\nFIG. 9 is another table illustrating the interaction of superconfigurations;\nFIG. 10 is a table depicting a buildable space according to one or more embodiments;\nFIG. 11 is a table depicting overlapping configurations;\nFIG. 12 is a table depicting a feature mask;\nFIG. 13 is a multi-valued decision diagram (MDD) representing the buildable space of FIG. 10, according to one or more embodiments;\nFIG. 14 is a comparison table;\nFIG. 15 is a diagram illustrating a reduction of the MDD of FIG. 13;\nFIG. 16 is a diagram illustrating merging of duplicate MDD nodes;\nFIG. 17 is a diagram illustrating MDD compression with deterministic families;\nFIG. 18 is a window displayed to a user based on a conflict resolution procedure of the configuration engine of FIG. 2 according to one embodiment;\nFIG. 19 is a window displayed to the user based on a conflict resolution procedure of the configuration engine of FIG. 2 according to another embodiment;\nFIG. 20 is a diagram illustrating a containsAny operation performed by the configuration engine according to one embodiment;\nFIG. 21 is another diagram illustrating a containsAny operation performed by the configuration engine according to another embodiment;\nFIG. 22 is a table listing a restricted buildable space of the buildable space in FIG. 10;\nFIG. 23 is a diagram illustrating a restricted buildable space of the buildable space in FIG. 13 and the table of FIG. 22;\nFIG. 24 is a flowchart illustrating a method for evaluating an MDD using reversible restrictions, according to one or more embodiments;\nFIG. 25 is a diagram illustrating an example of various steps of the method of FIG. 24;\nFIG. 26 is a flowchart illustrating a subroutine of the method of FIG. 24;\nFIG. 27 is another flowchart illustrating a subroutine of the method of FIG. 24;\nFIG. 28 is yet another flowchart illustrating a subroutine of the method of FIG. 24;\nFIG. 29 is a comparison table;\nFIG. 30 is a table illustrating a reduction of the buildable space of FIG. 10;\nFIG. 31 is a table illustrating a projected space after the overlap has been removed and the space has been compressed;\nFIG. 32 is a diagram illustrating the table of FIG. 30;\nFIG. 33 is a table illustrating combinations of features of the buildable space of FIG. 13;\nFIG. 34 is a flowchart illustrating a method for determining MDD feature states according to one or more embodiments;\nFIG. 35 is a table illustrating a set of superconfigurations;\nFIG. 36 is an example of a table illustrating a restricted domain after various steps of the method of FIG. 34;\nFIG. 37 is another example of a table illustrating a restricted domain after various steps of the method of FIG. 34;\nFIG. 38 is a table illustrating an example of the results of the method of FIG. 34;\nFIG. 39 is a flowchart illustrating another method for determining MDD feature states according to one or more embodiments;\nFIG. 40 is a flowchart illustrating a subroutine of the method of FIG. 39;\nFIG. 41 is another flowchart illustrating a subroutine of the method of FIG. 39;\nFIG. 42 is yet another flowchart illustrating a subroutine of the method of FIG. 39;\nFIG. 43 is another flowchart illustrating a subroutine of the method of FIG. 39;\nFIG. 44 is yet another flowchart illustrating a subroutine of the method of FIG. 39;\nFIG. 45 is a diagram illustrating an example of various steps of the method of FIG. 39;\nFIG. 46 is another diagram illustrating an example of various steps of the method of FIG. 39;\nFIG. 47 is a flowchart illustrating a method for resolving conflicts between configurations according to one or more embodiments;\nFIG. 48 is a flowchart illustrating a subroutine of the method of FIG. 47;\nFIG. 49 is a diagram illustrating an example of various steps of the method of FIG. 47;\nFIG. 50 is another flowchart illustrating a subroutine of the method of FIG. 47;\nFIG. 51 is yet another flowchart illustrating a subroutine of the method of FIG. 47;\nFIG. 52 is still yet another flowchart illustrating a subroutine of the method of FIG. 47;\nFIG. 53 is a table illustrating an example of additions and subtractions for the diagram of FIG. 49 according to various steps of the method of FIG. 47;\nFIG. 54 is a window illustrating an example of additions and subtractions that are displayed to the user based on various steps of the method of FIG. 47 according to one embodiment;\nFIG. 55 is a window illustrating an example of additions and subtractions that are displayed to the user based on various steps of the method of FIG. 47 according to another embodiment;\nFIG. 56 is a table illustrating a compression of three superconfigurations to two superconfigurations, according to one embodiment;\nFIG. 57 is a window illustrating an example of a resolution object that is displayed to the user based on various steps of the method of FIG. 47 according to another embodiment;\nFIG. 58 is another flowchart illustrating a subroutine of the method of FIG. 47;\nFIG. 59 is yet another flowchart illustrating a subroutine of the method of FIG. 47;\nFIG. 60 is still yet another flowchart illustrating a subroutine of the method of FIG. 47;\nFIG. 61 is another flowchart illustrating a subroutine of the method of FIG. 47;\nFIG. 62 is yet another flowchart illustrating a subroutine of the method of FIG. 47;\nFIG. 63 is still yet another flowchart illustrating a subroutine of the method of FIG. 47;\nFIG. 64 is a diagram illustrating an example of various steps of the method of FIG. 47;\nFIG. 65 is a table listing an invalid configuration as a bitset;\nFIG. 66 is a table illustrating the minimum edit space of the configuration of FIG. 65 converted to a matrix, as determined by various steps of the method of FIG. 47;\nFIG. 67 is a table illustrating a bitwise conjunction (AND) of the domain of the edit space from FIG. 66 with the invalid configuration from FIG. 65;\nFIG. 68 is a table illustrating the minimum edit space from FIG. 66 after it is trimmed to the families to change from FIG. 67;\nFIG. 69 is an example target matrix for a selection of a feature as determined by various steps of the method of FIG. 47;\nFIG. 70 is an example target matrix for a selection of another feature as determined by various steps of the method of FIG. 47;\nFIG. 71 is software code illustrating an example final resolution object, according to one or more embodiments;\nFIG. 72 is a window illustrating an example prompt provided to the user as part of a guided resolution;\nFIG. 73 is a window illustrating an example of another prompt provided to the user as part of the guided resolution;\nFIG. 74 is a window illustrating an example of yet another prompt provided to the user as part of the guided resolution;\nFIG. 75 is a diagram illustrating an example of various steps of the remove partial matches subroutine of FIG. 58;\nFIG. 76 is a table illustrating an example of various steps of the remove partial matches subroutine of FIG. 58;\nFIG. 77 is a table illustrating an example of various steps of the minimum edit space calculation of FIG. 48;\nFIG. 78 is another table illustrating an example of various steps of the minimum edit space calculation of FIG. 48;\nFIG. 79 is yet another table illustrating an example of various steps of the minimum edit space calculation of FIG. 48;\nFIG. 80 is still yet another table illustrating an example of various steps of the minimum edit space calculation of FIG. 48;\nFIG. 81 is another table illustrating an example of various steps of the minimum edit space calculation of FIG. 48;\nFIG. 82 is a flow chart illustrating a method for automatically completing a configuration according to one or more embodiments;\nFIG. 83 is a diagram illustrating a buildable space;\nFIG. 84 is a table that defines an alternate sequence structure for defining path weights of the buildable space of FIG. 83;\nFIG. 85 is a diagram illustrating an example of various steps of the method of FIG. 82 performed on the buildable space of FIG. 83;\nFIG. 86 is table illustrating path weight;\nFIG. 87 is another table illustrating path weight;\nFIG. 88 is yet another table illustrating path weight;\nFIG. 89 is a diagram illustrating an example of various steps of the method of FIG. 82 performed on the buildable space of FIG. 85;\nFIG. 90 is another table illustrating path weight;\nFIG. 91 is a table illustrating a matrix that defines the same buildable space as the diagram of FIG. 17;\nFIG. 92 is a table illustrating the standard feature conditions for the product definition defining the buildable space of FIG. 91;\nFIG. 93 is software code illustrating a method for automatically completing a configuration using a maximally standard algorithm according to one or more embodiments;\nFIG. 94 is a diagram illustrating an example of various steps of the method of FIG. 93;\nFIG. 95 is a flowchart illustrating another method for automatically completing a configuration using a maximally standard algorithm according to one or more embodiments;\nFIG. 96 is a flowchart illustrating a subroutine of the method of FIG. 95;\nFIG. 97 is another flowchart illustrating a subroutine of the method of FIG. 95;\nFIG. 98 is yet another flowchart illustrating a subroutine of the method of FIG. 95;\nFIG. 99 is still yet another flowchart illustrating a subroutine of the method of FIG. 95;\nFIG. 100 is a table illustrating a buildable space;\nFIG. 101 is a table illustrating standard feature conditions;\nFIG. 102 is a table illustrating an example of various steps of the method of FIG. 95;\nFIG. 103 is another table illustrating an example of various steps of the method of FIG. 95;\nFIG. 104 is yet another table illustrating an example of various steps of the method of FIG. 95;\nFIG. 105 is still yet another table illustrating an example of various steps of the method of FIG. 95;\nFIG. 106 is another table illustrating an example of various steps of the method of FIG. 95;\nFIG. 107 is yet another table illustrating an example of various steps of the method of FIG. 95;\nFIG. 108 is still yet another table illustrating an example of various steps of the method of FIG. 95;\nFIG. 109 is another table illustrating an example of various steps of the method of FIG. 95;\nFIG. 110 is software code illustrating an example of various steps of the method of FIG. 95;\nFIG. 111 is another table illustrating an example of various steps of the method of FIG. 95;\nFIG. 112 is yet another table illustrating an example of various steps of the method of FIG. 95;\nFIG. 113 is still yet another table illustrating an example of various steps of the method of FIG. 95;\nFIG. 114 is another table illustrating an example of various steps of the method of FIG. 95;\nFIG. 115 is yet another table illustrating an example of various steps of the method of FIG. 95;\nFIG. 116 is still yet another table illustrating an example of various steps of the method of FIG. 95; and\nFIG. 117 is another table illustrating an example of various steps of the method of FIG. 95.\n<BR><BR>DETAILED DESCRIPTION\nAs required, detailed embodiments of the present invention are disclosed herein; however, it is to be understood that the disclosed embodiments are merely exemplary of the invention that may be embodied in various and alternative forms.  The\nfigures are not necessarily to scale; some features may be exaggerated or minimized to show details of particular components.  Therefore, specific structural and functional details disclosed herein are not to be interpreted as limiting, but merely as a\nrepresentative basis for teaching one skilled in the art to variously employ the present invention.\nWith reference to FIG. 1, a product configuration system is illustrated in accordance with one or more embodiments and generally referenced by numeral 100.  The product configuration system 100 includes a server 102 and a configurator\napplication 104.  The configurator application 104 includes a configuration engine 106.  The server 102 includes memory 108 and a processor 110 for storing and operating the configurator application 104.  The product configuration system 100 communicates\nwith a user device, such as a personal computer 112 and/or a mobile device 114 (e.g., a tablet, a mobile phone, and the like), each of which include memory and a processor.  The configurator application 104 includes a \"front-end\" application (shown in\nFIG. 2) that may be installed to the user device 112, 114 from a computer-readable storage medium such as a CD-ROM, DVD or USB thumb drive.  Alternatively, the front-end application may be downloaded from the server 102 to the client device 112, 114 via\nan internet connection 116.  The design and efficiency of the application 104 therefore allows it to be optimized to run on multiple various operating system platforms and on devices having varying levels of processing capability and memory storage.\nThe configurator application 104 allows a user to explore a product offering, where the product is defined by selecting multiple features.  A common example is a build-and-price website that allows a user to customize a product by choosing\nfeatures such as size and color.  The configuration engine 106 validates the customized product (i.e., the configuration) as the user selects different features.\nThe product offering, or product definition, includes all of the allowed ways of combining features (or parts, options, or attributes) in order to make a complete product.  For example, a company might sell a product in two levels (e.g., base\nand luxury), A1 and A2, and in three colors, B1, B2 and B3.  Further, the company only offers the base model, A1, in one color, B1.  Features are grouped into families, in this case family A-\"level\" and family B-\"color.\" The product configuration space\nincludes the following four configurations: A1B1, A2B1, A2B2, and A2B3.  Product definition often comprises rules or constraints that limit or allow relationships between features.  In this example the rule might be \"A1 requires B1.\" A complex product\ncan be defined by thousands or even tens of thousands of rules.\nThe configurator application 104 allows the user to select options or features to create or modify a configuration.  When a user changes a configuration by adding and/or removing a feature, the configuration engine 106 validates the new\nconfiguration.  To perform this validation, the configuration engine 106 determines if the selected configuration fits within the allowed product space.  If the new configuration is invalid, the configuration engine 106 either prompts the user to make\nchanges, or make the changes itself according to a predefined hierarchy.  For example, the monitor of the personal computer 112 shown in FIG. 1 depicts a message window that is displayed to the user indicating changes to resolve the conflict between\nselected features.  The validation and conflict resolution is performed quickly (e.g., less than 2 seconds) and uses little memory and processing.  Ideally, this allows the user to explore the buildable space of allowable product configurations, often\nwhile viewing information associated with the configuration such as price or images.\nUsers interact with front-end applications that present the product information, e.g., on the monitor of their pc 112, and allow them to explore the buildable space.  Although, the configuration engine 106 is different from the front-end\napplication that is displayed on the pc 112, the applications interact closely with each other.  Examples of front-end applications include build-and-price websites, mobile shopping applications, interactive shopping kiosks, and back-office order entry\nand management systems.  When these front-end applications populate product information, they can communicate with the configuration engine 106.  The only people who interact directly with the configuration engine 106 are back-office users tending to the\ndata stored in the server 102.  The product configuration application 104 primarily interacts with other applications.\nIn the computer science field, exploration of a configuration space that is defined by rules or constraints is called constraint programming.  A configuration space can also be defined by a model that is a representation of the possible product\nconfigurations.  Many methods exist in the literature to solve configuration problems, with some using a constraints programming approach and others operating on product definition models.\nReferring to FIG. 2, an application programming interface (API) is illustrated in accordance with one or more embodiments, and generally referenced by numeral 120.  The API 120 illustrates the inputs, steps, and outputs of the configurator\napplication 104.  The configurator application 104 is contained within the server 102 and the user device (pc 112 and/or mobile device 114) according to one embodiment, and may be implemented using hardware and/or software control logic as described in\ngreater detail herein.\nThe configurator application 104 includes a database (DB) 122 for storing data as a catalog entry.  Each catalog entry will store the vehicle attributes (make, model, year, etc.), buildable product space, and extended feature attributes (images,\nprices, detailed descriptions, sales codes, etc.).  The data may be directly processed as is shown by a product definition data source 124, or it may come through a catalog management API 126.  The configurator application 104 also includes an extract,\ntransform and load (ETL) process 128 that provides an interface between the DB 122 and the product definition data source 124 and the catalog management API 126.  The configurator application 104 accesses data from the DB 122 and temporarily saves a copy\nof it in cache memory 130.\nThe configurator application 104 includes one or more \"front-end\" applications or \"top hats\" 132 that are accessible from the user device 112, 114.  Examples of such \"front-end\" applications 132 include consumer build and price sites, management\nlease ordering sites, and dealer ordering applications.\nThe configurator application 104 includes a service API 134 and a web service controller 136 for coordinating the user's requests.  The service API 134 includes a configuration service 138, an enumeration service 140 and a configuration details\nservice 142.\nThe configurator application 104 includes a plurality of processing engines 144, for optimizing the data provided to the front-end applications 132.  The engines include: the configuration engine 106, an image engine 146, a mapping engine 148\nand a pricing engine 150.  The image engine 146 provides one or more images associated with features of the configuration.  The mapping engine 148 provides feature codes from one or more feature code dictionaries.  For example, manufacturing systems and\nsales systems may use different codes for the same feature, and the mapping engine translates between the different coding schemes.  The pricing engine 150 provides pricing associated with the complete configurations and with individual features.  The\npricing engine 150 can also provide changes in pricing associated with changes in the configuration or features.\nThe configurator application 104 also includes a catalog controller 152 that lists which product definitions are available.  The catalog controller 152 receives a catalog request (e.g., what products are available), and provides a response\n(e.g., product A, product B and product C).  Then the user selects a product, and the front end application 132 submits a configuration load request.  Then the web service controller 136 returns a default configuration.\nThe web service controller 136 is a simple object access protocol (SOAP) web service using XML messages, according to one embodiment.  The service API 134 provides an XML request to the web service controller 136 based on each user selection\nmade in the front-end applications 132.  In other embodiments the web service controller 136 uses other protocol.\nThe web service controller 136 provides an XML response to the service API 134 in response to each XML request.  The web service controller 136 parses each XML request, makes appropriate calls to the processing engines 144 or catalog controller\n152, and transforms the output of the configuration engine 106, the image engine 146, the mapping engine 148 and the pricing engine 150 into the appropriate XML response.  The web service controller 136 includes author decorators 154 that are responsible\nfor building up each portion of the response, and includes logic to retrieve data from the database 122 via the cache 130 and save the data as a working copy.\nThe configuration engine 106 operates with reference to a valid buildable space.  The buildable space is also referred to as the product offering and is defined in terms of features that are grouped into mutually exclusive family sets.  All of\nthe possible features are grouped into families such that a valid configuration will contain one and only one feature from each family.\nIn one example product definition of a vehicle, (Vehicle A), exterior paint color is defined by the family PAA and its features are Green (PNWAD), Magnetic (PN4DQ), Blue1 (PNMAE), Red1 (PN4A7), Red2 (PNEAM), Black (PN3KQ), Silver (PN4AG), Orange\n(PN4AH), White (PNYW3), and Blue2 (PN4MAG).\nThe configurator application 104 uses extended feature attributes, or metadata associated with a feature, such as feature name and feature description when presenting the information to a user.  However, the configuration engine 106 uses feature\nand family codes.  A fully qualified feature is its \"family dot feature\" code, such as PAA.PNEAM to represent the paint family with paint color Red2.\nEach point of variation in the product specification can be considered a dimension where a value is selected.  The large number of these variation points on a motor vehicle results in many valid configurations.  Traditionally the large number of\nvalid configurations in this buildable space has been responsible for much computational effort to perform the configuration process, which may be referred to as \"the curse of dimensionality.\" The configuration system 100 provides improvements over\ntraditional systems because it operates efficiently even on highly complex buildable spaces, e.g. those containing more than 10.sup.24 valid configurations.\nA configuration is a particular product instance specified by a set of features.  Each feature belongs to exactly one family.  There may be at most one feature selected from each family.  A complete configuration contains exactly one feature\nfrom each and every family.  A partial configuration will include features from a subset of the families, and one or more families will not have a feature choice specified.\nIn a build and price application, the configuration engine 106 will typically work in complete configurations.  Partial configurations are useful for searching or filtering configurations, as would be done to find and amend orders in an order\nmanagement system.\nSome features are optional, such as moonroof, and a user may order a vehicle without the feature.  But, a complete configuration must still contain a choice for the family.  A \"less feature\" is used to specify the absence of an option.  For\nexample, Vehicle A, which has an optional power moonroof, the family (CHA) contains two features: without the moonroof (i.e., \"less moonroof\"--CHAAA) and with the moonroof (i.e., \"moonroof\"--CHAAC).  The buildable space defines all valid configurations.\nWith reference to FIGS. 3-5, a configuration can be expressed in a variety of different forms.  A configuration can be expressed in conjunctive normal form (CNF).  For example, in one embodiment, a product is defined by four families: A, B, C\nand D; where A, C, and D each have two possible choices, and B has three possible choices.  If there are no restrictions on what features can occur together (other than a single feature choice for each family), the set of choices can be defined as\n(A1|A2) & (B1|B2|B3) & (C1|C2) & (D1|D2).  For a full configuration, each clause will reduce to a single literal or selection for each family (e.g., A1, B1, C1, D1).\nFIG. 3 depicts a CNF Table 300 with two possible configurations.  The CNF table 300 includes a first CNF configuration 302 and a second CNF configuration 304.\nWith reference to FIG. 4, a configuration can also be expressed in binary form by a string of 0's and 1's, as depicted by Table 400.  In binary form, a zero (0) indicates the absence of a feature in a configuration, and a one (1) indicates the\npresence of a feature in the configuration.  For example, a first binary configuration 402 illustrates the first CNF configuration 302 in binary form, and a second binary configuration 404 illustrates the second CNF configuration 304 in binary form.  The\nliteral A2 is replaced with \"01\", as generally referenced by numeral 406.  Each column maps to a feature in the family: `0` in the first position indicates the feature A1 is not present in the first binary configuration 402, and `1` in the second\nposition indicates the feature A2 is present in the first binary configuration 402.  The first CNF configuration 302 (A2 & B2 & C1 & D2) is represented by the first binary configuration 402, where the ampersand (&) symbol is replaced by a space as a\ndelimiter between each family, i.e., \"01 010 10 01.\"\nA configuration space can be very large.  For example, a product definition with around 100 independent features could have over 10.sup.27 possible configurations.  If each configuration was stored as an uncompressed set of 0's and 1's, it would\ntake more than 12 billion Exabytes of memory to represent them all--which is not practical with the present day state of the art computer hardware.  Therefore the configurator application 104 uses compressed representation to facilitate computational\ntractability and efficiency within available memory.\nA bit is the basic unit of information in computing.  It can only have one of two values and is commonly represented as 0 or 1, or the Boolean values of false and true.  A bit set represents a vector or array of bits.  For example, Java has a\nnative utility class called \"BitSet\" that stores a set of bits with an array of values of a primitive 64-bit datatype called long.\nWith the rightmost position of the bit set index 0 and leftmost position index 8, 100101001 is equal to 1*2.sup.8+1*2.sup.5+1*2.sup.3+1*2.degree.=256+32+8+1=297.  Thus the bit set 100101001 can be stored using the long (or integer) 297.  An\narray of 2 long values (-8929791190748339525, 8791258171646) can represent a bit set of 107 features: 11 01 11 010 100 01 10 00010 00010 111 01 010 01 11 000100 000011 00100 00010 00010 11111 1100 01000001 001 01 11 11 11 01 10 11 11 11.\nThe Java BitSet class allows for varying bit set lengths.  But, for the configurator application 104, the set of features is fixed for a given vehicle.  Thus, the configuration engine 106 defines its own fixed length bit set object.  To store a\nconfiguration, a feature bit set is used.  The feature bit set associates a feature object with each bit position.  This mapping is defined in a structure object that defines a list of families with each family defining a list of features.\nFIG. 5 illustrates a table 500 that defines the mappings for the bit sets in table 400.  The bit sets shown in table 400 are printed in blocked format.  The bits for each family are grouped together with no delimiter and family blocks are\nseparated by a space.  The bit sets can also be printed in strict binary format with no extra spacing, e.g., the first binary configuration 402 of Table 400 could be rewritten as 010101001.  Alternatively, the bit sets can be printed in strict binary\nformat with the same delimiter between every feature and no extra delimiter between families, e.g., the first binary configuration 402 of Table 400 could be rewritten as 0 1 0 1 0 1 0 0 1.  Blocked format allows for better human readability; however,\nspace-delimited is a viable option when viewing the data in a table with labeled columns and importing bit set data into an Excel worksheet for analysis.\nWith reference to FIGS. 6-10, one or more configurations may be compressed and represented by a \"superconfiguration.\" FIG. 6 includes a table 600 listing a first configuration 602: (A2, B2, C1, D2), and a second configuration 604: (A1, B2, C1,\nD2).  Because the values are identical in all but one family `A`, the configurations 602, 604 can be compressed into a single superconfiguration 606.  The table 600 shows both the CNF and bit set forms of the configurations and superconfigurations. \nThus, a configuration is just a superconfiguration with only one possible value per family.\nReferring to FIG. 7, two superconfigurations can also be compressed as shown in table 700.  A first superconfiguration 702 and a second superconfiguration 704 are compressed into a third superconfiguration 706.\nWith reference to FIG. 8, bit sets, configurations and superconfigurations can be interacted using bitwise steps as shown in table 800.  Referring to \"OR\" step 802, when OR-ing two superconfigurations the resulting value for each family is the\nunion of the family set from each superconfiguration.  Thus, if any value in a family set (column) is \"1\", then the union of the family set is \"1.\" And referring to \"AND\" step 804, when AND-ing two superconfigurations the resulting value for each family\nis the intersection of the family set from each superconfiguration.  Thus, if all values in a family set (column) are \"1\", then the union of the family set is \"1.\"\nReferring to FIG. 9, when AND-ing two superconfigurations, the resulting superconfiguration is invalid if any family has no active bits, as shown in table 900.  The intersection for family B is empty causing the configuration to be invalid, as\nreferenced by numeral 902.\nWith reference to FIG. 10, the configuration system 100 expresses buildable space with a set of superconfigurations that define all valid configurations, according to one or more embodiments.  This compressed representation allows for more\nefficient storing and processing of a buildable space.  A non-overlapping set of super configurations can be stored in a matrix 1000, with each row stored as a bit set.\nReferring to FIG. 11, the configuration engine 106 does not use overlapping superconfigurations because they include redundant information which could lead to incorrect calculations.  Thus, all basic steps performed by the configuration engine\n106 rely on the fact that the buildable space contains no overlap.  Two superconfigurations are said to overlap if there exists one or more configurations that are defined by both superconfigurations.  Table 1100 shows a first superconfiguration 1102\nthat overlaps with a second superconfiguration 1104.  Row 1106 identifies all of the overlapping features.  For example, both superconfigurations 1102, 1104 include feature A2, as represented by numeral 1108, and therefore overlap.\nWith reference to FIG. 12, a superconfiguration can be used to define a feature mask.  A feature mask for a single family is created by setting the active bits in the family to zero to define the constrained features and setting all bits to 1\nfor the remaining families.  A feature mask for multiple families is the AND of the masks for each family.  Table 1200 shows several examples.  A feature mask can be used to search a configuration space (contains) or limit a configuration space\n(restrict).  Feature masks can be used to encode a feature condition in order to associate data with features, such as descriptions, prices and images.\nReferring to FIG. 13, the configuration system 100 uses a multi-valued decision diagram (MDD) to represent the buildable space, according to one or more embodiments.  An MDD representing the same buildable space as the superconfigurations matrix\n1000 (FIG. 10) is shown in accordance with one or more embodiments, and generally referenced by numeral 1300.  An MDD is capable of representing the configuration space for large and highly complex product offerings much more compactly than a matrix.\nThe MDD 1300 includes nodes, such as a root node (2), a terminal, Truth or True node (T) and a plurality of intervening nodes (3-16) arranged on a plurality of paths.  Each path includes the root node (2), the true node (T) and some of the\nintervening nodes connected by \"edges\" or arrows.  In terms of superconfigurations, a complete path from the root node (2) to the true node (T) defines a superconfiguration.  The superconfiguration shown in the top row 1308 of the matrix 1000 in FIG. 10\n(i.e., 100 100 110 100 10), is defined by a right path (2-3-4-5-6-T) in the MDD 1300.\nEach level of the MDD 1300 is associated with one family and the edges define the path for each feature.  Each node will have at most one outgoing path for each feature, thus the features are mutually exclusive.  Where there is a path between\ntwo nodes for more than one feature, a single edge is shown, but the edge label includes more than one (\"1\").  The edge labels correspond to a family's superconfiguration bits, where a \"1\" indicates the presence of a feature and a \"0\" indicates the\nabsence of a feature.  Where a feature is inactive, its edge points to the false terminal node, which is not shown in the diagram.  Each complete path from the root node to the truth node is of the same length in nodes when the nodes are expanded, e.g.,\nthere are no long edges.  An MDD that does not include any long edges may be referred to as a quasi-reduced MDD.\nThe MDD 1300 includes five different families 1302: package (Pkg), radio (Radio), paint (Paint), trim (Trim) and moonroof (MoonRf).  Each family includes multiple features.  For example, the package (Pkg) family includes a 400 package, a 401\npackage and a 402 package; and the radio family includes: a Standard (Std) radio, a Deluxe (Dlx) radio and a Navigation (Nav) radio.  The root node (2) is connected to intervening node 13 by edge label \"001\", which indicates the presence of the third\npackage (402) and the absence of the first two packages (400 and 401).  Again, some edge labels include more than one \"1\", which means that more than one feature is available.  For example, intervening node (7) is connected to intervening node (8) by an\nedge with a label \"011.\" This indicates that path 2, 7, 8 is a superconfiguration that includes the 401 package, and the Deluxe (Dlx) and/or the Navigation (Nav) radio.\nFIG. 14 is a table 1400 that illustrates a comparison of the size of a matrix based product configuration (e.g., table 1000, FIG. 10) and an MDD based product configuration (e.g., MDD 1300, FIG. 13).  For small product definitions (e.g., Vehicle\nA with 28 families) a matrix and an MDD have comparable size (20 KB).  However, for medium product definitions (e.g., Vehicle B with 84 families) the matrix size (23,026 KB) is much larger than the MDD size (766 KB).  For large product definitions (e.g.,\nVehicle C with 92 families) the matrix runs out of memory, but the MDD size (313 KB) is sufficient.  Therefore table 1400 illustrates that an MDD is a useful tool when analyzing large product configurations.  Using the MDD format, the minimum number of\nsuperconfigurations required to represent the buildable space of all possible configurations may be calculated.  For complex products that number exceeds reasonably available memory.\nWith reference to FIG. 15, the configuration engine 106 performs steps using reduced MDDs, such as reduced MDD 1500, in one or more embodiments.  FIG. 15 includes the MDD 1300 of FIG. 13 and a reduced MDD 1500.  In an MDD, a redundant node may\nbe removed and its incoming and outgoing edges may be combined to form a \"long edge.\" A redundant node is a node that corresponds to a family in which all features are active, i.e., its outgoing edge label includes only \"1\"s. For example, intervening\nnode 16 in MDD 1300 corresponds to the moonroof (MoonRf) family, and its outgoing edge label \"11\" indicates that both the moonroof (Vista) and no moonroof (Less) features are active.  Therefore node 16 is redundant and it can be removed, as depicted by\nthe \"X\" disposed over it in FIG. 15.  Nodes 10 and 12 of MDD 1300 are also redundant and may be removed, as depicted by the X's over them in FIG. 15.  The reduced MDD 1500 shows the result of removing redundant nodes 16, 10 and 12 and collapsing their\nrespective incoming and outgoing edges into long edges.  The paths from 13-T, 9-T, and 10-T do not include a node for the moonroof (MoonRf) family.  By collapsing the long edges, the reduced MDD 1300 has 3 fewer nodes, and some of its nodes have been\nrenumbered.  For example, since node 10 of MDD 1300 was removed, node 11 of MDD 1300 was renumbered as node 10 in reduced MDD 1500.  By reducing MDDs, the configuration system 100 reduces memory and processing usage.\nIn one or more embodiments, the configuration engine 106 performs steps using an expanded (not reduced) MDD, such as MDD 1300, e.g., during a \"Quick-Restrict\" step, as described below.  For a very large buildable space, the number of nodes added\nto expand long edges can be quite significant.  As an example, an MDD may have 17,283 nodes when long edges are compressed, but grow to 47,799 nodes when long edges are expanded.  Therefore good compression reduces the number of long edges significantly. However, the savings generated by the quick-restrict step are generally sufficient to justify the long edge expansion.\nIn the expanded MDD 1300, nodes 10, 12, and 16 are not only redundant; they are also duplicated.  Duplicate nodes are two nodes for a family (i.e., within a common row) that have identical outgoing edge labels.  The reduced MDD 1500 is in\ncanonical form, i.e., there are no duplicated nodes.  The configuration engine 106 creates MDDs in canonical form.  Canonical form helps to minimize the number of nodes required to represent the buildable space.\nFIG. 16 includes a non-canonical MDD 1600 with duplicate nodes.  Node 6 and node 8 include identical outgoing edge labels, and therefore are duplicates of each other, as referenced by numeral 1602.  Similarly, node 5 and node 7 are duplicates,\nas referenced by numeral 1604.  FIG. 16 also includes a canonical MDD 1610.  The duplicate nodes of MDD 1600 are merged in the canonical MDD 1610.  For example, the first duplicate nodes 1602 are merged to form a canonical node 6, as referenced by\nnumeral 1612.  And the second duplicate nodes 1604 are merged to form a canonical node 5, as referenced by numeral 1614.  The MDDs, e.g., MDD 1600, 1610, are serialized as plain text for storage in a database, such as the DB 122 shown in FIG. 2.  Such\ntext serialization ensures backwards compatibility across software versions and implementations.\nWith reference to FIG. 17, when a family's values in the configuration space can be determined by the values from one or more other families, the family is said to be deterministic.  Deterministic relationships are used to minimize the size of\nan MDD to allow for scaling to complex vehicle configurations.\nFIG. 17 includes an MDD 1700 that is similar to the MDD 1300 of FIG. 13, with the addition of two deterministic families: seat temperature control (Temp) and the presence of dice (Dice).  The presence of dice is determined by the paint color. \nThus, once the paint color (Paint) is known, there is just one choice for dice.  If paint is White, then dice are not present (NoDice); however if paint is Red or Blue, then Fuzzy dice are present (FuzzyDice).  The seat temperature control (Temp) is\ndetermined by the package (Pkg).  If Pkg is 400, then the seat temperature control is not available (LessTemp); if Pkg is 401, then heated seat temperature control is included (Heat); and if Pkg is 402, then heat and cool temperature control (HeatCool)\nis included.  In these examples Paint color and Pkg are the determinant families while Dice and Seat temp are deterministic.  This is because their state is fully specified by the state of the determinant.\nThe presence of deterministic features has a negative impact on MDD compression.  The MDD 1700 represents twenty-four configurations.  However, the deterministic families cause the MDD 1700 to increase from sixteen nodes to twenty-four nodes. \nGenerally, the number of nodes in an MDD is a good predictor of its performance.  Thus, it is ideal to have an MDD with as few nodes as possible.  To aid in MDD compression, the configuration system 100 extracts the relationship defining a deterministic\nfamily's values to form one or more external relationship MDDs, which allows for greater compression in the main MDD, i.e., MDD 1700.\nThe configuration system 100 extracts the two deterministic families (Temp and Dice) from MDD 1700 to form reduced an MDD 1702, a first external relationship MDD 1704 corresponding to the Dice family, and a second external relationship MDD 1706\ncorresponding to the Temp family.  The deterministic families (Temp and Dice) remain in the MDD 1702, but are trivialized--made all 1s--allowing the main MDD 1702 and the external relationship MDDs 1704, 1706 to share the same structure.\nThe combination of the main MDD 1702 and all its external relationship MDDs 1704, 1706 is referred to as a Global MDD.  A Global MDD can be operated in the same way as an MDD; but, each step must account for both the main space and the\nrelationships.\nThe configuration service 138 abstracts the implementation from any specific application and state management does not depend on the implementation being either \"stateful\" or \"stateless\", according to one or more embodiments.  The configuration\nservice 138 remembers a user's session history in a stateful implementation, and does not remember a user's session history in a stateless implementation.  However, the front-end application 132 treats the configuration service 138 as stateless in so far\nas it does not need to handle session synchronization.\nEach XML response to the front-end application 132 from the configuration service 138 includes a state object that is included in the next call.  The content of the state object is not dictated by the configuration service 138, but it contains\nany information necessary to maintain a user session.  The state object is not modified by the front-end application 132.\nA configuration session begins with an XML request to load initial content (i.e., a \"Load Request\") to populate a starting point of initial screens on the front-end applications 132.  This is followed by additional XML requests to update the\ncontent (\"Update Request\") as user changes the configuration by selecting different options in the front-end application.  The web service controller 136 responds with an XML configuration response that includes updated configuration content.\nEach feature included in such configuration responses includes a selection or feature state attribute.  In one embodiment, there are six different feature state values: Selected, Available, Included, Default, Excluded and Forbidden.\nA Selected feature state is a feature that has been explicitly selected by the user and generated in response to a Load or Update XML request.  The configuration service 138 cannot unselect this feature as a result of another selection without\nperforming a conflict resolution procedure, except for features in a mutually exclusive feature group.\nAn Available feature state is a feature that is not currently selected by the user.  But the user is free to select it without causing a conflict resolution procedure to be triggered.  In a mutually exclusive group of features (e.g. exterior\ncolor), although only one feature can be selected at a time, the other features in that group will be marked as \"Available\"--they will only be marked as \"Excluded\" if they conflict with a user selected feature in another family.\nAn Included feature state is a feature which is the only available choice in the family.  For example, this can occur when a selection of a feature requires another feature.  This can be the result of either a package selection that includes\nthis feature (e.g. \"Climate Pack\" includes \"Air Conditioning\"), or a \"must\"/\"requires\" relationship (e.g. \"Heated Seats\" requires \"Leather Seats).\nA Default feature state is a feature that was selected by the configuration service 138 as part of an automatic completion function, as described in detail below with reference to FIGS. 82-117.\nAn Excluded feature state is a feature that conflicts with another user selection.  Selecting this feature will prompt a conflict resolution procedure.\nA Forbidden feature state is a feature that violates a constraint that cannot be resolved if selected.  Attempting to select this feature will result in an error.  This state has been introduced to support external constraints that restrict the\nvalid buildable configurations.\nThe front-end application 132 alters the display of features based on their configuration state, in one or more embodiments.  For example, in one embodiment, the front-end application 132 shows a symbol next to an excluded feature to indicate\nthat it conflicts with a prior selection or it may choose not to display excluded or forbidden features.\nIn one embodiment, the configuration system 100 changes a feature from the Default feature state to the Selected feature in response to a user implicitly selecting the feature.  For example, if Default features are presented as checkboxes or\nradio buttons, there is no action the user can take to check an already checked item.  This means that while the user intended to select the feature, it is still marked as Default.  Such an implicitly selected Default feature may complicate conflict\nresolution strategies.  Thus, the configuration system 100 includes an option to change a feature from a Default feature state to the Selected feature state in response to a user viewing a default selection and not changing it.\nThe configuration service 138 will return a complete configuration to the front-end application 132 in response to any load or update request, according to one or more embodiments.  This feature is referred to as \"automatic completion.\" Default\nfeature selections will be added to any Selected features or Included features to create a complete configuration with respect to displayable families.  A feature is \"displayable\" if it can be displayed to the user, e.g. on the user's pc 112; whereas a\nfeature that cannot be displayed to the user is described as \"no-display\" or \"not displayable.\" The front-end application 132 may choose to distinguish the automatic feature selections from those explicitly selected by the user, using each feature's\nstate value returned in the configuration response.\nAlternatively, in other embodiments the automatic completion feature is disabled.  When the automatic completion feature is disabled, no default selections are made and the response will typically include an incomplete configuration.  This\nenables different front-end application 132 designs where a user is prompted to actively select each feature in the configuration.\nThe configurator application 104 includes a conflict resolution procedure in which, in response to an update request to select a feature that leads to an invalid configuration; the configuration service 138 returns a new valid configuration with\nthe newly selected feature and the minimum other changed features required to make the configuration valid.  If the auto completion feature is enabled, the new configuration will include any necessary Default features.  The web service controller 136\nimplements the conflict resolution feature to provide details on what features must be added and removed to resolve the conflict, as well as a \"reject state\" that is used if the user cancels the requested change.\nWith reference to FIG. 18, the configurator application 104 includes a \"single\" conflict resolution strategy, according to one or more embodiments.  The configuration service 138 resolves the conflict by finding a single valid configuration\ncontaining the new selection.  FIG. 18 depicts a user interface 1800 that is displayed to the user on the user device (e.g., on the monitor of the PC 112) by the front-end application 132 as part of the conflict resolution procedure.  The user interface\n1800 includes a message 1802 that alerts the user of a conflict (i.e., by selecting the adaptive cruise control feature, the Zetec package and the solar reflect windscreen features must be removed, and the titanium package must be added) and asks for\nconfirmation that they still want to make the change.  If the user cancels the change, e.g., by selecting the decline button 1804, the subsequent view request includes a reject state to undo the prior selection (i.e., adaptive cruise control) in the\nconfigurator application 104.  The update request may unselect a feature.  Since all families must have one feature selected to form a valid configuration, unselecting a feature is often equivalent to selecting the \"less\" feature in the family.  Removing\na feature from the configuration can also lead to a conflict.  For example, if the user removes an included feature, the selected feature which includes it will also be removed.\nReferring to FIG. 19, the configurator application 104 includes a branched conflict resolution strategy, according to one or more embodiments.  In branched conflict resolution, the configuration service 138 presents the user with a series of\nchoices to help them select from a set of valid configurations.  For example, FIG. 19 depicts a user interface 1900 that is displayed to the user on the user device (e.g., on the monitor of the PC 112) by the front-end application 132.  The user\ninterface 1900 includes a series of choices for a remote starter option (e.g., with or without (less) the remote starter), as referenced by numeral 1902, and a series of choices for the color of the seats (e.g., Charcoal Black or Medium Light Stone), as\nreferenced by numeral 1904.  In one embodiment, the branched conflict resolution strategy may be enabled by setting a return guided resolution flag (not shown), which is included in the communication between the front-end application 132 and the service\nAPI 134.\nWith respect to state management, when a branched conflict resolution is returned in the response to the service API 134, there will be no feature state because the new configuration isn't known until the user traverses the resolution tree,\n(i.e., selects from the options shown in the user interface 1900).  Once selections have been made, the front-end application 132 sends a second update request with all the changes made during resolution.  At this time the response will include the new\nconfiguration state.  Optionally, if there is only one target configuration, the response could include the new configuration state to save one call to the service.\nIn one or more embodiments, the conflict resolution strategy employed by the configurator application 104, may add a feature or subtract a feature, which is referred to as \"return delta\" functionality.  In one or more embodiments, the conflict\nresolution subtractions only contain Selected features removed from the configuration; and conflict resolution additions only contain Included features added to the configuration.  If the new configuration caused a change in a Default feature, this is\nnot included in the prompt to the user (e.g., not shown in the user interfaces 1800, 1900).  If all changes are for default choices, there are no changes to report, and the response will not include conflict resolution.\nAlternatively, in other embodiments, the response will include all additions and subtractions regardless of feature state when the request has set the return delta flag to true.  This allows the front-end application 132 to inspect the\nresolution and apply some additional logic when deciding whether to prompt the user for a conflict or to silently make the changes.\nThe configuration engine 106 \"validates\" each configuration.  A load request from the services API 134 may include a full or partial configuration as a starting point.  When a configuration is submitted to the configuration engine 106 with the\nload request, it is validated.  By default, or when a validate flag is True, conflict resolution will be triggered and the response will include a valid configuration.  However, if the request has set the validate flag to False, conflict resolution is\nnot performed and an error message will be included in the response if the submitted configuration is not valid.\nThe configuration engine 106 performs steps on a buildable space in order to process a configuration request and generate data to build a response.  The configuration engine 106 uses data structures and algorithms, including those based on\nmultivalued decision diagrams (MDD) to perform the configuration steps.  For comparison, some matrix based steps are also described.\nIn many cases the configuration engine 106 uses MDD steps to search the product space in the same way a structured query language (SQL) query searches a database.  Both are preforming relational algebra.  As appropriate, the SQL equivalent of\neach MDD step is described.\nThe configuration engine 106 checks if the buildable space defines a specific full configuration or a partial configuration, which is referred to as a \"contains any\" step.\nIn terms of SQL, this step is equivalent to performing a search and evaluating if there is at least one row in the result set.  For example, consider the partial configuration (Dlx, Vista).  If a database stored each configuration as a separate\nrow, and each family choice as a string column, the SQL query would be SELECT*FROM mdd WHERE Radio=`Dlx` AND Moonrf=`Vista`.\nFor efficient storage, matrix and MDDs represent the product with superconfigurations.  If each row in the database stored a superconfiguration with each feature as a Boolean column, the SQL would be SELECT*FROM mdd WHERE Dlx=TRUE AND\nVista=TRUE.\nFor example, in one embodiment, the configuration engine 106 searches an MDD by stating the query as a feature mask.  For example, to search for the partial configuration (Dlx, Vista) the mask would be 111 010 111 111 01.  The radio family\nincludes the following features: Standard (Std), Deluxe (Dlx) and Navigation (Nav).  Since the search is limited to (Dlx), the only active bit corresponds to Dlx (i.e., 010) for the radio family.  Additionally, the moonroof family includes: without a\nmoonroof (Less) and with a moonroof (Vista).  Since the search is limited to (Vista), the only active bit corresponds to Vista (i.e., 01).  All other families are all 1s.\nWhen the configuration engine 106 is performing a step to check for a partial configuration, one or more families will have all 1s.  This means that the mask defines multiple configurations.  The configuration engine 106 is querying the space to\ndetermine if any of the individual configurations defined in the feature mask superconfiguration are contained in the space.  Thus the step is called \"containsAny.\"\nWith reference to FIGS. 20 and 21, the configuration engine 106 performs an MDD-based \"containsAny\" step using a depth-first search of the space to look for the first valid path defining at least one of the configurations from the mask.  In a\ndepth-first search, the configuration engine 106 starts at the root node, and traverses the edges in descending order of its features; an edge of 011 will be processed by first inspecting 001 and then 010.\nFIG. 20 is an MDD 2000 that illustrates an example of the configuration engine 106 performing an MDD-based \"containsAny\" step for the partial configuration (Dlx, Vista).  To determine if this partial configuration is valid, the configuration\nengine 106 performs a depth-first search using the feature mask 111 010 111 111 01.  The search begins with the path 2-13.  This path is aborted when the Radio feature Dlx is inactive on edge 13-14, as shown by the dashed edge 2002.  Next, the\nconfiguration engine 106 searches path 2-13-8-11-12-T. This path, highlighted by nodes in solid line, ends in True node 2004, indicating a valid path has been found containing the partial configuration (Dlx, Vista).  Note there are three additional paths\ncontaining (Dlx, Vista), 2-13-8-9-10-T, 2-7-8-11-12-T, 2-7-8-9-10-T; but, the configuration engine 106 stops the \"containsAny\" step after the first path is found.\nFIG. 21 is an MDD 2100 that illustrates an example of the configuration engine 106 performing an MDD-based \"containsAny\" step for the partial configuration (Std, Vista).  To determine if this partial configuration is valid, the configuration\nengine 106 performs a depth-first search using the feature mask 111 100 111 111 01.  The search begins with path 2-13 which is aborted because neither edge 13-14, nor 13-8 is active for the standard radio feature (i.e., neither of the edge labels include\na \"1\" in their first digit), as shown by dashed edges 2102.  Next the configuration engine 106 searches path 2-7, which is also aborted because Std is not active, as shown by dashed edges 2104.  Finally, the configuration engine 106 searches path\n2-3-4-5-6 and aborts the search because 6-T is not valid for MoonRf.Vista, as shown by dashed edge 2106.  No paths are found containing both Std and Vista, thus this combination is found to be invalid.\nThe domain of a buildable space defines all the Available features--those features contained in one or more configurations.  The domain can be represented as a bit set where each 1 (active feature) denotes a feature contained in the domain and\neach zero (inactive feature) denotes a feature absent from the domain.  For any active bit in the domain, the space contains one or more configurations with that feature.  If there is an inactive bit in the domain, the space contains no configurations\nwith that feature.  For a matrix, the domain is calculated by the OR of all superconfigurations in the space.  The domain of the space shown in FIG. 10 is 111 111 111 111 11, because every feature is available in at least one configuration.\nWith an MDD, the configuration engine 106 calculates the domain by traversing the MDD in either a breadth-first or a depth-first manner, and using the active features on the edges to define the domain.  In a breadth-first search, the\nconfiguration engine 106 starts with a root node, then explores neighbor nodes first before evaluating the next family.  For example, the configuration engine 106 evaluates the MDD 2100 of FIG. 21 using a breadth-first strategy by starting with the root\nnode 2 and evaluating path 2-13.  Although path 2-13 is valid, the configuration engine evaluates neighbor nodes 7 and 3, i.e., paths: 2-7 and 2-3, before evaluating the next family, i.e., nodes: 14, 8 and 4.  Once a path is determined to be invalid, the\nconfiguration engine 106 stops evaluating nodes farther down the path.  For example, once path 13-14 is found to be invalid, the configuration engine 106 does not continue along the path to evaluate nodes 15 and 16.  And as described above, in a\ndepth-first search, the configuration engine 106 starts at the root node, and traverses the edges in descending order of its features.  In the depth-first search, levels (families) are not back-tracked until an invalid path, or the truth node, is\nencountered.  In the configuration engine 106, the full domain is not usually called, but rather domain is called on a restricted space.  The domain of a restricted space is used in determining feature states.\nThe configuration engine 106 restricts a space by keeping only those configurations containing a specific feature or combination of features.  With respect to a database query, the restrict step is equivalent to searching the table to find only\nthose rows that match the query.  The restricted features define the WHERE clause.  Consider the partial configuration (Nav, Ruby, Vista).  In terms of SQL, the query would be SELECT*FROM mdd WHERE Radio=`Nav` AND Trim=`Ruby` AND MoonRf=`Vista`.  In\nterms of superconfigurations, the step begins with creating a feature mask defining the query.  This is the same feature mask that would be used for a containsAny step.  For restrict, a space is created with the feature mask as its only\nsuperconfiguration.  Then, the restricted space is created by the AND of the original space with the feature combination space.\nFIGS. 22 and 23 show restrictions of the space defined in FIGS. 10 and 13.  In the table 1000 shown in FIG. 10, the last two rows of superconfigurations contain the radio feature (Nav), the trim feature (Ruby) and both moonroof features (Vista\nand Less), which indicates that Nav and Ruby are available with the moonroof (Vista) or without the moonroof (Less).  FIG. 22 is a table 2200 that depicts a restricted version of table 1000, in which the five superconfigurations of table 1000 are\nrestricted to two superconfigurations, and the Moonrf.Less bit is set to zero to remove the configurations for (Nav and Ruby and MoonRf.Less).  FIG. 23 is a restricted MDD 2300 illustrating the restricted superconfigurations of table 2200.\nFor some algorithms, successive restricts will be performed on the same space.  When an MDD is restricted, a new set of nodes is created and the edges are updated for the nodes to keep only the constrained features.  When many restrict\noperations are performed, many node objects must be created as the MDD is replicated.  For large MDDs, this can cause the memory usage or \"footprint\" to increase, and may also incur performance problems from \"garbage collection\", i.e., reclaiming memory\noccupied by objects that are no longer in use by the program.  The configuration engine 106 addresses these issues using a \"quick-restrict\" strategy.\nWith reference to FIG. 24, a method for evaluating an MDD using reversible restrictions (i.e., \"quick-restrict\") is illustrated in accordance with one or more embodiments and generally referenced by S100.  The quick-restrict method S100 is\nimplemented as an algorithm within the configuration engine 106 using software code contained within the server 102, according to one or more embodiments.  In other embodiments the software code is shared between the server 102 and the user devices 112,\n114.  FIG. 25 illustrates an original MDD 2500, and an MDD 2502 after it is \"quick-restricted\" to the partial configuration (Nav, Ruby, Vista) by the configuration engine 106 according to the quick-restrict method S100 of FIG. 24.\nAt S102, the configuration engine 106 saves a copy of the root node identity and a set of the node edges to the memory 108 (shown in FIG. 2).  The subroutine of S102 is shown in the flowchart of FIG. 26.  At step S104 the configuration engine\nidentifies each node (y).  Then at step S106 the configuration engine copies or clones each outgoing edge of the node (y), and returns to step S104 until each node (y) in the MDD 2500 is copied.  Then at step S108, the configuration engine 106 returns\nthe edge set and the identity of the root node to the main routine of FIG. 24.\nAt step S110, the configuration engine 106 performs the quick-restrict subroutine for the given selected features.  The subroutine of step S110 is shown in the flowchart of FIG. 27.  At step S112 the configuration engine 106 examines the cache\nmemory for source (SRC) node (y) to determine if the quick-restrict subroutine has already been performed on node (y), (i.e., does cache(y) exist?) If cache(y) exists, then the configuration engine 106 proceeds to step S114 and returns to the main\nroutine.  If cache(y) does not exist, the configuration engine 106 proceeds to step S116.\nAt step S116, the configuration engine 106 starts with array index zero, and sets the empty flag to true.  By setting the empty flag to true, the configuration engine 106 assumes that there are no valid paths from the node, i.e., that all edges\npoint to the false node.  At step S118, the configuration engine 106 evaluates the array index (z) to determine if (z) is less than the number of node (y)'s children.  A positive determination at step S118 indicates that the configuration engine 106 has\nnot analyzed all array indexes of node (y).  If the determination is positive, the configuration engine 106 proceeds to step S120.\nAt step S120, the configuration engine 106 checks if y's child, or destination (DST) node, at array index (z) is false.  If the configuration engine 106 determines that the child is false, then it proceeds to step S122, increments the array\nindex (z) by one, and returns to step S118.  With reference to FIG. 25, the MDD 2500 does not show false nodes, but they are still present.  For example, node 9 shows only one outgoing edge with the label \"001.\" This indicates that array indexes zero and\none are both false, but they are not shown extending to the false node on the MDD 2500 to avoid clutter.  When analyzing node 9, the configuration engine 106 makes a positive determination at S120 for array indexes zero and one, but makes a negative\ndetermination for array index two.  If the determination at step S120 is negative, the configuration engine 106 proceeds to step S124.\nAt step S124, the configuration engine 106 evaluates the quick-restricted features list for node (y) to determine if it contains feature (z).  Otherwise, the configuration engine 106 sets y's child node along z to false at S126 and then proceeds\nto step S122 to increment the array index(z) by one.\nAt step S128, the configuration engine 106 check's if y's child (DST) at array index (z) is true.  For example, with reference to MDD 2500, node 16 connects to the true node (T) along array indexes zero and one.  If the configuration engine 106\ndetermines that the child node is the true node, then it proceeds to step S130 and sets the empty flag to false (empty=false), which indicates that there is at least one edge that is connected to the true node (T), and then proceeds to step S122.  If the\ndetermination at step S128 is negative, the configuration engine proceeds to step S132.\nFor example, referring to MDD 2500, node 3 is illustrated with one outgoing edge with the label \"100\", which indicates that node 3 includes the Standard radio, but does not include the Deluxe radio or the Navigation radio.  Since the Navigation\nradio was selected by the user, the configuration engine 106 determines that none of node 3's outgoing edges contain (z)'s corresponding feature.  Therefore the configuration engine 106 sets node 3's children to false at S126, which is illustrated by\ndisconnecting the outgoing edge to node 4 (as shown in MDD 2502) and the edge label for path 3-4 is replaced with an edge label of \"000.\" However, referring to MDD 2500, node 7 includes two array indexes (011), which indicate that node 7 includes the\nDeluxe radio and the Navigation radio.  Since the Navigation radio was selected by the user, the configuration engine 106 determines that one of node 7's outgoing edges contain (z)'s corresponding feature at S124, therefore the outgoing edge is not\ndisconnected from node 8 (as shown in MDD 2502) and the edge label for path 7-8 is replaced with an edge label of \"001\".\nAs shown in MDD 2502, the configuration engine 106 removes the edge pointer for path 13-8 because Navigation is not an active feature for the Radio family (i.e., there was not a \"1\" in the third digit of the edge label); and removes the edge\npointer for path 15-16 because Ruby is not an active feature for the Trim family at S126.  Since only Vista is constrained for the moonroof family; the configuration engine 106 modifies the edge labels for paths 10-T and 12-T from \"11\" to \"01\".  If the\ndetermination at step S128 is negative, the configuration engine 106 proceeds to step S132.\nAt step S132, y's children, or (DST) nodes, are rewritten by the result of recursive invocation of the quick-restrict method on the child.  All nodes of the MDD are processed in this manner.\nAt step S134, the configuration engine 106 checks y's child at array index (z) to determine if it's not a false node.  If the determination is positive (e.g., if node (y) is connected to a valid node), then the configuration engine 106 proceeds\nto step S136 and sets the empty flag to false, before incrementing the array index (z) at S122.  However, if node (y) is connected to the false node along array index (z) then the configuration engine 106 proceeds directly to S122 to increment the array\nindex (z).\nThe quick restrict method S110 operates on the nodes in a depth first search fashion.  Steps S118-S136 demonstrate an iterative process that operates on each array index (z) of a node (y) before proceeding to the next node.  Once the\nconfiguration engine 106 has evaluated all array indexes (z) for a node (y), it will make a negative determination at step S118 (i.e., z will be greater than or equal to the number of y's children), and proceeds to step S138.\nAt step S138 the configuration engine 106 checks if all children (DST) of node (y) are false, i.e., it evaluates the empty flag to determine if any valid configurations were found.  If all of y's children are false, the configuration engine 106\nproceeds to step S140, sets node (y) to the false node, set cache(y) to y, and then returns the cache(y), i.e., saves the analysis of node (y) and returns to the main routine of FIG. 24.  Further, if the node does not contain any edges that conform to\nthe constraint, then the edge pointer is disconnected from the child node in the MDD.  If not all of the children nodes are false, then the configuration engine 106 proceeds to step S142, sets the cache(y) to (y), and then returns the cache(y), i.e.,\nsaves the analysis of node (y) and returns to the main routine of FIG. 24.\nFor example, referring to FIG. 25, the configuration engine 106 determines that node 3's features do not contain the Selected radio feature (Nav) at S124, and therefore sets node 3's child (node 4) to false at S126.  Setting node 4 to false is\nrepresented by disconnecting the edge pointer between node 3 and node 4 in MDD 2502.  The configuration engine 106 determined that all of node 3's children were set to false at S138, and therefore set node 3 to false at S140.  Setting node 3 to false is\nrepresented by disconnecting the incoming edge pointer to node 3 in the MDD 2502.\nSimilarly, the configuration engine 106 disconnects the incoming edge pointer to node 15 at S140, because all of node 15's children were set to false at S126, which is depicted by the disconnected outgoing edge pointer of node 15 in MDD 2502. \nAlthough the edge label for path 7-8 was revised at S126, the edge pointer was not disconnected.  Therefore the configuration engine 106 determines that not all of node's 7 children are false at S138, and proceeds to S142 without setting node 7 to false\nor disconnecting its incoming edge pointer in the MDD 2502.\nThe quick-restrict subroutine S110 is a recursive process.  This process continues until all nodes are analyzed.  The edges for complete paths from the root node (node 2) to the truth node (T) define the restricted configuration space.\nAt step S144 the configuration engine 106 performs additional steps on the restricted MDD 2502.  In one embodiment, after completing a traversal of the MDD in a first direction (e.g., downward), the configuration engine 106 determines the domain\nfor a restricted space by traversing the MDD again in the same direction (i.e., the configuration engine repeats S110 for all nodes).\nIn another embodiment, the configuration engine 106 determines the domain at the same time as traversing the MDD in the first direction (i.e., during S110).  Then at step S144, the configuration engine 106 changes direction (i.e., reverses) and\ntraverses the MDD in a second direction, e.g., upwards from the truth node (T) to the root node (2).  On the downward traversal, the configuration engine 106 trims the edges to conform to the constraint.  On the upward traversal, the domain bit set is\ncreated from the remaining edges.  Combining quick-restrict and domain in a single operation saves one traversal of the MDD.  However, the operation modifies the MDD and the edges must be reset to undo the quick-restrict.\nAt S146, the configuration engine 106 restores the original set of node edges to the memory 108 (shown in FIG. 2).  The subroutine of S146 is shown in the flowchart of FIG. 28.  At S148 the configuration engine identifies each node (y).  Then at\nstep S150 the configuration engine 106 copies each outgoing edge of the node (y), and returns to step S148 until each node (y) in the MDD 2500 is copied.  Then at step S152, the configuration engine 106 sets the MDD to the identity of the root node and\nreturns to the main routine of FIG. 24.\nAt step S154 the configuration engine 106 determines if the user has selected different features.  If the user has selected new features, the configuration engine 106 returns to S110.  If the user has not selected new features, then the\nconfiguration engine 106 proceeds to step S156 and deletes the copy of each node from S102 to free memory.\nAs shown in MDD 2502, paths 9-10-T and 11-12-T are duplicate paths, because they include the same features.  As described above with reference to FIGS. 22-23, the restrict operation will reuse nodes to avoid duplicate nodes or sub-paths. \nAlthough, the quick-restricted MDD 2502 may contain more nodes than the restricted MDD 2300, the configuration spaces defined by each are identical.\nThe quick-restrict method S100 provides advantages over existing methods by performing successive restricts without creating a new MDD for every step.  The configuration engine 106 saves the original edge pointers at S102 and then quickly resets\nthe MDD 2500 using the original edge pointers.\nThere are some cases, where a more efficient algorithm can perform the same operation without having to do the quick-restrict method, eliminating the time needed to reset the edge pointers.  This time savings, while small, can be significant\nwhen working with extremely large configuration spaces.  A \"Restricted Domain\" algorithm is one such algorithm.\nIn other embodiments, the configuration engine 106 determines a read-only restricted domain using an external set of edges (not shown).  Instead of modifying the original MDD node edges the external edges are modified to reflect the restricted\nspace.  The configuration engine 106 restricts on the downward traversal and then updates the domain on the upward traversal.  Such a method is a read-only, thread-safe operation, because the MDD is not modified.\nThe quick-restrict with domain operation method S100 is slightly slower than this read-only approach for the same calculation; however, the time saved in the read-only operation is due to not having to reset the edges.  FIG. 29 is a table 2900\nillustrating a comparison of the performance of the quick-restrict with domain operation method S100 to the read-only method.  The larger and more complex the buildable space, the more nodes in the MDD, and the more time it requires to reset the edges\nafter the quick-restrict method S100.\nWith reference to FIGS. 30-32, the configuration engine 106 performs a \"project\" operation of an MDD to trim a space to a subset of the families while keeping all unique configurations, according to one or more embodiments.  In terms of SQL, the\nprojection operation is equivalent to specifying which columns of a table are returned in the query.  To project the space to the package (Pkg) and the trim (Trim) families, the equivalent SQL would be: SELECT DISTINCT Pkg and Trim FROM mdd.\nSelecting distinct configurations means that the resulting space should contain no duplicated configurations.  During the MDD project operation, the configuration engine 106 removes any duplicated configurations (also called overlapping\nsuperconfigurations).\nFIG. 30 is a table 3000 that shows the result of the configuration engine 106 reducing the buildable space in FIG. 10 to keep only the columns for the package and trim families.  This space contains duplicate configurations.  For example a\nconfiguration including the 401 package and Ruby trim is defined in Row 3 and in Row 4.  Likewise a configuration including the 402 package and Ruby trim is defined in Row 3 and in Row 5.  Therefore Row 4 and Row 5 are duplicates of Row 3 and can be\nremoved.  Further, Row 2 and Row 3 can be compressed to a single row.  FIG. 31 is a table 3100 that shows the projected space after the overlap (duplicated configurations) has been removed and the space has been compressed.  FIG. 32 is an MDD 3200 that\nrepresents table 3000.\nWith reference to FIG. 33, the configuration engine 106 lists, or enumerates all valid configurations that are utilized in conjunction with a constraint restricting the families to a subset of all families, according to one or more embodiments. \nGiven a subset of families, enumeration will return all valid combinations of the features in those families.  In terms of superconfigurations, enumeration is the opposite of compression.\nThe configuration engine 106 works with individual features which are added or removed from a current single configuration.  While this suits the requirements of most ordering and build and price applications, in some cases, the configuration\nengine 106 enumerates the valid combinations of those features without working through all the possible paths.\nThe total number of possible permutations of features in a configuration model can be very large, so this configuration service is restricted to enumerating a reasonable subset of feature families.  The configuration engine 106 can impose limits\non the number of families that can be enumerated, however, it should be expected that a request resulting in more products than can be stored in a storage medium will not succeed.\nFIG. 33 is a table 3300 that shows all valid combinations of paint and trim defined in FIG. 13.  The configuration engine 106 generates this list by first projecting the space to paint and trim.  Next the configuration engine 106 traverses the\nMDD paths and expands each superconfiguration into individual configurations.\nThe configuration engine 106 determines if a new configuration is valid, in response to every configuration request.  Where auto-completion is enabled, the configuration request will contain a full configuration, otherwise it will be a partial\nconfiguration.  In either case, the configuration engine 106 validates the configuration request using the MDD \"containsAny\" operation.  A configuration is valid if the containsAny operation returns true.\nEach feature included in the configuration response will have a feature state attribute, e.g. Selected, Available, Included, Default, Excluded or Forbidden.  For a given set of selected features, the configuration engine 106 calculates the\nfeature states for the remaining features.\nThere are multiple approaches for calculating feature states.  In one embodiment, the configuration engine 106 calculates feature states using a basic algorithm that includes restricted domain steps which can be applied to both Matrices and\nMDDs.  In another embodiment, the configuration engine 106 calculates feature states for MDDs using dynamic programming techniques.\nWith reference to FIG. 34, a method for determining feature states using a restricted domain is illustrated in accordance with one or more embodiments and generally referenced by S200.  The method S200 is implemented as an algorithm within the\nconfiguration engine 106 using software code contained within the server 102, according to one or more embodiments.  In other embodiments the software code is shared between the server 102 and the user devices 112, 114.\nFirst the configuration engine 106 identifies Forbidden features and Excluded features.  At step S202 the configuration engine 106 determines the restricted domain with respect to any initial locked features imposed on the user.  For example,\nthe initial restriction can be timing point feature(s) which are features used to control the effectivity and visibility of configurations.  For example, a new feature (e.g., new engine x) may be available only after the start of a new model year.  Thus\nthe first day of the new model year would be such a visible timing point.  At step S204, the configuration engine 106 identifies features that are absent from the restricted domain, and classifies them as Forbidden features at S206.  At step S208, the\nconfiguration engine 106 classifies any feature that is not Forbidden, as an Excluded feature unless it is assigned another feature state (i.e., Available, Included or Default) in the remaining steps of the algorithm.\nAt step S210, the configuration engine 106 first determines the restricted domain of all selections to identify an initial set of Available features.  Then, for each selection F.sub.j, the configuration engine 106 checks the restricted domain\n(selected--F.sub.j) to identify Available features for Family j.\nFor example, FIG. 35 is a table 3500 illustrating a set of superconfigurations that define all valid configurations.  FIG. 36 is a table 3600 that depicts the restricted domains used to determine the Available features and the Excluded features\nwhen the Selected features are Red paint and Ruby trim.  A bit value of zero in table 3600 indicates that a feature is not Available, whereas a bit value of one indicates that the feature is Available.\nFirst, the configuration engine 106 determines the restricted domain of all selections to identify an initial set of Available features at S210.  For example, Red paint and Ruby trim are both available for the configurations listed in rows 3-5\nof the table 3500.  Packages 401 and 402 are Available, but package 400 is not Available for the configuration listed in rows 3-5, as referenced by numeral 3502.  Therefore the restricted domain for the package family is \"011\", as referenced by numeral\n3602, which indicates that package 400 is not Available (i.e., \"0\"), and package 401 and 402 are Available (i.e., \"11\").  Any feature that is active in this domain is set as active in the availability bit set.  Thus, the configuration engine 106\nidentifies package 401 and package 402 as being Available features, as referenced by numeral 3604, and these features are set as active (\"1\") in the availability bit set, as referenced by numeral 3606.\nNext, the configuration engine 106 evaluates the restricted domain (selected--Ruby) to identify Available features for the trim family.  To evaluate (selected--Ruby), the configuration evaluates configurations in which Red paint is Available. \nFor example, Red paint is Available for the configurations listed in rows 1 and 3-5 of the table 3500.  Stone trim and Ruby trim are Available for the configurations listed in rows 1, and 3-5; but Charcoal trim is not Available, as referenced by numeral\n3508.  Therefore the restricted domain for the trim family is \"101\", as referenced by numeral 3608.  The availability bit set for the trim family is revised to \"101\" based on this step, as referenced by numeral 3610.\nThen, the configuration engine 106 evaluates the restricted domain (selected--Red) to identify Available features for the paint family.  To evaluate (selected--Red), the configuration evaluates configurations in which Ruby trim is Available. \nFor example, Ruby trim is Available for the configurations listed in rows 3-5 of the table 3500.  Red paint and Blue paint are Available for the configurations listed in rows 3-5, but White paint is not Available, as referenced by numeral 3512. \nTherefore the restricted domain for the trim family is \"011\", as referenced by numeral 3612.  The availability bit set for the paint family is revised to \"011\" based on this step, as referenced by numeral 3614.\nAs shown in the availability bit set of table 3600, the restricted domain for Red paint includes both Stone trim and Ruby trim.  Both of these selections are Available without having to change the Red paint selection.  The selection of Ruby trim\nexcludes White paint, and shows that both Red and Blue paint are Available.  Thus White paint would require the trim selection to be changed to something other than Ruby.\nThe resulting availability can be defined as bit set 011 011 011 101 11.  The state of Red paint and Ruby trim will be Selected, all other active features will be Available and the inactive features, such as White paint and Charcoal trim, will\nbe Excluded.\nReferring back to FIG. 34, the configuration engine 106 identifies any Included features at step S212.  A feature is Included if there is only one Available feature for a non-Selected feature family.  The non-Selected feature families listed in\ntable 3600 are packaging (Pkg), radio (Radio) and moonroof (MoonRf).  All of these feature families include more than one Available feature (i.e., each family includes more than one \"1\" in each cell).  Thus, table 3600 shows no such Included features for\na selection of Red paint and Ruby trim.\nFIG. 37 is a table 3700 that depicts the restricted domains used to determine the Available features and the Excluded features when the Selected features are the 401 package (Pkg.401) and Red paint (Paint.Red).  An Included feature can be the\nresult of the interactions between multiple features.  For example, table 3700 shows that if the 401 package and Red paint are Selected, then Ruby trim is an Included feature, as referenced by numeral 3720, because it is the only possible trim choice\nthat is compatible with the 401 package and Red paint.\nThus, the configuration engine 106 determines the feature states e.g. Selected, Available, Included, Excluded and Forbidden for a given set of selections using the method S200.  This initial feature state determination is referred to as \"Minimum\nCompletion.\" FIG. 38 is a table 3800 that summarizes the results of the Minimum Completion determination when Red paint and Ruby trim have been selected from the product definition in FIG. 35.\nThe configuration engine 106 determines the restricted domain by traversing the MDD.  Performing the Minimum Completion operation using restricted domain means that for each additional selection, another restricted domain operation is performed. Thus, for N selections, N+2 restricted domain determinations are performed.  These restricted domain operations include an initial restriction at S202, a restriction for the initial available set, followed by one for each feature at S210.\nFor MDDs, there is an alternate approach for determining the Available features using dynamic programming principles with a single operation that includes one downward traversal and one upward traversal of the MDD.  This approach is more memory\nefficient and faster, especially for larger MDDs.\nWith reference to FIG. 39, a method for determining feature states using dynamic programming is illustrated in accordance with one or more embodiments and generally referenced by S300.  The method S300 is implemented as an algorithm within the\nconfiguration engine 106 using software code contained within the server 102, according to one or more embodiments.  In other embodiments the software code is shared between the server 102 and the user devices 112, 114.\nAt S302, the configuration engine 106 organizes the data into nodes by family and level.  The subroutine of S302 is shown in the flowchart of FIG. 40.  At step S304, the configuration engine 106 determines if a level node object exists, i.e., if\nthe nodes are already organized by level.  Otherwise, the configuration engine 106 proceeds to step S306 and organizes the nodes into a level node array where the length of the array is equal to the number of families.  The configuration engine 106\ninitializes each level array with an empty nodes list, i.e., sets the empty flag to true.  At step S308, for each node (y) analyzed, the configuration engine 106 appends a node (e.g., adds a child node) to the analyzed node's level node list.  Step S308\nis a recursive step, therefore the configuration engine 106 repeats S308 until it finds the True node.  After step S308 the configuration engine 106 proceeds to step S310 and returns to the main routine of FIG. 39 to analyze the nodes by level.\nFIG. 45 is an MDD 4500 illustrating the data organized by level according to S302 and a selection of Red paint and Ruby trim.  The MDD 400 includes five levels.  Level zero represents the package (Pkg) family, which includes three package\nfeatures: 400, 401 and 402 that are depicted by edges (level arrays) 001, 010 and 100, respectively, that extend from node 2.  Level one represents the Radio family, which includes three radio features: Std, Dlx and Nav that are depicted by edges (level\narrays) 001, 010 and 100, respectively, that extend from nodes 3-5.  Level two represents the Paint family, which includes three paint features: White, Red and Blue, that are depicted by edges (level arrays) 001, 010 and 100, respectively, that extend\nfrom nodes 6-8.  Level three represents the trim family, which includes three trim features: Stone, Charcoal and Ruby, that are depicted by edges (level arrays) 001, 010 and 100, respectively, that extend from nodes 9-12.  Level four represents the\nmoonroof (MoonRf) family, which includes two moonroof features: Less and Vista, that are depicted by edges (level arrays) 01 and 10, respectively, that extend from nodes 13-16.  Node 1 is the true node and node 0 is the false node (not shown).\nAt step S312, the configuration engine 106 initializes the state, or marking of each node, by creating a place for each value.  For example, by default, all features are initially set to false (i.e., not marked) except the root node 2 and the\ntrue node 1.  The root node 2 is set to true for the downward traversal (i.e., marked with a downward arrow); and the true node 1 is set to true for the upward traversal (i.e., marked with an upward arrow).  Marking a node with a downward arrow indicates\na valid partial configuration from the root node 2 down to the marked node and any intervening downward marked nodes along the path.  Similarly, marking a node with an upward arrow indicates a valid partial configuration from the true node 1 up to the\nmarked node and any intervening upward marked nodes along the path.\nAt S314, the configuration engine 106 creates a constraint object.  The subroutine of S314 is shown in the flowchart of FIG. 41.  The configuration engine 106 starts analyzing family level zero of the MDD 4500 (i.e., the package family) at step\nS316.  At step S318, the configuration engine 106 determines if the family level (x) is less than the total number of families included in the MDD.  If so, the configuration engine 106 proceeds to step S320.\nAt step S320 the configuration engine 106 determines if the user has selected a feature for family level (x).  If the user has selected a feature for family level (x), the configuration engine 106 proceeds to step S322 and sets the Selected\nfeature to the Allowed feature state and sets the non-selected features for family level (x) to not allowed.  If no features are selected for family level (x), the configuration engine 106 proceeds to step S324 and sets all features to the Allowed\nfeature state.  After steps S322 and S324, the configuration engine 106 proceeds to step S326 to evaluate the next family by incrementing family level (x) by one (i.e. x=x+1), then returns to step S318.\nOnce the configuration engine 106 has created a full constraint object using subroutine S314, the family level (x) will no longer be less than the total number of families, and the configuration engine 106 will make a negative determination at\nstep S318.  For example, after the configuration engine 106 evaluates the moonroof family (level 4), it will set x to five at step S326.  Since there are five families in the MDD 4500, the configuration engine 106 will determine that x (5) is not less\nthan the number of families (5) at step S318 and then proceed to step S328 and then return to the main routine of FIG. 39.\nAt step S330 the configuration engine 106 initializes an availability bit set.  The configuration engine 106 initializes the availability bit set by setting all bits to zero, which indicates that the features are Excluded.  Whereas a bit set\nvalue of one indicates that a feature is Available.\nAt S332, the configuration engine 106 traverses the MDD 4500 in a downward direction.  The subroutine of S332 is shown in the flowchart of FIG. 42.  The configuration engine 106 starts analyzing the nodes included in family level zero of the MDD\n4500 (i.e., the package family) at step S334.  At step S336, the configuration engine 106 determines if the family level (x) is less than the total number of families included in the MDD.  If so, the configuration engine 106 proceeds to step S338.\nAt step S338, the configuration engine 106 starts analyzing node zero.  At step S340 the configuration engine 106 compares the node number (y) to the number of nodes at the current level (x) to determine if y&lt;Level (x) number of nodes.  For\nexample, initially, x is equal to zero and Level (0) has one node, therefore y is less than 1.  If y is not less than the number of nodes at level (x), the configuration engine proceeds to step S342 and increments the level (x) by one.\nAfter a positive determination at step S340, the configuration engine 106 proceeds to step S344 and sets the currently analyzed node or source node (SRC) to level(x) node (y); and sets the array index (z) extending from SRC to zero.  The array\nindex (z) corresponds to a feature of the family (x).  At step S346 the configuration engine 106 compares the array index (z) to the SRC's number of children.  If z is not less than SRC's number of children, the configuration engine 106 proceeds to step\nS348 and increments the node (y) by one.  If the determination at step S346 is positive, the configuration engine 106 proceeds to step S350.\nAt step S350, the configuration engine 106 sets the destination node (DST) to be the child node of node (y) along array index (z) (DST=SRC.child(z)).  The configuration engine 106 analyzes three conditions to determine whether or not to mark the\ndestination node with a downward arrow:\n1) the destination node is not a false node;\n2) the source node was previously marked with a downward arrow; and\n3) the feature of array index (z) is allowed by constraint.\nThese three conditions are illustrated by steps S352-S358 in FIG. 42.\nAt step S352, the configuration engine 106 evaluates the DST node to determine if it is a false node.  Otherwise, the configuration engine 106 proceeds to step S354 to determine if the source node (i.e., the parent of the currently analyzed\ndestination node) was previously marked with a downward arrow.\nAfter a positive determination at S354, the configuration engine 106 determines if the feature of array index (z) is allowed by constraint at step S356, which was previously determined in steps S320-S324 (FIG. 41).  If the conditions of steps\nS352, S354 and S356 are met, the configuration engine 106 proceeds to step S358 and marks the destination node with a downward marker, by setting mark.down(DST) to true.  If any of the conditions of steps S352, S354 and S356 are not met, the\nconfiguration engine 106 proceeds to step S360 and increments the array index (z) by one.\nReferring to FIG. 45, the MDD 4500 illustrates the marked nodes after the downward traversal subroutine S332 of FIG. 42 for a selection of Red paint and Ruby trim.  The configuration engine 106 marks Node 2 with a downward marker at S312 because\nthe root node is a special case that always has a valid downward path.  On the downward traversal of the MDD 4500, a node is marked at S358 if the conditions of steps S352-S356 are met for the analyzed node.  For example, the configuration engine 106\nmarks destination node 3 with a downward marker or arrow 4502 at S356 because node 3 was determined to not be a false node at S352; node 3's source node (node 2) was previously marked with a downward arrow at S354; and the feature of the array index\nconnecting node 2 and node 3 (i.e., Pkg.400) was determined to be allowed by constraint at S356.  Since the user has not selected a packaging feature for this example, all packaging features are set to Allowed (see steps S320, S324 of FIG. 45.)\nSimilarly, the configuration engine 106 determines that the remaining radio nodes and the paint family nodes (nodes 4, 5, 6, 7, and 8) have valid downward markers because the package (Pkg) family and the Radio family are not constrained.  With respect to\nthe partial configurations of Pkg and Radio, all features are Available because the user has not selected a feature from either family.\nRegarding the trim level nodes (9-12), nodes 9 and 10 have downward markers because they were determined to not be false nodes at S352; their source nodes were marked with a downward arrow at S354; and they were determined to be on a valid path\nwith Red paint at S356.  However, nodes 11 and 12 do not have downward markers because they are not on a valid path with Red paint.  Since the user has selected Red paint, the non-selected paint features (White and Blue) are set to not allowed at step\nS322 (FIG. 41) and thus the condition of step S356 is not met for nodes 11 and 12.\nRegarding the moonroof level nodes (13-16), node 14 has a downward marker because it is valid with Ruby trim; however node 13 does not have a downward marker because it is not on a valid path with Ruby trim.  Since the user has selected Ruby\ntrim, the non-selected trim features (Stone and Charcoal) are set to not allowed at step S322 (FIG. 41) and thus the condition of step S356 is not met.  Additionally, nodes 15 and 16 are not marked because their source nodes (11 and 12) were not marked,\nand thus nodes 15 and 16 do not satisfy the condition of step S354.\nThe downward traversal subroutine S332 includes three for-loops.  Once the configuration engine 106 has analyzed all paths it will make a negative determination at step S336, i.e., the level (x) will not be less than the number of families; and\nthe configuration engine 106 will proceed to step S362 and return to the main routine of FIG. 39.\nAt S364, the configuration engine 106 traverses the MDD of FIG. 45 in an upward direction, which is illustrated by MDD 4600 in FIG. 46.  The subroutine of S364 is shown in the flowchart of FIG. 43.  The configuration engine 106 starts analyzing\nthe nodes included in the last family level of the MDD 4600 (i.e., the moonroof family) at step S366.  At step S368, the configuration engine 106 determines if the family level (x) is greater than or equal to zero (i.e., not negative).  If so, the\nconfiguration engine 106 proceeds to step S370.\nAt step S370, the configuration engine 106 starts analyzing node zero.  At step S372 the configuration engine 106 compares the node number (y) to the number of nodes at the current level (x) to determine if y&lt;Level (x) number of nodes.  For\nexample, initially, x is equal to zero and Level (0) has one node, and therefore y is less than 1.  If y is not less than the number of nodes at level (x), the configuration engine proceeds to step S374 and decreases the level (x) by one.\nAfter a positive determination at step S372, the configuration engine 106 proceeds to step S376 and sets the currently analyzed node or source node (SRC) to Level(x)(y); and sets the array index (z) extending from SRC to zero.  At step S378 the\nconfiguration engine 106 compares the array index (z) to the SRC's number of children.  If z is not less than SRC's number of children, the configuration engine 106 proceeds to step S380 and increments the node (y) by one.  If the determination at step\nS378 is positive, the configuration engine 106 proceeds to step S382.\nAt step S382, the configuration engine 106 sets the destination node (DST) to be the child node of node (y) along array index (z) (DST=SRC.child(z)).  The configuration engine 106 analyzes three conditions to determine whether or not to mark the\ndestination node with an upward arrow:\n1) the destination node is not a false node;\n2) the destination node was previously marked with an upward arrow; and\n3) the feature of array index (z) is allowed by constraint.\nThese three conditions are illustrated by steps S384-S388 in FIG. 43.\nAt step S384, the configuration engine 106 evaluates the DST node to determine if it is a false node.  Otherwise, the configuration engine 106 proceeds to step S386 to determine if the destination node (i.e., the child of the currently analyzed\nsource node) was previously marked with an upward arrow.\nAfter a positive determination at S386, the configuration engine 106 determines if the feature of array index (z) is allowed by constraint at step S388, which was previously determined in steps S320-S324 (FIG. 41).  If the conditions of steps\nS384, S386 and S388 are met, the configuration engine 106 proceeds to step S390 and marks the source node with an upward marker, by setting mark.up(SRC) to true.\nAt steps S392 and S394, the configuration engine 106 identifies Available features.  The configuration engine 106 evaluates the source node to determine if it was previously marked with a downward arrow at S392; and if so it proceeds to step\nS394 and sets the feature (z) of node (y) to Available.  Thus, Available features are identified by inspecting each node on the upward traversal.  If there is a valid downward path to the node, and a valid upward path from one of its destinations, the\nconfiguration engine 106 identifies this node as part of a valid path with respect to selections from other families.  Any feature that is on the edge from the node to the destination is identified as Available, because it can be selected without\nrequiring a change to the constrained features.  If any of the conditions of steps S384-S388 and S392 are not met, the configuration engine 106 proceeds to step S396 and increments the array index (z) by one.\nOnce the configuration engine 106 has analyzed all paths it will make a negative determination at step S368, i.e., the level (x) will not be greater than or equal to zero; and the configuration engine 106 will proceed to step S398 and return to\nthe main routine of FIG. 39.\nReferring to FIG. 39, after determining the availability of all features at S364, the configuration engine 106 proceeds to step S400 to determine the feature states.  The subroutine of S400 is shown in the flowchart of FIG. 44.  The\nconfiguration engine 106 starts analyzing the features included in family level zero of the MDD 4600 (e.g., the package family) at step S402.  At step S404, the configuration engine 106 determines if the family level (x) is less than the total number of\nfamilies included in the MDD.  If so, the configuration engine 106 proceeds to step S406.  At step S406, the configuration engine 106 starts analyzing node zero.  At step S408 the configuration engine 106 compares the node number (y) to the number of\nfeatures at the current family level (x) to determine if y&lt;family (x) number of features.\nAfter a positive determination at step S408, the configuration engine 106 proceeds to step S410 and sets the currently analyzed feature (FEAT) to Family(x).Feature(y).  At step S412, the configuration engine 106 evaluates all of the features of\na family, one at a time, to determine if a feature is selected.  If a feature (FEAT) is selected, the configuration engine 106 sets the state of the feature to Selected at S414.  If the feature is not selected, the configuration engine 106 proceeds to\nS416 to determine if the feature was set to Available at S394.  If the feature is Available, the configuration engine 106 proceeds to operation S418 and sets the state of the feature to Available.  If the feature is not Selected and not Available, the\nconfiguration engine 106 sets its state to Excluded at S420.  After steps S414, S418 and S420 the configuration engine 106 proceeds to step S422 to increment the analyzed feature (y) by one.  After evaluating each feature of family (x) to determine if it\nis Available, Selected or Excluded, the configuration engine 106 will make a negative determination at S408 and then proceed to step S424.\nAt steps S424-S428 the configuration engine 106 determines if family (x) has Included features.  First the configuration engine 106 determines if family (x) has any Selected features at S424.  Otherwise, the configuration determines if the\nfamily has exactly one Available feature at S426.  If only one feature of a given family is Available, then the sole Available feature is set to Included at S428.  After steps S424, S426 and S428 the configuration engine proceeds to step S430 and\nincrements the family level (x) by one, then repeats steps S404-S428 for the next family level.  Once the configuration engine 106 has determined the feature states for all families of the MDD, it makes a negative determination at S404 and then returns\nto the main routine at S432.\nJust as the restricted domain method S200 can be performed as a read only step, the dynamic programming method S300 is also read-only and thread safe when the downward and upward markers are kept externally.  Because feature state calculation\noperation is thread safe, multiple configuration requests could be handled simultaneously using the same MDD.  Each request has its own copy of external downward and upward markers, and shares the MDD.  Thread safety is a property that allows code to run\nin multi-threaded environments by re-establishing some of the correspondences between the actual flow of control and the text of the program, by means of synchronization.  For N selections, the restricted domain calculation requires N+2 MDD traversals. \nAn advantage of the dynamic programming method S300 over the restricted domain method S200 is that only two MDD traversals are required regardless of the number of selections.  This provides the dynamic programming method S300 with superior scalability\nfor large and complex MDDs.\nReferring to FIG. 46, the MDD 4600 illustrates the marked nodes after the configuration engine 106 has performed the dynamic programming method S300 including the downward traversal subroutine of FIG. 42 and the upward traversal subroutine of\nFIG. 43 for a selection of Red paint and Ruby trim.  The configuration engine 106 marks the truth node (T) with an upward marker at S312 because the truth node is a special case that always has a valid upward path.\nOn the upward traversal of the MDD 4600, a node is marked at S390 if the conditions of steps S384-S388 are met for the analyzed node.  Regarding the moonroof level of nodes, the configuration engine 106 marks node 13 with a upward marker or\narrow at S390 because its destination node (truth node) was determined to not be a false node at S384; node 13's destination node (truth node) was previously marked with an upward arrow at S386; and the feature of the array index connecting node 13 and\nthe truth node (i.e., MoonRf.Less) was determined to be allowed by constraint at S388.  Since the user has not selected a moonroof feature for this example, all moonroof features are set to Allowed (see steps S320, S324 of FIG. 41.) Similarly, the\nconfiguration engine 106 determines that the remaining moonroof level nodes (nodes 14, 15 and 16) have valid upward markers.\nThe configuration engine 106 determines the availability of the moonroof family features by evaluating the downward markers on the source moonroof nodes at S392 after evaluating the upward markers on the destination truth node (T) at S386. \nSince all of the moonroof nodes (13-16) were marked with a downward arrow and the truth node was marked with an upward arrow, the configuration engine 106 sets all of the moonroof features to Available at S394 and determines the initial availability bit\nset to be 000 000 000 000 11.\nRegarding the trim level nodes (9-12), the configuration engine 106 marks node 10 with a upward marker or arrow at S390 because its destination node (node 14) was determined to not be a false node at S384; node 10's destination node (node 14)\nwas previously marked with an upward arrow at S386; and the feature of the array index connecting node 10 and node 14 (i.e., Trim.Ruby) was determined to be allowed by constraint at S388, because it was selected by the user at S322.  Similarly, the\nconfiguration engine 106 marks node 11 with an upward marker or arrow at S390.  However, the configuration engine 106 does not mark nodes 9 and 12 with an upward arrow at S390 because they are not on a valid path with Ruby trim.  Since the user has\nselected Ruby trim, the non-selected trim features (Stone and Charcoal) are set to not allowed at step S322 (FIG. 41) and thus the condition of step S388 is not met for nodes 9 and 12.\nThe configuration engine 106 determines the availability of the trim family features by evaluating the downward markers on the source trim nodes S392, after evaluating the upward markers on the destination moonroof nodes (13-16) at S386.  Trim\nnodes 9 and 10 each have a downward marker and a destination with a valid upward marker (i.e., moonroof nodes 13 and 14).  Therefore Ruby trim along path 10-14 and Stone trim along path 9-13 are marked as Available features at S394 because either can be\non a path (in a configuration) with Red paint.  However, trim nodes 11 and 12 do not have a downward marker and therefore are not marked as Available.  The Trim selection can change from Ruby to Stone without requiring a change to the paint selection\n(Red).  However, the Trim selection cannot change from Ruby to Charcoal without requiring a change to the paint (Red).  Therefore the configuration engine 106 determines the Charcoal trim to be Excluded at S420.  The configuration engine 106 determines\nthe updated availability bit set to be 000 000 000 101 11.\nRegarding the paint level nodes (6-8), the configuration engine 106 marks node 7 with an upward marker because its destination node (10) was determined to not be the false node at S384; its destination node (10) was previously marked with an\nupward arrow (S386); and the features of the array indexes connecting node 7 and node 10 (i.e., Paint.Red) were determined to be allowed by constraint at S388 because it was selected by the user at S322.  Similarly, the configuration engine 106 marks\nnode 8 with an upward marker or arrow at S390.  However, the configuration engine 106 does not mark node 6 with an upward arrow at S390 because its destination node (9) was not marked with an upward arrow, and thus node 9 does not satisfy the condition\nof step S386.\nThe configuration engine 106 determines the availability of the paint family features by evaluating the downward markers on the source paint nodes (6-8) at S392, and by evaluating the upward markers on the destination trim level nodes (9-12) at\nS386.  Paint nodes 7 and 8 each have a downward marker and a destination with a valid upward marker (i.e., trim nodes 10 and 11).  Therefore Red paint along path 8-10 and path 7-10, and Blue paint along path 7-11 are marked as Available features at S394. White paint along path 6-9 is not marked as an Available feature at S394, because node 9 was not marked with an upward marker at S386.  Since Red paint and Blue paint are both Available, the paint selection can be changed between Red and Blue, without\nrequiring a change to the trim selection (Ruby).  The configuration engine 106 determines the updated availability bit set to be 000 000 011 101 11.\nWith respect to the partial configurations of the package and radio families, all features are allowed at S324 because the user has not selected a feature from either family.  Therefore nodes 2, 4 and 5 are marked with an upward arrow.  But node\n3 is not marked with an upward marker at S390 because its destination node (6) was not marked with an upward arrow, and thus node 3 does not satisfy the condition of step S386.\nThe configuration engine 106 determines the availability of the radio family by evaluating the downward markers on the source radio nodes (3-5) at S392, and by evaluating the upward markers on the destination paint nodes (6-8) at S386.  Radio\nnodes 4 and 5 each have a downward marker and a destination with a valid upward marker (i.e., paint nodes 7 and 8).  Therefore Navigation radio along path 5-8 and path 4-7, and Deluxe radio along path 5-7 and path 4-7 are marked as Available features at\nS394.  The Standard radio along path 3-6 is not marked as an Available feature at S394, because node 6 was not marked with an upward marker at S386.  Since the Navigation radio and the Deluxe radio are both Available, the radio selection can be changed\nbetween Navigation and Deluxe, without requiring a change to the paint selection (Red) or the trim selection (Ruby).  The configuration engine 106 determines the updated availability bit set to be 000 011 011 101 11.\nThe configuration engine 106 determines the availability of the package family by evaluating the downward markers on the source package node (2) at S392, and by evaluating the upward markers on the destination radio nodes (3-5) at S386.  The\npackage node 2 has a downward marker and destinations with valid upward markers (i.e., radio nodes 4 and 5).  Therefore the 401 package along path 2-4 and the 402 package along path 2-5 are marked as Available features at S394.  The 400 package along\npath 2-3 is not marked as an Available feature at S394, because node 3 was not marked with an upward marker at S386.  Since the 401 package and the 402 package are both Available, the package selection can be changed between 401 and 402, without\nrequiring a change to the paint selection (Red) or the trim selection (Ruby).  The configuration engine 106 determines the full availability bit set to be 011 011 011 101 11 using the dynamic programming method S300, which is consistent with its\ndetermination using the restricted domain method S200 as described above with reference to FIG. 34 and shown in FIG. 36.\nEach time the user selects a feature, the configuration engine 106 updates the configuration by adding the new feature and removing the sibling features of the same family.  Then the configuration engine 106 performs a \"containsAny\" operation,\nas described above with reference to FIGS. 20-21, to see if the MDD contains the new configuration.  If the MDD does not contain the new configuration, then the new configuration is invalid and the configuration engine 106 performs a conflict resolution\nstrategy.\nGenerally, there are two types of conflict resolution strategies invoked when a user selection, or change in selection, leads to a conflict: single conflict resolution and branched conflict resolution.\nIn single conflict resolution, the configuration engine 106 returns the single \"next-closest\" valid configuration and the feature additions and subtractions necessary to change the invalid configuration to a valid configuration in its response. \nThe \"closest\" valid configuration would typically be determined by simply changing the newly requested feature back to its prior state.  However, such a change would be inconsistent with the user's selection.  Therefore the configuration engine 106\ndetermines the next-closest valid configuration using a constraint that the newly requested feature is \"locked\" and not allowed to be changed, according to one or more embodiments.\nIn branched conflict resolution, the configuration engine 106 presents a set of configurations to the user in a resolution tree that are closest to the invalid configuration, and the user is prompted to make changes to the configuration to get\nto a valid configuration.  When resolving conflicts there may be multiple valid configurations all at the same distance from the initial configuration.  In this case there are a set of possible answers when finding the next-closest valid configuration. \nAn option then is to use branched conflict resolution.\nA strategy that is used to determine the closeness between configurations is referred to as the \"minimum edit distance.\" In a configurator application 104, the configuration engine 106 determines the minimum edit distance between an invalid\nconfiguration selected by the user and one or more valid configurations.  The minimum edit distance refers to the number of features in the configuration that must be changed in order to transform the invalid configuration into a valid configuration. \nWhen comparing the invalid configuration to a valid configuration, the configuration engine 106 considers substitute operations to identify what features must change to create a valid configuration without changing the newly requested locked feature.\nWith reference to FIG. 47, a method for resolving conflicts between a user selected invalid configuration and one or more valid configurations is illustrated in accordance with one or more embodiments and generally referenced by S500.  The\nmethod S500 is implemented as an algorithm within the configuration engine 106 using software code contained within the server 102, according to one or more embodiments.  In other embodiments the software code is shared between the server 102 and the\nuser devices 112, 114.\nAt step S502, the configuration engine 106 saves a copy of the root node identity and a set of the node edges to the memory 108 (shown in FIG. 2).  S502 is similar to subroutine S102 described above with reference to FIG. 26.  The configuration\nengine identifies each node (y), copies or clones each outgoing edge of each node (y) in an MDD, and then returns the edge set and the identity of the root node.\nAt step S504 the configuration engine 106 performs a minimum edit calculation of an MDD that is restricted to the configurations that contain the feature selection that triggered the conflict.  In one embodiment the configuration engine 106\nrestricts the MDD using the restrict method as described above with reference to FIGS. 22-23.  In other embodiments, the configuration engine 106 restricts the MDD using the quick-restrict method S100 described above with reference to FIGS. 24-28.  The\nquick-restrict based minimum edit calculation subroutine of S504 is shown in the flowchart of FIG. 48.\nAt step S506 the configuration engine 106 examines the cache memory for source (SRC) node (y) to determine if the quick-restrict subroutine has already been performed on node (y).  If cache (y) exists, then the configuration engine 106 proceeds\nto step S508 and returns to the main routine of FIG. 47.  If cache (y) does not exist, the configuration engine 106 proceeds to step S510.\nAt step S510, the configuration engine 106 starts with array index zero, and sets the empty flag to true.  By setting the empty flag to true, the configuration engine 106 assumes that there are no valid paths from the node, i.e., that all edges\npoint to the false node.  The configuration engine 106 also sets the minimum or best (Best) edit distance as the maximum allowable integer value (Integer Max Value).\nAt step S512, the configuration engine 106 evaluates the array index (z) to determine if (z) is less than the number of node (y)'s children.  A positive determination at step S512 indicates that the configuration engine 106 has not analyzed all\narray indexes of node (y).  If the determination is positive, the configuration engine 106 proceeds to step S514.\nAt step S514, the configuration engine 106 checks if y's child, or destination (DST) node, at array index (z) is false.  If the configuration engine 106 determines that the child is false, then it proceeds to step S516, increments the array\nindex (z) by one, and returns to step S512.  If the determination at step S514 is negative, the configuration engine 106 proceeds to step S518.\nAt step S518 the configuration engine 106 initializes the edits for feature (z) to the maximum integer value, e.g., by setting the total edit distance (cacheBot (z)) for the path from the truth node to the source node to the Integer Max Value.\nAt step S520, the configuration engine 106 evaluates the quick-restricted features list for node (y) to determine if it contains feature (z).  Otherwise, the configuration engine 106 sets y's child node along z to false at S522 and then proceeds\nto step S516 to increment the array index (z) by one.\nAt step S524, the configuration engine 106 sets the edit value (EDIT) for the source node at feature (z).  If the configuration includes feature (z), then the configuration engine sets EDIT to zero.  If the configuration does not include feature\n(z), then the configuration engine sets EDIT to one.\nAt step S528, the configuration engine 106 check's if y's child (DST) at array index (z) is true.  If DST is true, the configuration engine 106 proceeds to step S530 and sets the empty flag to false.  At S532, the configuration engine 106\ncalculates and stores the edit distance or cost (EDIT) for this feature.  Then the configuration engine 106 calculates the total edit distance (cacheBot (z)) for the path from the truth node to the source node, as the sum of a previously calculated edit\ndistance for the path (cacheMid (DST)) and EDIT.  At step S534, the configuration engine 106 compares the total edit distance (cacheBot(z)) to the minimum edit distance (Best) for the given invalid configuration.  If the total edit distance for the\ncurrent feature (cacheBot (z)) is less than Best, the configuration engine 106 proceeds to step S536 and sets cacheBot (z) as Best.  Then the configuration engine 106 proceeds to step S516 and increments feature (z) by one.  If the configuration engine\n106 determines that DST is not the true node at S528, it proceeds to step S538.\nAt step S538, y's children, or (DST) nodes, are rewritten by the result of recursive invocation of the quick-restrict method on the child.  All nodes of the MDD are processed in this manner.  At step S540, the configuration engine 106 checks DST\nto determine if it's not a false node.  If the determination is negative, i.e., DST is the false node, then the configuration engine 106 proceeds directly to S516 to increment the array index (z).  If the determination is positive (e.g., if node (y) is\nconnected to a valid node), then the configuration engine 106 proceeds to steps S530-S536 to update the EDIT distance and compare it to the Best minimum edit distance.\nThe quick restrict based minimum edit calculation subroutine S504 operates on the nodes in a depth first search fashion.  Steps S512-S540 demonstrate an iterative process that operates on each array index (z) of a node (y) before proceeding to\nthe next node.  Once the configuration engine 106 has evaluated all array indexes (z) for a node (y), it will make a negative determination at step S512 (i.e., z will be greater than or equal to the number of y's children), and proceeds to step S542.\nAt step S542 the configuration engine 106 checks if all children (DST) of node (y) are false, i.e., it evaluates the empty flag to determine if any valid configurations were found.  If all of y's children are false, the configuration engine 106\nproceeds to step S544, sets node (y) to the false node, and then returns the cache (y), i.e., saves the analysis of node (y) and returns to the main routine of FIG. 47.  Further, if the node does not contain any edges that conform to the constraint, then\nthe edge pointer is disconnected from the child node in the MDD.  If not all of the children nodes are false, then the configuration engine 106 proceeds to step S546, sets the cacheMid (SRC Node) to Best, and then sets feature (z) to zero.\nAt step S548, the configuration engine 106 again evaluates the array index (z) to determine if (z) is less than the number of node (y)'s children.  Otherwise, the configuration engine 106 proceeds to step S550, sets the cache (y) to (y), and\nthen returns the cache (y), i.e., saves the analysis of node (y) and returns to the main routine of FIG. 47.  A positive determination at step S548 indicates that the configuration engine 106 has not analyzed all array indexes of node (y).  If the\ndetermination is positive, the configuration engine 106 proceeds to step S552.\nAt step S552, the configuration engine 106 compares the total edit distance (cacheBot (z)) to the minimum edit distance (Best) for the given invalid configuration.  If the total edit distance for the current feature (cacheBot (z)) is greater\nthan Best, the configuration engine 106 proceeds to step S554 and sets DST node to false at step S554, and then increments feature (z) by one at step S556 and then returns to S548.\nThe quick-restrict based minimum edit calculation subroutine S504 is a recursive process.  This process continues until all nodes are analyzed, then the configuration engine 106 returns to the main routine of FIG. 47.  The edges for complete\npaths from the root node (node 2) to the truth node (T) define the restricted configuration space.\nThus, the configuration engine 106 calculates the minimum edit distance of all paths, and identifies the minimum edit distance using subroutine S504.  The configuration engine 106 calculates the minimum edit distance on the way back up the MDD,\ni.e., during an upward traversal.  When a new minimum edit distance is found, prior minimum edit paths are trimmed from the MDD by setting the minimum edit distance (Best) to the currently analyzed path (cacheBot (z)) at S536.  The minimum edit distance\nof a path refers to the sum of the edit distances of each edge.  The edit distance for each feature change is 1.  Where there is more than one active feature on an edge, the path for each feature is considered separately when calculating the minimum edit\ndistance.  Then the configuration engine 106 restricts the MDD to the paths that have the minimum edit distance by setting child or destination (DST) nodes to false if the edit distance for their path (cacheBot (z)) is greater than the minimum edit\ndistance (Best) at S554.\nFIG. 49 includes an original or unrestricted MDD 4900, an intermediate MDD 4902 and a final restricted MDD 4904 illustrating the impact of various steps of subroutine S504.\nIn one example, the user selects the 400 package.  Then the configuration engine 106 determines that the Standard (Std) radio, Stone trim and no moonroof (Less) are Included features; and that White paint is a Default feature.  The states of\nthese features are represented by underlined text, boxed text and circled text, respectively in FIG. 49.  Next the user selects Charcoal trim.  The new selected set (400, Charcoal) is not a valid combination because the 400 package can only occur with\nStone trim.  So the new configuration (400, Std, White, Charcoal, Less) is invalid.\nThe intermediate MDD 4902 illustrates the original MDD 4900 after the configuration engine 106 has performed the minimum edit calculation S504 on paths 2-13- .  . . T with respect to a newly selected Charcoal trim feature.  The configuration\nengine 106 first traverses path 2-13-14-15-16-T. No restrict is needed on the downward traversal because the only active trim feature on partial path 15-16 is Charcoal.\nThe configuration engine 106 calculates the minimum edit distance at steps S530-S536 (FIG. 48) during an upward traversal of the MDD.  The configuration engine 106 considers two edges for the partial path T-16: one edge with the moonroof (Vista)\nand one edge without the moonroof (Less).  The configuration engine 106 determines the edit distance for the partial path T-Vista-16 (i.e., with the moonroof (Vista)) to be one because it requires a change in the moonroof feature.  For the partial path\nT-Less-16 without the moonroof (Less), no change is required, so the edit distance is zero.  Because one path (T-Less-16) has a smaller edit distance than the other (T-Vista-16), the edge is restricted to keep the minimum edit path of T-Less-16.  The\nedge from 16-T now shows \"10\", and the edit cost for Node 16 is 0, as referenced by numeral 4906.\nContinuing on the upward traversal, the configuration engine 106 calculates the edit distance of the remaining partial paths to be: zero for 16-15, because it contains Charcoal trim; one for 15-14, because it contains Blue paint, not the Default\nWhite paint; one for 14-13, because it contains the Navigation radio, not the Included Standard radio; and one for 2-13, because it contains the 402 package, not the Selected 400 package.  Therefore the configuration engine 106 calculates the cumulative\nminimum edit distance for path 2-13-14-15-16-T to be three, as referenced by numeral 4908.\nThen the configuration engine 106 restricts the partial path 14-9-10-T because node 9 does not contain the selected Charcoal trim feature.\nNext, the configuration engine 106 considers path 2-13-8-11-12-T. First, partial path 8-11-12-T is considered, and found to have edit distance of 1 because node 8 contains Blue paint and not the Default White paint.  Then the configuration\nengine 106 restricts path 12-T to 12-Less-T; and restricts path 11-12 to 11-Charcoal-12 so that the edit distance for each is zero.\nThen the configuration engine 106 considers partial path 8-9-10-T; but, because of its previous analysis of node 9, it knows that this partial path has been restricted and the 8-9 edge is removed.  The cost of T-12-11-8-13 is 2.  At this point\nthe configuration engine 106 keeps both of the outgoing edges from 13 (i.e., 13-14 .  . . -T, and 13-8- .  . . -T) because they each require 2 edits.  The edit distance for partial path 13-2 is 1.  Thus, after traversing 2-13- .  . . -T, the\nconfiguration engine 106 determines that the current minimum edit distance for Node 2 is 3.\nThe final restricted MDD 4904 illustrates the original MDD 4900 after the configuration engine 106 has quick-restricted it to Charcoal trim at S504 and performed the minimum edit calculation for all paths.\nNext the configuration engine 106 considers path 2-7-8-11-12-T. The configuration engine 106 previously determined that the minimum edit distance at node 8 is 1.  The configuration engine 106 calculates the edit distance for partial path 8-7 to\nbe one because it contains Deluxe and Navigation radio features and not the Included Standard radio feature; and calculates the edit distance for partial path 7-2 to be one, because it contains the 401 package and not the selected 400 package.  The\nconfiguration engine 106 calculates the total edit distance for path 2-7-8-11-12-T to be three.  Since this total edit distance is the same as that of paths 2-13- .  . . -T, the configuration engine 106 keeps all three paths.\nNext the configuration engine 106 considers path 2-3-4-5-6-T. This path is restricted once the configuration engine 106 determines that partial path 5-6 is not compatible with the Selected Charcoal trim constraint.\nThe final MDD 4904 illustrates the final minimum edit space for the invalid configuration (400, Std, White, Charcoal, Less) with the Charcoal trim feature locked, after the configuration engine 106 has completed the minimum edit calculation\nsubroutine S504.  As shown in FIG. 49, the MDD 4904 contains three paths that each have a minimum edit distance of three: 2-1-14-15-16-T; 2-13-8-11-12; and 2-7-8-11-12-T.\nWith reference to FIG. 47, at step S558, the configuration engine 106 determines if the conflict resolution strategy selected for the application is a guided strategy, i.e., a branched resolution strategy.  If a guided conflict resolution is not\nselected, the configuration engine 106 proceeds to operation S560.  At step S560 the configuration engine 106 selects a single target configuration from the minimum edit space using an auto-completion technique such as sequence based or maximally\nstandard.  In one embodiment, the configuration engine 106 selects a single target configuration using a maximally standard auto-completion technique as described below with reference to FIGS. 93-117.  In another embodiment, the configuration engine 106\nselects a single target configuration using a maximum weight quick-restrict technique.\nThe maximum weight quick-restrict based single target configuration calculation subroutine of S560 is shown in the flowchart of FIG. 50.  The weights used in the weight calculation are based on priorities for features such that when there is\nmore than one feature available, the highest priority, or feature having the maximum weight, is chosen as the default.  S560 is similar to the minimum edit quick restrict calculation S504 of FIG. 48.  The only difference is that when the configuration\nengine 106 calculates the maximum weight, it 1) maximizes value instead of minimizing value (which changes the initial value of Best); and 2) calculates the weight for each path instead of the number of edits, where the weight is defined by a priority of\nthe features.\nReferring to FIG. 47, the configuration engine 106 resets or restores the original set of node edges to the memory 108 (shown in FIG. 2) at step S574.  S574 is similar to S146 described above with reference to FIG. 28.  At S574 the configuration\nengine 106 identifies each node (y), copies the outgoing edges of each node in the MDD.  Then the configuration engine 106 sets the MDD to the identity of the root node.\nAt step S576, the configuration engine 106 determines the feature states for the prior configuration.  The prior configuration refers to the prior valid configuration before the configuration engine 106 changed a feature based on a user\nselection; where the addition of the new feature led to an invalid configuration.  S576 is similar to subroutine S300 described above with reference to FIGS. 39-44.  At step S578, the configuration engine 106 determines the feature states for the new\ntarget configuration.  S578 is also similar to S300.\nWith reference to FIG. 49, in one embodiment the configuration engine 106 selects a single target configuration (401, Dlx, Blue, Charcoal, Less) from the minimum edit space of MDD 4904 as S560.  Once the target is identified, the configuration\nengine 106 determines feature states for the prior configuration at S576 and for the new target configuration at S578.  All features start as Default features.  Next, Selected features are determined by adding the previous selections that are still valid\nto the newly selected feature.  Then, the Available, Excluded and Available calculations are determined using the new selections.  In this example the new target configuration states are: Selected (Charcoal), Included (Blue) and Default (401, Dlx, Less).\nAt step S580 of FIG. 47, the configuration engine 106 generates a response that includes the feature additions and subtractions to resolve the conflict.  These features include feature state information--the new state for additions and the prior\nstate for subtractions.  The configuration engine 106 returns raw data including the new and prior feature state maps, the new configuration state (ConfigState), and the list of additions and subtractions.  The author decorator 154 will use this data to\ncompose the response.  The derivation of additions and subtractions subroutine S580 is shown in the flowchart of FIG. 51.\nAt S582, the configuration engine 106 starts analyzing feature (z).  At step S584, the configuration engine 106 determines if the feature (z) is less than the total number of features for the source node.  If so, the configuration engine 106\nproceeds to step S586.  At step S586, the configuration engine 106 defines the term \"Prior\" as the prior feature state of feature (z) and the term \"State\" as the new feature state of feature (z).\nAt step S588, the configuration engine 106 evaluates the feature state term Prior (determined at S576) to determine if feature (z) was present in the prior configuration.  S588 is illustrated in the flow chart of FIG. 52.  If the Prior term is\nequal to Selected, Included or Default, then the configuration engine 106 determines that the Prior term defines a State of a feature that is present in the Prior configuration and returns true at step S592.  Otherwise, the configuration engine 106\nreturns false at S594.  Then the configuration engine 106 sets a boolean before value (BEF) equal to the determination at steps S590-S592, i.e., true or false.\nAlso at step S588, the configuration engine 106 evaluates the feature state term State to determine if it is present in the New configuration.  If the State term is equal to Selected, Included or Default, then the configuration engine 106\nreturns TRUE at step S592.  Otherwise, the configuration engine 106 returns false at S594.  Then the configuration engine 106 sets a boolean after value (AFT) equal to the determination at steps S590-S592, i.e., true or false.\nAt step S594, the configuration engine 106 compares BEF to AFT for feature (z) to see if it has changed.  Otherwise, i.e. if BEF equals AFT, the configuration engine 106 proceeds to step S596 and increments the family level (x) by one.  If the\ndetermination is negative, then the feature was either added or subtracted, and the configuration engine 106 proceeds to step S598 to evaluate \"Return Delta.\"\n\"Return Delta\" refers to the amount of information provided to the user in response to a conflict.  The front-end application 132 determines this level of information by setting the return delta feature to true or false.  Enabling the return\ndelta feature (i.e., setting return delta to true) results in more information being provided to the user.  Conversely, setting return delta to false results in less information being provided to the user.\nWhen the Return Delta flag is set to true, the response will include all additions and subtractions regardless of feature state.  This could allow the front-end application 132 to inspect the resolution and apply some additional logic when\ndeciding whether to prompt the user in response to a conflict or to silently make the changes.  When the Return Delta flag is set to false, the conflict resolution subtractions will only contain Selected features removed from the configuration and\nadditions will only contain Included features added to the configuration.  If the new configuration caused a change in a Default feature, this is not included in the prompt to the user.  If all changes are for Default choices, there are no changes to\nreport, and the response will not include conflict resolution.  The Return Delta flag is set to false by default, in one or more embodiments.\nAt S598, if Return Delta is set to true, the configuration engine 106 proceeds to step S600 to evaluate BEF.  If BEF is set to false at S588 (which indicates that feature (z) was contained in AFT but not in BEF), the configuration engine 106\nadds feature (z) to the list of additions (additions.add(feat(x))) at step S602.  If BEF is set to true (which indicates that feature (z) was contained in AFT but not in BEF), the configuration engine 106 adds feature (z) to the list of subtractions\n(subtractions.add(feat(x))) at step S604.\nIf Return Delta is set to false, the configuration engine 106 proceeds to step S606.  At S606, the configuration engine 106 evaluates BEF and the state of (z).  If BEF is false and the state of (z) is Default, the configuration engine 106\nreturns to S596 to increment the family level (x) by one.  If the determination at S606 is negative, the configuration engine 106 proceeds to step S608.  At S608, if BEF is true and the state of (z) is Selected, the configuration engine 106 returns to\nS596.  Otherwise, the configuration engine 106 returns to S600.\nFIG. 53 is a table 5300 that illustrates the additions and subtractions for the MDD 4900 of FIG. 49 when Return Delta is true and when Return Delta is false.  The MDD 4900 had a Prior configuration of Selected (400), Included (Std, Stone, Less)\nand Default (White), as referenced by numeral 5302.  The configuration engine 106 selected a new target configuration of Selected (Charcoal), Included (Blue) and Default (401, Dlx, Less) at step S578, as referenced by numeral 5304.  When Return Delta is\nfalse, the configuration engine 106 does not show changes (additions or subtractions) to Default Features, but when return delta is true, all changes are shown, as referenced by numeral 5306.\nFIG. 54 is a window 5400 that is displayed to the user to convey the additions and subtractions of features to their prior configuration to accommodate the new configuration triggered by their selection of Charcoal trim, using a single target\nconfiguration when Return Delta is false.  Again, when Return Delta is false, the configuration engine 106 does not show changes (additions or subtractions) to Default features.\nFIG. 55 is a window 5500 that is displayed to the user to convey the additions and subtractions of features to their prior configuration when Return Delta is true.  Since Return Delta is true, the configuration engine 106 shows all changes,\nincluding changes to the Default features.\nReferring to FIG. 47, the configuration engine 106 determines if guided resolution (i.e., branched conflict resolution) is selected at step S558.  If so, it proceeds to step S610.\nIn contrast to single conflict resolution, which only presents a single next-closest configuration to the user, branched conflict resolution can present the entire minimum edit space to the user, in tree format.  This allows the front-end\napplication 132 to present the user with a series of prompts to drive towards a valid configuration.\nIn the minimum edit example described above with reference to FIGS. 49 and 53-55, the minimum edit space contains three superconfigurations defining four configurations.  This space can be compressed to two superconfigurations as shown in FIG.\n56.\nFIG. 56 is a table 5600 that illustrates an example in which the paint family has just one choice (Blue) and the package and radio families each have two choices (401, 402 and Dlx, Nav), but, the choices are not dependent one each other.  The\nchoice of package (401 or 402) does not change the choice of radio (Dlx, Nav).  When all the family choices are independent, the configuration engine 106 can resolve the conflicts in a single step.\nThe configuration engine 106 derives a resolution object that describes the actions to change the invalid configuration to a valid configuration, which is transformed by the author decorators 154 into a SOAP xml response (not shown) which can be\npresented to a user in a single pop up window 5700, as shown in FIG. 57.\nThis example illustrates the advantages offered by branched conflict resolution, as compared to single conflict resolution.  The configuration engine 106 presents the user with more information about how to resolve a conflict and asks them to\nchoose the valid package and radio features, rather than the application silently selecting a valid configuration.\nWhen there are no dependent choices, it is a relatively simple process to transform the target matrix into the conflict resolution response.  However, the resolution object is more complicated when one family's choice is dependent on another\nfamily.\nThe configuration engine 106 makes a series of prompts or inquiries to the user when the guided choices are dependent on a prior choice.  However, each prompt can include more than one independent choice.  When there is a nested or dependent\nchoice, the configuration engine 106 lists the divergent branch as the last feature group in the list.\nIn branched conflict resolution, the minimum edit space may include some partial matches, where a choice is present in some, but not all of the target configurations.  Partial matches in the configuration space can cause the target space to be\ntoo large, and it can lead to awkward user prompts.  In one or more embodiments, the configuration engine 106 trims the minimum edit space to remove partial matches.\nWith reference to FIG. 47, at step S610, the configuration engine 106 determines if removing partial matches functionality is enabled.  If the determination at S610 is positive, the configuration engine 106 proceeds to S612.  The algorithm for\nremoving partial matches S612 is shown in the flowchart of FIG. 58.\nWith reference to FIG. 58, at step S614 the configuration engine 106 creates a weight object, with positive weights for features that are contained within the configuration, and zero weight for features that are not contained within the\nconfiguration.\nAt step S616, the configuration engine 106 creates cache objects.  The configuration engine 106 returns data from cache for node (Y) for weightFeature and for weightNode, if it already exists.  WeightFeature refers to the weight from the node to\nthe bottom of the MDD (i.e., the true node)--for a specified feature.  WeightNode is a Node-based lookup instead of feature based lookup.  Thus, for each node, the configuration engine 106 determines the maximum weight path feature for a given node,\nstores the weight for each feature.  Once the configuration engine 106 knows the maximum feature weight for a node and trims its edges, then it stores the maximum node weight.  The maximum node weight is used as a cache for when the configuration engine\n106 analyzes subsequent nodes.  It can use the previously calculated maximum weight for that node and trim the outgoing edges from the node to only those edges with the maximum weight.\nAt step S618, the configuration engine 106 performs the maximum weight quick-restrict operation.  The maximum weight quick-restrict operation of S618 is the same as the maximum weight quick-restrict subroutine S560 described above with reference\nto FIG. 50.  After the quick restrict operation has removed partial matches, the configuration engine 106 proceeds to S620 (FIG. 47) to derive a resolution object.\nReferring back to FIG. 47, if the configuration engine 106 determines that removing partial matches functionality is not enabled at S610, it proceeds to S620 to derive a resolution object.  The algorithm for deriving a resolution object S620 is\nshown in the flowcharts of FIGS. 59-63.\nReferring to FIG. 59, the configuration engine 106 identifies families to change at step S622.  The algorithm for identifying families to change S622 is shown in the flowchart of FIG. 60.  Referring to FIG. 60, the configuration engine creates a\nbitset of the invalid configuration at step S624.  Next, the configuration engine calculates the domain bitset of the minimum edit space at step S626.  Then at step S628, the configuration engine ANDs the configuration bitset and the domain bitset.\nFIGS. 64-74 are examples illustrating the impact of various steps of the derive resolution object subroutine S620 of the branched conflict resolution method.  Referring to FIG. 64, in one example, a configuration of Default (400, Std, White,\nStone, Less) is modified when the user selects the 401 package.  The configuration engine 106 determines the new invalid configuration to be (401, Std, White, Stone, Less) with a minimum edit space depicted by MDD 6400.\nFIG. 65 is a table 6500 listing the invalid configuration (401, Std, White, Stone, Less) as a bitset (010 100 100 100 10).  FIG. 66 is a table 6600 that depicts the minimum edit space of the configuration converted to a matrix, as determined in\nstep S626 (FIG. 60).\nReferring back to FIG. 60, the configuration engine 106 starts analyzing the nodes included in family level zero (x) of the MDD at step S630.  At step S632, the configuration engine 106 determines if the family level (x) is less than the total\nnumber of families included in the MDD.  If so, the configuration engine 106 proceeds to step S634.\nAt S634, the configuration engine 106 evaluates the number of active features in the intersection, or bitwise conjunction, or \"ANDed\" bitset for family (x).  If there is at least one active feature in the ANDed bitset for family(x), the\nconfiguration engine 106 proceeds to step S636 and increments the family level (x) by one.  However, if there are no active features in the ANDed bitset for family(x), the configuration engine 106 proceeds to step S638 and adds family(x) to the list of\nfamilies to change, and then proceeds to step S636.\nFIG. 67 is a table 6700 illustrating the bitwise conjunction (AND) of the domain of the edit space in the example from table 6600 with the invalid configuration from table 6500.  The configuration engine 106 identifies any family with no active\nbits (i.e., only \"0\"s) in the sum, as referenced by numeral 6702, as a family to change to transform the invalid configuration into a valid one.  Thus, the configuration engine 106 determines that the radio, paint and trim families are families to\nchange.\nWith reference to FIG. 60, once the configuration engine 106 has analyzed all families, it will make a negative determination at step S632, i.e., the level (x) will not be less than the number of families.  Then the configuration engine 106\nproceeds to step S640 and returns to the routine of FIG. 59.\nReferring to FIG. 59, at step S642 the configuration engine 106 trims the edit space to the families identified in S622.  Then at step S644, the configuration engine 106 converts the trimmed space to a matrix, which is represented by table 6600\n(FIG. 66).\nFIG. 68 is a table 6800 that illustrates the minimum edit space from table 6600 after it is trimmed to the families to change (i.e., radio, paint and trim) from table 6700.\nAt step S646 (FIG. 59), the configuration engine 106 creates a resolution object that describes the actions to change the invalid configuration to a valid configuration.  The algorithm for creating a resolution object S646 is shown in the\nflowchart of FIG. 61.\nIn creating a resolution object S646, the configuration engine takes as input the invalid configuration, a target matrix (i.e., the edit space), the list of families to change and the list of families that have been processed so far.  The list\nof families to change is sorted in priority order, according to one or more embodiments.  This sort can be provided by an alternate sequence, or default to the minimum edit space family structure shown in FIG. 68.\nThe configuration engine 106 divides the families to change into No-Branch and Branch lists.  The configuration engine 106 identifies any family that is not identical in all rows of the target matrix as a Branch family.  Each resolution contains\na list of actions for any number of No-Branch families and a single Branch family.\nAn action specifies the family to change, its prior choice, and its possible choice(s).  To simplify parsing of a resolution, the configuration engine 106 organizes the Branch action to be the last action.  The Branch items lead to a divergent\nchoice and the choices for the remaining families are unknown until the Branch family choice is made.  Each choice of the Branch family will have an associated nested resolution object defined in a feature choice that results in resolution mapping.  The\nnested resolution objects are derived by with a new target matrix that is restricted to the feature choice of the branching family, the original families list, and the updated processed families list.\nReferring to FIG. 61, step S648 is a recursive call in which the configuration engine 106 sets the families to consider changing (Families to Consider) equal to the families list minus the families that were already processed (Families\nProcessed).\nAt step S650, the configuration engine 106 divides the families to consider changing (Families to Consider) into Branch and No-Branch lists.  A Branch family is a family whose bit pattern is not identical in all rows of the target matrix,\nwhereas a No-Branch family's bit pattern is identical in all rows.  The algorithm for dividing families into Branch and No-Branch S650 is shown in the flowchart of FIG. 62.\nWith reference to FIG. 62, the configuration engine 106 derives a unique bit pattern for each family based on the target matrix at S652.  The configuration engine 106 starts analyzing the nodes included in family level zero of the MDD at step\nS654.  At step S655, the configuration engine 106 determines if the family level (x) is less than the total number of families to consider changing in the MDD.  If so, the configuration engine 106 proceeds to step S656.\nAt step S656 the configuration engine 106 evaluates the number of unique patterns for family (x).  If there is more than one unique pattern, the configuration engine 106 proceeds to step S658 and adds the family to the Branch category.  If there\nis only one unique pattern, the configuration engine 106 proceeds to step S660 and adds family level (x) to the No-Branch list.  After steps S658 and S660, the configuration engine 106 increments the family level (x) by one and then returns to S655. \nOnce the configuration engine 106 has organized all families into the Branch and No-Branch lists, it makes a negative determination at S655, and then sorts the families within each list by priority at step S662, with the highest priority family listed\nfirst.  The priority of each family is based on its family weight and is determined by a separate system, according to one or more embodiments.  After S662, the configuration engine 106 returns to the create resolution object subroutine S646 of FIG. 61.\nReferring back to FIG. 68, the first call to derive the resolution method object S620 will use the invalid configuration from FIG. 65, the target matrix from FIG. 68, and will pass an empty list for the processed families list--deriveResolution\n(Cfg65, Matrix68, [Radio, Paint, Trim], [ ]).  As shown in table 6800, the bit pattern for radio (i.e., \"011\") is the same in both rows, but is different for both paint and trim.  Therefore the configuration engine 106 identifies radio as a No-Branch\nfamily at S656 and S660, because it only has one unique pattern.  And the configuration engine 106 identifies paint and trim as Branch families at S656 and S658, because they each have more than one unique pattern.\nReferring back to FIG. 61, the configuration engine 106 initializes a resolution object at S664 by creating an empty object.  The configuration engine 106 starts analyzing the first No-Branch family (b=0) at step S666.  At step S668, the\nconfiguration engine 106 determines if the No-Branch family index (b) is less than the total number of No-Branch families.  If so, the configuration engine 106 proceeds to S670.  At step S670, the configuration engine 106 creates an action for No-Branch\nfamily index (b) and adds the action to the Resolution Object.  The algorithm for S670 is shown in the flowchart of FIG. 63.\nWith reference to FIG. 63, the configuration engine 106 initializes an empty Action object at step S672.  Next the configuration engine 106 sets a current feature (z) equal to the family feature (Family) in the invalid configuration at step\nS674.\nAt step S676, the configuration engine 106 sets the group of valid features for the user to choose from (Choices) equal to the active features for the No-Branch family index (b) in the target matrix domain.  Then at step S678, the configuration\nengine 106 returns the Action object to the subroutine S646 of FIG. 61.  With reference to FIG. 61, the configuration engine 106 adds the No-Branch family index (b) to the families processed list at step S679, then it increments the No-Branch family\nindex (b) by one and then returns to step S668.\nReferring to FIGS. 65-71, the configuration engine 106 initializes an empty resolution and adds an action for all No-Branch families, which in this case is radio--the only No-Branch family identified from table 6800.  As shown in table 6500, the\ninvalid configuration includes the Standard radio (i.e., \"100\") and the trimmed minimum edit space of table 6800 shows the possible valid choices for radio include Deluxe and Navigation (i.e., \"011\").  The Action for radio in this example specifies the\nfamily to change (i.e., radio), its prior choice (Standard), and its possible choices (Deluxe and Navigation), which may be represented by: Action {Radio, [Std], [Dlx, Nav]} as shown in FIG. 71.\nReferring back to FIG. 61, once the configuration engine 106 has analyzed all of the No-Branch families, it will make a negative determination at step S668 (i.e., the No-Branch family index (b) is greater than or equal to the number of No-Branch\nfamilies) and then proceed to step S680.  At S680 the configuration engine 106 evaluates the number of Branch families.  If there are zero Branch families, the configuration engine 106 returns to the derive resolution subroutine S620 of FIG. 59.  If\nthere are Branch families (i.e., Branch families &gt;0), the configuration engine 106 proceeds to step S682.\nAt S682 the configuration engine 106 sets Family equal to the first family (i.e., the highest priority family) in the Branch list.  At step S684 the configuration engine 106 creates Action for the Family.  The configuration engine 106\ninitializes an empty Action Object and sets the current feature equal to the Family configuration feature.  Next the configuration engine updates the Action to set Choices equal to the active features for Family in the target matrix domain.  At S688, the\nconfiguration engine 106 creates a new Families Processed list by appending Family to the Families Processed list.\nAt step S690, the configuration engine 106 starts analyzing Choice (c=0).  At step S692, the configuration engine 106 compares Choice (c) to the number of choices.  If Choice (c) is less than the number of choices, then the configuration engine\n106 proceeds to step S694 and creates a new target matrix that is restricted to Choice (c).\nAt step S696, the configuration engine 106 creates a Resolution Object for Choice (c) using the new target matrix and the new Families Processed list by the result of recursive invocation.  At step S698, the configuration engine 106 updates the\nAction to set Branch for Choice (c) equal to the nested Resolution Object.  At step S700, the configuration engine 106 increments Choice (c) by one and returns to step S692.  Once the configuration engine 106 has analyzed all Choices, it determines that\nChoice (c) is equal to the total number of choices at S692 (i.e., C is not less than # Choices).  In response to a negative determination at S692, the configuration engine 106 proceeds to step S702 and adds the Action object to the Resolution.  Then it\nreturns to subroutine S620 (FIG. 59) and then back to the main conflict resolution routine S500 of FIG. 47.\nWith reference to FIGS. 65-71, the configuration engine 106 generates the Action for the highest priority Branch family, which in this case is the Paint family because it defaulted to using MDD/Matrix structure/family ordering where the right to\nleft ordering defines priority values.  As shown in table 6700, paint oriented to the left of trim, so paint is higher priority.  For each paint Choice, the configuration engine derives a nested resolution by first creating a new target matrix by\nrestricting to the paint choice, and making a call to derive resolution.\nAs shown in the trimmed minimum edit space of table 6800, there are two possible Choices for the paint family--Red (i.e., \"010\") and Blue (\"001\").  There will be two additional calls to derive resolution: one for Red\npaint--deriveResolution(Cfg65, Matrix.Red, [Radio, Paint, Trim], [Radio, Paint]); and one for Blue paint--deriveResolution(Cfg65, Matrix.Blue, [Radio, Paint, Trim], [Radio, Paint]).  As shown in FIG. 71, the Action for paint in this example specifies the\nfamily to change (i.e., paint), its prior choice (White, i.e., \"100\" in table 6500), and its possible choices (Red and Blue), which may be represented by: Action {Paint, [White], [Red, Blue]}.\nIn both cases (Red paint and Blue paint), the configuration engine 106 uses a trimmed target matrix and the families list contains only one family (trim) because there is only one other Branch family in this example.  FIG. 69 is a target matrix\n6900 for the Red paint choice.  The target matrix 6900 shows that there is just one choice for trim (i.e., Ruby, \"001\").  FIG. 70 is a target matrix 7000 for the Blue paint choice.  The target matrix 7000 shows that there are two choices for trim (i.e.,\nCharcoal and Ruby, \"011\").  The configuration engine 106 determines the resulting resolution of each target matrix 6900 and 7000 and adds the nested resolutions for paint to its action to determine a final resolution object 7100 (FIG. 71).\nAs shown in FIG. 71, the Action for the nested resolution for Red paint in this example specifies the family to change (i.e., trim), its prior choice (Stone, i.e., \"100\" in table 6500), and its possible choice (Ruby), which is represented by:\nAction {Trim, [Stone], [Ruby] }.  The Action for the nested resolution for Blue paint in this example specifies the family to change (i.e., trim), its prior choice (Stone, i.e., \"100\" in table 6500), and its possible choices (Charcoal and Ruby), which is\nrepresented by: Action {Trim, [Stone], [Charcoal, Ruby]}.\nReferring back to FIG. 47, at S704, the configuration engine 106 restores the original set of node edges to the memory 108 (shown in FIG. 2).  S704 is similar to subroutine S146 of FIG. 28.  The configuration engine identifies each node (y),\ncopies each outgoing edge of each node.  Then, the configuration engine 106 sets the MDD to the identity of the root node.  At step S706, the configuration engine 106 returns a response by providing the resolution object 7100 to the author decorator 154;\nwho in turn transforms the resolution object 7100 into a SOAP xml response (FIG. 2) which is presented to the user in a series of windows, as shown in FIGS. 72-74.\nAs described above with reference to resolution object 7100 (FIG. 71), the configuration engine 106 determined a guided resolution that includes a nested choice for trim.  The Available choices for trim depend on the user's selection for paint. \nFIG. 72 depicts a window 7200 with a first prompt that is displayed to the user.  FIG. 73 and FIG. 74 show the next prompt displayed as determined by the choice of Red or Blue paint.\nIf the user selects Red paint in response to the prompt shown in window 7200, the configuration engine 106 will guide them along partial path 8-9-10 (FIG. 64) and then display window 7300 to instruct them to change the trim from Stone to Ruby.\nHowever, if the user selects Blue paint in response to the prompt shown in window 7200, the configuration engine 106 will guide them along partial path 8-11-12 (FIG. 64) and then display window 7400 to instruct them to change the trim from Stone\nto one of Charcoal and Ruby.\nAs described above with reference to FIG. 58, in branched conflict resolution the minimum edit space may include some partial matches, where a choice is present in some, but not all of the target configurations.  Partial matches in the\nconfiguration space can cause the target space to be too large, and it can lead to awkward user prompts.  The configuration engine 106 may trim the minimum edit space using the removing partial matches subroutine S612.  This is done using the maximum\nweight quick-restrict operation, according to one or more embodiments.  However, only the partial match features are provided with relative non-zero weights; all other features are given an equal weight of zero at S614.\nFIGS. 75-76 are examples illustrating the impact of various steps of the remove partial matches subroutine S612.  In the illustrated embodiment, a selection of D2 leads to the invalid configuration (A1, B2, C3, D2, E3, F1) with the minimum edit\nspace shown in MDD 7500 of FIG. 75.  There are two partial matches--B2 (i.e., the outgoing edge \"010\" from node 12) and E3 (i.e., the outgoing edge \"001\" from node 11)--where a user selection could remain the same or be changed.  If B2 remains unchanged,\nthen E3 must change to E2, because E3 is not located along the same path as B2 (i.e., partial path 11-12-13-14).  But, E3 can remain unchanged if B2 changes to B3, because E3 is located on the same path as B3 (i.e., partial path 11-15-16-14).\nWith an alternate sequence {A1 A2 B1 B2 B3 D1 D2 C1 C2 C3 C4 E1 E2 E3 F1 F2}, and an invalid configuration of {D2 A1 E3 B2 C3 F1}, the structure used for path weights is {A1 B2 C3 D2 E3 F1}.  The maximum weight operation will ignore any edges\nwith negative weights (A2 B1 C1 C2 C4 D1 E1 E2 F2).  The weights for the two paths in the minimum edit space are shown in Table 7600 of FIG. 76.  The first row shows path 2-10-11-12-13-14-1.  This path defines the configuration of {D2 A1 E2 B2 C2 F2} and\na path weight bit set of 010100.  There are two active bits in the path weight which correspond to the features B2 and D2--the two features on this path with non-negative weights.  There are no active bits for the other features (A1, C2, E2, F2) because\nthey have negative weights and are ignored.  The second row shows path 2-10-11-15-16-13-1.  This path defines the configuration of {D2 A1 E3 B3 C2 F2} and a path weight bit set of 000110.  There are two active bits in the path weight which correspond to\nthe features D2 and E3.  Based on these weights, the configuration engine 106 trims the space to a single path of 2-10-11-12-13-14-T. The higher priority family B will remain unchanged, and the resolution will include a change for family E.\nWhen an update request is made, the configuration engine 106 modifies the prior configuration by adding the newly Selected feature (while also removing the prior choice for the feature's family).  As described above with reference to FIGS. 47\nand 48, if the updated configuration is invalid, conflict resolution is triggered and the configuration engine 106 calculates the minimum edit space at S504.  The service API 134 does not dictate how the minimum edit space is calculated.  The\nconfiguration engine 106 determines the level of precedence to be given to prior Selected features.\nIn one embodiment, the configuration engine 106 treats all features in the invalid configuration equally, regardless of feature state.  In this instance the minimum edit calculation S504 is performed using the full invalid configuration.\nIn another embodiment, the configuration engine 106 gives precedence to keeping the maximum number of previously selected features.  The configuration engine 106 performs this strategy by performing the minimum edit calculation S504 using a\npartial configuration that ignores any feature whose prior state is Included or Default.  Only the new and previous Selected features are kept when making the minimum edit space calculation.  In one embodiment the configuration engine 106 performs the\nminimum edit calculation S504 after determining whether or not the resolution is guided at S558.  If the resolution is not guided, the configuration engine 106 performs the minimum edit space calculation S504 using only the Selected features.  However,\nif the resolution is guided, the configuration engine 106 performs the minimum edit space calculation S504 using the full invalid configuration.\nFIGS. 77-81 are examples illustrating the impact of various steps of the minimum edit space calculation S504 using a full configuration and using a partial configuration.  In the illustrated embodiments, the configuration engine 106 analyzes the\nfull buildable space shown in Table 7700 of FIG. 77, where the features are numerically named--e.g. Family E has two features E1 and E2.  If the previous configuration is Selected (F1, E2) and Included (A2, T1, R1) and Default (S5, P1, Y3) and an update\nrequest is received to select T2.  The configuration engine 106 determines that the updated configuration is invalid because (F1, E2, T2) is not a valid combination.  As shown in Table 7700, row 1 is the only configuration that includes both F1 and E2,\nbut it includes T1 not T2.\nThe two possible minimum edit spaces are shown in Table 7800 of FIG. 78 and Table 7900 of FIG. 79.  The first minimum edit space (7800) considers the partial configuration where only the new set of selected features is used in the minimum edit\nspace calculation (F1, E2, T2) and the second minimum edit space (7900) considers the full configuration where the complete invalid configuration is used in the minimum edit space calculation (F1, E2, A2, T2, R1, S5, P1, Y3).\nUsing the matrix structure as the priority sequence, the configuration engine 106 identifies a single target configuration from each minimum edit space.  The priority sequence is based on the matrix as is with left most bit being highest\npriority.  So in this case, the configuration engine 106 selects a configuration by choosing features for each family in a left-to right fashion, and choosing the left-most available feature for each family.  With reference to FIG. 78, since the E and F\nfamilies are the same for all configurations; and the configuration in the bottom row has the highest priority feature for family Y, the first space will result in a target of E1, F2, Y1, T2, R3, P1, S1, A2 which corresponds to the bottom row of Table\n7800.  The second space will result in a target of E1, F2, Y3, T2, R1, P1, S5, A2.  The decision on how to calculate the minimum edit space will affect the target configuration, and thus affects the number of feature edits required.\nTable 8000 of FIG. 80 shows the changes required (i.e., the shaded features in target 1) when the configuration engine 106 makes the minimum edit space calculation with only the selected features, based on the minimum edit space in Table 7800. \nAs shown in Table 8000, the features to change are: E1, F2, Y1, R3 and S1.\nTable 8100 of FIG. 81 shows the changes required (i.e., the shaded features in target 2) when the minimum edit space calculation is made with the full invalid configuration, based on the minimum edit space in Table 7900.  As shown in Table 8000,\nthe features to change are: E1 and F2.  In both cases the changes to families E and F are the same because T2 is only available with E1 and F2.  But, if the minimum edit space calculation considers only the Selected features, there are three other\nrequired changes (i.e., Y1, R3 and S1, as shown in Table 8000).\nWhen the configuration engine 106 performs the calculation with the full configuration, it minimizes the total edits, as shown in Table 8100.  It gives no special precedence to previous Selected features.\nWhen the configuration engine 106 performs the calculation with only the new selected set, it is attempting to minimize the changes to prior selections by giving precedence to Selected features.  The side effect is that this increases the total\nnumber of edits required, as shown in Table 8000.\nThe other motivation to perform the minimum edit space calculation on only Selected features is to ensure that the maximally standard default is always driven by the Selected set.\nThe configuration engine 106 results include a Boolean flag to indicate if there is a conflict.  When there is a conflict, the configuration engine 106 determines either a single conflict resolution object or a branched conflict resolution\nobject, depending on the guided resolution flag.\nBecause the services API 134 dictates that a conflict resolution is returned only if there are changes required to the previous selected features, it is possible that the same configuration request will return conflict=true when guided=true, but\nwill return conflict=false when guided=false.\nUsing the product definition from FIG. 10, in one example the configuration engine 106 considers a configuration where the user has selected Red paint, and autocomplete is true.  One such configuration is Selected (Red) and Default (400, Std,\nStone, Less).  If the user updates the configuration by selecting the navigation (Nav) radio, the new configuration (Nav, Red, 400, Stone, Less) is invalid.\nWhen guided resolution is true, the configuration engine 106 returns a conflict of false and a returns resolution such as {Actions [Action {Pkg, [400], [401,402] }, Action {Trim, [Stone], [Ruby]}]}.\nHowever, when guided resolution is false, the API dictates that there is no conflict because the new Selected features (Nav, Red) are compatible.  Even though changes are required for Pkg and Trim, because these were default choices, no conflict\nis reported.  The configuration engine 106 will return conflict of false even though the new configuration and associated feature states show that there is a necessary change to prior default choices for the 400 package, and Stone trim--{Std=AVAILABLE,\nNav=SELECTED, Stone=EXCLUDED, White=EXCLUDED, Charcoal=EXCLUDED, Vista=AVAILABLE, Dlx=AVAILABLE, Red=SELECTED, 400=EXCLUDED, 401=DEFAULT, 402=AVAILABLE, Less=DEFAULT, Blue=AVAILABLE, Ruby=INCLUDED}.\nThe service API 134 specifies that a request can select or unselect a feature.  Selecting a feature adds it to the configuration.  When a feature is unselected, the API dictates only that the feature state is no longer Selected.  It does not\nrequire that the feature be removed from the configuration.\nThere are at least two embodiments.  In a first embodiment, the configuration engine 106 removes the unselected feature from the Selected set and proceeds normally.  In a second embodiment, the configuration engine 106 removes the unselected\nfeature from the configuration entirely.\nRemoving the unselected feature from the Selected set follows the API specification that the feature is no longer Selected.  However, the feature may not actually be removed from the configuration.  In a configurator application, this could mean\nthat the user unchecks the box to remove the feature only to have the checkbox checked again because it is not removed from the configuration.  This behavior can be difficult because no matter what the user does to try and remove the feature, the feature\nkeeps getting added back.\nIn this first embodiment, if a Default or Included feature is unselected, there will be no change in the configuration or feature states.  The Selected set does not change because the feature being unselected wasn't in the Selected set.  As\nsuch, an Included feature will remain Included and a default will remain default.  Included state depends on the Selected set which did not change and auto completion is designed to give repeatable results for the same minimally complete configuration\nwhich did not change.\nIf a Selected feature is unselected, the feature state may change to Included or Default.  If the feature is Included by the remaining Selected features, its state will change from Selected to Included.  Otherwise, it is possible that the\nremoved feature is added back during auto completion.\nDepending on the front-end application 132, the user is most likely unaware of the feature states of Selected, Included and Default.  If the user is unaware of feature states, it can be quite perplexing to unselect a feature only to have it\nremain in the configuration.\nTo avoid this confusion, in the second embodiment, the configuration engine 106 removes the feature from the configuration regardless of its state.  This implementation will trigger conflict resolution when a feature from the configuration is\nunselected.  To ensure the unselected feature remains absent from the new configuration, the configuration engine 106 restricts the buildable space to only those configurations that do not contain the unselected feature prior to the minimum edit\ncalculation.  This approach ensures that the unselected feature is removed from the configuration.\nWhen auto completion is enabled, the configuration engine 106 makes Default choices until the configuration is complete with respect to displayable families.  This is done by making determinations for each incomplete family that is consistent\nwith prior Selected and Included feature states.\nIn one embodiment, the configuration engine 106 makes Default feature state determinations based on a priority sequence for each family and feature.  Incomplete families are processed in priority order, and where more than one feature is valid\nwith prior Selected, Included and Default feature states, the feature priority is used to make the Default determination.\nWith reference to FIG. 82, a method for automatically completing a configuration using a sequence-based approach is illustrated in accordance with one or more embodiments and generally referenced by S750.  The method S750 is implemented as an\nalgorithm within the configuration engine 106 using software code contained within the server 102, according to one or more embodiments.  In other embodiments the software code is shared between the server 102 and the user devices 112, 114.  The method\nS750 uses quick-restrict and domain to make default selections.\nAt S752, the configuration engine 106 starts with an MDD restricted to Selected features, and a configuration defined by the Selected and Included features.  At S754, the configuration engine 106 sorts families by priority.  Then, at S756, for\neach family without Selected or Included features, that are sorted by priority, the configuration engine 106 calculates the domain of the current restricted space.  At S758, the configuration engine determines the highest priority feature for the family,\nmarks it as a Default feature, and further restricts the restricted space to this feature.\nAlternatively, in another embodiment, after S752, the configuration engine 106 proceeds to S760 and uses sequences to determine the maximally weighted path in the MDD that contains the Selected and Included features, which identifies default\nchoices for families to complete.\nPath weight can be represented by a feature Bitset, where the families are ordered left to right according to priority (with the leftmost family being the highest priority), and features are also ordered left to right according to priority\nwithin each family (with the feature corresponding to the leftmost bit being the highest priority).  This is analogous to sorting the features in descending priority and assigning weights by powers of 2, -1 2 4 8 16 .  . . , and ensures that each path\nwill be uniquely weighted, and that there will be exactly one maximally weighted path when each family and feature is assigned a sequence.  To compare two paths, the Bitsets are sorted in descending bit order.\nInitially the path weight is 0, and as an edge is added during MDD traversal, edge weight is added to the path by simply setting a corresponding bit associated with the feature on that edge.\nIdeally, the MDD structure would reflect the priority sequence for features and families.  However, compression of the MDD requires the family ordering to be determined by the compression algorithm, and the feature order is arbitrarily\ndetermined by feature conditions of the MDD algorithm.  While the MDD structure can't be used to store priority sequence, a secondary structure can be created to store this sequencing.  The MDD structure is used to determine the feature for each edge,\nand the alternate/secondary structure is used to set the feature's bits in the path weight Bitset.\nFIG. 83 shows an MDD 8300 that defines the same buildable space as MDD 1300 (FIG. 13), except that the features within each family are sorted alphabetically and the family order is based on MDD compression.  For example, the radio features are\nsorted as STD, DLX and NAV in MDD 1300 and as DLX, NAV and STD in MDD 8300.  FIG. 84 is a table 8400 that defines the alternate sequence structure defining path weights, which is the same as the structure of MDD 1300.\nReferring back to FIG. 82, the configuration engine 106 begins the weighted operation with a minimally completed configuration, and starts with a quick-restrict operation (S752).  In another embodiment, the configuration engine 106 combines the\nquick-restrict operation with the weighted operation (S760), as is done in Minimum Edit Distance subroutine described with reference to FIG. 48 regarding resolving configuration conflicts.  On the downward traversal, no additional action is taken.  On\nthe upward traversal, the configuration engine 106 calculates the path weight with the aid of the alternate sequence structure 8400.  Where a node has more than one outgoing edge, the weight is calculated separately for each feature that has a valid\noutgoing edge.  When a new maximally weighted path is found, lesser weighted paths are trimmed from the MDD.\nFIG. 85 illustrates an MDD 8500 after the configuration engine 106 restricts the MDD 8300 (FIG. 83) to a selection of Blue paint and no Included or Default features, i.e., a minimally complete configuration: Selected{Blue}+Included{ }+Default{\n}, as described with reference to S752.  Then configuration engine 106 starts the weighted operation, i.e., S760, with the quick-restricted space shown in MDD 8500.  Using depth-first search and traversing child edges in descending bit order, the first\npath traversed is 2-8-9-10-6-T.\nThe configuration engine 106 calculates path weight on the upward traversal beginning with partial path T-6-10-9.  This path weight, along with the weight of its partial paths, is shown in Table 8600 of FIG. 86.\nThe configuration engine 106 continues the downward traversal from Node 9 with the 401 package (Pkg.401).  There are two partial paths to consider: 9-5-7-T and 9-5-6-T. The two partial paths from Node 5 to the truth node are compared to find the\nmaximum weight between Ruby and Charcoal Trim, as shown in Table 8700 (FIG. 87).  The configuration engine 106 determines that Charcoal Trim (path 9-5-6-T) is the maximum, because 000 000 001 010 00 is greater than 000 000 001 001 00, as referenced by\nnumeral 8702, and the edge 5-7 (Ruby Trim) is removed (shown in FIG. 89).\nNext, the configuration engine 106 compares the paths from Node 9 to the Truth node, as shown in Table 8800 (FIG. 88).  The configuration engine 106 determines that the partial path for the 401 Package is the maximum because the corresponding\nbits (010) are greater than the corresponding bits of the 402 package (i.e., 001), as referenced by numeral 8802; and trims edge 9-10 from the MDD 8500.  At this point the MDD will look like MDD 8900, as shown in FIG. 89.\nThe maximum weight path for edge 8-9 is MoonRf.Less, because the corresponding bits for Less (10) are greater than the corresponding bits for Vista (01).  The configuration engine 106 determines that the configuration\n{Dlx,Less,401,Charcoal,Blue} is the maximum weight for path 2-8- .  . . -T and that the maximum weight configuration for path 2-3- .  . . -T is {Std,Less,401,Charcoal,Blue}.  The edge weights for these paths are shown in Table 9000 in FIG. 90, and the\nmaximum weight outgoing edge from node 2 is Dlx, because 010 is greater than 001 (Nav), as referenced by numeral 9002.\nThe configuration engine 106 trims edges 2-8-9-5, 10-6 and 7-T as shown in MDD 8900 (FIG. 89).  This leaves the maximum weight path as 2-3-4-5-6-T, and the configuration engine 106 marks Radio.Dlx, MoonRf.Less, Pkg.401 and Trim.Charcoal as\nDefault features at S760 to generate an autocompleted configuration of: Selected {Blue}+Included{ }+Default{Dlx,Less,401,Charcoal}.\nA problem with sequence based auto completion is that it requires additional data to define the priority sequence.  This requires manual setup for every vehicle in the catalog.  Furthermore, it is not guaranteed to provide the maximally standard\nconfiguration.\nSequence-based auto completion is attempting to supplement the MDD with data that will allow the autocompleted configuration to be maximally standard.  A \"maximally standard\" configuration is one where a configuration contains the most possibly\nstandard content, where standard content is determined by the product definition.  A standard feature is generally a feature that is included in the base price for a product, such as a vehicle.  Whereas an optional feature is typically an upgrade and\nwill increase the price of the product.\nFor simpler product definition, it is may be possible to ensure maximally standard configurations using the alternate sequence approach.  However, for more complex product definition, this approach will not work.\nThe product definition defines a set of feature conditions that determine when a feature is available.  There are three types of availability--as a standard feature, as an included feature, and as an optional feature.  A feature could have\ndifferent availability depending on the current configuration.  A standard feature is a feature that is included in the base product (vehicle) configuration and an optional feature is a feature that is not included in the base product.  An optional\nfeature is typically an upgrade that will add cost to the base price, but this is not always the case as a feature could be a zero-cost option or even a less expensive option than the standard feature.  An included feature is generally a feature that is\nassociated with another feature (e.g., a package) and was added to the product by selecting the other feature.  For example, leather seats and fuzzy dice may be included in the 401 package.  When the user selects the 401 package, they see one change in\nprice for the package, but the change includes both features (i.e., leather seats and fuzzy dice).\nThe configuration engine 106 uses the maximally standard algorithm to distinguish feature availability based on standard or optional feature conditions.  A feature included in a package is a special case of a standard feature.  In addition to\nthe valid buildable space, the product definition also defines the standard feature conditions for each family.  When the configuration engine 106 selects Default features using the maximally standard algorithm, it is configured to select as many\nstandard features as possible to avoid or limit adding optional content and potentially increasing the price when the user has not explicitly selected the feature.\nFIG. 91 is a Table 9100 that shows a matrix that defines the same buildable space as MDD 1700 (FIG. 17).  FIG. 92 is a Table 9200 that shows the standard feature conditions for the product definition defining the buildable space.\nFor the package (Pkg) family, there is a single feature condition defining Pkg.400 as the standard package, as referenced by numeral 9202.  For the Radio family, there are two standard feature conditions, as referenced by numeral 9204.  The\nfirst (upper row) defines Radio.Std as the standard Radio for Pkg.400.  The second (lower row) defines Radio.Dlx as the standard Radio for Pkg.401 and Pkg.402.  The buildable space shows that Radio.Nav is also available.  Because this feature condition\nis not included in the Standard feature conditions (i.e., Radio.Nav is not active (1) in condition 9204), the navigation radio (Nav) is defined as an optional choice that can be added in place of the deluxe radio (Dlx) for the 401 or 402 package.  There\nis a single feature condition for the moonroof family defining no moonroof (Less) as the standard package, as referenced by numeral 9206.  There are two standard feature conditions for the dice family, as referenced by numeral 9208; the first defines no\ndice as the standard feature for white paint; and the second defines fuzzy dice as the standard feature for red and blue paint.  There are three standard features for the seat temperature (Temp) family, as referenced by numeral 9210; the first defines no\nseat temperature feature (LessTemp) as the standard feature for the 400 package; the second defines heated seat control (Heat) as the standard feature for the 401 package; and the third defines heated and cooled seat control (HeatCool) as the standard\nfeature for the 402 package.\nWith reference to FIG. 93, a method for automatically completing a configuration using a maximally standard algorithm is illustrated as software code in accordance with one or more embodiments and generally referenced by 9300.\nTo automatically complete the configuration using standard feature conditions, the configuration engine 106 first restricts the buildable space to the minimally complete configuration at operation 9301.  Families absent from the configuration\nare processed in priority order, and the space is restricted for each successive choice.  To make the default choice for a family, its standard feature conditions are inspected to see what standard choice(s) are still possible at operation 9304.  If no\nstandard choices are possible, the domain of the restricted space will define possible optional choices at operation 9306.  Where more than one possible choice exists for a family, alternate sequencing is used to choose the highest priority feature as\nthe default at operation 9308.\nIt is uncommon, but valid, for a family to have to no standard feature conditions.  This is handled as if no standard features are available, and the choice will be made from the optional content.\nIt is also valid for the standard feature conditions to define more than one standard feature for the same partial configuration.  Where more than one standard feature is available, the highest priority feature will be chosen.\nWhere all feature conditions for a family are stored in a single MDD, the standard features that are still allowed with prior choices can be identified by an AND operation of this MDD with the current restricted buildable space.  An AND\noperation generates a new MDD for each inspection of a feature condition MDD.  As discussed in the Quick-Restrict section, this will incur performance problems from garbage collection.  The alternate approach, as shown in FIG. 93, is to divide the\nstandard feature conditions by feature (and not just family) and use the containsAny operation.  The containsAny operation is the same logic as an AND operation, however the new space is not created.\nWith reference to FIG. 94, in one embodiment, the configuration engine 106 considers a scenario where a user has selected the Vista moonroof and Ruby trim.  With these two selections, Fuzy Dice is included.  Given a priority order of [Pkg,\nRadio, Moonrf, Temp, Paint, Dice, Trim], the families to autocomplete, in order are [Pkg, Radio, Temp, Paint].  The configuration engine 106 does not auto-complete the Dice, Trim and Moonroof families because they are already \"complete\", i.e., they have\nfeatures with Selected or Included feature states.\nThe configuration engine 106 restricts the MDD to the minimally complete configuration Vista, Ruby, and Fuzzy Dice as shown by MDD 9400 in FIG. 94.\nFirst, the configuration engine 106 processes the package family (Pkg) because it has the highest priority.  As described with reference to FIG. 92, there is one standard feature condition for the package family (i.e., Pkg 400, 9202).  Because\nthe 400 package (i.e., the left-most feature of Pkg) is not contained in the restricted space illustrated by MDD 9400, the standard feature is not available.  MDD 9400 shows that the domain of the package family is 011 showing that both the 401 and 402\npackages are available in the restricted space.  The configuration engine 106 chooses the 401 package based on priority and the space is further restricted to package 401 (i.e., nodes 9 and 10 are removed) as shown by MDD 9402.  The restricted space now\ncontains a single superconfiguration.\nNext, the configuration engine processes the radio family.  As described with reference to FIG. 92, there are two standard feature conditions for the radio family: one for Radio.Std and one for Radio.Dlx (9204, FIG. 92).  At this point the\ndeluxe (Dlx) radio and the navigation (Nav) radio are available in the restricted space illustrated by MDD 9402.  The configuration engine 106 selects Dlx as a Default feature, because it is the only standard feature remaining in the restricted space,\nand further restricts the buildable space to Dlx, as indicated by the modified edge label from 011 to 010 and reference by numeral 9404.  However, this restriction will not change availability for other families since the space is already a single\nsuperconfiguration.\nNext, the configuration engine 106 processes the seat temperature (Temp) family.  There are three standard feature conditions for Temp (9210, FIG. 92).  But, since Pkg 401 has already been selected, only Temp.Heat will be available, as indicated\nby edge label 010 in MDD 9402.  Therefore the configuration engine 106 adds heated seats (Heat) to the configuration as a Default feature.\nNext, the configuration engine 106 processes the paint family.  There are no standard feature conditions for paint (Table 9200, FIG. 92).  The domain of the restricted space has two choices--Red and Blue, as indicated by edge label 011 in MDD\n9402.  The configuration engine 106 adds Red as the Default choice, and further restricts the MDD 9402 to Red (010) as referenced by numeral 9406, because Red (010) has more weight than Blue (001).\nFinally, the configuration engine 106 processes the dice family.  There are two feature conditions for Dice (9208, FIG. 92).  Because Red paint has been added to the configuration, only Fuzzy Dice is available, and fuzzy dice is already an\nIncluded feature.  Therefore the configuration engine 106 does not change its feature state.\nWith reference to FIGS. 95-99, another method for automatically completing a configuration using a maximally standard algorithm is illustrated in accordance with one or more embodiments and generally referenced by S800.  The maximally standard\nauto-completion method S800 is implemented as an algorithm within the configuration engine 106 using software code contained within the server 102, according to one or more embodiments.  In other embodiments the software code is shared between the server\n102 and the user devices 112, 114.\nAt S802, the configuration engine 106 generates a maximally standard data space (MsDataSpace) based on a total or global buildable space and a relationships work object (relWork).  The total buildable space includes a main space that defines all\npossible configurations of non-deterministic features and relationships spaces that define the availability of deterministic features in terms of non-deterministic features.  The intersection of the main space and the relationships spaces define all\npossibleconfigurations.  The main space and relationship spaces are specified by MDDs, according to one or more embodiments.  The total buildable space includes the main MDD and a relationships MDD, and is quick-restricted to any Selected and Included\nfeatures.  RelWork is a temporary object that is used to process a specific condition that may occur based on the order families are processed.  As discussed below, relWork is nontrivial if after selecting a Default feature from a deterministic family,\nthere is more than one defining feature condition such that the configuration engine 106 cannot quick restrict the main MDD.  Then at S804, the configuration engine 106 identifies any family without any Selected or Included features as a family to\ncomplete.\nWith reference to steps S806-811, the configuration engine 106 analyzes each family of the MDD in priority order.  The configuration engine 106 starts analyzing the first family in the sorted families to complete list at step S806.  At step\nS808, the configuration engine 106 determines if the index (x) is less than the total number of families included in the families to complete list.  If not, the configuration engine 106 proceeds to S810 (Done).  If so, the configuration engine 106\nproceeds to step S812 to determine the possible available standard features for family (x) within the restricted buildable space (MsDataSpace).  Once the configuration engine 106 has completed its analysis of family (x), it returns to S811 and starts\nanalyzing the next family by incrementing x by 1.  The subroutine of S812 is shown in the flowchart of FIG. 96.\nWith reference to FIG. 96, at S814 the configuration engine 106 initializes the list of possible standard features by setting it to empty.  With reference to steps S816, S818 and S842, the configuration engine 106 analyzes each feature of\nfamily(x).  The configuration engine 106 starts analyzing feature zero (z=0) at S816.  At step S818 the configuration engine 106 compares feature (z) to the number of features at the current family (x) to determine if z&lt;the number of features in\nfamily (x).  If the determination is positive, the configuration engine 106 proceeds to S820 to determine the essential sets for feature availability.  Once the configuration engine 106 has completed its analysis of feature (z) of family (x), it returns\nto S842 and starts analyzing the next feature of family (x) by incrementing z by 1.  The subroutine of S820 is shown in the flowchart of FIG. 97.\nReferring to FIG. 97, the configuration engine 106 determines a setlist of \"essential sets\" for the availability of feature (z) at S820-S848.  At S824 the configuration engine 106 initializes the setlist by adding the main MDD of the current\nbuildable space (buildableSpace).  Then at S826, the configuration engine 106 evaluates relWork to determine if it is not trivial (i.e., not all 1).  If relWork is not all trivial, (i.e., a previous Default selection was made from a deterministic family\nsuch that the relationship defined more than one determinant condition) then the configuration engine 106 proceeds to S828 and adds relWork to the setlist.  After S828, or in response to a negative determination at S826, the configuration engine 106\nproceeds to S830 to determine if there are not any standard feature conditions defined for this feature.  If there are no standard feature conditions defined for feature (z), then its standard space is null.  If there are standard feature conditions\ndefined for feature (z), then a negative determination is made at S830, and the configuration engine 106 proceeds to S832 and adds the standard space to the setlist.  After S832, or in response to a positive determination at S830, the configuration\nengine 106 proceeds to S834 to determine if the family of feature (z) is deterministic.  If family (x) is deterministic, the configuration engine 106 adds the relationship space for family (x) to the setlist at S836.  After S836, or in response to a\nnegative determination at S834, the configuration engine 106 proceeds to S838 and returns the setlist to the subroutine of FIG. 96.\nReferring to FIG. 96, at S840 the configuration engine 106 determines if the intersection of all spaces in the setlist for feature (z) is empty (i.e., if feature (z) is not a standard feature or it is a standard feature that is not available\nwith the current configuration).  If the determination at S840 is negative, the configuration engine 106 proceeds to S844 and adds feature (z) to the list of possible available standard features (POSSIBLE).  After S844, or after a positive determination\nat S840, the configuration engine 106 proceeds to S842 to analyze the next feature (z) of family (x).  Once the configuration engine 106 has analyzed all features of family (x), it makes a negative determination at S818 and proceeds to S846 to return the\npossible available standard features for family (x) to the main maximally standard routine of FIG. 95.\nWith reference to FIG. 95, at S848 the configuration engine determines if there are any standard features for family (x).  If there are no standard features, i.e., if POSSIBLE is empty, then the configuration engine 106 proceeds to S850 to find\nthe domain of family (x) in the maximally standard data space (MsDataSpace).  The subroutine of S850 is shown in the flowchart of FIG. 98.\nWith reference to FIG. 98, the configuration engine 106 determines the domain of family (x) at S850-S858.  At S852, the configuration engine 106 calculates the domain space of family (x) as the intersection of the main space and the relWork.  If\nthe configuration engine 106 determines that family (x) is deterministic at S854 based on the product definition, then it proceeds to S856.  At S856 the configuration engine 106 sets the domain space equal to the intersection of the domain space and\nrelationship space for that family.  After S856, or in response to a determination that family (x) is not deterministic at S854, the configuration engine 106 proceeds to S858 and sets the Domain to the domain of the domain space, adds any feature from\nfamily (x) that is present to the Domain to the list of possible features and returns to the main maximally standard routine of FIG. 95.\nReferring to FIG. 95, after determining the domain of family (x) at S850, or in response to a negative determination at S848, the configuration engine 106 proceeds to S860 and sorts POSSIBLE by an alternate sequence that defines the priority of\nthe features.  At S862 the configuration engine 106 selects the first feature in the sorted list as the Default feature for Family (x).  Then the configuration engine 106 proceeds to S864 to restrict the maximally standard data space to the new Default\nfeature.  The subroutine of S864 is shown in the flowchart of FIG. 99.\nWith reference to FIG. 99, at S864-S880, the configuration engine 106 further restricts the maximally standard data space to the new Default feature.  At S866 the configuration engine 106 restricts the main space to the new Default feature. \nThen if family (x) is deterministic, the configuration engine 106 proceeds to S870 and defines a temporary relationship (relTemp) by restricting the family relationship space to the new Default feature choice.  Then at S872, the configuration engine 106\nsets relWork to the intersection of relWork and relTemp.  At S874, the configuration engine 106 evaluates relWork to determine if it has a single path, i.e., a \"singleton.\" If the standard features (relWork) is a singleton, the configuration engine 106\nproceeds to S876 and uses quick restrict to restrict the main space using the single bitmask from relWork; and then resets relWork to be trivial (all 1s) at S878.  After S878, or in response to a negative determination at S868 or S874, the configuration\nengine 106 proceeds to S880 and returns to the main maximally standard routine of FIG. 95.\nWith reference to FIGS. 100-101, deterministic relationships are used to enable efficient creation and storage of the full buildable space.  As described previously, the global buildable space can be stored in a Global MDD that has a main space\n(e.g., an MDD) and a set of relationship spaces (e.g., MDDs).  Maximally standard auto completion requires standard feature conditions.  The buildable space (FIG. 100) and Standard Feature Conditions (FIG. 101) are shown as Tables 10000 and 10100,\nrespectfully, and combined in a single Buildable object.\nThere is no concept of displayable and non-displayable families during MDD generation.  Displayable families refer to content this is displayed to the user, for example paint color is displayed to a user in a build and price application. \nWhereas non-displayable families refer to content that is not displayed to the user, such as an electrical harness in a build and price application.  A Superconfiguration Generator (SCG) library (not shown) is a component of the ETL 128 (FIG. 2).  The\nSCG library simply finds all relationships in order to generate the smallest possible main space.\nSome algorithms that target displayable content (e.g., validation and feature state mapper) have been optimized to work on a single MDD, and others require all displayable content to be in a single MDD (e.g., minimum edit).  Valid input for the\nconfigurator is a global space where no displayable families have been pulled to an external relationship, even if it is deterministic.\nOne possible way to build a global space that conforms to the configurator input is to control which families can be deterministic.  The SCG algorithm includes an argument called relignore which can be used to specify which families are not\nallowed to be deterministic.  This argument can be used to specify that displayable families are not allowed to be deterministic.\nAnother approach is to allow SCG to build the MDD by pulling out whatever relationships it finds.  Then, an extra step is used before the space can be used by the configurator.  Any relationship that defines a display family dependence on the\nmain MDD is flattened back into the main MDD.  To do this efficiently, the MDD is recompressed as the relationships are flattened.\nGenerally both approaches will take the same amount of processing time.  In the second approach, the MDD may be generated much faster, but that any time savings is used in the extra flattening step.\nThe configuration engine 106 will be validating two types of configurations--a configuration of displayable features only or an expanded configuration of displayable and no display features.\nTo validate a configuration of displayable features the relationships can be ignored because the configuration engine 106 does not allow any displayable family to be deterministic.  This means that the main MDD contains all of the information\nnecessary to define feature combinations from the displayable families.  There is no information in the relationships that will shrink the space of displayable families that is defined in the main MDD.  Thus, only the main MDD is used to validate a\nconfiguration of display family features.  To validate a configuration of displayable families, simply call contains operation on the main MDD.\nTo validate a configuration that contains displayable and no-display features, both the main MDD and the relationships are inspected.  Just as the MDD containsAny operation is used to validate a configuration against an MDD, the Global MDD also\nhas a containsAny operation that can validate a configuration against a Global MDD.  The Global MDD operation utilizes the MDD containsAnyParallel operation, to validate a fully expanded configuration, the parallel operation will turn the mask into its\nown MDD and inspect that space along with the main space and all relationship MDDs.  To validate a partial configuration of both display and no display features, the parallel operation inspects the mask MDD, the main MDD and the relationships associated\nwith each deterministic feature in the configuration.  When processing a partial configuration, relationships for families that have no feature in the configuration can be ignored.\nFIG. 102 is a table 10200 that shows several example configurations, the relevant MDDs, and the containsAny call that the configuration engine 106 uses to validate the configuration.\nConflict resolution is also limited to displayable content.  As with the \"contains\" operation, when dealing with configurations that do not contain deterministic features, the main MDD contains sufficient information for the conflict resolution\nwithout including the relationships.\nAs described with reference to FIG. 47, conflict resolution begins with a minimum edit distance calculation that is performed on the main MDD.\nFor Single Conflict Resolution, the target configuration is identified by performing auto completion in the minimum edit space.  Because the main MDD includes no display content, the target configuration will also include no display content. \nThe no-display content is stripped from the configuration engine response.  Alternatively, the author decorators can be modified to ignore no-display features when adding conflict resolution to the xml response.\nFor Branched Conflict Resolution, the entire minimum edit space is used to build the response.  The minimum edit space is projected to displayable content before building the response.\nThere is no concept of displayable and non-displayable families during the first stage of authoring or determining the feature conditions.  As such, the feature conditions for displayable families may be determined with a dependency on\nno-display families.  This means that when the maximally standard auto completion algorithm uses the full configuration space; it accounts for the external relationship MDDs in addition to the main MDD.\nWhen using a Global Space (main space+relationships spaces) for maximally standard auto completion, the basic logic is the same as using an MDD.  Instead of checking a single MDD, the algorithm checks the global space--both the main MDD and the\nrelationship MDDs.  The basic operations of restrict, containsAny and domain accounts for both the main space and external relationships.\nDuring auto completion, the configuration engine 106 restricts the main space for each feature choice (S864).  When the choice is deterministic, the external relationship defines the determinant conditions for each feature.  The deterministic\nrelationship space is restricted to the feature choice to determine the determinant conditions and then the main space is restricted to the corresponding determinant conditions.\nWhen a deterministic feature has a single determinant condition, the configuration engine 106 quick-restricts the main space using the determinant condition, according to one or more embodiments (S874-S876).  The buildable space as shown in\nTable 10000 (FIG. 100) includes a main space 10002 and a relationships space 10004.  The relationships space 10004 shows that features Y2, Y5 and Y6 map to B1 as referenced by numeral 10006, and that features Y1, Y3, and Y4 map to B2 as referenced by\nnumeral 10008.  Table 10300 of FIG. 103 shows only one row remains after the relationship is restricted to the choice B1 (S870).  The configuration engine 106 quick-restricts the main space using this single superconfiguration as the bitmask.  After B1\nis chosen, the main space is restricted to B1 (S866) and is also restricted to Y2, Y5, and Y6 (S876), as shown in Table 10400 of FIG. 104, and referenced by numeral 10402.\nThe quick-restrict operation accepts a single bit mask.  This means that the main space cannot be quick-restricted to reflect a deterministic choice whenever a deterministic feature has multiple determinant conditions.  Table 10000 (FIG. 100)\nshows that family K is determined by two families [A,S] as referenced by numeral 10010.  Table 10500 of FIG. 105 shows the two rows defining the determinant conditions for feature K2.  The first row of Table 10500 shows that A2,S3; A2,S5; A2,S6 all map\nto K2 and the second row shows that A1,S3 also maps to K2.  When K2 is chosen, the main space is restricted to K2, but the configuration engine 106 cannot quick-restrict it with the K2 determinants because the restricted relationship space defines two\nsuperconfigurations.  Instead, the configuration engine 106 adds a special relWork space, as referenced by numeral 10602, to store the determinant conditions as shown FIG. 106.  After restricting to K2, relWork contains the two determinant conditions for\nK2.\nJust as the global space requires both the main MDD and all its relationships to fully define the space, relWork is necessary to fully define the restricted space.  However, if relWork is trivial (i.e., all 1s) then the configuration engine 106\ncan ignore it because it isn't further restricting the space.\nThe configuration engine 106 initializes the relWork space as a trivial space, with a single superconfiguration of all 1s, according to one or more embodiments.  When a deterministic choice is made that has multiple determinant conditions,\nrelWork is AND'ed with the restricted relationship space (S872).  If the result of the AND operation is a single superconfiguration (S874), the main space is restricted with that superconfiguration (S876) and relWork is trivialized (S878).\nReferring to FIG. 107, if the configuration engine 106 further restricts the space to M2, then there is just one row remaining in relationship M as shown in Table 10700.  When this restricted relationship space is ANDed with relWork (from FIG.\n106), just one row remains as shown in Table 10800 of FIG. 108.  This is used to restrict the main space, and then relWork is reset, with the final result shown in Table 10900 of FIG. 109.\nThe configuration engine 106 uses the containsAny operation of the maximally standard auto completion algorithm to determine if a Standard feature condition space is still valid in the restricted space, according to one or more embodiments.\nFor two MDDs, the operation mdd1.containsAny(mdd2) is equivalent to not(isEmpty(mdd1.and(mdd2)).  The ContainsAny operation can be extended to operate on two or more MDDs and is called containsAnyParallel.  For three MDDs, the operation\nmdd1.containsAnyParallel([mdd2,mdd3]) is equivalent to not(isEmpty(mdd1.and(mdd2).and(mdd3)).\nWhen dealing with deterministic relationships, this contains any operation may need to include the relWork MDD.\nIn order for the configuration engine 106 to determine if a standard feature is available in the restricted space (S812), the containsAny operation must always operate on the standard space and the main space and may need to account for the\nrelWork space and an external relationship space.  When the family is deterministic and relWork is not trivial the operation will be standardSpace.containsAny(mainSpace, rel, relWork).  The operation can skip relWork if it is trivial and will only\ninclude a relationship if the feature is deterministic (S822).\nThe configuration engine 106 determines if any standard features for A are still valid in the space from FIG. 103, by accounting for the A standard space and the main space in the containsAny operation.  There is no relationship space because A\nis not deterministic and the relWork is ignored because it is trivial (i.e., A is all is in Table 10300).\nIn order for the configuration engine 106 to determine if any standard features for B are still valid in the space from FIG. 103, the containsAny operation must account for the B standard space, the main space and relationship B space.  The\nconfiguration engine 106 ignores relWork because it is trivial.\nThe configuration engine 106 determines if any standard features for M are still valid in the space from FIG. 106, by accounting for the M standard Space, main Space, Relationship M space, and relWork in the containsAny operation.\nThe maximally standard auto completion algorithm uses domain calculation when the standard feature conditions do not identify a possible choice.  Because only the domain of a single family is needed, not all of the relationships must be\nincluded.  The domain calculation must consider the main space, the relWork space, and, if the family is deterministic, the external relationship space.  This is done by first ANDing the spaces, and then calculating the domain on the resulting space\n(S850).\nThe algorithm for maximally standard auto completion without deterministic relationships was shown previously in FIG. 93.\nThe modifications to account for deterministic relationships are: 1) Change mdd.quickRestrict to SPACE.RESTRICT; 2) Change mdd.containsAny with SPACE.containsAny, where space defines the main MDD, the relationship MDDs, and the relWork MDD\ndiscussed above in the Restrict Global Space section; and 3) Change mdd.findDomain.toListActive(Fa) to SPACE.findDomain(Fa).  The new algorithm is shown as flowcharts in FIGS. 95-99 and as software code in FIG. 110.\nThe following example illustrates the modified algorithm and references steps in the flow charts and operations in the software code where applicable.  This example will use the global space and standard feature conditions defined previously in\nTable 10000 (FIG. 100) and Table 10100 (FIG. 101).  Table 10100 also lists the family priority order, as generally referenced by numeral 10102.\nWith reference to FIG. 111, the configuration engine 106 restricts the space starting with a minimally complete configuration of Selected {Y3,E1,P1}+Included {F2} (11001, FIG. 110; S802, FIG. 95).  The configuration engine 106 makes Default\nchoices for the remaining families in priority order as defined in Table 10100 (FIG. 101), i.e.: V, R, K, B, A, M, T, I, S (S804, FIG. 95).\nReferring to FIG. 112, the configuration engine 106 determines that Family V is deterministic and includes a single standard feature condition.  To determine if standard feature V3 is available, the configuration engine 106 checks the main\nspace, standard space and deterministic relationship (S820, FIG. 97).  Operation 11004 (FIG. 110) stdV3.containsAnyParallel(mainSpace, relV) returns false because V3 is not available with the current choice Y3 (see also S840, FIG. 96).  The domain of V,\nfrom operation 1106 (FIG. 110) AND(relV,mainSpace), will identify only one possible choice (see also S852-S858, FIG. 98).  V2 is added and the newly restricted space, as determined at S864, FIG. 96 and operation 11008, FIG. 110, is shown in Table 11200\nof FIG. 112 and referenced by numeral 11202.\nWith reference to FIGS. 112-113, the configuration engine 106 determines that Family R has no standard feature conditions (S830-S836, FIG. 97; operation 11004, FIG. 110).  The domain of the restricted space identifies two possible choices--R1,\nR4 as referenced by numeral 11204 (S852-S858, FIG. 98; operation 1106, FIG. 110).  Without alternate sequencing, R1 is picked as the Default choice and the space is further restricted (S864, FIG. 99; operation 11008, FIG. 110) as shown in Table 11300 of\nFIG. 113, and referenced by numeral 11302.\nReferring back to FIG. 101, the configuration engine 106 determines that Family K has two standard feature conditions (S830-S836, FIG. 97; operation 11004, FIG. 110).  StdK1 defines K1 as standard for V1 and StdK2 defines K2 as standard for V2\nor V3.  Because V2 has been previously chosen, K2 is the only available standard choice and is added to the configuration.  The configuration engine 106 further restricts the space to reflect this choice (S864, FIG. 99; operation 11008, FIG. 110). \nFamily K is deterministic.  When RelK is restricted to K2, there are two rows remaining.  The main space cannot be quick-restricted and relWork is updated as shown in Table 11400 of FIG. 114.\nWith reference to FIG. 115, the configuration engine 106 adds B2 based on its Standard space and chooses A2 because it is standard with {R1, V2}.  The restricted space after these choices is shown in Table 11500 of FIG. 115.  Table 11500 shows\nthat the configuration engine 106 could restrict relWork to A2, minimize it to one row, use it to restrict the main space and then trivialize it; however, the containsAny optimizations (operation 11004, FIG. 110) dictate that it is actually better to\nwait until relWork is minimized by another deterministic feature.  It is actually counterproductive to restrict relWork for every choice.\nReferring to FIG. 116, the configuration engine 106 determines that Family M has standard feature conditions (S830-S836, FIG. 97; operation 11004, FIG. 110).  M1 is the only standard feature that is still available in the restricted space. \nAfter relWork is updated for M1, only one row remains, i.e., the second row of Table 11500 of FIG. 115.  This row is used to restrict the main space and relWork is trivialized, as shown by Table 11600 of FIG. 116 (S864, FIG. 99; operation 11008, FIG.\n110).  The restricted space after processing family M is shown in Table 11600.\nWith reference to FIG. 117, the configuration engine 106 adds T1 as the Default choice from its Standard Feature Condition and I1 is chosen as the Default from the possible choices I1 and I2 (S830-S836, FIG. 97; operation 11004, FIG. 110).  The\ndeterministic relationship for I shows that I1 maps to S1 or S5.  After T1 and I1 are chosen, S5 remains the only choice for family S, as shown in Table 11700 of FIG. 117.\nThe configuration engine's use of relWork to account for deterministic relationships when quick-restricting the main space, along with the containsAnyParallel operation, allows for a very efficient maximally standard auto completion algorithm. \nThis allows the configuration engine 106 to support maximally standard configurations without requiring feature condition authoring to be modified in order to account for display and no display families.\nComputing devices described herein, generally include computer-executable instructions where the instructions may be executable by one or more computing devices such as those listed above.  Computer-executable instructions may be compiled or\ninterpreted from computer programs created using a variety of programming languages and/or technologies, including, without limitation, and either alone or in combination, Java.TM., C, C++, C#, Visual Basic, Java Script, Perl, etc. In general, a\nprocessor (e.g., a microprocessor) receives instructions, e.g., from a memory, a computer-readable medium, etc., and executes these instructions, thereby performing one or more processes, including one or more of the processes described herein.  Such\ninstructions and other data may be stored and transmitted using a variety of computer-readable media.\nWhile exemplary embodiments are described above, it is not intended that these embodiments describe all possible forms of the invention.  Rather, the words used in the specification are words of description rather than limitation, and it is\nunderstood that various changes may be made without departing from the spirit and scope of the invention.  Additionally, the features of various implementing embodiments may be combined to form further embodiments of the invention.\n<BR><BR><CENTER><b>* * * * *</b></CENTER>\n<HR>\n   <CENTER>\n   <a href=http://pdfpiw.uspto.gov/.piw?Docid=10318701&homeurl=http%3A%2F%2Fpatft.uspto.gov%2Fnetacgi%2Fnph-Parser%3FSect1%3DPTO2%2526Sect2%3DHITOFF%2526p%3D1%2526u%3D%25252Fnetahtml%25252FPTO%25252Fsearch-bool.html%2526r%3D1%2526f%3DG%2526l%3D50%2526co1%3DAND%2526d%3DPTXT%2526s1%3D20170206304%2526OS%3D%2526RS%3D&PageNum=&Rtype=&SectionNum=&idkey=NONE&Input=View+first+page><img src=\"/netaicon/PTO/image.gif\" alt=\"[Image]\" border=\"0\" valign=\"middle\"></A>\n   <TABLE>\n   <TR><TD align=\"center\"><A href=\"https://certifiedcopycenter.uspto.gov/other/patft/view.html?backUrl1=http%3A//patft.uspto.gov/netacgi/nph-Parser?Sect1%3DPTO2%26Sect2%3DHITOFF%26p%3D1%26u%3D%25252Fnetahtml%25252FPTO%25252Fsearch-bool.html%26r%3D1%26f%3DG%26l%3D50%26co1%3DAND%26d%3DPTXT%26s1%3D20170206304%26OS%3D&backLabel1=Back%20to%20Document%3A%2010318701\"><IMG border=\"0\" src=\"/netaicon/PTO/cart.gif\" border=\"0\" valign=\"m\niddle\" alt=\"[View Shopping Cart]\"></A>\n   <A href=\"https://certifiedcopycenter.uspto.gov/other/patft/order.html?docNumber=10318701&backUrl1=http%3A//patft.uspto.gov/netacgi/nph-Parser?Sect1%3DPTO2%26Sect2%3DHITOFF%26p%3D1%26u%3D%25252Fnetahtml%25252FPTO%25252Fsearch-bool.html%26r%3D1%26f%3DG%26l%3D50%26co1%3DAND%26d%3DPTXT%26s1%3D20170206304%26OS%3D&backLabel1=Back%20to%20Document%3A%2010318701\">\n   <IMG border=\"0\" src=\"/netaicon/PTO/order.gif\" valign=\"middle\" alt=\"[Add to Shopping Cart]\"></A>\n   </TD></TR>\n   <TR><TD align=\"center\">\n   <A href=\"#top\"><IMG valign=\"middle\" src=\"/netaicon/PTO/top.gif\" border=\"0\" alt=\"[Top]\"></A>\n   </TD></TR>\n   </TABLE>\n   <A name=\"bottom\"></A>\n   <A href=\"/netahtml/PTO/index.html\"><IMG src=\"/netaicon/PTO/home.gif\" alt=\"[Home]\" border=\"0\" valign=\"middle\"></A>\n   <A href=\"/netahtml/PTO/search-bool.html\"><IMG src=\"/netaicon/PTO/boolean.gif\" alt=\"[Boolean Search]\" border=\"0\" valign=\"middle\"></A>\n   <A href=\"/netahtml/PTO/search-adv.htm\"><IMG border=\"0\" src=\"/netaicon/PTO/manual.gif\" alt=\"[Manual Search]\" valign=\"middle\"></A>\n   <A href=\"/netahtml/PTO/srchnum.htm\"><IMG src=\"/netaicon/PTO/number.gif\" alt=\"[Number Search]\" border=\"0\" valign=\"middle\"></A>\n   <A href=\"/netahtml/PTO/help/help.htm\"><IMG border=\"0\" src=\"/netaicon/PTO/help.gif\" alt=\"[Help]\" valign=\"middle\"></A>\n   </CENTER>\n</BODY>\n</HTML", "application_number": "15294149", "abstract": " A system is provided with a memory device and a processor. The memory\n     device is adapted to store data representative of a multi-valued decision\n     diagram (MDD) specifying a buildable space of all possible configurations\n     of a vehicle. The processor is in communication with the memory and is\n     programmed to identify an invalid configuration, and to generate a\n     restricted buildable space, including to determine an edit distance of\n     each complete path indicative of a number of features to change the\n     invalid configuration of that path to one of the valid configurations,\n     identify a minimum of the edit distances, and remove configurations\n     having edit distances larger than the minimum. The processor is further\n     programmed to identify at least one feature to change the invalid\n     configuration to at least one valid configuration based on the restricted\n     buildable space; and to generate output indicative of the at least one\n     feature to change.\n", "citations": ["4479197", "4591983", "4827423", "4873643", "4875162", "5119307", "5165015", "5225987", "5233513", "5255356", "5257387", "5260866", "5283865", "5293479", "5295067", "5295242", "5307261", "5311424", "5311437", "5353432", "5367622", "5367627", "5369566", "5394522", "5428791", "5434791", "5487135", "5499357", "5500802", "5515269", "5515524", "5546575", "5552995", "5579529", "5586039", "5590319", "5594651", "5621905", "5630025", "5675748", "5740425", "5745765", "5761063", "5777877", "5781906", "5815395", "5825651", "5844554", "5850539", "5864660", "5877966", "5963953", "5987473", "5991826", "6002854", "6035305", "6055529", "6115547", "6122560", "6125408", "6137499", "6151697", "6167380", "6167383", "6177942", "6192355", "6205446", "6208987", "6223094", "6223170", "6247128", "6259451", "6272390", "6278982", "6282537", "6300948", "6324534", "6349274", "6366922", "6377956", "6405308", "6407761", "6412012", "6430730", "6519588", "6523040", "6536014", "6549908", "6556991", "6557002", "6581068", "6615220", "6633788", "6647305", "6678882", "6687705", "6757678", "6810401", "6836766", "6839711", "6850895", "6850921", "6853996", "6898472", "6918124", "6937966", "6938038", "6965887", "6986104", "6988014", "7003360", "7039602", "7043309", "7050956", "7062478", "7065499", "7069537", "7076507", "7076521", "7082426", "7093010", "7096350", "7096465", "7107297", "7127424", "7188333", "7188335", "7200582", "7225038", "7225197", "7233885", "7237187", "7246087", "7328177", "7337174", "7337179", "7343212", "7343584", "7386562", "7424444", "7461049", "7487072", "7509326", "7516103", "7567922", "7580871", "7584079", "7650296", "7698170", "7760746", "7797177", "7809758", "7860690", "7869981", "7873503", "7882057", "7930149", "7953639", "7953767", "7953779", "7992145", "7996329", "8078489", "8249885", "8280700", "8306795", "8463682", "8665731", "8805825", "8918750", "9020880", "9098854", "20020013775", "20020035463", "20020052803", "20020095348", "20020107861", "20020116417", "20020124005", "20020143653", "20020161668", "20020165701", "20020177911", "20020184308", "20030041088", "20030046047", "20030055751", "20030061238", "20030069737", "20030130749", "20030177412", "20030195806", "20030216951", "20040064441", "20040068485", "20040073436", "20040073448", "20040102995", "20040162835", "20040167906", "20050071146", "20050080648", "20050114158", "20050163143", "20050268255", "20060064685", "20060095711", "20060100829", "20070094204", "20090323539", "20110082675", "20120253754", "20140019739", "20150120490", "20150331974", "20150379442"], "related": ["62280609", "62352463"]}, {"id": "20170206305", "patent_code": "10318703", "patent_name": "Maximally standard automatic completion using a multi-valued decision\n     diagram", "year": "2019", "inventor_and_country_data": " Inventors: \nHunsaker; Melinda Kaye (Canton, MI), Goodman; Bryan Roger (Northville, MI), Fradkin; Yakov M. (Farmington Hills, MI)  ", "description": "<BR><BR>CROSS-REFERENCE TO RELATED APPLICATIONS\nThis application claims the benefit of U.S. provisional application Ser.\n     No. 62/280,609 filed Jan. 19, 2016 and U.S. provisional application Ser.\n     No. 62/352,463 filed Jun. 20, 2016, the disclosures of which are hereby\n     incorporated in their entirety by reference herein.\n         <HR>\n<CENTER><b><i>Claims</b></i></CENTER> <HR> <BR><BR>What is claimed is: 1.  A method comprising: storing, in a memory, data representative of a multi-valued decision diagram (MDD) specifying a buildable space of all possible configurations of a\nvehicle, the MDD including a root node, a truth node, and at least one level of intervening nodes, each level of the MDD corresponding to a family of mutually-exclusive features represented by at least one node, each intervening node of a level\nconnecting to nodes of a next adjacent level by outgoing edges having labels indicating valid features of the family and to nodes of a prior adjacent level by incoming edges that are outgoing edges of the prior adjacent level, such that a complete path\nfrom the root node through the outgoing edges to the truth node defines at least one of the valid configurations;  identifying a minimally complete configuration including features having Selected and Included feature states;  generating a restricted\nbuildable space of the MDD based on the minimally complete configuration;  generating a further restricted buildable space of the MDD including features having Default feature states, including identifying families that do not include features with\nSelected or Included feature states as families to change, determining a weight of each path in the restricted buildable space, indicative of a priority of the features along the path based on predetermined data, identifying the maximum weight of all\npaths, removing configurations having weights that are less than the maximum weight, and for each family to change along the maximum weight path, set the highest priority feature to the Default feature state;  wherein each family along the maximum weight\npath includes a feature having a Selected, Included or Default feature state to generate a complete configuration.\n2.  The method of claim 1, wherein the restricted buildable space is generated during a downward traversal of the MDD and the path weights are calculated on an upward traversal of the MDD.\n3.  The method of claim 1, wherein each feature is assigned a weight such that each path is uniquely weighted.\n4.  The method of claim 3 wherein the weight of each path is represented by a bitset indicative of a sum of the weight of each feature along the path.\n5.  The method of claim 4, wherein identifying the maximum weight of all paths further comprises sorting the bitset for each path in descending order.\n6.  The method of claim 1, wherein the weight of each feature is defined by an alternate structure separate from the MDD.\n7.  A method comprising: storing, in a memory, data representative of a multi-valued decision diagram (MDD) specifying a buildable space of all possible configurations of a vehicle, the MDD including a root node, a truth node, and at least one\nlevel of intervening nodes, each level of the MDD corresponding to a family of mutually-exclusive features represented by at least one node, each intervening node of a level connecting to nodes of a next adjacent level by outgoing edges having labels\nindicating valid features of the family and to nodes of a prior adjacent level by incoming edges that are outgoing edges of the prior adjacent level, such that a complete path from the root node through the outgoing edges to the truth node defines at\nleast one of the valid configurations;  identifying a minimally complete configuration including features having Selected and Included feature states;  generating a restricted buildable space of the MDD based on the minimally complete configuration; \nidentifying families that do not include features with Selected or Included feature states as families to complete;  sorting the families to complete by a predefined family priority order;  for each family to complete in priority order, if the family has\na standard feature available in the restricted buildable space, setting the standard feature to a Default feature state, otherwise setting a highest priority available feature to the Default feature state, and generating a further restricted buildable\nspace of the MDD based on the Default feature;  and identifying a complete configuration once each family to complete is assigned a Default feature.\n8.  The method of claim 7, further comprising setting a highest priority standard feature to a Default feature state for each family to complete having more than one standard feature.\n9.  The method of claim 7, further comprising determining an availability of each feature from predetermined feature conditions indicative of relationships between the families, including: (i) standard for a feature that is included in a base\nvehicle;  and (ii) optional for a feature that is not included in the base vehicle.\n10.  A system comprising: a memory device adapted to store data representative of at least one multi-valued decision diagram (MDD) specifying a total buildable space of all possible configurations of a vehicle, each MDD including a root node, a\ntruth node, and at least one level of intervening nodes, each level of each MDD corresponding to a family of mutually-exclusive features represented by at least one node, each intervening node of a level connecting to nodes of a next adjacent level by\noutgoing edges having labels indicating valid features of the family and to nodes of a prior adjacent level by incoming edges that are outgoing edges of the prior adjacent level, such that a complete path from the root node through the outgoing edges to\nthe truth node defines at least one of the valid configurations;  and a processor in communication with the memory, programmed to identify a partial configuration including features having Selected and Included feature states;  generate a restricted\nbuildable space of the total buildable space based on the partial configuration;  identify families that do not include features with Selected or Included feature states as families to complete;  for each family to complete in priority order, add any\navailable standard features for the family to a possible set, if the possible set is empty, add a domain space of the family to the possible set, set the highest priority feature of the possible set to a Default feature state according to an alternate\nsequence indicative of priority of the features, and generate a further restricted buildable space of the total buildable space based on the Default feature;  and generate a complete configuration including features having Default feature states for each\nfamily to complete.\n11.  The system of claim 10, wherein the processor is further programmed to: initialize the possible set to an empty set;  and for each feature, find a list of essential sets for the feature, and if an intersection of all spaces in the essential\nset is not empty, add the feature to the possible set;  wherein the intersection is empty if the feature is not standard or the feature is not currently available with the partial configuration.\n12.  The system of claim 11, wherein, to find the list of essential sets for the feature, the processor is further programmed to: initialize a setlist to the restricted buildable space;  if a relationships work object is non-trivial, add the\nrelationships work object to the setlist, wherein the relationship works object defines a temporary object that is used to process specific relationship conditions between families based on an order the families are processed;  if a standard space for\nthe feature is not empty, add the standard space to the setlist;  if the family is deterministic, add a relationship space defining relationships between the feature and features of other families to the setlist;  and return the setlist as the list of\nessential sets.\n13.  The system of claim 10, wherein the processor is further programmed to generate the domain of a family, including to: determine the domain space as an intersection of the restricted buildable space and a relationships work object defining a\ntemporary object;  if a product definition indicates that the family is a deterministic family defined by at least one determinant family in the configuration, further intersect the domain space with a relationship space defining the deterministic\nfamily;  and add any of the features present in the domain space to the family domain.\n14.  The system of claim 10, wherein, to generate the further restricted buildable space, the processor is further programmed to: restrict the restricted buildable space according to the Default feature;  and if the family is deterministic,\nrestrict a relationship space to the Default feature to determine a temporary relationship space, generate an updated relationships work object by intersecting the relationships work object and the temporary relationship space, and if the relationship\nworks object has a single path, generate an updated restricted buildable space by intersecting the restricted buildable space and the relationships work object, and reset the relationship works object.\n15.  The system of claim 14, wherein the restricted buildable space, the relationship space and the relationship works object further comprise MDDs.\n16.  The system of claim 10, wherein the processor is further programmed to: identify a displayable family as any family having features that are displayed to a user on a user interface;  and specify that displayable families are not\ndeterministic.\n17.  A system comprising: a memory device adapted to store data representative of a multi-valued decision diagram (MDD) specifying a buildable space of all possible configurations of a vehicle, the MDD including a root node, a truth node, and at\nleast one level of intervening nodes, each level of the MDD corresponding to a family of mutually-exclusive features represented by at least one node, each intervening node of a level connecting to nodes of a next adjacent level by outgoing edges having\nlabels indicating valid features of the family and to nodes of a prior adjacent level by incoming edges that are outgoing edges of the prior adjacent level, such that a complete path from the root node through the outgoing edges to the truth node defines\nat least one of the valid configurations;  and a processor in communication with the memory, programmed to identify a minimally complete configuration including features having Selected and Included feature states;  generate a restricted buildable space\nof the MDD based on the minimally complete configuration;  generate a further restricted buildable space of the MDD including features having Default feature states, including identify families that do not include features with Selected or Included\nfeature states as families to change, determine a weight of each path in the restricted buildable space, indicative of a priority of the features along the path based on predetermined data, identify the maximum weight of all paths, remove configurations\nhaving weights that are less than the maximum weight, and for each family to change along the maximum weight path, set the highest priority feature to the Default feature state;  wherein each family along the maximum weight path includes a feature having\na Selected, Included or Default feature state to generate a complete configuration.\n18.  The system of claim 17, wherein each feature is assigned a weight such that each path is uniquely weighted.\n19.  The system of claim 18, wherein the weight of each path is represented by a bitset indicative of a sum of the weight of each feature along the path.\n20.  The system of claim 17, wherein the weight of each feature is defined by an alternate structure separate from the MDD. <HR> <CENTER><b><i>Description</b></i></CENTER> <HR> <BR><BR>TECHNICAL FIELD\nOne or more embodiments generally relate to systems and methods for configuring a product.\n<BR><BR>BACKGROUND\nProduct configuration is an aspect of industries that offer customizable products with a wide variety of features.  The process of selecting a configuration, or features that include a configuration, is used in multiple aspects of marketing and\nsales, order management and production planning, and product development.  Examples include virtually constructing an ideal product (e.g., a vehicle) using a build-and-price application or selecting features for a prototype.\nThe product definition or product offering in the automotive industry is often of staggering dimensionality and size.  It is common for a vehicle to be offered with thirty or more optional feature categories, such as paint color, engine size,\nradio type, and wheel style.  Allowing a user to quickly explore a complex space that could include more than 10.sup.30 valid configurations is a challenging problem in constraints programming.\n<BR><BR>SUMMARY\nIn one embodiment, a method is provided for storing, in a memory, data representative of a multi-valued decision diagram (MDD) specifying a buildable space of all possible configurations of a vehicle.  The MDD includes a root node, a truth node,\nand at least one level of intervening nodes.  Each level of the MDD corresponds to a family of mutually-exclusive features represented by at least one node.  Each intervening node of a level connects to nodes of a next adjacent level by outgoing edges\nhaving labels indicating valid features of the family and to nodes of a prior adjacent level by incoming edges that are outgoing edges of the prior adjacent level, such that a complete path from the root node through the outgoing edges to the truth node\ndefines at least one of the valid configurations.  A minimally complete configuration including features having Selected and Included feature states is identified.  A restricted buildable space of the MDD is generated, based on the minimally complete\nconfiguration.  A further restricted buildable space of the MDD including features having Default feature states is generated.  Families that do not include features with Selected or Included feature states are identified as families to change.  A weight\nof each path in the restricted buildable space, indicative of a priority of the features along the path based on predetermined data, is determined.  And each feature is assigned a unique weight.  The maximum weight of all paths is identified. \nConfigurations having weights that are less than the maximum weight are removed.  For each family to change along the maximum weight path, the highest priority feature is set to the Default feature state.  Each family along the maximum weight path\nincludes a feature having a Selected, Included or Default feature state to generate a complete configuration.\nIn another embodiment, a method is provided for storing, in a memory, data representative of a multi-valued decision diagram (MDD) specifying a buildable space of all possible configurations of a vehicle.  The MDD includes a root node, a truth\nnode, and at least one level of intervening nodes.  Each level of the MDD corresponds to a family of mutually-exclusive features represented by at least one node.  Each intervening node of a level connecting to nodes of a next adjacent level by outgoing\nedges having labels indicating valid features of the family and to nodes of a prior adjacent level by incoming edges that are outgoing edges of the prior adjacent level, such that a complete path from the root node through the outgoing edges to the truth\nnode defines at least one of the valid configurations.  A minimally complete configuration including features having Selected and Included feature states is identified.  A restricted buildable space of the MDD is generated based on the minimally complete\nconfiguration.  Families that do not include features with Selected or Included feature states are identified as families to complete.  The families to complete are sorted by a predefined family priority order.  For each family to complete in priority\norder, if the family has a standard feature available in the restricted buildable space, the standard feature is set to a Default feature state, otherwise a highest priority available feature is set to the Default feature state.  A further restricted\nbuildable space of the MDD is generated based on the Default feature state.  A complete configuration is identified once each family to complete is assigned a Default feature state.\nIn yet another embodiment, a system is provided with a memory device and a processor.  The memory device is adapted to store data representative of at least one multi-valued decision diagram (MDD) that specifies a total buildable space of all\npossible configurations of a vehicle.  Each MDD includes a root node, a truth node, and at least one level of intervening nodes.  Each level of each MDD corresponds to a family of mutually-exclusive features that are represented by at least one node. \nEach intervening node of a level connects to nodes of a next adjacent level by outgoing edges having labels indicating valid features of the family and to nodes of a prior adjacent level by incoming edges that are outgoing edges of the prior adjacent\nlevel, such that a complete path from the root node through the outgoing edges to the truth node defines at least one of the valid configurations.  The processor is in communication with the memory and is programmed to identify a partial configuration\nincluding features having Selected and Included feature states; generate a restricted buildable space of the total buildable space based on the partial configuration; and identify families that do not include features with Selected or Included feature\nstates as families to complete.  The processor is further programmed to, for each family to complete in priority order, add any available standard features for the family to a possible set, if the possible set is empty, add a domain space of the family\nto the possible set, select the highest priority feature of the possible set as a Default feature state according to an alternate sequence indicative of priority of the features, and generate a further restricted buildable space of the total buildable\nspace based on the Default feature state.  The processor is also further programmed to generate a complete configuration including features having Default feature states for each family to complete.\nIn still yet another embodiment, a system is provided with a memory device and a processor.  The memory device is adapted to store data representative of a multi-valued decision diagram (MDD) that specifies a buildable space of all possible\nconfigurations of a vehicle.  The MDD includes a root node, a truth node, and at least one level of intervening nodes.  Each level of the MDD corresponds to a family of mutually-exclusive features that are represented by at least one node.  Each\nintervening node of a level connects to nodes of a next adjacent level by outgoing edges having labels indicating valid features of the family and to nodes of a prior adjacent level by incoming edges that are outgoing edges of the prior adjacent level,\nsuch that a complete path from the root node through the outgoing edges to the truth node defines at least one of the valid configurations.  The processor is in communication with the memory and is programmed to identify a minimally complete\nconfiguration including features having Selected and Included feature states; and to generate a restricted buildable space of the MDD based on the minimally complete configuration.  The processor is further programmed to generate a further restricted\nbuildable space of the MDD including features having Default feature states, including identify families that do not include features with Selected or Included feature states as families to change, determine a weight of each path in the restricted\nbuildable space, indicative of a priority of the features along the path based on predetermined data, identify the maximum weight of all paths, remove configurations having weights that are less than the maximum weight, and for each family to change\nalong the maximum weight path, set the highest priority feature to the Default feature state.  Each family along the maximum weight path includes a feature having a Selected, Included or Default feature state to generate a complete configuration.\n<BR><BR>BRIEF DESCRIPTION OF THE DRAWINGS\nFIG. 1 is a block diagram of a product configuration system, according to one or more embodiments;\nFIG. 2 is an application programming interface illustrating an application of the product configuration system of FIG. 1 including a configuration engine;\nFIG. 3 is a table illustrating configurations expressed in conjunctive normal form;\nFIG. 4 is a table illustrating configurations expressed in conjunctive normal form and in binary form;\nFIG. 5 is a table illustrating mappings of the configurations of FIG. 4;\nFIG. 6 is a table illustrating multiple configurations and a superconfiguration;\nFIG. 7 is a table illustrating multiple superconfigurations;\nFIG. 8 is a table illustrating the interaction of superconfigurations;\nFIG. 9 is another table illustrating the interaction of superconfigurations;\nFIG. 10 is a table depicting a buildable space according to one or more embodiments;\nFIG. 11 is a table depicting overlapping configurations;\nFIG. 12 is a table depicting a feature mask;\nFIG. 13 is a multi-valued decision diagram (MDD) representing the buildable space of FIG. 10, according to one or more embodiments;\nFIG. 14 is a comparison table;\nFIG. 15 is a diagram illustrating a reduction of the MDD of FIG. 13;\nFIG. 16 is a diagram illustrating merging of duplicate MDD nodes;\nFIG. 17 is a diagram illustrating MDD compression with deterministic families;\nFIG. 18 is a window displayed to a user based on a conflict resolution procedure of the configuration engine of FIG. 2 according to one embodiment;\nFIG. 19 is a window displayed to the user based on a conflict resolution procedure of the configuration engine of FIG. 2 according to another embodiment;\nFIG. 20 is a diagram illustrating a containsAny operation performed by the configuration engine according to one embodiment;\nFIG. 21 is another diagram illustrating a containsAny operation performed by the configuration engine according to another embodiment;\nFIG. 22 is a table listing a restricted buildable space of the buildable space in FIG. 10;\nFIG. 23 is a diagram illustrating a restricted buildable space of the buildable space in FIG. 13 and the table of FIG. 22;\nFIG. 24 is a flowchart illustrating a method for evaluating an MDD using reversible restrictions, according to one or more embodiments;\nFIG. 25 is a diagram illustrating an example of various steps of the method of FIG. 24;\nFIG. 26 is a flowchart illustrating a subroutine of the method of FIG. 24;\nFIG. 27 is another flowchart illustrating a subroutine of the method of FIG. 24;\nFIG. 28 is yet another flowchart illustrating a subroutine of the method of FIG. 24;\nFIG. 29 is a comparison table;\nFIG. 30 is a table illustrating a reduction of the buildable space of FIG. 10;\nFIG. 31 is a table illustrating a projected space after the overlap has been removed and the space has been compressed;\nFIG. 32 is a diagram illustrating the table of FIG. 30;\nFIG. 33 is a table illustrating combinations of features of the buildable space of FIG. 13;\nFIG. 34 is a flowchart illustrating a method for determining MDD feature states according to one or more embodiments;\nFIG. 35 is a table illustrating a set of superconfigurations;\nFIG. 36 is an example of a table illustrating a restricted domain after various steps of the method of FIG. 34;\nFIG. 37 is another example of a table illustrating a restricted domain after various steps of the method of FIG. 34;\nFIG. 38 is a table illustrating an example of the results of the method of FIG. 34;\nFIG. 39 is a flowchart illustrating another method for determining MDD feature states according to one or more embodiments;\nFIG. 40 is a flowchart illustrating a subroutine of the method of FIG. 39;\nFIG. 41 is another flowchart illustrating a subroutine of the method of FIG. 39;\nFIG. 42 is yet another flowchart illustrating a subroutine of the method of FIG. 39;\nFIG. 43 is another flowchart illustrating a subroutine of the method of FIG. 39;\nFIG. 44 is yet another flowchart illustrating a subroutine of the method of FIG. 39;\nFIG. 45 is a diagram illustrating an example of various steps of the method of FIG. 39;\nFIG. 46 is another diagram illustrating an example of various steps of the method of FIG. 39;\nFIG. 47 is a flowchart illustrating a method for resolving conflicts between configurations according to one or more embodiments;\nFIG. 48 is a flowchart illustrating a subroutine of the method of FIG. 47;\nFIG. 49 is a diagram illustrating an example of various steps of the method of FIG. 47;\nFIG. 50 is another flowchart illustrating a subroutine of the method of FIG. 47;\nFIG. 51 is yet another flowchart illustrating a subroutine of the method of FIG. 47;\nFIG. 52 is still yet another flowchart illustrating a subroutine of the method of FIG. 47;\nFIG. 53 is a table illustrating an example of additions and subtractions for the diagram of FIG. 49 according to various steps of the method of FIG. 47;\nFIG. 54 is a window illustrating an example of additions and subtractions that are displayed to the user based on various steps of the method of FIG. 47 according to one embodiment;\nFIG. 55 is a window illustrating an example of additions and subtractions that are displayed to the user based on various steps of the method of FIG. 47 according to another embodiment;\nFIG. 56 is a table illustrating a compression of three superconfigurations to two superconfigurations, according to one embodiment;\nFIG. 57 is a window illustrating an example of a resolution object that is displayed to the user based on various steps of the method of FIG. 47 according to another embodiment;\nFIG. 58 is another flowchart illustrating a subroutine of the method of FIG. 47;\nFIG. 59 is yet another flowchart illustrating a subroutine of the method of FIG. 47;\nFIG. 60 is still yet another flowchart illustrating a subroutine of the method of FIG. 47;\nFIG. 61 is another flowchart illustrating a subroutine of the method of FIG. 47;\nFIG. 62 is yet another flowchart illustrating a subroutine of the method of FIG. 47;\nFIG. 63 is still yet another flowchart illustrating a subroutine of the method of FIG. 47;\nFIG. 64 is a diagram illustrating an example of various steps of the method of FIG. 47;\nFIG. 65 is a table listing an invalid configuration as a bitset;\nFIG. 66 is a table illustrating the minimum edit space of the configuration of FIG. 65 converted to a matrix, as determined by various steps of the method of FIG. 47;\nFIG. 67 is a table illustrating a bitwise conjunction (AND) of the domain of the edit space from FIG. 66 with the invalid configuration from FIG. 65;\nFIG. 68 is a table illustrating the minimum edit space from FIG. 66 after it is trimmed to the families to change from FIG. 67;\nFIG. 69 is an example target matrix for a selection of a feature as determined by various steps of the method of FIG. 47;\nFIG. 70 is an example target matrix for a selection of another feature as determined by various steps of the method of FIG. 47;\nFIG. 71 is software code illustrating an example final resolution object, according to one or more embodiments;\nFIG. 72 is a window illustrating an example prompt provided to the user as part of a guided resolution;\nFIG. 73 is a window illustrating an example of another prompt provided to the user as part of the guided resolution;\nFIG. 74 is a window illustrating an example of yet another prompt provided to the user as part of the guided resolution;\nFIG. 75 is a diagram illustrating an example of various steps of the remove partial matches subroutine of FIG. 58;\nFIG. 76 is a table illustrating an example of various steps of the remove partial matches subroutine of FIG. 58;\nFIG. 77 is a table illustrating an example of various steps of the minimum edit space calculation of FIG. 48;\nFIG. 78 is another table illustrating an example of various steps of the minimum edit space calculation of FIG. 48;\nFIG. 79 is yet another table illustrating an example of various steps of the minimum edit space calculation of FIG. 48;\nFIG. 80 is still yet another table illustrating an example of various steps of the minimum edit space calculation of FIG. 48;\nFIG. 81 is another table illustrating an example of various steps of the minimum edit space calculation of FIG. 48;\nFIG. 82 is a flow chart illustrating a method for automatically completing a configuration according to one or more embodiments;\nFIG. 83 is a diagram illustrating a buildable space;\nFIG. 84 is a table that defines an alternate sequence structure for defining path weights of the buildable space of FIG. 83;\nFIG. 85 is a diagram illustrating an example of various steps of the method of FIG. 82 performed on the buildable space of FIG. 83;\nFIG. 86 is table illustrating path weight;\nFIG. 87 is another table illustrating path weight;\nFIG. 88 is yet another table illustrating path weight;\nFIG. 89 is a diagram illustrating an example of various steps of the method of FIG. 82 performed on the buildable space of FIG. 85;\nFIG. 90 is another table illustrating path weight;\nFIG. 91 is a table illustrating a matrix that defines the same buildable space as the diagram of FIG. 17;\nFIG. 92 is a table illustrating the standard feature conditions for the product definition defining the buildable space of FIG. 91;\nFIG. 93 is software code illustrating a method for automatically completing a configuration using a maximally standard algorithm according to one or more embodiments;\nFIG. 94 is a diagram illustrating an example of various steps of the method of FIG. 93;\nFIG. 95 is a flowchart illustrating another method for automatically completing a configuration using a maximally standard algorithm according to one or more embodiments;\nFIG. 96 is a flowchart illustrating a subroutine of the method of FIG. 95;\nFIG. 97 is another flowchart illustrating a subroutine of the method of FIG. 95;\nFIG. 98 is yet another flowchart illustrating a subroutine of the method of FIG. 95;\nFIG. 99 is still yet another flowchart illustrating a subroutine of the method of FIG. 95;\nFIG. 100 is a table illustrating a buildable space;\nFIG. 101 is a table illustrating standard feature conditions;\nFIG. 102 is a table illustrating an example of various steps of the method of FIG. 95;\nFIG. 103 is another table illustrating an example of various steps of the method of FIG. 95;\nFIG. 104 is yet another table illustrating an example of various steps of the method of FIG. 95;\nFIG. 105 is still yet another table illustrating an example of various steps of the method of FIG. 95;\nFIG. 106 is another table illustrating an example of various steps of the method of FIG. 95;\nFIG. 107 is yet another table illustrating an example of various steps of the method of FIG. 95;\nFIG. 108 is still yet another table illustrating an example of various steps of the method of FIG. 95;\nFIG. 109 is another table illustrating an example of various steps of the method of FIG. 95;\nFIG. 110 is software code illustrating an example of various steps of the method of FIG. 95;\nFIG. 111 is another table illustrating an example of various steps of the method of FIG. 95;\nFIG. 112 is yet another table illustrating an example of various steps of the method of FIG. 95;\nFIG. 113 is still yet another table illustrating an example of various steps of the method of FIG. 95;\nFIG. 114 is another table illustrating an example of various steps of the method of FIG. 95;\nFIG. 115 is yet another table illustrating an example of various steps of the method of FIG. 95;\nFIG. 116 is still yet another table illustrating an example of various steps of the method of FIG. 95; and\nFIG. 117 is another table illustrating an example of various steps of the method of FIG. 95.\n<BR><BR>DETAILED DESCRIPTION\nAs required, detailed embodiments of the present invention are disclosed herein; however, it is to be understood that the disclosed embodiments are merely exemplary of the invention that may be embodied in various and alternative forms.  The\nfigures are not necessarily to scale; some features may be exaggerated or minimized to show details of particular components.  Therefore, specific structural and functional details disclosed herein are not to be interpreted as limiting, but merely as a\nrepresentative basis for teaching one skilled in the art to variously employ the present invention.\nWith reference to FIG. 1, a product configuration system is illustrated in accordance with one or more embodiments and generally referenced by numeral 100.  The product configuration system 100 includes a server 102 and a configurator\napplication 104.  The configurator application 104 includes a configuration engine 106.  The server 102 includes memory 108 and a processor 110 for storing and operating the configurator application 104.  The product configuration system 100 communicates\nwith a user device, such as a personal computer 112 and/or a mobile device 114 (e.g., a tablet, a mobile phone, and the like), each of which include memory and a processor.  The configurator application 104 includes a \"front-end\" application (shown in\nFIG. 2) that may be installed to the user device 112, 114 from a computer-readable storage medium such as a CD-ROM, DVD or USB thumb drive.  Alternatively, the front-end application may be downloaded from the server 102 to the client device 112, 114 via\nan internet connection 116.  The design and efficiency of the application 104 therefore allows it to be optimized to run on multiple various operating system platforms and on devices having varying levels of processing capability and memory storage.\nThe configurator application 104 allows a user to explore a product offering, where the product is defined by selecting multiple features.  A common example is a build-and-price website that allows a user to customize a product by choosing\nfeatures such as size and color.  The configuration engine 106 validates the customized product (i.e., the configuration) as the user selects different features.\nThe product offering, or product definition, includes all of the allowed ways of combining features (or parts, options, or attributes) in order to make a complete product.  For example, a company might sell a product in two levels (e.g., base\nand luxury), A1 and A2, and in three colors, B1, B2 and B3.  Further, the company only offers the base model, A1, in one color, B1.  Features are grouped into families, in this case family A-\"level\" and family B-\"color.\" The product configuration space\nincludes the following four configurations: A1B1, A2B1, A2B2, and A2B3.  Product definition often comprises rules or constraints that limit or allow relationships between features.  In this example the rule might be \"A1 requires B1.\" A complex product\ncan be defined by thousands or even tens of thousands of rules.\nThe configurator application 104 allows the user to select options or features to create or modify a configuration.  When a user changes a configuration by adding and/or removing a feature, the configuration engine 106 validates the new\nconfiguration.  To perform this validation, the configuration engine 106 determines if the selected configuration fits within the allowed product space.  If the new configuration is invalid, the configuration engine 106 either prompts the user to make\nchanges, or make the changes itself according to a predefined hierarchy.  For example, the monitor of the personal computer 112 shown in FIG. 1 depicts a message window that is displayed to the user indicating changes to resolve the conflict between\nselected features.  The validation and conflict resolution is performed quickly (e.g., less than 2 seconds) and uses little memory and processing.  Ideally, this allows the user to explore the buildable space of allowable product configurations, often\nwhile viewing information associated with the configuration such as price or images.\nUsers interact with front-end applications that present the product information, e.g., on the monitor of their pc 112, and allow them to explore the buildable space.  Although, the configuration engine 106 is different from the front-end\napplication that is displayed on the pc 112, the applications interact closely with each other.  Examples of front-end applications include build-and-price websites, mobile shopping applications, interactive shopping kiosks, and back-office order entry\nand management systems.  When these front-end applications populate product information, they can communicate with the configuration engine 106.  The only people who interact directly with the configuration engine 106 are back-office users tending to the\ndata stored in the server 102.  The product configuration application 104 primarily interacts with other applications.\nIn the computer science field, exploration of a configuration space that is defined by rules or constraints is called constraint programming.  A configuration space can also be defined by a model that is a representation of the possible product\nconfigurations.  Many methods exist in the literature to solve configuration problems, with some using a constraints programming approach and others operating on product definition models.\nReferring to FIG. 2, an application programming interface (API) is illustrated in accordance with one or more embodiments, and generally referenced by numeral 120.  The API 120 illustrates the inputs, steps, and outputs of the configurator\napplication 104.  The configurator application 104 is contained within the server 102 and the user device (pc 112 and/or mobile device 114) according to one embodiment, and may be implemented using hardware and/or software control logic as described in\ngreater detail herein.\nThe configurator application 104 includes a database (DB) 122 for storing data as a catalog entry.  Each catalog entry will store the vehicle attributes (make, model, year, etc.), buildable product space, and extended feature attributes (images,\nprices, detailed descriptions, sales codes, etc.).  The data may be directly processed as is shown by a product definition data source 124, or it may come through a catalog management API 126.  The configurator application 104 also includes an extract,\ntransform and load (ETL) process 128 that provides an interface between the DB 122 and the product definition data source 124 and the catalog management API 126.  The configurator application 104 accesses data from the DB 122 and temporarily saves a copy\nof it in cache memory 130.\nThe configurator application 104 includes one or more \"front-end\" applications or \"top hats\" 132 that are accessible from the user device 112, 114.  Examples of such \"front-end\" applications 132 include consumer build and price sites, management\nlease ordering sites, and dealer ordering applications.\nThe configurator application 104 includes a service API 134 and a web service controller 136 for coordinating the user's requests.  The service API 134 includes a configuration service 138, an enumeration service 140 and a configuration details\nservice 142.\nThe configurator application 104 includes a plurality of processing engines 144, for optimizing the data provided to the front-end applications 132.  The engines include: the configuration engine 106, an image engine 146, a mapping engine 148\nand a pricing engine 150.  The image engine 146 provides one or more images associated with features of the configuration.  The mapping engine 148 provides feature codes from one or more feature code dictionaries.  For example, manufacturing systems and\nsales systems may use different codes for the same feature, and the mapping engine translates between the different coding schemes.  The pricing engine 150 provides pricing associated with the complete configurations and with individual features.  The\npricing engine 150 can also provide changes in pricing associated with changes in the configuration or features.\nThe configurator application 104 also includes a catalog controller 152 that lists which product definitions are available.  The catalog controller 152 receives a catalog request (e.g., what products are available), and provides a response\n(e.g., product A, product B and product C).  Then the user selects a product, and the front end application 132 submits a configuration load request.  Then the web service controller 136 returns a default configuration.\nThe web service controller 136 is a simple object access protocol (SOAP) web service using XML, messages, according to one embodiment.  The service API 134 provides an XML request to the web service controller 136 based on each user selection\nmade in the front-end applications 132.  In other embodiments the web service controller 136 uses other protocol.\nThe web service controller 136 provides an XML response to the service API 134 in response to each XML request.  The web service controller 136 parses each XML request, makes appropriate calls to the processing engines 144 or catalog controller\n152, and transforms the output of the configuration engine 106, the image engine 146, the mapping engine 148 and the pricing engine 150 into the appropriate XML response.  The web service controller 136 includes author decorators 154 that are responsible\nfor building up each portion of the response, and includes logic to retrieve data from the database 122 via the cache 130 and save the data as a working copy.\nThe configuration engine 106 operates with reference to a valid buildable space.  The buildable space is also referred to as the product offering and is defined in terms of features that are grouped into mutually exclusive family sets.  All of\nthe possible features are grouped into families such that a valid configuration will contain one and only one feature from each family.\nIn one example product definition of a vehicle, (Vehicle A), exterior paint color is defined by the family PAA and its features are Green (PNWAD), Magnetic (PN4DQ), Blue1 (PNMAE), Red1 (PN4A7), Red2 (PNEAM), Black (PN3KQ), Silver (PN4AG), Orange\n(PN4AH), White (PNYW3), and Blue2 (PN4MAG).\nThe configurator application 104 uses extended feature attributes, or metadata associated with a feature, such as feature name and feature description when presenting the information to a user.  However, the configuration engine 106 uses feature\nand family codes.  A fully qualified feature is its \"family dot feature\" code, such as PAA.PNEAM to represent the paint family with paint color Red2.\nEach point of variation in the product specification can be considered a dimension where a value is selected.  The large number of these variation points on a motor vehicle results in many valid configurations.  Traditionally the large number of\nvalid configurations in this buildable space has been responsible for much computational effort to perform the configuration process, which may be referred to as \"the curse of dimensionality.\" The configuration system 100 provides improvements over\ntraditional systems because it operates efficiently even on highly complex buildable spaces, e.g. those containing more than 10.sup.24 valid configurations.\nA configuration is a particular product instance specified by a set of features.  Each feature belongs to exactly one family.  There may be at most one feature selected from each family.  A complete configuration contains exactly one feature\nfrom each and every family.  A partial configuration will include features from a subset of the families, and one or more families will not have a feature choice specified.\nIn a build and price application, the configuration engine 106 will typically work in complete configurations.  Partial configurations are useful for searching or filtering configurations, as would be done to find and amend orders in an order\nmanagement system.\nSome features are optional, such as moonroof, and a user may order a vehicle without the feature.  But, a complete configuration must still contain a choice for the family.  A \"less feature\" is used to specify the absence of an option.  For\nexample, Vehicle A, which has an optional power moonroof, the family (CHA) contains two features: without the moonroof (i.e., \"less moonroof\"--CHAAA) and with the moonroof (i.e., \"moonroof\"--CHAAC).  The buildable space defines all valid configurations.\nWith reference to FIGS. 3-5, a configuration can be expressed in a variety of different forms.  A configuration can be expressed in conjunctive normal form (CNF).  For example, in one embodiment, a product is defined by four families: A, B, C\nand D; where A, C, and D each have two possible choices, and B has three possible choices.  If there are no restrictions on what features can occur together (other than a single feature choice for each family), the set of choices can be defined as\n(A1|A2) & (B1|B2|B3) & (C1|C2) & (D1|D2).  For a full configuration, each clause will reduce to a single literal or selection for each family (e.g., A1, B1, C1, D1).\nFIG. 3 depicts a CNF Table 300 with two possible configurations.  The CNF table 300 includes a first CNF configuration 302 and a second CNF configuration 304.\nWith reference to FIG. 4, a configuration can also be expressed in binary form by a string of 0's and 1's, as depicted by Table 400.  In binary form, a zero (0) indicates the absence of a feature in a configuration, and a one (1) indicates the\npresence of a feature in the configuration.  For example, a first binary configuration 402 illustrates the first CNF configuration 302 in binary form, and a second binary configuration 404 illustrates the second CNF configuration 304 in binary form.  The\nliteral A2 is replaced with \"01\", as generally referenced by numeral 406.  Each column maps to a feature in the family: `0` in the first position indicates the feature A1 is not present in the first binary configuration 402, and `1` in the second\nposition indicates the feature A2 is present in the first binary configuration 402.  The first CNF configuration 302 (A2 & B2 & C1 & D2) is represented by the first binary configuration 402, where the ampersand (&) symbol is replaced by a space as a\ndelimiter between each family, i.e., \"01 010 10 01.\"\nA configuration space can be very large.  For example, a product definition with around 100 independent features could have over 10.sup.27 possible configurations.  If each configuration was stored as an uncompressed set of 0's and 1's, it would\ntake more than 12 billion Exabytes of memory to represent them all--which is not practical with the present day state of the art computer hardware.  Therefore the configurator application 104 uses compressed representation to facilitate computational\ntractability and efficiency within available memory.\nA bit is the basic unit of information in computing.  It can only have one of two values and is commonly represented as 0 or 1, or the Boolean values of false and true.  A bit set represents a vector or array of bits.  For example, Java has a\nnative utility class called \"BitSet\" that stores a set of bits with an array of values of a primitive 64-bit datatype called long.\nWith the rightmost position of the bit set index 0 and leftmost position index 8, 100101001 is equal to 1*2.sup.8+1*2.sup.5+1*2.sup.3+1*2.degree.=256+32+8+1=297.  Thus the bit set 100101001 can be stored using the long (or integer) 297.  An\narray of 2 long values (-8929791190748339525, 8791258171646) can represent a bit set of 107 features: 11 01 11 010 100 01 10 00010 00010 111 01 010 01 11 000100 000011 00100 00010 00010 11111 1100 01000001 001 01 11 11 11 01 10 11 11 11.\nThe Java BitSet class allows for varying bit set lengths.  But, for the configurator application 104, the set of features is fixed for a given vehicle.  Thus, the configuration engine 106 defines its own fixed length bit set object.  To store a\nconfiguration, a feature bit set is used.  The feature bit set associates a feature object with each bit position.  This mapping is defined in a structure object that defines a list of families with each family defining a list of features.\nFIG. 5 illustrates a table 500 that defines the mappings for the bit sets in table 400.  The bit sets shown in table 400 are printed in blocked format.  The bits for each family are grouped together with no delimiter and family blocks are\nseparated by a space.  The bit sets can also be printed in strict binary format with no extra spacing, e.g., the first binary configuration 402 of Table 400 could be rewritten as 010101001.  Alternatively, the bit sets can be printed in strict binary\nformat with the same delimiter between every feature and no extra delimiter between families, e.g., the first binary configuration 402 of Table 400 could be rewritten as 0 1 0 1 0 1 0 0 1.  Blocked format allows for better human readability; however,\nspace-delimited is a viable option when viewing the data in a table with labeled columns and importing bit set data into an Excel worksheet for analysis.\nWith reference to FIGS. 6-10, one or more configurations may be compressed and represented by a \"superconfiguration.\" FIG. 6 includes a table 600 listing a first configuration 602: (A2, B2, C1, D2), and a second configuration 604: (A1, B2, C1,\nD2).  Because the values are identical in all but one family `A`, the configurations 602, 604 can be compressed into a single superconfiguration 606.  The table 600 shows both the CNF and bit set forms of the configurations and superconfigurations. \nThus, a configuration is just a superconfiguration with only one possible value per family.\nReferring to FIG. 7, two superconfigurations can also be compressed as shown in table 700.  A first superconfiguration 702 and a second superconfiguration 704 are compressed into a third superconfiguration 706.\nWith reference to FIG. 8, bit sets, configurations and superconfigurations can be interacted using bitwise steps as shown in table 800.  Referring to \"OR\" step 802, when OR-ing two superconfigurations the resulting value for each family is the\nunion of the family set from each superconfiguration.  Thus, if any value in a family set (column) is \"1\", then the union of the family set is \"1.\" And referring to \"AND\" step 804, when AND-ing two superconfigurations the resulting value for each family\nis the intersection of the family set from each superconfiguration.  Thus, if all values in a family set (column) are \"1\", then the union of the family set is \"1.\"\nReferring to FIG. 9, when AND-ing two superconfigurations, the resulting superconfiguration is invalid if any family has no active bits, as shown in table 900.  The intersection for family B is empty causing the configuration to be invalid, as\nreferenced by numeral 902.\nWith reference to FIG. 10, the configuration system 100 expresses buildable space with a set of superconfigurations that define all valid configurations, according to one or more embodiments.  This compressed representation allows for more\nefficient storing and processing of a buildable space.  A non-overlapping set of super configurations can be stored in a matrix 1000, with each row stored as a bit set.\nReferring to FIG. 11, the configuration engine 106 does not use overlapping superconfigurations because they include redundant information which could lead to incorrect calculations.  Thus, all basic steps performed by the configuration engine\n106 rely on the fact that the buildable space contains no overlap.  Two superconfigurations are said to overlap if there exists one or more configurations that are defined by both superconfigurations.  Table 1100 shows a first superconfiguration 1102\nthat overlaps with a second superconfiguration 1104.  Row 1106 identifies all of the overlapping features.  For example, both superconfigurations 1102, 1104 include feature A2, as represented by numeral 1108, and therefore overlap.\nWith reference to FIG. 12, a superconfiguration can be used to define a feature mask.  A feature mask for a single family is created by setting the active bits in the family to zero to define the constrained features and setting all bits to 1\nfor the remaining families.  A feature mask for multiple families is the AND of the masks for each family.  Table 1200 shows several examples.  A feature mask can be used to search a configuration space (contains) or limit a configuration space\n(restrict).  Feature masks can be used to encode a feature condition in order to associate data with features, such as descriptions, prices and images.\nReferring to FIG. 13, the configuration system 100 uses a multi-valued decision diagram (MDD) to represent the buildable space, according to one or more embodiments.  An MDD representing the same buildable space as the superconfigurations matrix\n1000 (FIG. 10) is shown in accordance with one or more embodiments, and generally referenced by numeral 1300.  An MDD is capable of representing the configuration space for large and highly complex product offerings much more compactly than a matrix.\nThe MDD 1300 includes nodes, such as a root node (2), a terminal, Truth or True node (T) and a plurality of intervening nodes (3-16) arranged on a plurality of paths.  Each path includes the root node (2), the true node (T) and some of the\nintervening nodes connected by \"edges\" or arrows.  In terms of superconfigurations, a complete path from the root node (2) to the true node (T) defines a superconfiguration.  The superconfiguration shown in the top row 1308 of the matrix 1000 in FIG. 10\n(i.e., 100 100 110 100 10), is defined by a right path (2-3-4-5-6-T) in the MDD 1300.\nEach level of the MDD 1300 is associated with one family and the edges define the path for each feature.  Each node will have at most one outgoing path for each feature, thus the features are mutually exclusive.  Where there is a path between\ntwo nodes for more than one feature, a single edge is shown, but the edge label includes more than one (\"1\").  The edge labels correspond to a family's superconfiguration bits, where a \"1\" indicates the presence of a feature and a \"0\" indicates the\nabsence of a feature.  Where a feature is inactive, its edge points to the false terminal node, which is not shown in the diagram.  Each complete path from the root node to the truth node is of the same length in nodes when the nodes are expanded, e.g.,\nthere are no long edges.  An MDD that does not include any long edges may be referred to as a quasi-reduced MDD.\nThe MDD 1300 includes five different families 1302: package (Pkg), radio (Radio), paint (Paint), trim (Trim) and moonroof (MoonRf).  Each family includes multiple features.  For example, the package (Pkg) family includes a 400 package, a 401\npackage and a 402 package; and the radio family includes: a Standard (Std) radio, a Deluxe (Dlx) radio and a Navigation (Nav) radio.  The root node (2) is connected to intervening node 13 by edge label \"001\", which indicates the presence of the third\npackage (402) and the absence of the first two packages (400 and 401).  Again, some edge labels include more than one \"1\", which means that more than one feature is available.  For example, intervening node (7) is connected to intervening node (8) by an\nedge with a label \"011.\" This indicates that path 2, 7, 8 is a superconfiguration that includes the 401 package, and the Deluxe (Dlx) and/or the Navigation (Nav) radio.\nFIG. 14 is a table 1400 that illustrates a comparison of the size of a matrix based product configuration (e.g., table 1000, FIG. 10) and an MDD based product configuration (e.g., MDD 1300, FIG. 13).  For small product definitions (e.g., Vehicle\nA with 28 families) a matrix and an MDD have comparable size (20 KB).  However, for medium product definitions (e.g., Vehicle B with 84 families) the matrix size (23,026 KB) is much larger than the MDD size (766 KB).  For large product definitions (e.g.,\nVehicle C with 92 families) the matrix runs out of memory, but the MDD size (313 KB) is sufficient.  Therefore table 1400 illustrates that an MDD is a useful tool when analyzing large product configurations.  Using the MDD format, the minimum number of\nsuperconfigurations required to represent the buildable space of all possible configurations may be calculated.  For complex products that number exceeds reasonably available memory.\nWith reference to FIG. 15, the configuration engine 106 performs steps using reduced MDDs, such as reduced MDD 1500, in one or more embodiments.  FIG. 15 includes the MDD 1300 of FIG. 13 and a reduced MDD 1500.  In an MDD, a redundant node may\nbe removed and its incoming and outgoing edges may be combined to form a \"long edge.\" A redundant node is a node that corresponds to a family in which all features are active, i.e., its outgoing edge label includes only \"1\"s. For example, intervening\nnode 16 in MDD 1300 corresponds to the moonroof (MoonRf) family, and its outgoing edge label \"11\" indicates that both the moonroof (Vista) and no moonroof (Less) features are active.  Therefore node 16 is redundant and it can be removed, as depicted by\nthe \"X\" disposed over it in FIG. 15.  Nodes 10 and 12 of MDD 1300 are also redundant and may be removed, as depicted by the X's over them in FIG. 15.  The reduced MDD 1500 shows the result of removing redundant nodes 16, 10 and 12 and collapsing their\nrespective incoming and outgoing edges into long edges.  The paths from 13-T, 9-T, and 10-T do not include a node for the moonroof (MoonRf) family.  By collapsing the long edges, the reduced MDD 1300 has 3 fewer nodes, and some of its nodes have been\nrenumbered.  For example, since node 10 of MDD 1300 was removed, node 11 of MDD 1300 was renumbered as node 10 in reduced MDD 1500.  By reducing MDDs, the configuration system 100 reduces memory and processing usage.\nIn one or more embodiments, the configuration engine 106 performs steps using an expanded (not reduced) MDD, such as MDD 1300, e.g., during a \"Quick-Restrict\" step, as described below.  For a very large buildable space, the number of nodes added\nto expand long edges can be quite significant.  As an example, an MDD may have 17,283 nodes when long edges are compressed, but grow to 47,799 nodes when long edges are expanded.  Therefore good compression reduces the number of long edges significantly. However, the savings generated by the quick-restrict step are generally sufficient to justify the long edge expansion.\nIn the expanded MDD 1300, nodes 10, 12, and 16 are not only redundant; they are also duplicated.  Duplicate nodes are two nodes for a family (i.e., within a common row) that have identical outgoing edge labels.  The reduced MDD 1500 is in\ncanonical form, i.e., there are no duplicated nodes.  The configuration engine 106 creates MDDs in canonical form.  Canonical form helps to minimize the number of nodes required to represent the buildable space.\nFIG. 16 includes a non-canonical MDD 1600 with duplicate nodes.  Node 6 and node 8 include identical outgoing edge labels, and therefore are duplicates of each other, as referenced by numeral 1602.  Similarly, node 5 and node 7 are duplicates,\nas referenced by numeral 1604.  FIG. 16 also includes a canonical MDD 1610.  The duplicate nodes of MDD 1600 are merged in the canonical MDD 1610.  For example, the first duplicate nodes 1602 are merged to form a canonical node 6, as referenced by\nnumeral 1612.  And the second duplicate nodes 1604 are merged to form a canonical node 5, as referenced by numeral 1614.  The MDDs, e.g., MDD 1600, 1610, are serialized as plain text for storage in a database, such as the DB 122 shown in FIG. 2.  Such\ntext serialization ensures backwards compatibility across software versions and implementations.\nWith reference to FIG. 17, when a family's values in the configuration space can be determined by the values from one or more other families, the family is said to be deterministic.  Deterministic relationships are used to minimize the size of\nan MDD to allow for scaling to complex vehicle configurations.\nFIG. 17 includes an MDD 1700 that is similar to the MDD 1300 of FIG. 13, with the addition of two deterministic families: seat temperature control (Temp) and the presence of dice (Dice).  The presence of dice is determined by the paint color. \nThus, once the paint color (Paint) is known, there is just one choice for dice.  If paint is White, then dice are not present (NoDice); however if paint is Red or Blue, then Fuzzy dice are present (FuzzyDice).  The seat temperature control (Temp) is\ndetermined by the package (Pkg).  If Pkg is 400, then the seat temperature control is not available (LessTemp); if Pkg is 401, then heated seat temperature control is included (Heat); and if Pkg is 402, then heat and cool temperature control (HeatCool)\nis included.  In these examples Paint color and Pkg are the determinant families while Dice and Seat temp are deterministic.  This is because their state is fully specified by the state of the determinant.\nThe presence of deterministic features has a negative impact on MDD compression.  The MDD 1700 represents twenty-four configurations.  However, the deterministic families cause the MDD 1700 to increase from sixteen nodes to twenty-four nodes. \nGenerally, the number of nodes in an MDD is a good predictor of its performance.  Thus, it is ideal to have an MDD with as few nodes as possible.  To aid in MDD compression, the configuration system 100 extracts the relationship defining a deterministic\nfamily's values to form one or more external relationship MDDs, which allows for greater compression in the main MDD, i.e., MDD 1700.\nThe configuration system 100 extracts the two deterministic families (Temp and Dice) from MDD 1700 to form reduced an MDD 1702, a first external relationship MDD 1704 corresponding to the Dice family, and a second external relationship MDD 1706\ncorresponding to the Temp family.  The deterministic families (Temp and Dice) remain in the MDD 1702, but are trivialized--made all is--allowing the main MDD 1702 and the external relationship MDDs 1704, 1706 to share the same structure.\nThe combination of the main MDD 1702 and all its external relationship MDDs 1704, 1706 is referred to as a Global MDD.  A Global MDD can be operated in the same way as an MDD; but, each step must account for both the main space and the\nrelationships.\nThe configuration service 138 abstracts the implementation from any specific application and state management does not depend on the implementation being either \"stateful\" or \"stateless\", according to one or more embodiments.  The configuration\nservice 138 remembers a user's session history in a stateful implementation, and does not remember a user's session history in a stateless implementation.  However, the front-end application 132 treats the configuration service 138 as stateless in so far\nas it does not need to handle session synchronization.\nEach XML response to the front-end application 132 from the configuration service 138 includes a state object that is included in the next call.  The content of the state object is not dictated by the configuration service 138, but it contains\nany information necessary to maintain a user session.  The state object is not modified by the front-end application 132.\nA configuration session begins with an XML request to load initial content (i.e., a \"Load Request\") to populate a starting point of initial screens on the front-end applications 132.  This is followed by additional XML requests to update the\ncontent (\"Update Request\") as user changes the configuration by selecting different options in the front-end application.  The web service controller 136 responds with an XML configuration response that includes updated configuration content.\nEach feature included in such configuration responses includes a selection or feature state attribute.  In one embodiment, there are six different feature state values: Selected, Available, Included, Default, Excluded and Forbidden.\nA Selected feature state is a feature that has been explicitly selected by the user and generated in response to a Load or Update XML request.  The configuration service 138 cannot unselect this feature as a result of another selection without\nperforming a conflict resolution procedure, except for features in a mutually exclusive feature group.\nAn Available feature state is a feature that is not currently selected by the user.  But the user is free to select it without causing a conflict resolution procedure to be triggered.  In a mutually exclusive group of features (e.g. exterior\ncolor), although only one feature can be selected at a time, the other features in that group will be marked as \"Available\"--they will only be marked as \"Excluded\" if they conflict with a user selected feature in another family.\nAn Included feature state is a feature which is the only available choice in the family.  For example, this can occur when a selection of a feature requires another feature.  This can be the result of either a package selection that includes\nthis feature (e.g. \"Climate Pack\" includes \"Air Conditioning\"), or a \"must\"/\"requires\" relationship (e.g. \"Heated Seats\" requires \"Leather Seats).\nA Default feature state is a feature that was selected by the configuration service 138 as part of an automatic completion function, as described in detail below with reference to FIGS. 82-117.\nAn Excluded feature state is a feature that conflicts with another user selection.  Selecting this feature will prompt a conflict resolution procedure.\nA Forbidden feature state is a feature that violates a constraint that cannot be resolved if selected.  Attempting to select this feature will result in an error.  This state has been introduced to support external constraints that restrict the\nvalid buildable configurations.\nThe front-end application 132 alters the display of features based on their configuration state, in one or more embodiments.  For example, in one embodiment, the front-end application 132 shows a symbol next to an excluded feature to indicate\nthat it conflicts with a prior selection or it may choose not to display excluded or forbidden features.\nIn one embodiment, the configuration system 100 changes a feature from the Default feature state to the Selected feature in response to a user implicitly selecting the feature.  For example, if Default features are presented as checkboxes or\nradio buttons, there is no action the user can take to check an already checked item.  This means that while the user intended to select the feature, it is still marked as Default.  Such an implicitly selected Default feature may complicate conflict\nresolution strategies.  Thus, the configuration system 100 includes an option to change a feature from a Default feature state to the Selected feature state in response to a user viewing a default selection and not changing it.\nThe configuration service 138 will return a complete configuration to the front-end application 132 in response to any load or update request, according to one or more embodiments.  This feature is referred to as \"automatic completion.\" Default\nfeature selections will be added to any Selected features or Included features to create a complete configuration with respect to displayable families.  A feature is \"displayable\" if it can be displayed to the user, e.g. on the user's pc 112; whereas a\nfeature that cannot be displayed to the user is described as \"no-display\" or \"not displayable.\" The front-end application 132 may choose to distinguish the automatic feature selections from those explicitly selected by the user, using each feature's\nstate value returned in the configuration response.\nAlternatively, in other embodiments the automatic completion feature is disabled.  When the automatic completion feature is disabled, no default selections are made and the response will typically include an incomplete configuration.  This\nenables different front-end application 132 designs where a user is prompted to actively select each feature in the configuration.\nThe configurator application 104 includes a conflict resolution procedure in which, in response to an update request to select a feature that leads to an invalid configuration; the configuration service 138 returns a new valid configuration with\nthe newly selected feature and the minimum other changed features required to make the configuration valid.  If the auto completion feature is enabled, the new configuration will include any necessary Default features.  The web service controller 136\nimplements the conflict resolution feature to provide details on what features must be added and removed to resolve the conflict, as well as a \"reject state\" that is used if the user cancels the requested change.\nWith reference to FIG. 18, the configurator application 104 includes a \"single\" conflict resolution strategy, according to one or more embodiments.  The configuration service 138 resolves the conflict by finding a single valid configuration\ncontaining the new selection.  FIG. 18 depicts a user interface 1800 that is displayed to the user on the user device (e.g., on the monitor of the PC 112) by the front-end application 132 as part of the conflict resolution procedure.  The user interface\n1800 includes a message 1802 that alerts the user of a conflict (i.e., by selecting the adaptive cruise control feature, the Zetec package and the solar reflect windscreen features must be removed, and the titanium package must be added) and asks for\nconfirmation that they still want to make the change.  If the user cancels the change, e.g., by selecting the decline button 1804, the subsequent view request includes a reject state to undo the prior selection (i.e., adaptive cruise control) in the\nconfigurator application 104.  The update request may unselect a feature.  Since all families must have one feature selected to form a valid configuration, unselecting a feature is often equivalent to selecting the \"less\" feature in the family.  Removing\na feature from the configuration can also lead to a conflict.  For example, if the user removes an included feature, the selected feature which includes it will also be removed.\nReferring to FIG. 19, the configurator application 104 includes a branched conflict resolution strategy, according to one or more embodiments.  In branched conflict resolution, the configuration service 138 presents the user with a series of\nchoices to help them select from a set of valid configurations.  For example, FIG. 19 depicts a user interface 1900 that is displayed to the user on the user device (e.g., on the monitor of the PC 112) by the front-end application 132.  The user\ninterface 1900 includes a series of choices for a remote starter option (e.g., with or without (less) the remote starter), as referenced by numeral 1902, and a series of choices for the color of the seats (e.g., Charcoal Black or Medium Light Stone), as\nreferenced by numeral 1904.  In one embodiment, the branched conflict resolution strategy may be enabled by setting a return guided resolution flag (not shown), which is included in the communication between the front-end application 132 and the service\nAPI 134.\nWith respect to state management, when a branched conflict resolution is returned in the response to the service API 134, there will be no feature state because the new configuration isn't known until the user traverses the resolution tree,\n(i.e., selects from the options shown in the user interface 1900).  Once selections have been made, the front-end application 132 sends a second update request with all the changes made during resolution.  At this time the response will include the new\nconfiguration state.  Optionally, if there is only one target configuration, the response could include the new configuration state to save one call to the service.\nIn one or more embodiments, the conflict resolution strategy employed by the configurator application 104, may add a feature or subtract a feature, which is referred to as \"return delta\" functionality.  In one or more embodiments, the conflict\nresolution subtractions only contain Selected features removed from the configuration; and conflict resolution additions only contain Included features added to the configuration.  If the new configuration caused a change in a Default feature, this is\nnot included in the prompt to the user (e.g., not shown in the user interfaces 1800, 1900).  If all changes are for default choices, there are no changes to report, and the response will not include conflict resolution.\nAlternatively, in other embodiments, the response will include all additions and subtractions regardless of feature state when the request has set the return delta flag to true.  This allows the front-end application 132 to inspect the\nresolution and apply some additional logic when deciding whether to prompt the user for a conflict or to silently make the changes.\nThe configuration engine 106 \"validates\" each configuration.  A load request from the services API 134 may include a full or partial configuration as a starting point.  When a configuration is submitted to the configuration engine 106 with the\nload request, it is validated.  By default, or when a validate flag is True, conflict resolution will be triggered and the response will include a valid configuration.  However, if the request has set the validate flag to False, conflict resolution is\nnot performed and an error message will be included in the response if the submitted configuration is not valid.\nThe configuration engine 106 performs steps on a buildable space in order to process a configuration request and generate data to build a response.  The configuration engine 106 uses data structures and algorithms, including those based on\nmultivalued decision diagrams (MDD) to perform the configuration steps.  For comparison, some matrix based steps are also described.\nIn many cases the configuration engine 106 uses MDD steps to search the product space in the same way a structured query language (SQL) query searches a database.  Both are preforming relational algebra.  As appropriate, the SQL equivalent of\neach MDD step is described.\nThe configuration engine 106 checks if the buildable space defines a specific full configuration or a partial configuration, which is referred to as a \"contains any\" step.\nIn terms of SQL, this step is equivalent to performing a search and evaluating if there is at least one row in the result set.  For example, consider the partial configuration (Dlx, Vista).  If a database stored each configuration as a separate\nrow, and each family choice as a string column, the SQL query would be SELECT * FROM mdd WHERE Radio=`Dlx` AND Moonrf=`Vista`.\nFor efficient storage, matrix and MDDs represent the product with superconfigurations.  If each row in the database stored a superconfiguration with each feature as a Boolean column, the SQL would be SELECT * FROM mdd WHERE Dlx=TRUE AND\nVista=TRUE.\nFor example, in one embodiment, the configuration engine 106 searches an MDD by stating the query as a feature mask.  For example, to search for the partial configuration (Dlx, Vista) the mask would be 111 010 111 111 01.  The radio family\nincludes the following features: Standard (Std), Deluxe (Dlx) and Navigation (Nav).  Since the search is limited to (Dlx), the only active bit corresponds to Dlx (i.e., 010) for the radio family.  Additionally, the moonroof family includes: without a\nmoonroof (Less) and with a moonroof (Vista).  Since the search is limited to (Vista), the only active bit corresponds to Vista (i.e., 01).  All other families are all 1s.\nWhen the configuration engine 106 is performing a step to check for a partial configuration, one or more families will have all 1s.  This means that the mask defines multiple configurations.  The configuration engine 106 is querying the space to\ndetermine if any of the individual configurations defined in the feature mask superconfiguration are contained in the space.  Thus the step is called \"containsAny.\"\nWith reference to FIGS. 20 and 21, the configuration engine 106 performs an MDD-based \"containsAny\" step using a depth-first search of the space to look for the first valid path defining at least one of the configurations from the mask.  In a\ndepth-first search, the configuration engine 106 starts at the root node, and traverses the edges in descending order of its features; an edge of 011 will be processed by first inspecting 001 and then 010.\nFIG. 20 is an MDD 2000 that illustrates an example of the configuration engine 106 performing an MDD-based \"containsAny\" step for the partial configuration (Dlx, Vista).  To determine if this partial configuration is valid, the configuration\nengine 106 performs a depth-first search using the feature mask 111 010 111 111 01.  The search begins with the path 2-13.  This path is aborted when the Radio feature Dlx is inactive on edge 13-14, as shown by the dashed edge 2002.  Next, the\nconfiguration engine 106 searches path 2-13-8-11-12-T. This path, highlighted by nodes in solid line, ends in True node 2004, indicating a valid path has been found containing the partial configuration (Dlx, Vista).  Note there are three additional paths\ncontaining (Dlx, Vista), 2-13-8-9-10-T, 2-7-8-11-12-T, 2-7-8-9-10-T; but, the configuration engine 106 stops the \"containsAny\" step after the first path is found.\nFIG. 21 is an MDD 2100 that illustrates an example of the configuration engine 106 performing an MDD-based \"containsAny\" step for the partial configuration (Std, Vista).  To determine if this partial configuration is valid, the configuration\nengine 106 performs a depth-first search using the feature mask 111 100 111 111 01.  The search begins with path 2-13 which is aborted because neither edge 13-14, nor 13-8 is active for the standard radio feature (i.e., neither of the edge labels include\na \"1\" in their first digit), as shown by dashed edges 2102.  Next the configuration engine 106 searches path 2-7, which is also aborted because Std is not active, as shown by dashed edges 2104.  Finally, the configuration engine 106 searches path\n2-3-4-5-6 and aborts the search because 6-T is not valid for MoonRf.Vista, as shown by dashed edge 2106.  No paths are found containing both Std and Vista, thus this combination is found to be invalid.\nThe domain of a buildable space defines all the Available features--those features contained in one or more configurations.  The domain can be represented as a bit set where each 1 (active feature) denotes a feature contained in the domain and\neach zero (inactive feature) denotes a feature absent from the domain.  For any active bit in the domain, the space contains one or more configurations with that feature.  If there is an inactive bit in the domain, the space contains no configurations\nwith that feature.  For a matrix, the domain is calculated by the OR of all superconfigurations in the space.  The domain of the space shown in FIG. 10 is 111 111 111 111 11, because every feature is available in at least one configuration.\nWith an MDD, the configuration engine 106 calculates the domain by traversing the MDD in either a breadth-first or a depth-first manner, and using the active features on the edges to define the domain.  In a breadth-first search, the\nconfiguration engine 106 starts with a root node, then explores neighbor nodes first before evaluating the next family.  For example, the configuration engine 106 evaluates the MDD 2100 of FIG. 21 using a breadth-first strategy by starting with the root\nnode 2 and evaluating path 2-13.  Although path 2-13 is valid, the configuration engine evaluates neighbor nodes 7 and 3, i.e., paths: 2-7 and 2-3, before evaluating the next family, i.e., nodes: 14, 8 and 4.  Once a path is determined to be invalid, the\nconfiguration engine 106 stops evaluating nodes farther down the path.  For example, once path 13-14 is found to be invalid, the configuration engine 106 does not continue along the path to evaluate nodes 15 and 16.  And as described above, in a\ndepth-first search, the configuration engine 106 starts at the root node, and traverses the edges in descending order of its features.  In the depth-first search, levels (families) are not back-tracked until an invalid path, or the truth node, is\nencountered.  In the configuration engine 106, the full domain is not usually called, but rather domain is called on a restricted space.  The domain of a restricted space is used in determining feature states.\nThe configuration engine 106 restricts a space by keeping only those configurations containing a specific feature or combination of features.  With respect to a database query, the restrict step is equivalent to searching the table to find only\nthose rows that match the query.  The restricted features define the WHERE clause.  Consider the partial configuration (Nay, Ruby, Vista).  In terms of SQL, the query would be SELECT * FROM mdd WHERE Radio=`Nav` AND Trim=`Ruby` AND MoonRf=`Vista`.  In\nterms of superconfigurations, the step begins with creating a feature mask defining the query.  This is the same feature mask that would be used for a containsAny step.  For restrict, a space is created with the feature mask as its only\nsuperconfiguration.  Then, the restricted space is created by the AND of the original space with the feature combination space.\nFIGS. 22 and 23 show restrictions of the space defined in FIGS. 10 and 13.  In the table 1000 shown in FIG. 10, the last two rows of superconfigurations contain the radio feature (Nav), the trim feature (Ruby) and both moonroof features (Vista\nand Less), which indicates that Nav and Ruby are available with the moonroof (Vista) or without the moonroof (Less).  FIG. 22 is a table 2200 that depicts a restricted version of table 1000, in which the five superconfigurations of table 1000 are\nrestricted to two superconfigurations, and the Moonrf Less bit is set to zero to remove the configurations for (Nav and Ruby and MoonRf.Less).  FIG. 23 is a restricted MDD 2300 illustrating the restricted superconfigurations of table 2200.\nFor some algorithms, successive restricts will be performed on the same space.  When an MDD is restricted, a new set of nodes is created and the edges are updated for the nodes to keep only the constrained features.  When many restrict\noperations are performed, many node objects must be created as the MDD is replicated.  For large MDDs, this can cause the memory usage or \"footprint\" to increase, and may also incur performance problems from \"garbage collection\", i.e., reclaiming memory\noccupied by objects that are no longer in use by the program.  The configuration engine 106 addresses these issues using a \"quick-restrict\" strategy.\nWith reference to FIG. 24, a method for evaluating an MDD using reversible restrictions (i.e., \"quick-restrict\") is illustrated in accordance with one or more embodiments and generally referenced by S100.  The quick-restrict method S100 is\nimplemented as an algorithm within the configuration engine 106 using software code contained within the server 102, according to one or more embodiments.  In other embodiments the software code is shared between the server 102 and the user devices 112,\n114.  FIG. 25 illustrates an original MDD 2500, and an MDD 2502 after it is \"quick-restricted\" to the partial configuration (Nav, Ruby, Vista) by the configuration engine 106 according to the quick-restrict method S100 of FIG. 24.\nAt S102, the configuration engine 106 saves a copy of the root node identity and a set of the node edges to the memory 108 (shown in FIG. 2).  The subroutine of S102 is shown in the flowchart of FIG. 26.  At step S104 the configuration engine\nidentifies each node (y).  Then at step S106 the configuration engine copies or clones each outgoing edge of the node (y), and returns to step S104 until each node (y) in the MDD 2500 is copied.  Then at step S108, the configuration engine 106 returns\nthe edge set and the identity of the root node to the main routine of FIG. 24.\nAt step S110, the configuration engine 106 performs the quick-restrict subroutine for the given selected features.  The subroutine of step S110 is shown in the flowchart of FIG. 27.  At step S112 the configuration engine 106 examines the cache\nmemory for source (SRC) node (y) to determine if the quick-restrict subroutine has already been performed on node (y), (i.e., does cache(y) exist?) If cache(y) exists, then the configuration engine 106 proceeds to step S114 and returns to the main\nroutine.  If cache(y) does not exist, the configuration engine 106 proceeds to step S116.\nAt step S116, the configuration engine 106 starts with array index zero, and sets the empty flag to true.  By setting the empty flag to true, the configuration engine 106 assumes that there are no valid paths from the node, i.e., that all edges\npoint to the false node.  At step S118, the configuration engine 106 evaluates the array index (z) to determine if (z) is less than the number of node (y)'s children.  A positive determination at step S118 indicates that the configuration engine 106 has\nnot analyzed all array indexes of node (y).  If the determination is positive, the configuration engine 106 proceeds to step S120.\nAt step S120, the configuration engine 106 checks if y's child, or destination (DST) node, at array index (z) is false.  If the configuration engine 106 determines that the child is false, then it proceeds to step S122, increments the array\nindex (z) by one, and returns to step S118.  With reference to FIG. 25, the MDD 2500 does not show false nodes, but they are still present.  For example, node 9 shows only one outgoing edge with the label \"001.\" This indicates that array indexes zero and\none are both false, but they are not shown extending to the false node on the MDD 2500 to avoid clutter.  When analyzing node 9, the configuration engine 106 makes a positive determination at S120 for array indexes zero and one, but makes a negative\ndetermination for array index two.  If the determination at step S120 is negative, the configuration engine 106 proceeds to step S124.\nAt step S124, the configuration engine 106 evaluates the quick-restricted features list for node (y) to determine if it contains feature (z).  Otherwise, the configuration engine 106 sets y's child node along z to false at S126 and then proceeds\nto step S122 to increment the array index(z) by one.\nAt step S128, the configuration engine 106 check's if y's child (DST) at array index (z) is true.  For example, with reference to MDD 2500, node 16 connects to the true node (T) along array indexes zero and one.  If the configuration engine 106\ndetermines that the child node is the true node, then it proceeds to step S130 and sets the empty flag to false (empty=false), which indicates that there is at least one edge that is connected to the true node (T), and then proceeds to step S122.  If the\ndetermination at step S128 is negative, the configuration engine proceeds to step S132.\nFor example, referring to MDD 2500, node 3 is illustrated with one outgoing edge with the label \"100\", which indicates that node 3 includes the Standard radio, but does not include the Deluxe radio or the Navigation radio.  Since the Navigation\nradio was selected by the user, the configuration engine 106 determines that none of node 3's outgoing edges contain (z)'s corresponding feature.  Therefore the configuration engine 106 sets node 3's children to false at S126, which is illustrated by\ndisconnecting the outgoing edge to node 4 (as shown in MDD 2502) and the edge label for path 3-4 is replaced with an edge label of \"000.\" However, referring to MDD 2500, node 7 includes two array indexes (011), which indicate that node 7 includes the\nDeluxe radio and the Navigation radio.  Since the Navigation radio was selected by the user, the configuration engine 106 determines that one of node 7's outgoing edges contain (z)'s corresponding feature at S124, therefore the outgoing edge is not\ndisconnected from node 8 (as shown in MDD 2502) and the edge label for path 7-8 is replaced with an edge label of \"001\".\nAs shown in MDD 2502, the configuration engine 106 removes the edge pointer for path 13-8 because Navigation is not an active feature for the Radio family (i.e., there was not a \"1\" in the third digit of the edge label); and removes the edge\npointer for path 15-16 because Ruby is not an active feature for the Trim family at S126.  Since only Vista is constrained for the moonroof family; the configuration engine 106 modifies the edge labels for paths 10-T and 12-T from \"11\" to \"01\".  If the\ndetermination at step S128 is negative, the configuration engine 106 proceeds to step S132.\nAt step S132, y's children, or (DST) nodes, are rewritten by the result of recursive invocation of the quick-restrict method on the child.  All nodes of the MDD are processed in this manner.\nAt step S134, the configuration engine 106 checks y's child at array index (z) to determine if it's not a false node.  If the determination is positive (e.g., if node (y) is connected to a valid node), then the configuration engine 106 proceeds\nto step S136 and sets the empty flag to false, before incrementing the array index (z) at S122.  However, if node (y) is connected to the false node along array index (z) then the configuration engine 106 proceeds directly to S122 to increment the array\nindex (z).\nThe quick restrict method S110 operates on the nodes in a depth first search fashion.  Steps S118-S136 demonstrate an iterative process that operates on each array index (z) of a node (y) before proceeding to the next node.  Once the\nconfiguration engine 106 has evaluated all array indexes (z) for a node (y), it will make a negative determination at step S118 (i.e., z will be greater than or equal to the number of y's children), and proceeds to step S138.\nAt step S138 the configuration engine 106 checks if all children (DST) of node (y) are false, i.e., it evaluates the empty flag to determine if any valid configurations were found.  If all of y's children are false, the configuration engine 106\nproceeds to step S140, sets node (y) to the false node, set cache(y) to y, and then returns the cache(y), i.e., saves the analysis of node (y) and returns to the main routine of FIG. 24.  Further, if the node does not contain any edges that conform to\nthe constraint, then the edge pointer is disconnected from the child node in the MDD.  If not all of the children nodes are false, then the configuration engine 106 proceeds to step S142, sets the cache(y) to (y), and then returns the cache(y), i.e.,\nsaves the analysis of node (y) and returns to the main routine of FIG. 24.\nFor example, referring to FIG. 25, the configuration engine 106 determines that node 3's features do not contain the Selected radio feature (Nav) at S124, and therefore sets node 3's child (node 4) to false at S126.  Setting node 4 to false is\nrepresented by disconnecting the edge pointer between node 3 and node 4 in MDD 2502.  The configuration engine 106 determined that all of node 3's children were set to false at S138, and therefore set node 3 to false at S140.  Setting node 3 to false is\nrepresented by disconnecting the incoming edge pointer to node 3 in the MDD 2502.\nSimilarly, the configuration engine 106 disconnects the incoming edge pointer to node 15 at S140, because all of node 15's children were set to false at S126, which is depicted by the disconnected outgoing edge pointer of node 15 in MDD 2502. \nAlthough the edge label for path 7-8 was revised at S126, the edge pointer was not disconnected.  Therefore the configuration engine 106 determines that not all of node's 7 children are false at S138, and proceeds to S142 without setting node 7 to false\nor disconnecting its incoming edge pointer in the MDD 2502.\nThe quick-restrict subroutine S110 is a recursive process.  This process continues until all nodes are analyzed.  The edges for complete paths from the root node (node 2) to the truth node (T) define the restricted configuration space.\nAt step S144 the configuration engine 106 performs additional steps on the restricted MDD 2502.  In one embodiment, after completing a traversal of the MDD in a first direction (e.g., downward), the configuration engine 106 determines the domain\nfor a restricted space by traversing the MDD again in the same direction (i.e., the configuration engine repeats S110 for all nodes).\nIn another embodiment, the configuration engine 106 determines the domain at the same time as traversing the MDD in the first direction (i.e., during S110).  Then at step S144, the configuration engine 106 changes direction (i.e., reverses) and\ntraverses the MDD in a second direction, e.g., upwards from the truth node (T) to the root node (2).  On the downward traversal, the configuration engine 106 trims the edges to conform to the constraint.  On the upward traversal, the domain bit set is\ncreated from the remaining edges.  Combining quick-restrict and domain in a single operation saves one traversal of the MDD.  However, the operation modifies the MDD and the edges must be reset to undo the quick-restrict.\nAt S146, the configuration engine 106 restores the original set of node edges to the memory 108 (shown in FIG. 2).  The subroutine of S146 is shown in the flowchart of FIG. 28.  At S148 the configuration engine identifies each node (y).  Then at\nstep S150 the configuration engine 106 copies each outgoing edge of the node (y), and returns to step S148 until each node (y) in the MDD 2500 is copied.  Then at step S152, the configuration engine 106 sets the MDD to the identity of the root node and\nreturns to the main routine of FIG. 24.\nAt step S154 the configuration engine 106 determines if the user has selected different features.  If the user has selected new features, the configuration engine 106 returns to S110.  If the user has not selected new features, then the\nconfiguration engine 106 proceeds to step S156 and deletes the copy of each node from S102 to free memory.\nAs shown in MDD 2502, paths 9-10-T and 11-12-T are duplicate paths, because they include the same features.  As described above with reference to FIGS. 22-23, the restrict operation will reuse nodes to avoid duplicate nodes or sub-paths. \nAlthough, the quick-restricted MDD 2502 may contain more nodes than the restricted MDD 2300, the configuration spaces defined by each are identical.\nThe quick-restrict method S100 provides advantages over existing methods by performing successive restricts without creating a new MDD for every step.  The configuration engine 106 saves the original edge pointers at S102 and then quickly resets\nthe MDD 2500 using the original edge pointers.\nThere are some cases, where a more efficient algorithm can perform the same operation without having to do the quick-restrict method, eliminating the time needed to reset the edge pointers.  This time savings, while small, can be significant\nwhen working with extremely large configuration spaces.  A \"Restricted Domain\" algorithm is one such algorithm.\nIn other embodiments, the configuration engine 106 determines a read-only restricted domain using an external set of edges (not shown).  Instead of modifying the original MDD node edges the external edges are modified to reflect the restricted\nspace.  The configuration engine 106 restricts on the downward traversal and then updates the domain on the upward traversal.  Such a method is a read-only, thread-safe operation, because the MDD is not modified.\nThe quick-restrict with domain operation method S100 is slightly slower than this read-only approach for the same calculation; however, the time saved in the read-only operation is due to not having to reset the edges.  FIG. 29 is a table 2900\nillustrating a comparison of the performance of the quick-restrict with domain operation method S100 to the read-only method.  The larger and more complex the buildable space, the more nodes in the MDD, and the more time it requires to reset the edges\nafter the quick-restrict method S100.\nWith reference to FIGS. 30-32, the configuration engine 106 performs a \"project\" operation of an MDD to trim a space to a subset of the families while keeping all unique configurations, according to one or more embodiments.  In terms of SQL, the\nprojection operation is equivalent to specifying which columns of a table are returned in the query.  To project the space to the package (Pkg) and the trim (Trim) families, the equivalent SQL would be: SELECT DISTINCT Pkg and Trim FROM mdd.\nSelecting distinct configurations means that the resulting space should contain no duplicated configurations.  During the MDD project operation, the configuration engine 106 removes any duplicated configurations (also called overlapping\nsuperconfigurations).\nFIG. 30 is a table 3000 that shows the result of the configuration engine 106 reducing the buildable space in FIG. 10 to keep only the columns for the package and trim families.  This space contains duplicate configurations.  For example a\nconfiguration including the 401 package and Ruby trim is defined in Row 3 and in Row 4.  Likewise a configuration including the 402 package and Ruby trim is defined in Row 3 and in Row 5.  Therefore Row 4 and Row 5 are duplicates of Row 3 and can be\nremoved.  Further, Row 2 and Row 3 can be compressed to a single row.  FIG. 31 is a table 3100 that shows the projected space after the overlap (duplicated configurations) has been removed and the space has been compressed.  FIG. 32 is an MDD 3200 that\nrepresents table 3000.\nWith reference to FIG. 33, the configuration engine 106 lists, or enumerates all valid configurations that are utilized in conjunction with a constraint restricting the families to a subset of all families, according to one or more embodiments. \nGiven a subset of families, enumeration will return all valid combinations of the features in those families.  In terms of superconfigurations, enumeration is the opposite of compression.\nThe configuration engine 106 works with individual features which are added or removed from a current single configuration.  While this suits the requirements of most ordering and build and price applications, in some cases, the configuration\nengine 106 enumerates the valid combinations of those features without working through all the possible paths.\nThe total number of possible permutations of features in a configuration model can be very large, so this configuration service is restricted to enumerating a reasonable subset of feature families.  The configuration engine 106 can impose limits\non the number of families that can be enumerated, however, it should be expected that a request resulting in more products than can be stored in a storage medium will not succeed.\nFIG. 33 is a table 3300 that shows all valid combinations of paint and trim defined in FIG. 13.  The configuration engine 106 generates this list by first projecting the space to paint and trim.  Next the configuration engine 106 traverses the\nMDD paths and expands each superconfiguration into individual configurations.\nThe configuration engine 106 determines if a new configuration is valid, in response to every configuration request.  Where auto-completion is enabled, the configuration request will contain a full configuration, otherwise it will be a partial\nconfiguration.  In either case, the configuration engine 106 validates the configuration request using the MDD \"containsAny\" operation.  A configuration is valid if the containsAny operation returns true.\nEach feature included in the configuration response will have a feature state attribute, e.g. Selected, Available, Included, Default, Excluded or Forbidden.  For a given set of selected features, the configuration engine 106 calculates the\nfeature states for the remaining features.\nThere are multiple approaches for calculating feature states.  In one embodiment, the configuration engine 106 calculates feature states using a basic algorithm that includes restricted domain steps which can be applied to both Matrices and\nMDDs.  In another embodiment, the configuration engine 106 calculates feature states for MDDs using dynamic programming techniques.\nWith reference to FIG. 34, a method for determining feature states using a restricted domain is illustrated in accordance with one or more embodiments and generally referenced by S200.  The method S200 is implemented as an algorithm within the\nconfiguration engine 106 using software code contained within the server 102, according to one or more embodiments.  In other embodiments the software code is shared between the server 102 and the user devices 112, 114.\nFirst the configuration engine 106 identifies Forbidden features and Excluded features.  At step S202 the configuration engine 106 determines the restricted domain with respect to any initial locked features imposed on the user.  For example,\nthe initial restriction can be timing point feature(s) which are features used to control the effectivity and visibility of configurations.  For example, a new feature (e.g., new engine x) may be available only after the start of a new model year.  Thus\nthe first day of the new model year would be such a visible timing point.  At step S204, the configuration engine 106 identifies features that are absent from the restricted domain, and classifies them as Forbidden features at S206.  At step S208, the\nconfiguration engine 106 classifies any feature that is not Forbidden, as an Excluded feature unless it is assigned another feature state (i.e., Available, Included or Default) in the remaining steps of the algorithm.\nAt step S210, the configuration engine 106 first determines the restricted domain of all selections to identify an initial set of Available features.  Then, for each selection F.sub.j, the configuration engine 106 checks the restricted domain\n(selected--F.sub.F) to identify Available features for Family j.\nFor example, FIG. 35 is a table 3500 illustrating a set of superconfigurations that define all valid configurations.  FIG. 36 is a table 3600 that depicts the restricted domains used to determine the Available features and the Excluded features\nwhen the Selected features are Red paint and Ruby trim.  A bit value of zero in table 3600 indicates that a feature is not Available, whereas a bit value of one indicates that the feature is Available.\nFirst, the configuration engine 106 determines the restricted domain of all selections to identify an initial set of Available features at S210.  For example, Red paint and Ruby trim are both available for the configurations listed in rows 3-5\nof the table 3500.  Packages 401 and 402 are Available, but package 400 is not Available for the configuration listed in rows 3-5, as referenced by numeral 3502.  Therefore the restricted domain for the package family is \"011\", as referenced by numeral\n3602, which indicates that package 400 is not Available (i.e., \"0\"), and package 401 and 402 are Available (i.e., \"11\").  Any feature that is active in this domain is set as active in the availability bit set.  Thus, the configuration engine 106\nidentifies package 401 and package 402 as being Available features, as referenced by numeral 3604, and these features are set as active (\"1\") in the availability bit set, as referenced by numeral 3606.\nNext, the configuration engine 106 evaluates the restricted domain (selected--Ruby) to identify Available features for the trim family.  To evaluate (selected--Ruby), the configuration evaluates configurations in which Red paint is Available. \nFor example, Red paint is Available for the configurations listed in rows 1 and 3-5 of the table 3500.  Stone trim and Ruby trim are Available for the configurations listed in rows 1, and 3-5; but Charcoal trim is not Available, as referenced by numeral\n3508.  Therefore the restricted domain for the trim family is \"101\", as referenced by numeral 3608.  The availability bit set for the trim family is revised to \"101\" based on this step, as referenced by numeral 3610.\nThen, the configuration engine 106 evaluates the restricted domain (selected--Red) to identify Available features for the paint family.  To evaluate (selected--Red), the configuration evaluates configurations in which Ruby trim is Available. \nFor example, Ruby trim is Available for the configurations listed in rows 3-5 of the table 3500.  Red paint and Blue paint are Available for the configurations listed in rows 3-5, but White paint is not Available, as referenced by numeral 3512. \nTherefore the restricted domain for the trim family is \"011\", as referenced by numeral 3612.  The availability bit set for the paint family is revised to \"011\" based on this step, as referenced by numeral 3614.\nAs shown in the availability bit set of table 3600, the restricted domain for Red paint includes both Stone trim and Ruby trim.  Both of these selections are Available without having to change the Red paint selection.  The selection of Ruby trim\nexcludes White paint, and shows that both Red and Blue paint are Available.  Thus White paint would require the trim selection to be changed to something other than Ruby.\nThe resulting availability can be defined as bit set 011 011 011 101 11.  The state of Red paint and Ruby trim will be Selected, all other active features will be Available and the inactive features, such as White paint and Charcoal trim, will\nbe Excluded.\nReferring back to FIG. 34, the configuration engine 106 identifies any Included features at step S212.  A feature is Included if there is only one Available feature for a non-Selected feature family.  The non-Selected feature families listed in\ntable 3600 are packaging (Pkg), radio (Radio) and moonroof (MoonRf).  All of these feature families include more than one Available feature (i.e., each family includes more than one \"1\" in each cell).  Thus, table 3600 shows no such Included features for\na selection of Red paint and Ruby trim.\nFIG. 37 is a table 3700 that depicts the restricted domains used to determine the Available features and the Excluded features when the Selected features are the 401 package (Pkg.401) and Red paint (Paint.Red).  An Included feature can be the\nresult of the interactions between multiple features.  For example, table 3700 shows that if the 401 package and Red paint are Selected, then Ruby trim is an Included feature, as referenced by numeral 3720, because it is the only possible trim choice\nthat is compatible with the 401 package and Red paint.\nThus, the configuration engine 106 determines the feature states e.g. Selected, Available, Included, Excluded and Forbidden for a given set of selections using the method S200.  This initial feature state determination is referred to as \"Minimum\nCompletion.\" FIG. 38 is a table 3800 that summarizes the results of the Minimum Completion determination when Red paint and Ruby trim have been selected from the product definition in FIG. 35.\nThe configuration engine 106 determines the restricted domain by traversing the MDD.  Performing the Minimum Completion operation using restricted domain means that for each additional selection, another restricted domain operation is performed. Thus, for N selections, N+2 restricted domain determinations are performed.  These restricted domain operations include an initial restriction at S202, a restriction for the initial available set, followed by one for each feature at S210.\nFor MDDs, there is an alternate approach for determining the Available features using dynamic programming principles with a single operation that includes one downward traversal and one upward traversal of the MDD.  This approach is more memory\nefficient and faster, especially for larger MDDs.\nWith reference to FIG. 39, a method for determining feature states using dynamic programming is illustrated in accordance with one or more embodiments and generally referenced by S300.  The method S300 is implemented as an algorithm within the\nconfiguration engine 106 using software code contained within the server 102, according to one or more embodiments.  In other embodiments the software code is shared between the server 102 and the user devices 112, 114.\nAt S302, the configuration engine 106 organizes the data into nodes by family and level.  The subroutine of S302 is shown in the flowchart of FIG. 40.  At step S304, the configuration engine 106 determines if a level node object exists, i.e., if\nthe nodes are already organized by level.  Otherwise, the configuration engine 106 proceeds to step S306 and organizes the nodes into a level node array where the length of the array is equal to the number of families.  The configuration engine 106\ninitializes each level array with an empty nodes list, i.e., sets the empty flag to true.  At step S308, for each node (y) analyzed, the configuration engine 106 appends a node (e.g., adds a child node) to the analyzed node's level node list.  Step S308\nis a recursive step, therefore the configuration engine 106 repeats S308 until it finds the True node.  After step S308 the configuration engine 106 proceeds to step S310 and returns to the main routine of FIG. 39 to analyze the nodes by level.\nFIG. 45 is an MDD 4500 illustrating the data organized by level according to S302 and a selection of Red paint and Ruby trim.  The MDD 400 includes five levels.  Level zero represents the package (Pkg) family, which includes three package\nfeatures: 400, 401 and 402 that are depicted by edges (level arrays) 001, 010 and 100, respectively, that extend from node 2.  Level one represents the Radio family, which includes three radio features: Std, Dlx and Nav that are depicted by edges (level\narrays) 001, 010 and 100, respectively, that extend from nodes 3-5.  Level two represents the Paint family, which includes three paint features: White, Red and Blue, that are depicted by edges (level arrays) 001, 010 and 100, respectively, that extend\nfrom nodes 6-8.  Level three represents the trim family, which includes three trim features: Stone, Charcoal and Ruby, that are depicted by edges (level arrays) 001, 010 and 100, respectively, that extend from nodes 9-12.  Level four represents the\nmoonroof (MoonRf) family, which includes two moonroof features: Less and Vista, that are depicted by edges (level arrays) 01 and 10, respectively, that extend from nodes 13-16.  Node 1 is the true node and node 0 is the false node (not shown).\nAt step S312, the configuration engine 106 initializes the state, or marking of each node, by creating a place for each value.  For example, by default, all features are initially set to false (i.e., not marked) except the root node 2 and the\ntrue node 1.  The root node 2 is set to true for the downward traversal (i.e., marked with a downward arrow); and the true node 1 is set to true for the upward traversal (i.e., marked with an upward arrow).  Marking a node with a downward arrow indicates\na valid partial configuration from the root node 2 down to the marked node and any intervening downward marked nodes along the path.  Similarly, marking a node with an upward arrow indicates a valid partial configuration from the true node 1 up to the\nmarked node and any intervening upward marked nodes along the path.\nAt S314, the configuration engine 106 creates a constraint object.  The subroutine of S314 is shown in the flowchart of FIG. 41.  The configuration engine 106 starts analyzing family level zero of the MDD 4500 (i.e., the package family) at step\nS316.  At step S318, the configuration engine 106 determines if the family level (x) is less than the total number of families included in the MDD.  If so, the configuration engine 106 proceeds to step S320.\nAt step S320 the configuration engine 106 determines if the user has selected a feature for family level (x).  If the user has selected a feature for family level (x), the configuration engine 106 proceeds to step S322 and sets the Selected\nfeature to the Allowed feature state and sets the non-selected features for family level (x) to not allowed.  If no features are selected for family level (x), the configuration engine 106 proceeds to step S324 and sets all features to the Allowed\nfeature state.  After steps S322 and S324, the configuration engine 106 proceeds to step S326 to evaluate the next family by incrementing family level (x) by one (i.e. x=x+1), then returns to step S318.\nOnce the configuration engine 106 has created a full constraint object using subroutine S314, the family level (x) will no longer be less than the total number of families, and the configuration engine 106 will make a negative determination at\nstep S318.  For example, after the configuration engine 106 evaluates the moonroof family (level 4), it will set x to five at step S326.  Since there are five families in the MDD 4500, the configuration engine 106 will determine that x (5) is not less\nthan the number of families (5) at step S318 and then proceed to step S328 and then return to the main routine of FIG. 39.\nAt step S330 the configuration engine 106 initializes an availability bit set.  The configuration engine 106 initializes the availability bit set by setting all bits to zero, which indicates that the features are Excluded.  Whereas a bit set\nvalue of one indicates that a feature is Available.\nAt S332, the configuration engine 106 traverses the MDD 4500 in a downward direction.  The subroutine of S332 is shown in the flowchart of FIG. 42.  The configuration engine 106 starts analyzing the nodes included in family level zero of the MDD\n4500 (i.e., the package family) at step S334.  At step S336, the configuration engine 106 determines if the family level (x) is less than the total number of families included in the MDD.  If so, the configuration engine 106 proceeds to step S338.\nAt step S338, the configuration engine 106 starts analyzing node zero.  At step S340 the configuration engine 106 compares the node number (y) to the number of nodes at the current level (x) to determine if y&lt;Level (x) number of nodes.  For\nexample, initially, x is equal to zero and Level (0) has one node, therefore y is less than 1.  If y is not less than the number of nodes at level (x), the configuration engine proceeds to step S342 and increments the level (x) by one.\nAfter a positive determination at step S340, the configuration engine 106 proceeds to step S344 and sets the currently analyzed node or source node (SRC) to level(x) node (y); and sets the array index (z) extending from SRC to zero.  The array\nindex (z) corresponds to a feature of the family (x).  At step S346 the configuration engine 106 compares the array index (z) to the SRC's number of children.  If z is not less than SRC's number of children, the configuration engine 106 proceeds to step\nS348 and increments the node (y) by one.  If the determination at step S346 is positive, the configuration engine 106 proceeds to step S350.\nAt step S350, the configuration engine 106 sets the destination node (DST) to be the child node of node (y) along array index (z) (DST=SRC.child(z)).  The configuration engine 106 analyzes three conditions to determine whether or not to mark the\ndestination node with a downward arrow: 1) the destination node is not a false node; 2) the source node was previously marked with a downward arrow; and 3) the feature of array index (z) is allowed by constraint.  These three conditions are illustrated\nby steps S352-S358 in FIG. 42.\nAt step S352, the configuration engine 106 evaluates the DST node to determine if it is a false node.  Otherwise, the configuration engine 106 proceeds to step S354 to determine if the source node (i.e., the parent of the currently analyzed\ndestination node) was previously marked with a downward arrow.\nAfter a positive determination at S354, the configuration engine 106 determines if the feature of array index (z) is allowed by constraint at step S356, which was previously determined in steps S320-S324 (FIG. 41).  If the conditions of steps\nS352, S354 and S356 are met, the configuration engine 106 proceeds to step S358 and marks the destination node with a downward marker, by setting mark.down(DST) to true.  If any of the conditions of steps S352, S354 and S356 are not met, the\nconfiguration engine 106 proceeds to step S360 and increments the array index (z) by one.\nReferring to FIG. 45, the MDD 4500 illustrates the marked nodes after the downward traversal subroutine S332 of FIG. 42 for a selection of Red paint and Ruby trim.  The configuration engine 106 marks Node 2 with a downward marker at S312 because\nthe root node is a special case that always has a valid downward path.  On the downward traversal of the MDD 4500, a node is marked at S358 if the conditions of steps S352-S356 are met for the analyzed node.  For example, the configuration engine 106\nmarks destination node 3 with a downward marker or arrow 4502 at S356 because node 3 was determined to not be a false node at S352; node 3's source node (node 2) was previously marked with a downward arrow at S354; and the feature of the array index\nconnecting node 2 and node 3 (i.e., Pkg.400) was determined to be allowed by constraint at S356.  Since the user has not selected a packaging feature for this example, all packaging features are set to Allowed (see steps S320, S324 of FIG. 45.)\nSimilarly, the configuration engine 106 determines that the remaining radio nodes and the paint family nodes (nodes 4, 5, 6, 7, and 8) have valid downward markers because the package (Pkg) family and the Radio family are not constrained.  With respect to\nthe partial configurations of Pkg and Radio, all features are Available because the user has not selected a feature from either family.\nRegarding the trim level nodes (9-12), nodes 9 and 10 have downward markers because they were determined to not be false nodes at S352; their source nodes were marked with a downward arrow at S354; and they were determined to be on a valid path\nwith Red paint at S356.  However, nodes 11 and 12 do not have downward markers because they are not on a valid path with Red paint.  Since the user has selected Red paint, the non-selected paint features (White and Blue) are set to not allowed at step\nS322 (FIG. 41) and thus the condition of step S356 is not met for nodes 11 and 12.\nRegarding the moonroof level nodes (13-16), node 14 has a downward marker because it is valid with Ruby trim; however node 13 does not have a downward marker because it is not on a valid path with Ruby trim.  Since the user has selected Ruby\ntrim, the non-selected trim features (Stone and Charcoal) are set to not allowed at step S322 (FIG. 41) and thus the condition of step S356 is not met.  Additionally, nodes 15 and 16 are not marked because their source nodes (11 and 12) were not marked,\nand thus nodes 15 and 16 do not satisfy the condition of step S354.\nThe downward traversal subroutine S332 includes three for-loops.  Once the configuration engine 106 has analyzed all paths it will make a negative determination at step S336, i.e., the level (x) will not be less than the number of families; and\nthe configuration engine 106 will proceed to step S362 and return to the main routine of FIG. 39.\nAt S364, the configuration engine 106 traverses the MDD of FIG. 45 in an upward direction, which is illustrated by MDD 4600 in FIG. 46.  The subroutine of S364 is shown in the flowchart of FIG. 43.  The configuration engine 106 starts analyzing\nthe nodes included in the last family level of the MDD 4600 (i.e., the moonroof family) at step S366.  At step S368, the configuration engine 106 determines if the family level (x) is greater than or equal to zero (i.e., not negative).  If so, the\nconfiguration engine 106 proceeds to step S370.\nAt step S370, the configuration engine 106 starts analyzing node zero.  At step S372 the configuration engine 106 compares the node number (y) to the number of nodes at the current level (x) to determine if y&lt;Level (x) number of nodes.  For\nexample, initially, x is equal to zero and Level (0) has one node, and therefore y is less than 1.  If y is not less than the number of nodes at level (x), the configuration engine proceeds to step S374 and decreases the level (x) by one.\nAfter a positive determination at step S372, the configuration engine 106 proceeds to step S376 and sets the currently analyzed node or source node (SRC) to Level(x)(y); and sets the array index (z) extending from SRC to zero.  At step S378 the\nconfiguration engine 106 compares the array index (z) to the SRC's number of children.  If z is not less than SRC's number of children, the configuration engine 106 proceeds to step S380 and increments the node (y) by one.  If the determination at step\nS378 is positive, the configuration engine 106 proceeds to step S382.\nAt step S382, the configuration engine 106 sets the destination node (DST) to be the child node of node (y) along array index (z) (DST=SRC.child(z)).  The configuration engine 106 analyzes three conditions to determine whether or not to mark the\ndestination node with an upward arrow: 1) the destination node is not a false node; 2) the destination node was previously marked with an upward arrow; and 3) the feature of array index (z) is allowed by constraint.  These three conditions are\nillustrated by steps S384-S388 in FIG. 43.\nAt step S384, the configuration engine 106 evaluates the DST node to determine if it is a false node.  Otherwise, the configuration engine 106 proceeds to step S386 to determine if the destination node (i.e., the child of the currently analyzed\nsource node) was previously marked with an upward arrow.\nAfter a positive determination at S386, the configuration engine 106 determines if the feature of array index (z) is allowed by constraint at step S388, which was previously determined in steps S320-S324 (FIG. 41).  If the conditions of steps\nS384, S386 and S388 are met, the configuration engine 106 proceeds to step S390 and marks the source node with an upward marker, by setting mark.up(SRC) to true.\nAt steps S392 and S394, the configuration engine 106 identifies Available features.  The configuration engine 106 evaluates the source node to determine if it was previously marked with a downward arrow at S392; and if so it proceeds to step\nS394 and sets the feature (z) of node (y) to Available.  Thus, Available features are identified by inspecting each node on the upward traversal.  If there is a valid downward path to the node, and a valid upward path from one of its destinations, the\nconfiguration engine 106 identifies this node as part of a valid path with respect to selections from other families.  Any feature that is on the edge from the node to the destination is identified as Available, because it can be selected without\nrequiring a change to the constrained features.  If any of the conditions of steps S384-S388 and S392 are not met, the configuration engine 106 proceeds to step S396 and increments the array index (z) by one.\nOnce the configuration engine 106 has analyzed all paths it will make a negative determination at step S368, i.e., the level (x) will not be greater than or equal to zero; and the configuration engine 106 will proceed to step S398 and return to\nthe main routine of FIG. 39.\nReferring to FIG. 39, after determining the availability of all features at S364, the configuration engine 106 proceeds to step S400 to determine the feature states.  The subroutine of S400 is shown in the flowchart of FIG. 44.  The\nconfiguration engine 106 starts analyzing the features included in family level zero of the MDD 4600 (e.g., the package family) at step S402.  At step S404, the configuration engine 106 determines if the family level (x) is less than the total number of\nfamilies included in the MDD.  If so, the configuration engine 106 proceeds to step S406.  At step S406, the configuration engine 106 starts analyzing node zero.  At step S408 the configuration engine 106 compares the node number (y) to the number of\nfeatures at the current family level (x) to determine if y&lt;family (x) number of features.\nAfter a positive determination at step S408, the configuration engine 106 proceeds to step S410 and sets the currently analyzed feature (FEAT) to Family(x).Feature(y).  At step S412, the configuration engine 106 evaluates all of the features of\na family, one at a time, to determine if a feature is selected.  If a feature (FEAT) is selected, the configuration engine 106 sets the state of the feature to Selected at S414.  If the feature is not selected, the configuration engine 106 proceeds to\nS416 to determine if the feature was set to Available at S394.  If the feature is Available, the configuration engine 106 proceeds to operation S418 and sets the state of the feature to Available.  If the feature is not Selected and not Available, the\nconfiguration engine 106 sets its state to Excluded at S420.  After steps S414, S418 and S420 the configuration engine 106 proceeds to step S422 to increment the analyzed feature (y) by one.  After evaluating each feature of family (x) to determine if it\nis Available, Selected or Excluded, the configuration engine 106 will make a negative determination at S408 and then proceed to step S424.\nAt steps S424-S428 the configuration engine 106 determines if family (x) has Included features.  First the configuration engine 106 determines if family (x) has any Selected features at S424.  Otherwise, the configuration determines if the\nfamily has exactly one Available feature at S426.  If only one feature of a given family is Available, then the sole Available feature is set to Included at S428.  After steps S424, S426 and S428 the configuration engine proceeds to step S430 and\nincrements the family level (x) by one, then repeats steps S404-S428 for the next family level.  Once the configuration engine 106 has determined the feature states for all families of the MDD, it makes a negative determination at S404 and then returns\nto the main routine at S432.\nJust as the restricted domain method S200 can be performed as a read only step, the dynamic programming method S300 is also read-only and thread safe when the downward and upward markers are kept externally.  Because feature state calculation\noperation is thread safe, multiple configuration requests could be handled simultaneously using the same MDD.  Each request has its own copy of external downward and upward markers, and shares the MDD.  Thread safety is a property that allows code to run\nin multi-threaded environments by re-establishing some of the correspondences between the actual flow of control and the text of the program, by means of synchronization.  For N selections, the restricted domain calculation requires N+2 MDD traversals. \nAn advantage of the dynamic programming method S300 over the restricted domain method S200 is that only two MDD traversals are required regardless of the number of selections.  This provides the dynamic programming method S300 with superior scalability\nfor large and complex MDDs.\nReferring to FIG. 46, the MDD 4600 illustrates the marked nodes after the configuration engine 106 has performed the dynamic programming method S300 including the downward traversal subroutine of FIG. 42 and the upward traversal subroutine of\nFIG. 43 for a selection of Red paint and Ruby trim.  The configuration engine 106 marks the truth node (T) with an upward marker at S312 because the truth node is a special case that always has a valid upward path.\nOn the upward traversal of the MDD 4600, a node is marked at S390 if the conditions of steps S384-S388 are met for the analyzed node.  Regarding the moonroof level of nodes, the configuration engine 106 marks node 13 with a upward marker or\narrow at S390 because its destination node (truth node) was determined to not be a false node at S384; node 13's destination node (truth node) was previously marked with an upward arrow at S386; and the feature of the array index connecting node 13 and\nthe truth node (i.e., MoonRf.Less) was determined to be allowed by constraint at S388.  Since the user has not selected a moonroof feature for this example, all moonroof features are set to Allowed (see steps S320, S324 of FIG. 41.) Similarly, the\nconfiguration engine 106 determines that the remaining moonroof level nodes (nodes 14, 15 and 16) have valid upward markers.\nThe configuration engine 106 determines the availability of the moonroof family features by evaluating the downward markers on the source moonroof nodes at S392 after evaluating the upward markers on the destination truth node (T) at S386. \nSince all of the moonroof nodes (13-16) were marked with a downward arrow and the truth node was marked with an upward arrow, the configuration engine 106 sets all of the moonroof features to Available at S394 and determines the initial availability bit\nset to be 000 000 000 000 11.\nRegarding the trim level nodes (9-12), the configuration engine 106 marks node 10 with a upward marker or arrow at S390 because its destination node (node 14) was determined to not be a false node at S384; node 10's destination node (node 14)\nwas previously marked with an upward arrow at S386; and the feature of the array index connecting node 10 and node 14 (i.e., Trim.Ruby) was determined to be allowed by constraint at S388, because it was selected by the user at S322.  Similarly, the\nconfiguration engine 106 marks node 11 with an upward marker or arrow at S390.  However, the configuration engine 106 does not mark nodes 9 and 12 with an upward arrow at S390 because they are not on a valid path with Ruby trim.  Since the user has\nselected Ruby trim, the non-selected trim features (Stone and Charcoal) are set to not allowed at step S322 (FIG. 41) and thus the condition of step S388 is not met for nodes 9 and 12.\nThe configuration engine 106 determines the availability of the trim family features by evaluating the downward markers on the source trim nodes S392, after evaluating the upward markers on the destination moonroof nodes (13-16) at S386.  Trim\nnodes 9 and 10 each have a downward marker and a destination with a valid upward marker (i.e., moonroof nodes 13 and 14).  Therefore Ruby trim along path 10-14 and Stone trim along path 9-13 are marked as Available features at S394 because either can be\non a path (in a configuration) with Red paint.  However, trim nodes 11 and 12 do not have a downward marker and therefore are not marked as Available.  The Trim selection can change from Ruby to Stone without requiring a change to the paint selection\n(Red).  However, the Trim selection cannot change from Ruby to Charcoal without requiring a change to the paint (Red).  Therefore the configuration engine 106 determines the Charcoal trim to be Excluded at S420.  The configuration engine 106 determines\nthe updated availability bit set to be 000 000 000 101 11.\nRegarding the paint level nodes (6-8), the configuration engine 106 marks node 7 with an upward marker because its destination node (10) was determined to not be the false node at S384; its destination node (10) was previously marked with an\nupward arrow (S386); and the features of the array indexes connecting node 7 and node 10 (i.e., Paint.Red) were determined to be allowed by constraint at S388 because it was selected by the user at S322.  Similarly, the configuration engine 106 marks\nnode 8 with an upward marker or arrow at S390.  However, the configuration engine 106 does not mark node 6 with an upward arrow at S390 because its destination node (9) was not marked with an upward arrow, and thus node 9 does not satisfy the condition\nof step S386.\nThe configuration engine 106 determines the availability of the paint family features by evaluating the downward markers on the source paint nodes (6-8) at S392, and by evaluating the upward markers on the destination trim level nodes (9-12) at\nS386.  Paint nodes 7 and 8 each have a downward marker and a destination with a valid upward marker (i.e., trim nodes 10 and 11).  Therefore Red paint along path 8-10 and path 7-10, and Blue paint along path 7-11 are marked as Available features at S394. White paint along path 6-9 is not marked as an Available feature at S394, because node 9 was not marked with an upward marker at S386.  Since Red paint and Blue paint are both Available, the paint selection can be changed between Red and Blue, without\nrequiring a change to the trim selection (Ruby).  The configuration engine 106 determines the updated availability bit set to be 000 000 011 101 11.\nWith respect to the partial configurations of the package and radio families, all features are allowed at S324 because the user has not selected a feature from either family.  Therefore nodes 2, 4 and 5 are marked with an upward arrow.  But node\n3 is not marked with an upward marker at S390 because its destination node (6) was not marked with an upward arrow, and thus node 3 does not satisfy the condition of step S386.\nThe configuration engine 106 determines the availability of the radio family by evaluating the downward markers on the source radio nodes (3-5) at S392, and by evaluating the upward markers on the destination paint nodes (6-8) at S386.  Radio\nnodes 4 and 5 each have a downward marker and a destination with a valid upward marker (i.e., paint nodes 7 and 8).  Therefore Navigation radio along path 5-8 and path 4-7, and Deluxe radio along path 5-7 and path 4-7 are marked as Available features at\nS394.  The Standard radio along path 3-6 is not marked as an Available feature at S394, because node 6 was not marked with an upward marker at S386.  Since the Navigation radio and the Deluxe radio are both Available, the radio selection can be changed\nbetween Navigation and Deluxe, without requiring a change to the paint selection (Red) or the trim selection (Ruby).  The configuration engine 106 determines the updated availability bit set to be 000 011 011 101 11.\nThe configuration engine 106 determines the availability of the package family by evaluating the downward markers on the source package node (2) at S392, and by evaluating the upward markers on the destination radio nodes (3-5) at S386.  The\npackage node 2 has a downward marker and destinations with valid upward markers (i.e., radio nodes 4 and 5).  Therefore the 401 package along path 2-4 and the 402 package along path 2-5 are marked as Available features at S394.  The 400 package along\npath 2-3 is not marked as an Available feature at S394, because node 3 was not marked with an upward marker at S386.  Since the 401 package and the 402 package are both Available, the package selection can be changed between 401 and 402, without\nrequiring a change to the paint selection (Red) or the trim selection (Ruby).  The configuration engine 106 determines the full availability bit set to be 011 011 011 101 11 using the dynamic programming method S300, which is consistent with its\ndetermination using the restricted domain method S200 as described above with reference to FIG. 34 and shown in FIG. 36.\nEach time the user selects a feature, the configuration engine 106 updates the configuration by adding the new feature and removing the sibling features of the same family.  Then the configuration engine 106 performs a \"containsAny\" operation,\nas described above with reference to FIGS. 20-21, to see if the MDD contains the new configuration.  If the MDD does not contain the new configuration, then the new configuration is invalid and the configuration engine 106 performs a conflict resolution\nstrategy.\nGenerally, there are two types of conflict resolution strategies invoked when a user selection, or change in selection, leads to a conflict: single conflict resolution and branched conflict resolution.\nIn single conflict resolution, the configuration engine 106 returns the single \"next-closest\" valid configuration and the feature additions and subtractions necessary to change the invalid configuration to a valid configuration in its response. \nThe \"closest\" valid configuration would typically be determined by simply changing the newly requested feature back to its prior state.  However, such a change would be inconsistent with the user's selection.  Therefore the configuration engine 106\ndetermines the next-closest valid configuration using a constraint that the newly requested feature is \"locked\" and not allowed to be changed, according to one or more embodiments.\nIn branched conflict resolution, the configuration engine 106 presents a set of configurations to the user in a resolution tree that are closest to the invalid configuration, and the user is prompted to make changes to the configuration to get\nto a valid configuration.  When resolving conflicts there may be multiple valid configurations all at the same distance from the initial configuration.  In this case there are a set of possible answers when finding the next-closest valid configuration. \nAn option then is to use branched conflict resolution.\nA strategy that is used to determine the closeness between configurations is referred to as the \"minimum edit distance.\" In a configurator application 104, the configuration engine 106 determines the minimum edit distance between an invalid\nconfiguration selected by the user and one or more valid configurations.  The minimum edit distance refers to the number of features in the configuration that must be changed in order to transform the invalid configuration into a valid configuration. \nWhen comparing the invalid configuration to a valid configuration, the configuration engine 106 considers substitute operations to identify what features must change to create a valid configuration without changing the newly requested locked feature.\nWith reference to FIG. 47, a method for resolving conflicts between a user selected invalid configuration and one or more valid configurations is illustrated in accordance with one or more embodiments and generally referenced by S500.  The\nmethod S500 is implemented as an algorithm within the configuration engine 106 using software code contained within the server 102, according to one or more embodiments.  In other embodiments the software code is shared between the server 102 and the\nuser devices 112, 114.\nAt step S502, the configuration engine 106 saves a copy of the root node identity and a set of the node edges to the memory 108 (shown in FIG. 2).  S502 is similar to subroutine S102 described above with reference to FIG. 26.  The configuration\nengine identifies each node (y), copies or clones each outgoing edge of each node (y) in an MDD, and then returns the edge set and the identity of the root node.\nAt step S504 the configuration engine 106 performs a minimum edit calculation of an MDD that is restricted to the configurations that contain the feature selection that triggered the conflict.  In one embodiment the configuration engine 106\nrestricts the MDD using the restrict method as described above with reference to FIGS. 22-23.  In other embodiments, the configuration engine 106 restricts the MDD using the quick-restrict method S100 described above with reference to FIGS. 24-28.  The\nquick-restrict based minimum edit calculation subroutine of S504 is shown in the flowchart of FIG. 48.\nAt step S506 the configuration engine 106 examines the cache memory for source (SRC) node (y) to determine if the quick-restrict subroutine has already been performed on node (y).  If cache (y) exists, then the configuration engine 106 proceeds\nto step S508 and returns to the main routine of FIG. 47.  If cache (y) does not exist, the configuration engine 106 proceeds to step S510.\nAt step S510, the configuration engine 106 starts with array index zero, and sets the empty flag to true.  By setting the empty flag to true, the configuration engine 106 assumes that there are no valid paths from the node, i.e., that all edges\npoint to the false node.  The configuration engine 106 also sets the minimum or best (Best) edit distance as the maximum allowable integer value (Integer Max Value).\nAt step S512, the configuration engine 106 evaluates the array index (z) to determine if (z) is less than the number of node (y)'s children.  A positive determination at step S512 indicates that the configuration engine 106 has not analyzed all\narray indexes of node (y).  If the determination is positive, the configuration engine 106 proceeds to step S514.\nAt step S514, the configuration engine 106 checks if y's child, or destination (DST) node, at array index (z) is false.  If the configuration engine 106 determines that the child is false, then it proceeds to step S516, increments the array\nindex (z) by one, and returns to step S512.  If the determination at step S514 is negative, the configuration engine 106 proceeds to step S518.\nAt step S518 the configuration engine 106 initializes the edits for feature (z) to the maximum integer value, e.g., by setting the total edit distance (cacheBot (z)) for the path from the truth node to the source node to the Integer Max Value.\nAt step S520, the configuration engine 106 evaluates the quick-restricted features list for node (y) to determine if it contains feature (z).  Otherwise, the configuration engine 106 sets y's child node along z to false at 5522 and then proceeds\nto step S516 to increment the array index (z) by one.\nAt step S524, the configuration engine 106 sets the edit value (EDIT) for the source node at feature (z).  If the configuration includes feature (z), then the configuration engine sets EDIT to zero.  If the configuration does not include feature\n(z), then the configuration engine sets EDIT to one.\nAt step S528, the configuration engine 106 check's if y's child (DST) at array index (z) is true.  If DST is true, the configuration engine 106 proceeds to step S530 and sets the empty flag to false.  At 5532, the configuration engine 106\ncalculates and stores the edit distance or cost (EDIT) for this feature.  Then the configuration engine 106 calculates the total edit distance (cacheBot (z)) for the path from the truth node to the source node, as the sum of a previously calculated edit\ndistance for the path (cacheMid (DST)) and EDIT.  At step S534, the configuration engine 106 compares the total edit distance (cacheBot(z)) to the minimum edit distance (Best) for the given invalid configuration.  If the total edit distance for the\ncurrent feature (cacheBot (z)) is less than Best, the configuration engine 106 proceeds to step S536 and sets cacheBot (z) as Best.  Then the configuration engine 106 proceeds to step S516 and increments feature (z) by one.  If the configuration engine\n106 determines that DST is not the true node at S528, it proceeds to step S538.\nAt step S538, y's children, or (DST) nodes, are rewritten by the result of recursive invocation of the quick-restrict method on the child.  All nodes of the MDD are processed in this manner.  At step S540, the configuration engine 106 checks DST\nto determine if it's not a false node.  If the determination is negative, i.e., DST is the false node, then then the configuration engine 106 proceeds directly to S516 to increment the array index (z).  If the determination is positive (e.g., if node (y)\nis connected to a valid node), then the configuration engine 106 proceeds to steps S530-S536 to update the EDIT distance and compare it to the Best minimum edit distance.\nThe quick restrict based minimum edit calculation subroutine S504 operates on the nodes in a depth first search fashion.  Steps S512-S540 demonstrate an iterative process that operates on each array index (z) of a node (y) before proceeding to\nthe next node.  Once the configuration engine 106 has evaluated all array indexes (z) for a node (y), it will make a negative determination at step S512 (i.e., z will be greater than or equal to the number of y's children), and proceeds to step S542.\nAt step S542 the configuration engine 106 checks if all children (DST) of node (y) are false, i.e., it evaluates the empty flag to determine if any valid configurations were found.  If all of y's children are false, the configuration engine 106\nproceeds to step S544, sets node (y) to the false node, and then returns the cache (y), i.e., saves the analysis of node (y) and returns to the main routine of FIG. 47.  Further, if the node does not contain any edges that conform to the constraint, then\nthe edge pointer is disconnected from the child node in the MDD.  If not all of the children nodes are false, then the configuration engine 106 proceeds to step S546, sets the cacheMid (SRC Node) to Best, and then sets feature (z) to zero.\nAt step S548, the configuration engine 106 again evaluates the array index (z) to determine if (z) is less than the number of node (y)'s children.  Otherwise, the configuration engine 106 proceeds to step S550, sets the cache (y) to (y), and\nthen returns the cache (y), i.e., saves the analysis of node (y) and returns to the main routine of FIG. 47.  A positive determination at step S548 indicates that the configuration engine 106 has not analyzed all array indexes of node (y).  If the\ndetermination is positive, the configuration engine 106 proceeds to step S552.\nAt step S552, the configuration engine 106 compares the total edit distance (cacheBot (z)) to the minimum edit distance (Best) for the given invalid configuration.  If the total edit distance for the current feature (cacheBot (z)) is greater\nthan Best, the configuration engine 106 proceeds to step S554 and sets DST node to false at step S554, and then increments feature (z) by one at step S556 and then returns to S548.\nThe quick-restrict based minimum edit calculation subroutine S504 is a recursive process.  This process continues until all nodes are analyzed, then the configuration engine 106 returns to the main routine of FIG. 47.  The edges for complete\npaths from the root node (node 2) to the truth node (T) define the restricted configuration space.\nThus, the configuration engine 106 calculates the minimum edit distance of all paths, and identifies the minimum edit distance using subroutine S504.  The configuration engine 106 calculates the minimum edit distance on the way back up the MDD,\ni.e., during an upward traversal.  When a new minimum edit distance is found, prior minimum edit paths are trimmed from the MDD by setting the minimum edit distance (Best) to the currently analyzed path (cacheBot (z)) at S536.  The minimum edit distance\nof a path refers to the sum of the edit distances of each edge.  The edit distance for each feature change is 1.  Where there is more than one active feature on an edge, the path for each feature is considered separately when calculating the minimum edit\ndistance.  Then the configuration engine 106 restricts the MDD to the paths that have the minimum edit distance by setting child or destination (DST) nodes to false if the edit distance for their path (cacheBot (z)) is greater than the minimum edit\ndistance (Best) at S554.\nFIG. 49 includes an original or unrestricted MDD 4900, an intermediate MDD 4902 and a final restricted MDD 4904 illustrating the impact of various steps of subroutine S504.\nIn one example, the user selects the 400 package.  Then the configuration engine 106 determines that the Standard (Std) radio, Stone trim and no moonroof (Less) are Included features; and that White paint is a Default feature.  The states of\nthese features are represented by underlined text, boxed text and circled text, respectively in FIG. 49.  Next the user selects Charcoal trim.  The new selected set (400, Charcoal) is not a valid combination because the 400 package can only occur with\nStone trim.  So the new configuration (400, Std, White, Charcoal, Less) is invalid.\nThe intermediate MDD 4902 illustrates the original MDD 4900 after the configuration engine 106 has performed the minimum edit calculation S504 on paths 2-13- .  . . T with respect to a newly selected Charcoal trim feature.  The configuration\nengine 106 first traverses path 2-13-14-15-16-T. No restrict is needed on the downward traversal because the only active trim feature on partial path 15-16 is Charcoal.\nThe configuration engine 106 calculates the minimum edit distance at steps S530-S536 (FIG. 48) during an upward traversal of the MDD.  The configuration engine 106 considers two edges for the partial path T-16: one edge with the moonroof (Vista)\nand one edge without the moonroof (Less).  The configuration engine 106 determines the edit distance for the partial path T-Vista-16 (i.e., with the moonroof (Vista)) to be one because it requires a change in the moonroof feature.  For the partial path\nT-Less-16 without the moonroof (Less), no change is required, so the edit distance is zero.  Because one path (T-Less-16) has a smaller edit distance than the other (T-Vista-16), the edge is restricted to keep the minimum edit path of T-Less-16.  The\nedge from 16-T now shows \"10\", and the edit cost for Node 16 is 0, as referenced by numeral 4906.\nContinuing on the upward traversal, the configuration engine 106 calculates the edit distance of the remaining partial paths to be: zero for 16-15, because it contains Charcoal trim; one for 15-14, because it contains Blue paint, not the Default\nWhite paint; one for 14-13, because it contains the Navigation radio, not the Included Standard radio; and one for 2-13, because it contains the 402 package, not the Selected 400 package.  Therefore the configuration engine 106 calculates the cumulative\nminimum edit distance for path 2-13-14-15-16-T to be three, as referenced by numeral 4908.\nThen the configuration engine 106 restricts the partial path 14-9-10-T because node 9 does not contain the selected Charcoal trim feature.\nNext, the configuration engine 106 considers path 2-13-8-11-12-T. First, partial path 8-11-12-T is considered, and found to have edit distance of 1 because node 8 contains Blue paint and not the Default White paint.  Then the configuration\nengine 106 restricts path 12-T to 12-Less-T; and restricts path 11-12 to 11-Charcoal-12 so that the edit distance for each is zero.\nThen the configuration engine 106 considers partial path 8-9-10-T; but, because of its previous analysis of node 9, it knows that this partial path has been restricted and the 8-9 edge is removed.  The cost of T-12-11-8-13 is 2.  At this point\nthe configuration engine 106 keeps both of the outgoing edges from 13 (i.e., 13-14 .  . . -T, and 13-8- .  . . -T) because they each require 2 edits.  The edit distance for partial path 13-2 is 1.  Thus, after traversing 2-13- .  . . -T, the\nconfiguration engine 106 determines that the current minimum edit distance for Node 2 is 3.\nThe final restricted MDD 4904 illustrates the original MDD 4900 after the configuration engine 106 has quick-restricted it to Charcoal trim at S504 and performed the minimum edit calculation for all paths.\nNext the configuration engine 106 considers path 2-7-8-11-12-T. The configuration engine 106 previously determined that the minimum edit distance at node 8 is 1.  The configuration engine 106 calculates the edit distance for partial path 8-7 to\nbe one because it contains Deluxe and Navigation radio features and not the Included Standard radio feature; and calculates the edit distance for partial path 7-2 to be one, because it contains the 401 package and not the selected 400 package.  The\nconfiguration engine 106 calculates the total edit distance for path 2-7-8-11-12-T to be three.  Since this total edit distance is the same as that of paths 2-13- .  . . -T, the configuration engine 106 keeps all three paths.\nNext the configuration engine 106 considers path 2-3-4-5-6-T. This path is restricted once the configuration engine 106 determines that partial path 5-6 is not compatible with the Selected Charcoal trim constraint.\nThe final MDD 4904 illustrates the final minimum edit space for the invalid configuration (400, Std, White, Charcoal, Less) with the Charcoal trim feature locked, after the configuration engine 106 has completed the minimum edit calculation\nsubroutine S504.  As shown in FIG. 49, the MDD 4904 contains three paths that each have a minimum edit distance of three: 2-1-14-15-16-T; 2-13-8-11-12; and 2-7-8-11-12-T.\nWith reference to FIG. 47, at step S558, the configuration engine 106 determines if the conflict resolution strategy selected for the application is a guided strategy, i.e., a branched resolution strategy.  If a guided conflict resolution is not\nselected, the configuration engine 106 proceeds to operation S560.  At step S560 the configuration engine 106 selects a single target configuration from the minimum edit space using an auto-completion technique such as sequence based or maximally\nstandard.  In one embodiment, the configuration engine 106 selects a single target configuration using a maximally standard auto-completion technique as described below with reference to FIGS. 93-117.  In another embodiment, the configuration engine 106\nselects a single target configuration using a maximum weight quick-restrict technique.\nThe maximum weight quick-restrict based single target configuration calculation subroutine of S560 is shown in the flowchart of FIG. 50.  The weights used in the weight calculation are based on priorities for features such that when there is\nmore than one feature available, the highest priority, or feature having the maximum weight, is chosen as the default.  S560 is similar to the minimum edit quick restrict calculation S504 of FIG. 48.  The only difference is that when the configuration\nengine 106 calculates the maximum weight, it 1) maximizes value instead of minimizing value (which changes the initial value of Best); and 2) calculates the weight for each path instead of the number of edits, where the weight is defined by a priority of\nthe features.\nReferring to FIG. 47, the configuration engine 106 resets or restores the original set of node edges to the memory 108 (shown in FIG. 2) at step S574.  S574 is similar to S146 described above with reference to FIG. 28.  At S574 the configuration\nengine 106 identifies each node (y), copies the outgoing edges of each node in the MDD.  Then the configuration engine 106 sets the MDD to the identity of the root node.\nAt step S576, the configuration engine 106 determines the feature states for the prior configuration.  The prior configuration refers to the prior valid configuration before the configuration engine 106 changed a feature based on a user\nselection; where the addition of the new feature led to an invalid configuration.  S576 is similar to subroutine S300 described above with reference to FIGS. 39-44.  At step S578, the configuration engine 106 determines the feature states for the new\ntarget configuration.  S578 is also similar to S300.\nWith reference to FIG. 49, in one embodiment the configuration engine 106 selects a single target configuration (401, Dlx, Blue, Charcoal, Less) from the minimum edit space of MDD 4904 as S560.  Once the target is identified, the configuration\nengine 106 determines feature states for the prior configuration at S576 and for the new target configuration at S578.  All features start as Default features.  Next, Selected features are determined by adding the previous selections that are still valid\nto the newly selected feature.  Then, the Available, Excluded and Available calculations are determined using the new selections.  In this example the new target configuration states are: Selected (Charcoal), Included (Blue) and Default (401, Dlx, Less).\nAt step S580 of FIG. 47, the configuration engine 106 generates a response that includes the feature additions and subtractions to resolve the conflict.  These features include feature state information--the new state for additions and the prior\nstate for subtractions.  The configuration engine 106 returns raw data including the new and prior feature state maps, the new configuration state (ConfigState), and the list of additions and subtractions.  The author decorator 154 will use this data to\ncompose the response.  The derivation of additions and subtractions subroutine S580 is shown in the flowchart of FIG. 51.\nAt 5582, the configuration engine 106 starts analyzing feature (z).  At step S584, the configuration engine 106 determines if the feature (z) is less than the total number of features for the source node.  If so, the configuration engine 106\nproceeds to step S586.  At step S586, the configuration engine 106 defines the term \"Prior\" as the prior feature state of feature (z) and the term \"State\" as the new feature state of feature (z).\nAt step S588, the configuration engine 106 evaluates the feature state term Prior (determined at S576) to determine if feature (z) was present in the prior configuration.  S588 is illustrated in the flow chart of FIG. 52.  If the Prior term is\nequal to Selected, Included or Default, then the configuration engine 106 determines that the Prior term defines a State of a feature that is present in the Prior configuration and returns true at step S592.  Otherwise, the configuration engine 106\nreturns false at S594.  Then the configuration engine 106 sets a boolean before value (BEF) equal to the determination at steps S590-S592, i.e., true or false.\nAlso at step S588, the configuration engine 106 evaluates the feature state term State to determine if it is present in the New configuration.  If the State term is equal to Selected, Included or Default, then the configuration engine 106\nreturns TRUE at step S592.  Otherwise, the configuration engine 106 returns false at S594.  Then the configuration engine 106 sets a boolean after value (AFT) equal to the determination at steps S590-S592, i.e., true or false.\nAt step S594, the configuration engine 106 compares BEF to AFT for feature (z) to see if it has changed.  Otherwise, i.e. if BEF equals AFT, the configuration engine 106 proceeds to step S596 and increments the family level (x) by one.  If the\ndetermination is negative, then the feature was either added or subtracted, and the configuration engine 106 proceeds to step S598 to evaluate \"Return Delta.\"\n\"Return Delta\" refers to the amount of information provided to the user in response to a conflict.  The front-end application 132 determines this level of information by setting the return delta feature to true or false.  Enabling the return\ndelta feature (i.e., setting return delta to true) results in more information being provided to the user.  Conversely, setting return delta to false results in less information being provided to the user.\nWhen the Return Delta flag is set to true, the response will include all additions and subtractions regardless of feature state.  This could allow the front-end application 132 to inspect the resolution and apply some additional logic when\ndeciding whether to prompt the user in response to a conflict or to silently make the changes.  When the Return Delta flag is set to false, the conflict resolution subtractions will only contain Selected features removed from the configuration and\nadditions will only contain Included features added to the configuration.  If the new configuration caused a change in a Default feature, this is not included in the prompt to the user.  If all changes are for Default choices, there are no changes to\nreport, and the response will not include conflict resolution.  The Return Delta flag is set to false by default, in one or more embodiments.\nAt S598, if Return Delta is set to true, the configuration engine 106 proceeds to step S600 to evaluate BEF.  If BEF is set to false at S588 (which indicates that feature (z) was contained in AFT but not in BEF), the configuration engine 106\nadds feature (z) to the list of additions (additions.add(feat(x))) at step S602.  If BEF is set to true (which indicates that feature (z) was contained in AFT but not in BEF), the configuration engine 106 adds feature (z) to the list of subtractions\n(subtractions.add(feat(x))) at step S604.\nIf Return Delta is set to false, the configuration engine 106 proceeds to step S606.  At S606, the configuration engine 106 evaluates BEF and the state of (z).  If BEF is false and the state of (z) is Default, the configuration engine 106\nreturns to S596 to increment the family level (x) by one.  If the determination at S606 is negative, the configuration engine 106 proceeds to step S608.  At S608, if BEF is true and the state of (z) is Selected, the configuration engine 106 returns to\nS596.  Otherwise, the configuration engine 106 returns to S600.\nFIG. 53 is a table 5300 that illustrates the additions and subtractions for the MDD 4900 of FIG. 49 when Return Delta is true and when Return Delta is false.  The MDD 4900 had a Prior configuration of Selected (400), Included (Std, Stone, Less)\nand Default (White), as referenced by numeral 5302.  The configuration engine 106 selected a new target configuration of Selected (Charcoal), Included (Blue) and Default (401, Dlx, Less) at step S578, as referenced by numeral 5304.  When Return Delta is\nfalse, the configuration engine 106 does not show changes (additions or subtractions) to Default Features, but when return delta is true, all changes are shown, as referenced by numeral 5306.\nFIG. 54 is a window 5400 that is displayed to the user to convey the additions and subtractions of features to their prior configuration to accommodate the new configuration triggered by their selection of Charcoal trim, using a single target\nconfiguration when Return Delta is false.  Again, when Return Delta is false, the configuration engine 106 does not show changes (additions or subtractions) to Default features.\nFIG. 55 is a window 5500 that is displayed to the user to convey the additions and subtractions of features to their prior configuration when Return Delta is true.  Since Return Delta is true, the configuration engine 106 shows all changes,\nincluding changes to the Default features.\nReferring to FIG. 47, the configuration engine 106 determines if guided resolution (i.e., branched conflict resolution) is selected at step S558.  If so, it proceeds to step S610.\nIn contrast to single conflict resolution, which only presents a single next-closest configuration to the user, branched conflict resolution can present the entire minimum edit space to the user, in tree format.  This allows the front-end\napplication 132 to present the user with a series of prompts to drive towards a valid configuration.\nIn the minimum edit example described above with reference to FIGS. 49 and 53-55, the minimum edit space contains three superconfigurations defining four configurations.  This space can be compressed to two superconfigurations as shown in FIG.\n56.\nFIG. 56 is a table 5600 that illustrates an example in which the paint family has just one choice (Blue) and the package and radio families each have two choices (401, 402 and Dlx, Nav), but, the choices are not dependent one each other.  The\nchoice of package (401 or 402) does not change the choice of radio (Dlx, Nav).  When all the family choices are independent, the configuration engine 106 can resolve the conflicts in a single step.\nThe configuration engine 106 derives a resolution object that describes the actions to change the invalid configuration to a valid configuration, which is transformed by the author decorators 154 into a SOAP xml response (not shown) which can be\npresented to a user in a single pop up window S700, as shown in FIG. 57.\nThis example illustrates the advantages offered by branched conflict resolution, as compared to single conflict resolution.  The configuration engine 106 presents the user with more information about how to resolve a conflict and asks them to\nchoose the valid package and radio features, rather than the application silently selecting a valid configuration.\nWhen there are no dependent choices, it is a relatively simple process to transform the target matrix into the conflict resolution response.  However, the resolution object is more complicated when one family's choice is dependent on another\nfamily.\nThe configuration engine 106 makes a series of prompts or inquiries to the user when the guided choices are dependent on a prior choice.  However, each prompt can include more than one independent choice.  When there is a nested or dependent\nchoice, the configuration engine 106 lists the divergent branch as the last feature group in the list.\nIn branched conflict resolution, the minimum edit space may include some partial matches, where a choice is present in some, but not all of the target configurations.  Partial matches in the configuration space can cause the target space to be\ntoo large, and it can lead to awkward user prompts.  In one or more embodiments, the configuration engine 106 trims the minimum edit space to remove partial matches.\nWith reference to FIG. 47, at step S610, the configuration engine 106 determines if removing partial matches functionality is enabled.  If the determination at S610 is positive, the configuration engine 106 proceeds to S612.  The algorithm for\nremoving partial matches S612 is shown in the flowchart of FIG. 58.\nWith reference to FIG. 58, at step S614 the configuration engine 106 creates a weight object, with positive weights for features that are contained within the configuration, and zero weight for features that are not contained within the\nconfiguration.\nAt step S616, the configuration engine 106 creates cache objects.  The configuration engine 106 returns data from cache for node (Y) for weightFeature and for weightNode, if it already exists.  WeightFeature refers to the weight from the node to\nthe bottom of the MDD (i.e., the true node)--for a specified feature.  WeightNode is a Node-based lookup instead of feature based lookup.  Thus, for each node, the configuration engine 106 determines the maximum weight path feature for a given node,\nstores the weight for each feature.  Once the configuration engine 106 knows the maximum feature weight for a node and trims its edges, then it stores the maximum node weight.  The maximum node weight is used as a cache for when the configuration engine\n106 analyzes subsequent nodes.  It can use the previously calculated maximum weight for that node and trim the outgoing edges from the node to only those edges with the maximum weight.\nAt step S618, the configuration engine 106 performs the maximum weight quick-restrict operation.  The maximum weight quick-restrict operation of S618 is the same as the maximum weight quick-restrict subroutine S560 described above with reference\nto FIG. 50.  After the quick restrict operation has removed partial matches, the configuration engine 106 proceeds to S620 (FIG. 47) to derive a resolution object.\nReferring back to FIG. 47, if the configuration engine 106 determines that removing partial matches functionality is not enabled at S610, it proceeds to S620 to derive a resolution object.  The algorithm for deriving a resolution object S620 is\nshown in the flowcharts of FIGS. 59-63.\nReferring to FIG. 59, the configuration engine 106 identifies families to change at step S622.  The algorithm for identifying families to change S622 is shown in the flowchart of FIG. 60.  Referring to FIG. 60, the configuration engine creates a\nbitset of the invalid configuration at step S624.  Next, the configuration engine calculates the domain bitset of the minimum edit space at step S626.  Then at step S628, the configuration engine ANDS the configuration bitset and the domain bitset.\nFIGS. 64-74 are examples illustrating the impact of various steps of the derive resolution object subroutine S620 of the branched conflict resolution method.  Referring to FIG. 64, in one example, a configuration of Default (400, Std, White,\nStone, Less) is modified when the user selects the 401 package.  The configuration engine 106 determines the new invalid configuration to be (401, Std, White, Stone, Less) with a minimum edit space depicted by MDD 6400.\nFIG. 65 is a table 6500 listing the invalid configuration (401, Std, White, Stone, Less) as a bitset (010 100 100 100 10).  FIG. 66 is a table 6600 that depicts the minimum edit space of the configuration converted to a matrix, as determined in\nstep S626 (FIG. 60).\nReferring back to FIG. 60, the configuration engine 106 starts analyzing the nodes included in family level zero (x) of the MDD at step S630.  At step S632, the configuration engine 106 determines if the family level (x) is less than the total\nnumber of families included in the MDD.  If so, the configuration engine 106 proceeds to step S634.\nAt S634, the configuration engine 106 evaluates the number of active features in the intersection, or bitwise conjunction, or \"ANDed\" bitset for family (x).  If there is at least one active feature in the ANDed bitset for family(x), the\nconfiguration engine 106 proceeds to step S636 and increments the family level (x) by one.  However, if there are no active features in the ANDed bitset for family(x), the configuration engine 106 proceeds to step S638 and adds family(x) to the list of\nfamilies to change, and then proceeds to step S636.\nFIG. 67 is a table 6700 illustrating the bitwise conjunction (AND) of the domain of the edit space in the example from table 6600 with the invalid configuration from table 6500.  The configuration engine 106 identifies any family with no active\nbits (i.e., only \"0\" s) in the sum, as referenced by numeral 6702, as a family to change to transform the invalid configuration into a valid one.  Thus, the configuration engine 106 determines that the radio, paint and trim families are families to\nchange.\nWith reference to FIG. 60, once the configuration engine 106 has analyzed all families, it will make a negative determination at step S632, i.e., the level (x) will not be less than the number of families.  Then the configuration engine 106\nproceeds to step S640 and returns to the routine of FIG. 59.\nReferring to FIG. 59, at step S642 the configuration engine 106 trims the edit space to the families identified in S622.  Then at step S644, the configuration engine 106 converts the trimmed space to a matrix, which is represented by table 6600\n(FIG. 66).\nFIG. 68 is a table 6800 that illustrates the minimum edit space from table 6600 after it is trimmed to the families to change (i.e., radio, paint and trim) from table 6700.\nAt step S646 (FIG. 59), the configuration engine 106 creates a resolution object that describes the actions to change the invalid configuration to a valid configuration.  The algorithm for creating a resolution object S646 is shown in the\nflowchart of FIG. 61.\nIn creating a resolution object S646, the configuration engine takes as input the invalid configuration, a target matrix (i.e., the edit space), the list of families to change and the list of families that have been processed so far.  The list\nof families to change is sorted in priority order, according to one or more embodiments.  This sort can be provided by an alternate sequence, or default to the minimum edit space family structure shown in FIG. 68.\nThe configuration engine 106 divides the families to change into No-Branch and Branch lists.  The configuration engine 106 identifies any family that is not identical in all rows of the target matrix as a Branch family.  Each resolution contains\na list of actions for any number of No-Branch families and a single Branch family.\nAn action specifies the family to change, its prior choice, and its possible choice(s).  To simplify parsing of a resolution, the configuration engine 106 organizes the Branch action to be the last action.  The Branch items lead to a divergent\nchoice and the choices for the remaining families are unknown until the Branch family choice is made.  Each choice of the Branch family will have an associated nested resolution object defined in a feature choice that results in resolution mapping.  The\nnested resolution objects are derived by with a new target matrix that is restricted to the feature choice of the branching family, the original families list, and the updated processed families list.\nReferring to FIG. 61, step S648 is a recursive call in which the configuration engine 106 sets the families to consider changing (Families to Consider) equal to the families list minus the families that were already processed (Families\nProcessed).\nAt step S650, the configuration engine 106 divides the families to consider changing (Families to Consider) into Branch and No-Branch lists.  A Branch family is a family whose bit pattern is not identical in all rows of the target matrix,\nwhereas a No-Branch family's bit pattern is identical in all rows.  The algorithm for dividing families into Branch and No-Branch S650 is shown in the flowchart of FIG. 62.\nWith reference to FIG. 62, the configuration engine 106 derives a unique bit pattern for each family based on the target matrix at 5652.  The configuration engine 106 starts analyzing the nodes included in family level zero of the MDD at step\nS654.  At step S655, the configuration engine 106 determines if the family level (x) is less than the total number of families to consider changing in the MDD.  If so, the configuration engine 106 proceeds to step S656.\nAt step S656 the configuration engine 106 evaluates the number of unique patterns for family (x).  If there is more than one unique pattern, the configuration engine 106 proceeds to step S658 and adds the family to the Branch category.  If there\nis only one unique pattern, the configuration engine 106 proceeds to step S660 and adds family level (x) to the No-Branch list.  After steps S658 and S660, the configuration engine 106 increments the family level (x) by one and then returns to S655. \nOnce the configuration engine 106 has organized all families into the Branch and No-Branch lists, it makes a negative determination at S655, and then sorts the families within each list by priority at step S662, with the highest priority family listed\nfirst.  The priority of each family is based on its family weight and is determined by a separate system, according to one or more embodiments.  After S662, the configuration engine 106 returns to the create resolution object subroutine S646 of FIG. 61.\nReferring back to FIG. 68, the first call to derive the resolution method object S620 will use the invalid configuration from FIG. 65, the target matrix from FIG. 68, and will pass an empty list for the processed families list--deriveResolution\n(Cfg65, Matrix68, [Radio, Paint, Trim], [ ]).  As shown in table 6800, the bit pattern for radio (i.e., \"011\") is the same in both rows, but is different for both paint and trim.  Therefore the configuration engine 106 identifies radio as a No-Branch\nfamily at S656 and S660, because it only has one unique pattern.  And the configuration engine 106 identifies paint and trim as Branch families at S656 and S658, because they each have more than one unique pattern.\nReferring back to FIG. 61, the configuration engine 106 initializes a resolution object at 5664 by creating an empty object.  The configuration engine 106 starts analyzing the first No-Branch family (b=0) at step S666.  At step S668, the\nconfiguration engine 106 determines if the No-Branch family index (b) is less than the total number of No-Branch families.  If so, the configuration engine 106 proceeds to S670.  At step S670, the configuration engine 106 creates an action for No-Branch\nfamily index (b) and adds the action to the Resolution Object.  The algorithm for S670 is shown in the flowchart of FIG. 63.\nWith reference to FIG. 63, the configuration engine 106 initializes an empty Action object at step S672.  Next the configuration engine 106 sets a current feature (z) equal to the family feature (Family) in the invalid configuration at step\nS674.\nAt step S676, the configuration engine 106 sets the group of valid features for the user to choose from (Choices) equal to the active features for the No-Branch family index (b) in the target matrix domain.  Then at step S678, the configuration\nengine 106 returns the Action object to the subroutine S646 of FIG. 61.  With reference to FIG. 61, the configuration engine 106 adds the No-Branch family index (b) to the families processed list at step S679, then it increments the No-Branch family\nindex (b) by one and then returns to step S668.\nReferring to FIGS. 65-71, the configuration engine 106 initializes an empty resolution and adds an action for all No-Branch families, which in this case is radio--the only No-Branch family identified from table 6800.  As shown in table 6500, the\ninvalid configuration includes the Standard radio (i.e., \"100\") and the trimmed minimum edit space of table 6800 shows the possible valid choices for radio include Deluxe and Navigation (i.e., \"011\").  The Action for radio in this example specifies the\nfamily to change (i.e., radio), its prior choice (Standard), and its possible choices (Deluxe and Navigation), which may be represented by: Action {Radio, [Std], [Dlx, Nav]} as shown in FIG. 71.\nReferring back to FIG. 61, once the configuration engine 106 has analyzed all of the No-Branch families, it will make a negative determination at step S668 (i.e., the No-Branch family index (b) is greater than or equal to the number of No-Branch\nfamilies) and then proceed to step S680.  At S680 the configuration engine 106 evaluates the number of Branch families.  If there are zero Branch families, the configuration engine 106 returns to the derive resolution subroutine S620 of FIG. 59.  If\nthere are Branch families (i.e., Branch families &gt;0), the configuration engine 106 proceeds to step S682.\nAt S682 the configuration engine 106 sets Family equal to the first family (i.e., the highest priority family) in the Branch list.  At step S684 the configuration engine 106 creates Action for the Family.  The configuration engine 106\ninitializes an empty Action Object and sets the current feature equal to the Family configuration feature.  Next the configuration engine updates the Action to set Choices equal to the active features for Family in the target matrix domain.  At 5688, the\nconfiguration engine 106 creates a new Families Processed list by appending Family to the Families Processed list.\nAt step S690, the configuration engine 106 starts analyzing Choice (c=0).  At step S692, the configuration engine 106 compares Choice (c) to the number of choices.  If Choice (c) is less than the number of choices, then the configuration engine\n106 proceeds to step S694 and creates a new target matrix that is restricted to Choice (c).\nAt step S696, the configuration engine 106 creates a Resolution Object for Choice (c) using the new target matrix and the new Families Processed list by the result of recursive invocation.  At step S698, the configuration engine 106 updates the\nAction to set Branch for Choice (c) equal to the nested Resolution Object.  At step S700, the configuration engine 106 increments Choice (c) by one and returns to step S692.  Once the configuration engine 106 has analyzed all Choices, it determines that\nChoice (c) is equal to the total number of choices at S692 (i.e., C is not less than # Choices).  In response to a negative determination at S692, the configuration engine 106 proceeds to step S702 and adds the Action object to the Resolution.  Then it\nreturns to subroutine S620 (FIG. 59) and then back to the main conflict resolution routine S500 of FIG. 47.\nWith reference to FIGS. 65-71, the configuration engine 106 generates the Action for the highest priority Branch family, which in this case is the Paint family because it defaulted to using MDD/Matrix structure/family ordering where the right to\nleft ordering defines priority values.  As shown in table 6700, paint oriented to the left of trim, so paint is higher priority.  For each paint Choice, the configuration engine derives a nested resolution by first creating a new target matrix by\nrestricting to the paint choice, and making a call to derive resolution.\nAs shown in the trimmed minimum edit space of table 6800, there are two possible Choices for the paint family--Red (i.e., \"010\") and Blue (\"001\").  There will be two additional calls to derive resolution: one for Red\npaint--deriveResolution(Cfg65, Matrix.Red, [Radio, Paint, Trim], [Radio, Paint]); and one for Blue paint--deriveResolution(Cfg65, Matrix.Blue, [Radio, Paint, Trim], [Radio, Paint]).  As shown in FIG. 71, the Action for paint in this example specifies the\nfamily to change (i.e., paint), its prior choice (White, i.e., \"100\" in table 6500), and its possible choices (Red and Blue), which may be represented by: Action {Paint, [White], [Red, Blue]}.\nIn both cases (Red paint and Blue paint), the configuration engine 106 uses a trimmed target matrix and the families list contains only one family (trim) because there is only one other Branch family in this example.  FIG. 69 is a target matrix\n6900 for the Red paint choice.  The target matrix 6900 shows that there is just one choice for trim (i.e., Ruby, \"001\").  FIG. 70 is a target matrix 7000 for the Blue paint choice.  The target matrix 7000 shows that there are two choices for trim (i.e.,\nCharcoal and Ruby, \"011\").  The configuration engine 106 determines the resulting resolution of each target matrix 6900 and 7000 and adds the nested resolutions for paint to its action to determine a final resolution object 7100 (FIG. 71).\nAs shown in FIG. 71, the Action for the nested resolution for Red paint in this example specifies the family to change (i.e., trim), its prior choice (Stone, i.e., \"100\" in table 6500), and its possible choice (Ruby), which is represented by:\nAction {Trim, [Stone], [Ruby]}.  The Action for the nested resolution for Blue paint in this example specifies the family to change (i.e., trim), its prior choice (Stone, i.e., \"100\" in table 6500), and its possible choices (Charcoal and Ruby), which is\nrepresented by: Action {Trim, [Stone], [Charcoal, Ruby]}.\nReferring back to FIG. 47, at 5704, the configuration engine 106 restores the original set of node edges to the memory 108 (shown in FIG. 2).  5704 is similar to subroutine S146 of FIG. 28.  The configuration engine identifies each node (y),\ncopies each outgoing edge of each node.  Then, the configuration engine 106 sets the MDD to the identity of the root node.  At step S706, the configuration engine 106 returns a response by providing the resolution object 7100 to the author decorator 154;\nwho in turn transforms the resolution object 7100 into a SOAP xml response (FIG. 2) which is presented to the user in a series of windows, as shown in FIGS. 72-74.\nAs described above with reference to resolution object 7100 (FIG. 71), the configuration engine 106 determined a guided resolution that includes a nested choice for trim.  The Available choices for trim depend on the user's selection for paint. \nFIG. 72 depicts a window 7200 with a first prompt that is displayed to the user.  FIG. 73 and FIG. 74 show the next prompt displayed as determined by the choice of Red or Blue paint.\nIf the user selects Red paint in response to the prompt shown in window 7200, the configuration engine 106 will guide them along partial path 8-9-10 (FIG. 64) and then display window 7300 to instruct them to change the trim from Stone to Ruby.\nHowever, if the user selects Blue paint in response to the prompt shown in window 7200, the configuration engine 106 will guide them along partial path 8-11-12 (FIG. 64) and then display window 7400 to instruct them to change the trim from Stone\nto one of Charcoal and Ruby.\nAs described above with reference to FIG. 58, in branched conflict resolution the minimum edit space may include some partial matches, where a choice is present in some, but not all of the target configurations.  Partial matches in the\nconfiguration space can cause the target space to be too large, and it can lead to awkward user prompts.  The configuration engine 106 may trim the minimum edit space using the removing partial matches subroutine S612.  This is done using the maximum\nweight quick-restrict operation, according to one or more embodiments.  However, only the partial match features are provided with relative non-zero weights; all other features are given an equal weight of zero at S614.\nFIGS. 75-76 are examples illustrating the impact of various steps of the remove partial matches subroutine S612.  In the illustrated embodiment, a selection of D2 leads to the invalid configuration (A1, B2, C3, D2, E3, F1) with the minimum edit\nspace shown in MDD 7500 of FIG. 75.  There are two partial matches--B2 (i.e., the outgoing edge \"010\" from node 12) and E3 (i.e., the outgoing edge \"001\" from node 11)--where a user selection could remain the same or be changed.  If B2 remains unchanged,\nthen E3 must change to E2, because E3 is not located along the same path as B2 (i.e., partial path 11-12-13-14).  But, E3 can remain unchanged if B2 changes to B3, because E3 is located on the same path as B3 (i.e., partial path 11-15-16-14).\nWith an alternate sequence {A1 A2 B1 B2 B3 D1 D2 C1 C2 C3 C4 E1 E2 E3 F1 F2}, and an invalid configuration of {D2 A1 E3 B2 C3 F1}, the structure used for path weights is {A1 B2 C3 D2 E3 F1}.  The maximum weight operation will ignore any edges\nwith negative weights (A2 B1 C1 C2 C4 D1 E1 E2 F2).  The weights for the two paths in the minimum edit space are shown in Table 7600 of FIG. 76.  The first row shows path 2-10-11-12-13-14-1.  This path defines the configuration of {D2 A1 E2 B2 C2 F2} and\na path weight bit set of 010100.  There are two active bits in the path weight which correspond to the features B2 and D2--the two features on this path with non-negative weights.  There are no active bits for the other features (A1, C2, E2, F2) because\nthey have negative weights and are ignored.  The second row shows path 2-10-11-15-16-13-1.  This path defines the configuration of {D2 A1 E3 B3 C2 F2} and a path weight bit set of 000110.  There are two active bits in the path weight which correspond to\nthe features D2 and E3.  Based on these weights, the configuration engine 106 trims the space to a single path of 2-10-11-12-13-14-T. The higher priority family B will remain unchanged, and the resolution will include a change for family E.\nWhen an update request is made, the configuration engine 106 modifies the prior configuration by adding the newly Selected feature (while also removing the prior choice for the feature's family).  As described above with reference to FIGS. 47\nand 48, if the updated configuration is invalid, conflict resolution is triggered and the configuration engine 106 calculates the minimum edit space at S504.  The service API 134 does not dictate how the minimum edit space is calculated.  The\nconfiguration engine 106 determines the level of precedence to be given to prior Selected features.\nIn one embodiment, the configuration engine 106 treats all features in the invalid configuration equally, regardless of feature state.  In this instance the minimum edit calculation S504 is performed using the full invalid configuration.\nIn another embodiment, the configuration engine 106 gives precedence to keeping the maximum number of previously selected features.  The configuration engine 106 performs this strategy by performing the minimum edit calculation S504 using a\npartial configuration that ignores any feature whose prior state is Included or Default.  Only the new and previous Selected features are kept when making the minimum edit space calculation.  In one embodiment the configuration engine 106 performs the\nminimum edit calculation S504 after determining whether or not the resolution is guided at S558.  If the resolution is not guided, the configuration engine 106 performs the minimum edit space calculation S504 using only the Selected features.  However,\nif the resolution is guided, the configuration engine 106 performs the minimum edit space calculation S504 using the full invalid configuration.\nFIGS. 77-81 are examples illustrating the impact of various steps of the minimum edit space calculation S504 using a full configuration and using a partial configuration.  In the illustrated embodiments, the configuration engine 106 analyzes the\nfull buildable space shown in Table 7700 of FIG. 77, where the features are numerically named--e.g. Family E has two features E1 and E2.  If the previous configuration is Selected (F1, E2) and Included (A2, T1, R1) and Default (S5, P1, Y3) and an update\nrequest is received to select T2.  The configuration engine 106 determines that the updated configuration is invalid because (F1, E2, T2) is not a valid combination.  As shown in Table 7700, row 1 is the only configuration that includes both F1 and E2,\nbut it includes T1 not T2.\nThe two possible minimum edit spaces are shown in Table 7800 of FIG. 78 and Table 7900 of FIG. 79.  The first minimum edit space (7800) considers the partial configuration where only the new set of selected features is used in the minimum edit\nspace calculation (F1, E2, T2) and the second minimum edit space (7900) considers the full configuration where the complete invalid configuration is used in the minimum edit space calculation (F1, E2, A2, T2, R1, S5, P1, Y3).\nUsing the matrix structure as the priority sequence, the configuration engine 106 identifies a single target configuration from each minimum edit space.  The priority sequence is based on the matrix as is with left most bit being highest\npriority.  So in this case, the configuration engine 106 selects a configuration by choosing features for each family in a left-to right fashion, and choosing the left-most available feature for each family.  With reference to FIG. 78, since the E and F\nfamilies are the same for all configurations; and the configuration in the bottom row has the highest priority feature for family Y, the first space will result in a target of E1, F2, Y1, T2, R3, P1, S1, A2 which corresponds to the bottom row of Table\n7800.  The second space will result in a target of E1, F2, Y3, T2, R1, P1, S5, A2.  The decision on how to calculate the minimum edit space will affect the target configuration, and thus affects the number of feature edits required.\nTable 8000 of FIG. 80 shows the changes required (i.e., the shaded features in target 1) when the configuration engine 106 makes the minimum edit space calculation with only the selected features, based on the minimum edit space in Table 7800. \nAs shown in Table 8000, the features to change are: E1, F2, Y1, R3 and S1.\nTable 8100 of FIG. 81 shows the changes required (i.e., the shaded features in target 2) when the minimum edit space calculation is made with the full invalid configuration, based on the minimum edit space in Table 7900.  As shown in Table 8000,\nthe features to change are: E1 and F2.  In both cases the changes to families E and F are the same because T2 is only available with E1 and F2.  But, if the minimum edit space calculation considers only the Selected features, there are three other\nrequired changes (i.e., Y1, R3 and S1, as shown in Table 8000).\nWhen the configuration engine 106 performs the calculation with the full configuration, it minimizes the total edits, as shown in Table 8100.  It gives no special precedence to previous Selected features.\nWhen the configuration engine 106 performs the calculation with only the new selected set, it is attempting to minimize the changes to prior selections by giving precedence to Selected features.  The side effect is that this increases the total\nnumber of edits required, as shown in Table 8000.\nThe other motivation to perform the minimum edit space calculation on only Selected features is to ensure that the maximally standard default is always driven by the Selected set.\nThe configuration engine 106 results include a Boolean flag to indicate if there is a conflict.  When there is a conflict, the configuration engine 106 determines either a single conflict resolution object or a branched conflict resolution\nobject, depending on the guided resolution flag.\nBecause the services API 134 dictates that a conflict resolution is returned only if there are changes required to the previous selected features, it is possible that the same configuration request will return conflict=true when guided=true, but\nwill return conflict=false when guided=false.\nUsing the product definition from FIG. 10, in one example the configuration engine 106 considers a configuration where the user has selected Red paint, and autocomplete is true.  One such configuration is Selected (Red) and Default (400, Std,\nStone, Less).  If the user updates the configuration by selecting the navigation (Nav) radio, the new configuration (Nav, Red, 400, Stone, Less) is invalid.\nWhen guided resolution is true, the configuration engine 106 returns a conflict of false and a returns resolution such as {Actions [Action {Pkg, [400], [401, 402]}, Action {Trim, [Stone], [Ruby]}]}.\nHowever, when guided resolution is false, the API dictates that there is no conflict because the new Selected features (Nav, Red) are compatible.  Even though changes are required for Pkg and Trim, because these were default choices, no conflict\nis reported.  The configuration engine 106 will return conflict of false even though the new configuration and associated feature states show that there is a necessary change to prior default choices for the 400 package, and Stone trim--{Std=AVAILABLE,\nNav=SELECTED, Stone=EXCLUDED, White=EXCLUDED, Charcoal=EXCLUDED, Vista=AVAILABLE, Dlx=AVAILABLE, Red=SELECTED, 400=EXCLUDED, 401=DEFAULT, 402=AVAILABLE, Less=DEFAULT, Blue=AVAILABLE, Ruby=INCLUDED}.\nThe service API 134 specifies that a request can select or unselect a feature.  Selecting a feature adds it to the configuration.  When a feature is unselected, the API dictates only that the feature state is no longer Selected.  It does not\nrequire that the feature be removed from the configuration.\nThere are at least two embodiments.  In a first embodiment, the configuration engine 106 removes the unselected feature from the Selected set and proceeds normally.  In a second embodiment, the configuration engine 106 removes the unselected\nfeature from the configuration entirely.\nRemoving the unselected feature from the Selected set follows the API specification that the feature is no longer Selected.  However, the feature may not actually be removed from the configuration.  In a configurator application, this could mean\nthat the user unchecks the box to remove the feature only to have the checkbox checked again because it is not removed from the configuration.  This behavior can be difficult because no matter what the user does to try and remove the feature, the feature\nkeeps getting added back.\nIn this first embodiment, if a Default or Included feature is unselected, there will be no change in the configuration or feature states.  The Selected set does not change because the feature being unselected wasn't in the Selected set.  As\nsuch, an Included feature will remain Included and a default will remain default.  Included state depends on the Selected set which did not change and auto completion is designed to give repeatable results for the same minimally complete configuration\nwhich did not change.\nIf a Selected feature is unselected, the feature state may change to Included or Default.  If the feature is Included by the remaining Selected features, its state will change from Selected to Included.  Otherwise, it is possible that the\nremoved feature is added back during auto completion.\nDepending on the front-end application 132, the user is most likely unaware of the feature states of Selected, Included and Default.  If the user is unaware of feature states, it can be quite perplexing to unselect a feature only to have it\nremain in the configuration.\nTo avoid this confusion, in the second embodiment, the configuration engine 106 removes the feature from the configuration regardless of its state.  This implementation will trigger conflict resolution when a feature from the configuration is\nunselected.  To ensure the unselected feature remains absent from the new configuration, the configuration engine 106 restricts the buildable space to only those configurations that do not contain the unselected feature prior to the minimum edit\ncalculation.  This approach ensures that the unselected feature is removed from the configuration.\nWhen auto completion is enabled, the configuration engine 106 makes Default choices until the configuration is complete with respect to displayable families.  This is done by making determinations for each incomplete family that is consistent\nwith prior Selected and Included feature states.\nIn one embodiment, the configuration engine 106 makes Default feature state determinations based on a priority sequence for each family and feature.  Incomplete families are processed in priority order, and where more than one feature is valid\nwith prior Selected, Included and Default feature states, the feature priority is used to make the Default determination.\nWith reference to FIG. 82, a method for automatically completing a configuration using a sequence-based approach is illustrated in accordance with one or more embodiments and generally referenced by S750.  The method S750 is implemented as an\nalgorithm within the configuration engine 106 using software code contained within the server 102, according to one or more embodiments.  In other embodiments the software code is shared between the server 102 and the user devices 112, 114.  The method\nS750 uses quick-restrict and domain to make default selections.\nAt S752, the configuration engine 106 starts with an MDD restricted to Selected features, and a configuration defined by the Selected and Included features.  At S754, the configuration engine 106 sorts families by priority.  Then, at S756, for\neach family without Selected or Included features, that are sorted by priority, the configuration engine 106 calculates the domain of the current restricted space.  At S758, the configuration engine determines the highest priority feature for the family,\nmarks it as a Default feature, and further restricts the restricted space to this feature.\nAlternatively, in another embodiment, after S752, the configuration engine 106 proceeds to S760 and uses sequences to determine the maximally weighted path in the MDD that contains the Selected and Included features, which identifies default\nchoices for families to complete.\nPath weight can be represented by a feature Bitset, where the families are ordered left to right according to priority (with the leftmost family being the highest priority), and features are also ordered left to right according to priority\nwithin each family (with the feature corresponding to the leftmost bit being the highest priority).  This is analogous to sorting the features in descending priority and assigning weights by powers of 2, -1 2 4 8 16 .  . . , and ensures that each path\nwill be uniquely weighted, and that there will be exactly one maximally weighted path when each family and feature is assigned a sequence.  To compare two paths, the Bitsets are sorted in descending bit order.\nInitially the path weight is 0, and as an edge is added during MDD traversal, edge weight is added to the path by simply setting a corresponding bit associated with the feature on that edge.\nIdeally, the MDD structure would reflect the priority sequence for features and families.  However, compression of the MDD requires the family ordering to be determined by the compression algorithm, and the feature order is arbitrarily\ndetermined by feature conditions of the MDD algorithm.  While the MDD structure can't be used to store priority sequence, a secondary structure can be created to store this sequencing.  The MDD structure is used to determine the feature for each edge,\nand the alternate/secondary structure is used to set the feature's bits in the path weight Bitset.\nFIG. 83 shows an MDD 8300 that defines the same buildable space as MDD 1300 (FIG. 13), except that the features within each family are sorted alphabetically and the family order is based on MDD compression.  For example, the radio features are\nsorted as STD, DLX and NAV in MDD 1300 and as DLX, NAV and STD in MDD 8300.  FIG. 84 is a table 8400 that defines the alternate sequence structure defining path weights, which is the same as the structure of MDD 1300.\nReferring back to FIG. 82, the configuration engine 106 begins the weighted operation with a minimally completed configuration, and starts with a quick-restrict operation (S752).  In another embodiment, the configuration engine 106 combines the\nquick-restrict operation with the weighted operation (S760), as is done in Minimum Edit Distance subroutine described with reference to FIG. 48 regarding resolving configuration conflicts.  On the downward traversal, no additional action is taken.  On\nthe upward traversal, the configuration engine 106 calculates the path weight with the aid of the alternate sequence structure 8400.  Where a node has more than one outgoing edge, the weight is calculated separately for each feature that has a valid\noutgoing edge.  When a new maximally weighted path is found, lesser weighted paths are trimmed from the MDD.\nFIG. 85 illustrates an MDD 8500 after the configuration engine 106 restricts the MDD 8300 (FIG. 83) to a selection of Blue paint and no Included or Default features, i.e., a minimally complete configuration: Selected{Blue}+Included{ }+Default{\n}, as described with reference to S752.  Then configuration engine 106 starts the weighted operation, i.e., S760, with the quick-restricted space shown in MDD 8500.  Using depth-first search and traversing child edges in descending bit order, the first\npath traversed is 2-8-9-10-6-T.\nThe configuration engine 106 calculates path weight on the upward traversal beginning with partial path T-6-10-9.  This path weight, along with the weight of its partial paths, is shown in Table 8600 of FIG. 86.\nThe configuration engine 106 continues the downward traversal from Node 9 with the 401 package (Pkg.401).  There are two partial paths to consider: 9-5-7-T and 9-5-6-T. The two partial paths from Node 5 to the truth node are compared to find the\nmaximum weight between Ruby and Charcoal Trim, as shown in Table 8700 (FIG. 87).  The configuration engine 106 determines that Charcoal Trim (path 9-5-6-T) is the maximum, because 000 000 001 010 00 is greater than 000 000 001 001 00, as referenced by\nnumeral 8702, and the edge 5-7 (Ruby Trim) is removed (shown in FIG. 89).\nNext, the configuration engine 106 compares the paths from Node 9 to the Truth node, as shown in Table 8800 (FIG. 88).  The configuration engine 106 determines that the partial path for the 401 Package is the maximum because the corresponding\nbits (010) are greater than the corresponding bits of the 402 package (i.e., 001), as referenced by numeral 8802; and trims edge 9-10 from the MDD 8500.  At this point the MDD will look like MDD 8900, as shown in FIG. 89.\nThe maximum weight path for edge 8-9 is MoonRf.Less, because the corresponding bits for Less (10) are greater than the corresponding bits for Vista (01).  The configuration engine 106 determines that the configuration {Dlx, Less, 401, Charcoal,\nBlue} is the maximum weight for path 2-8- .  . . -T and that the maximum weight configuration for path 2-3- .  . . -T is {Std, Less, 401, Charcoal, Blue}.  The edge weights for these paths are shown in Table 9000 in FIG. 90, and the maximum weight\noutgoing edge from node 2 is Dlx, because 010 is greater than 001 (Nav), as referenced by numeral 9002.\nThe configuration engine 106 trims edges 2-8-9-5, 10-6 and 7-T as shown in MDD 8900 (FIG. 89).  This leaves the maximum weight path as 2-3-4-5-6-T, and the configuration engine 106 marks Radio.Dlx, MoonRf.Less, Pkg.401 and Trim.Charcoal as\nDefault features at S760 to generate an autocompleted configuration of: Selected {Blue}+Included{ }+Default{Dlx, Less, 401, Charcoal}.\nA problem with sequence based auto completion is that it requires additional data to define the priority sequence.  This requires manual setup for every vehicle in the catalog.  Furthermore, it is not guaranteed to provide the maximally standard\nconfiguration.\nSequence-based auto completion is attempting to supplement the MDD with data that will allow the autocompleted configuration to be maximally standard.  A \"maximally standard\" configuration is one where a configuration contains the most possibly\nstandard content, where standard content is determined by the product definition.  A standard feature is generally a feature that is included in the base price for a product, such as a vehicle.  Whereas an optional feature is typically an upgrade and\nwill increase the price of the product.\nFor simpler product definition, it is may be possible to ensure maximally standard configurations using the alternate sequence approach.  However, for more complex product definition, this approach will not work.\nThe product definition defines a set of feature conditions that determine when a feature is available.  There are three types of availability--as a standard feature, as an included feature, and as an optional feature.  A feature could have\ndifferent availability depending on the current configuration.  A standard feature is a feature that is included in the base product (vehicle) configuration and an optional feature is a feature that is not included in the base product.  An optional\nfeature is typically an upgrade that will add cost to the base price, but this is not always the case as a feature could be a zero-cost option or even a less expensive option than the standard feature.  An included feature is generally a feature that is\nassociated with another feature (e.g., a package) and was added to the product by selecting the other feature.  For example, leather seats and fuzzy dice may be included in the 401 package.  When the user selects the 401 package, they see one change in\nprice for the package, but the change includes both features (i.e., leather seats and fuzzy dice).\nThe configuration engine 106 uses the maximally standard algorithm to distinguish feature availability based on standard or optional feature conditions.  A feature included in a package is a special case of a standard feature.  In addition to\nthe valid buildable space, the product definition also defines the standard feature conditions for each family.  When the configuration engine 106 selects Default features using the maximally standard algorithm, it is configured to select as many\nstandard features as possible to avoid or limit adding optional content and potentially increasing the price when the user has not explicitly selected the feature.\nFIG. 91 is a Table 9100 that shows a matrix that defines the same buildable space as MDD 1700 (FIG. 17).  FIG. 92 is a Table 9200 that shows the standard feature conditions for the product definition defining the buildable space.\nFor the package (Pkg) family, there is a single feature condition defining Pkg.400 as the standard package, as referenced by numeral 9202.  For the Radio family, there are two standard feature conditions, as referenced by numeral 9204.  The\nfirst (upper row) defines Radio.  Std as the standard Radio for Pkg.400.  The second (lower row) defines Radio.Dlx as the standard Radio for Pkg.401 and Pkg.402.  The buildable space shows that Radio.Nav is also available.  Because this feature condition\nis not included in the Standard feature conditions (i.e., Radio.Nav is not active (1) in condition 9204), the navigation radio (Nav) is defined as an optional choice that can be added in place of the deluxe radio (Dlx) for the 401 or 402 package.  There\nis a single feature condition for the moonroof family defining no moonroof (Less) as the standard package, as referenced by numeral 9206.  There are two standard feature conditions for the dice family, as referenced by numeral 9208; the first defines no\ndice as the standard feature for white paint; and the second defines fuzzy dice as the standard feature for red and blue paint.  There are three standard features for the seat temperature (Temp) family, as referenced by numeral 9210; the first defines no\nseat temperature feature (LessTemp) as the standard feature for the 400 package; the second defines heated seat control (Heat) as the standard feature for the 401 package; and the third defines heated and cooled seat control (HeatCool) as the standard\nfeature for the 402 package.\nWith reference to FIG. 93, a method for automatically completing a configuration using a maximally standard algorithm is illustrated as software code in accordance with one or more embodiments and generally referenced by 9300.\nTo automatically complete the configuration using standard feature conditions, the configuration engine 106 first restricts the buildable space to the minimally complete configuration at operation 9301.  Families absent from the configuration\nare processed in priority order, and the space is restricted for each successive choice.  To make the default choice for a family, its standard feature conditions are inspected to see what standard choice(s) are still possible at operation 9304.  If no\nstandard choices are possible, the domain of the restricted space will define possible optional choices at operation 9306.  Where more than one possible choice exists for a family, alternate sequencing is used to choose the highest priority feature as\nthe default at operation 9308.\nIt is uncommon, but valid, for a family to have to no standard feature conditions.  This is handled as if no standard features are available, and the choice will be made from the optional content.\nIt is also valid for the standard feature conditions to define more than one standard feature for the same partial configuration.  Where more than one standard feature is available, the highest priority feature will be chosen.\nWhere all feature conditions for a family are stored in a single MDD, the standard features that are still allowed with prior choices can be identified by an AND operation of this MDD with the current restricted buildable space.  An AND\noperation generates a new MDD for each inspection of a feature condition MDD.  As discussed in the Quick-Restrict section, this will incur performance problems from garbage collection.  The alternate approach, as shown in FIG. 93, is to divide the\nstandard feature conditions by feature (and not just family) and use the containsAny operation.  The containsAny operation is the same logic as an AND operation, however the new space is not created.\nWith reference to FIG. 94, in one embodiment, the configuration engine 106 considers a scenario where a user has selected the Vista moonroof and Ruby trim.  With these two selections, Fuzy Dice is included.  Given a priority order of [Pkg,\nRadio, Moonrf, Temp, Paint, Dice, Trim], the families to autocomplete, in order are [Pkg, Radio, Temp, Paint].  The configuration engine 106 does not auto-complete the Dice, Trim and Moonroof families because they are already \"complete\", i.e., they have\nfeatures with Selected or Included feature states.\nThe configuration engine 106 restricts the MDD to the minimally complete configuration Vista, Ruby, and Fuzzy Dice as shown by MDD 9400 in FIG. 94.\nFirst, the configuration engine 106 processes the package family (Pkg) because it has the highest priority.  As described with reference to FIG. 92, there is one standard feature condition for the package family (i.e., Pkg 400, 9202).  Because\nthe 400 package (i.e., the left-most feature of Pkg) is not contained in the restricted space illustrated by MDD 9400, the standard feature is not available.  MDD 9400 shows that the domain of the package family is 011 showing that both the 401 and 402\npackages are available in the restricted space.  The configuration engine 106 chooses the 401 package based on priority and the space is further restricted to package 401 (i.e., nodes 9 and 10 are removed) as shown by MDD 9402.  The restricted space now\ncontains a single superconfiguration.\nNext, the configuration engine processes the radio family.  As described with reference to FIG. 92, there are two standard feature conditions for the radio family: one for Radio.  Std and one for Radio.Dlx (9204, FIG. 92).  At this point the\ndeluxe (Dlx) radio and the navigation (Nav) radio are available in the restricted space illustrated by MDD 9402.  The configuration engine 106 selects Dlx as a Default feature, because it is the only standard feature remaining in the restricted space,\nand further restricts the buildable space to Dlx, as indicated by the modified edge label from 011 to 010 and reference by numeral 9404.  However, this restriction will not change availability for other families since the space is already a single\nsuperconfiguration.\nNext, the configuration engine 106 processes the seat temperature (Temp) family.  There are three standard feature conditions for Temp (9210, FIG. 92).  But, since Pkg 401 has already been selected, only Temp.Heat will be available, as indicated\nby edge label 010 in MDD 9402.  Therefore the configuration engine 106 adds heated seats (Heat) to the configuration as a Default feature.\nNext, the configuration engine 106 processes the paint family.  There are no standard feature conditions for paint (Table 9200, FIG. 92).  The domain of the restricted space has two choices--Red and Blue, as indicated by edge label 011 in MDD\n9402.  The configuration engine 106 adds Red as the Default choice, and further restricts the MDD 9402 to Red (010) as referenced by numeral 9406, because Red (010) has more weight than Blue (001).\nFinally, the configuration engine 106 processes the dice family.  There are two feature conditions for Dice (9208, FIG. 92).  Because Red paint has been added to the configuration, only Fuzzy Dice is available, and fuzzy dice is already an\nIncluded feature.  Therefore the configuration engine 106 does not change its feature state.\nWith reference to FIGS. 95-99, another method for automatically completing a configuration using a maximally standard algorithm is illustrated in accordance with one or more embodiments and generally referenced by S800.  The maximally standard\nauto-completion method S800 is implemented as an algorithm within the configuration engine 106 using software code contained within the server 102, according to one or more embodiments.  In other embodiments the software code is shared between the server\n102 and the user devices 112, 114.\nAt S802, the configuration engine 106 generates a maximally standard data space (MsDataSpace) based on a total or global buildable space and a relationships work object (relWork).  The total buildable space includes a main space that defines all\npossible configurations of non-deterministic features and relationships spaces that define the availability of deterministic features in terms of non-deterministic features.  The intersection of the main space and the relationships spaces define all\npossible configurations.  The main space and relationship spaces are specified by MDDs, according to one or more embodiments.  The total buildable space includes the main MDD and a relationships MDD, and is quick-restricted to any Selected and Included\nfeatures.  RelWork is a temporary object that is used to process a specific condition that may occur based on the order families are processed.  As discussed below, relWork is nontrivial if after selecting a Default feature from a deterministic family,\nthere is more than one defining feature condition such that the configuration engine 106 cannot quick restrict the main MDD.  Then at S804, the configuration engine 106 identifies any family without any Selected or Included features as a family to\ncomplete.\nWith reference to steps S806-811, the configuration engine 106 analyzes each family of the MDD in priority order.  The configuration engine 106 starts analyzing the first family in the sorted families to complete list at step S806.  At step\nS808, the configuration engine 106 determines if the index (x) is less than the total number of families included in the families to complete list.  If not, the configuration engine 106 proceeds to 5810 (Done).  If so, the configuration engine 106\nproceeds to step S812 to determine the possible available standard features for family (x) within the restricted buildable space (MsDataSpace).  Once the configuration engine 106 has completed its analysis of family (x), it returns to S811 and starts\nanalyzing the next family by incrementing x by 1.  The subroutine of S812 is shown in the flowchart of FIG. 96.\nWith reference to FIG. 96, at 5814 the configuration engine 106 initializes the list of possible standard features by setting it to empty.  With reference to steps S816, S818 and S842, the configuration engine 106 analyzes each feature of\nfamily(x).  The configuration engine 106 starts analyzing feature zero (z=0) at S816.  At step S818 the configuration engine 106 compares feature (z) to the number of features at the current family (x) to determine if z&lt;the number of features in\nfamily (x).  If the determination is positive, the configuration engine 106 proceeds to S820 to determine the essential sets for feature availability.  Once the configuration engine 106 has completed its analysis of feature (z) of family (x), it returns\nto S842 and starts analyzing the next feature of family (x) by incrementing z by 1.  The subroutine of S820 is shown in the flowchart of FIG. 97.\nReferring to FIG. 97, the configuration engine 106 determines a setlist of \"essential sets\" for the availability of feature (z) at S820-S848.  At S824 the configuration engine 106 initializes the setlist by adding the main MDD of the current\nbuildable space (buildableSpace).  Then at S826, the configuration engine 106 evaluates relWork to determine if it is not trivial (i.e., not all 1).  If relWork is not all trivial, (i.e., a previous Default selection was made from a deterministic family\nsuch that the relationship defined more than one determinant condition) then the configuration engine 106 proceeds to S828 and adds relWork to the setlist.  After S828, or in response to a negative determination at S826, the configuration engine 106\nproceeds to S830 to determine if there are not any standard feature conditions defined for this feature.  If there are no standard feature conditions defined for feature (z), then its standard space is null.  If there are standard feature conditions\ndefined for feature (z), then a negative determination is made at S830, and the configuration engine 106 proceeds to S832 and adds the standard space to the setlist.  After S832, or in response to a positive determination at S830, the configuration\nengine 106 proceeds to S834 to determine if the family of feature (z) is deterministic.  If family (x) is deterministic, the configuration engine 106 adds the relationship space for family (x) to the setlist at S836.  After S836, or in response to a\nnegative determination at S834, the configuration engine 106 proceeds to S838 and returns the setlist to the subroutine of FIG. 96.\nReferring to FIG. 96, at S840 the configuration engine 106 determines if the intersection of all spaces in the setlist for feature (z) is empty (i.e., if feature (z) is not a standard feature or it is a standard feature that is not available\nwith the current configuration).  If the determination at S840 is negative, the configuration engine 106 proceeds to S844 and adds feature (z) to the list of possible available standard features (POSSIBLE).  After S844, or after a positive determination\nat S840, the configuration engine 106 proceeds to S842 to analyze the next feature (z) of family (x).  Once the configuration engine 106 has analyzed all features of family (x), it makes a negative determination at S818 and proceeds to S846 to return the\npossible available standard features for family (x) to the main maximally standard routine of FIG. 95.\nWith reference to FIG. 95, at S848 the configuration engine determines if there are any standard features for family (x).  If there are no standard features, i.e., if POSSIBLE is empty, then the configuration engine 106 proceeds to S850 to find\nthe domain of family (x) in the maximally standard data space (MsDataSpace).  The subroutine of S850 is shown in the flowchart of FIG. 98.\nWith reference to FIG. 98, the configuration engine 106 determines the domain of family (x) at S850-S858.  At S852, the configuration engine 106 calculates the domain space of family (x) as the intersection of the main space and the relWork.  If\nthe configuration engine 106 determines that family (x) is deterministic at S854 based on the product definition, then it proceeds to S856.  At S856 the configuration engine 106 sets the domain space equal to the intersection of the domain space and\nrelationship space for that family.  After S856, or in response to a determination that family (x) is not deterministic at S854, the configuration engine 106 proceeds to S858 and sets the Domain to the domain of the domain space, adds any feature from\nfamily(x) that is present to the Domain to the list of possible features and returns to the main maximally standard routine of FIG. 95.\nReferring to FIG. 95, after determining the domain of family (x) at S850, or in response to a negative determination at S848, the configuration engine 106 proceeds to S860 and sorts POSSIBLE by an alternate sequence that defines the priority of\nthe features.  At S862 the configuration engine 106 selects the first feature in the sorted list as the Default feature for Family (x).  Then the configuration engine 106 proceeds to S864 to restrict the maximally standard data space to the new Default\nfeature.  The subroutine of S864 is shown in the flowchart of FIG. 99.\nWith reference to FIG. 99, at S864-S880, the configuration engine 106 further restricts the maximally standard data space to the new Default feature.  At S866 the configuration engine 106 restricts the main space to the new Default feature. \nThen if family (x) is deterministic, the configuration engine 106 proceeds to S870 and defines a temporary relationship (relTemp) by restricting the family relationship space to the new Default feature choice.  Then at S872, the configuration engine 106\nsets relWork to the intersection of relWork and relTemp.  At S874, the configuration engine 106 evaluates relWork to determine if it has a single path, i.e., a \"singleton.\" If the standard features (relWork) is a singleton, the configuration engine 106\nproceeds to S876 and uses quick restrict to restrict the main space using the single bitmask from relWork; and then resets relWork to be trivial (all 1s) at S878.  After S878, or in response to a negative determination at S868 or S874, the configuration\nengine 106 proceeds to S880 and returns to the main maximally standard routine of FIG. 95.\nWith reference to FIGS. 100-101, deterministic relationships are used to enable efficient creation and storage of the full buildable space.  As described previously, the global buildable space can be stored in a Global MDD that has a main space\n(e.g., an MDD) and a set of relationship spaces (e.g., MDDs).  Maximally standard auto completion requires standard feature conditions.  The buildable space (FIG. 100) and Standard Feature Conditions (FIG. 101) are shown as Tables 10000 and 10100,\nrespectfully, and combined in a single Buildable object.\nThere is no concept of displayable and non-displayable families during MDD generation.  Displayable families refer to content this is displayed to the user, for example paint color is displayed to a user in a build and price application. \nWhereas non-displayable families refer to content that is not displayed to the user, such as an electrical harness in a build and price application.  A Superconfiguration Generator (SCG) library (not shown) is a component of the ETL 128 (FIG. 2).  The\nSCG library simply finds all relationships in order to generate the smallest possible main space.\nSome algorithms that target displayable content (e.g., validation and feature state mapper) have been optimized to work on a single MDD, and others require all displayable content to be in a single MDD (e.g., minimum edit).  Valid input for the\nconfigurator is a global space where no displayable families have been pulled to an external relationship, even if it is deterministic.\nOne possible way to build a global space that conforms to the configurator input is to control which families can be deterministic.  The SCG algorithm includes an argument called relignore which can be used to specify which families are not\nallowed to be deterministic.  This argument can be used to specify that displayable families are not allowed to be deterministic.\nAnother approach is to allow SCG to build the MDD by pulling out whatever relationships it finds.  Then, an extra step is used before the space can be used by the configurator.  Any relationship that defines a display family dependence on the\nmain MDD is flattened back into the main MDD.  To do this efficiently, the MDD is recompressed as the relationships are flattened.\nGenerally both approaches will take the same amount of processing time.  In the second approach, the MDD may be generated much faster, but that any time savings is used in the extra flattening step.\nThe configuration engine 106 will be validating two types of configurations--a configuration of displayable features only or an expanded configuration of displayable and no display features.\nTo validate a configuration of displayable features the relationships can be ignored because the configuration engine 106 does not allow any displayable family to be deterministic.  This means that the main MDD contains all of the information\nnecessary to define feature combinations from the displayable families.  There is no information in the relationships that will shrink the space of displayable families that is defined in the main MDD.  Thus, only the main MDD is used to validate a\nconfiguration of display family features.  To validate a configuration of displayable families, simply call contains operation on the main MDD.\nTo validate a configuration that contains displayable and no-display features, both the main MDD and the relationships are inspected.  Just as the MDD containsAny operation is used to validate a configuration against an MDD, the Global MDD also\nhas a containsAny operation that can validate a configuration against a Global MDD.  The Global MDD operation utilizes the MDD containsAnyParallel operation, to validate a fully expanded configuration, the parallel operation will turn the mask into its\nown MDD and inspect that space along with the main space and all relationship MDDs.  To validate a partial configuration of both display and no display features, the parallel operation inspects the mask MDD, the main MDD and the relationships associated\nwith each deterministic feature in the configuration.  When processing a partial configuration, relationships for families that have no feature in the configuration can be ignored.\nFIG. 102 is a table 10200 that shows several example configurations, the relevant MDDs, and the containsAny call that the configuration engine 106 uses to validate the configuration.\nConflict resolution is also limited to displayable content.  As with the \"contains\" operation, when dealing with configurations that do not contain deterministic features, the main MDD contains sufficient information for the conflict resolution\nwithout including the relationships.\nAs described with reference to FIG. 47, conflict resolution begins with a minimum edit distance calculation that is performed on the main MDD.\nFor Single Conflict Resolution, the target configuration is identified by performing auto completion in the minimum edit space.  Because the main MDD includes no display content, the target configuration will also include no display content. \nThe no-display content is stripped from the configuration engine response.  Alternatively, the author decorators can be modified to ignore no-display features when adding conflict resolution to the xml response.\nFor Branched Conflict Resolution, the entire minimum edit space is used to build the response.  The minimum edit space is projected to displayable content before building the response.\nThere is no concept of displayable and non-displayable families during the first stage of authoring or determining the feature conditions.  As such, the feature conditions for displayable families may be determined with a dependency on\nno-display families.  This means that when the maximally standard auto completion algorithm uses the full configuration space; it accounts for the external relationship MDDs in addition to the main MDD.\nWhen using a Global Space (main space+relationships spaces) for maximally standard auto completion, the basic logic is the same as using an MDD.  Instead of checking a single MDD, the algorithm checks the global space--both the main MDD and the\nrelationship MDDs.  The basic operations of restrict, containsAny and domain accounts for both the main space and external relationships.\nDuring auto completion, the configuration engine 106 restricts the main space for each feature choice (S864).  When the choice is deterministic, the external relationship defines the determinant conditions for each feature.  The deterministic\nrelationship space is restricted to the feature choice to determine the determinant conditions and then the main space is restricted to the corresponding determinant conditions.\nWhen a deterministic feature has a single determinant condition, the configuration engine 106 quick-restricts the main space using the determinant condition, according to one or more embodiments (S874-S876).  The buildable space as shown in\nTable 10000 (FIG. 100) includes a main space 10002 and a relationships space 10004.  The relationships space 10004 shows that features Y2, Y5 and Y6 map to B1 as referenced by numeral 10006, and that features Y1, Y3, and Y4 map to B2 as referenced by\nnumeral 10008.  Table 10300 of FIG. 103 shows only one row remains after the relationship is restricted to the choice B1 (S870).  The configuration engine 106 quick-restricts the main space using this single superconfiguration as the bitmask.  After B1\nis chosen, the main space is restricted to B1 (S866) and is also restricted to Y2, Y5, and Y6 (S876), as shown in Table 10400 of FIG. 104, and referenced by numeral 10402.\nThe quick-restrict operation accepts a single bit mask.  This means that the main space cannot be quick-restricted to reflect a deterministic choice whenever a deterministic feature has multiple determinant conditions.  Table 10000 (FIG. 100)\nshows that family K is determined by two families [A,S] as referenced by numeral 10010.  Table 10500 of FIG. 105 shows the two rows defining the determinant conditions for feature K2.  The first row of Table 10500 shows that A2,S3; A2,S5; A2,S6 all map\nto K2 and the second row shows that A1,S3 also maps to K2.  When K2 is chosen, the main space is restricted to K2, but the configuration engine 106 cannot quick-restrict it with the K2 determinants because the restricted relationship space defines two\nsuperconfigurations.  Instead, the configuration engine 106 adds a special relWork space, as referenced by numeral 10602, to store the determinant conditions as shown FIG. 106.  After restricting to K2, relWork contains the two determinant conditions for\nK2.\nJust as the global space requires both the main MDD and all its relationships to fully define the space, relWork is necessary to fully define the restricted space.  However, if relWork is trivial (i.e., all 1s) then the configuration engine 106\ncan ignore it because it isn't further restricting the space.\nThe configuration engine 106 initializes the relWork space as a trivial space, with a single superconfiguration of all 1s, according to one or more embodiments.  When a deterministic choice is made that has multiple determinant conditions,\nrelWork is AND'ed with the restricted relationship space (S872).  If the result of the AND operation is a single superconfiguration (S874), the main space is restricted with that superconfiguration (S876) and relWork is trivialized (S878).\nReferring to FIG. 107, if the configuration engine 106 further restricts the space to M2, then there is just one row remaining in relationship M as shown in Table 10700.  When this restricted relationship space is ANDed with relWork (from FIG.\n106), just one row remains as shown in Table 10800 of FIG. 108.  This is used to restrict the main space, and then relWork is reset, with the final result shown in Table 10900 of FIG. 109.\nThe configuration engine 106 uses the containsAny operation of the maximally standard auto completion algorithm to determine if a Standard feature condition space is still valid in the restricted space, according to one or more embodiments.\nFor two MDDs, the operation mdd1.containsAny(mdd2) is equivalent to not(isEmpty(mdd1.and(mdd2)).  The ContainsAny operation can be extended to operate on two or more MDDs and is called containsAnyParallel.  For three MDDs, the operation\nmdd1.containsAnyParallel([mdd2,mdd3]) is equivalent to not(isEmpty(mdd1.and(mdd2).and(mdd3)).\nWhen dealing with deterministic relationships, this contains any operation may need to include the relWork MDD.\nIn order for the configuration engine 106 to determine if a standard feature is available in the restricted space (S812), the containsAny operation must always operate on the standard space and the main space and may need to account for the\nrelWork space and an external relationship space.  When the family is deterministic and relWork is not trivial the operation will be standardSpace.containsAny(mainSpace, rel, relWork).  The operation can skip relWork if it is trivial and will only\ninclude a relationship if the feature is deterministic (S822).\nThe configuration engine 106 determines if any standard features for A are still valid in the space from FIG. 103, by accounting for the A standard space and the main space in the containsAny operation.  There is no relationship space because A\nis not deterministic and the relWork is ignored because it is trivial (i.e., A is all is in Table 10300).\nIn order for the configuration engine 106 to determine if any standard features for B are still valid in the space from FIG. 103, the containsAny operation must account for the B standard space, the main space and relationship B space.  The\nconfiguration engine 106 ignores relWork because it is trivial.\nThe configuration engine 106 determines if any standard features for M are still valid in the space from FIG. 106, by accounting for the M standard Space, main Space, Relationship M space, and relWork in the containsAny operation.\nThe maximally standard auto completion algorithm uses domain calculation when the standard feature conditions do not identify a possible choice.  Because only the domain of a single family is needed, not all of the relationships must be\nincluded.  The domain calculation must consider the main space, the relWork space, and, if the family is deterministic, the external relationship space.  This is done by first ANDing the spaces, and then calculating the domain on the resulting space\n(S850).\nThe algorithm for maximally standard auto completion without deterministic relationships was shown previously in FIG. 93.\nThe modifications to account for deterministic relationships are: 1) Change mdd.quickRestrict to SPACE.RESTRICT; 2) Change mdd.containsAny with SPACE.containsAny, where space defines the main MDD, the relationship MDDs, and the relWork MDD\ndiscussed above in the Restrict Global Space section; and 3) Change mdd.findDomain.toListActive(Fa) to SPACE.findDomain(Fa).  The new algorithm is shown as flowcharts in FIGS. 95-99 and as software code in FIG. 110.\nThe following example illustrates the modified algorithm and references steps in the flow charts and operations in the software code where applicable.  This example will use the global space and standard feature conditions defined previously in\nTable 10000 (FIG. 100) and Table 10100 (FIG. 101).  Table 10100 also lists the family priority order, as generally referenced by numeral 10102.\nWith reference to FIG. 111, the configuration engine 106 restricts the space starting with a minimally complete configuration of Selected {Y3, E1, P1}+Included {F2} (11001, FIG. 110; S802, FIG. 95).  The configuration engine 106 makes Default\nchoices for the remaining families in priority order as defined in Table 10100 (FIG. 101), i.e.: V, R, K, B, A, M, T, I, S (S804, FIG. 95).\nReferring to FIG. 112, the configuration engine 106 determines that Family V is deterministic and includes a single standard feature condition.  To determine if standard feature V3 is available, the configuration engine 106 checks the main\nspace, standard space and deterministic relationship (S820, FIG. 97).  Operation 11004 (FIG. 110) stdV3.containsAnyParallel(mainSpace, relV) returns false because V3 is not available with the current choice Y3 (see also S840, FIG. 96).  The domain of V,\nfrom operation 1106 (FIG. 110) AND(relV,mainSpace), will identify only one possible choice (see also S852-S858, FIG. 98).  V2 is added and the newly restricted space, as determined at S864, FIG. 96 and operation 11008, FIG. 110, is shown in Table 11200\nof FIG. 112 and referenced by numeral 11202.\nWith reference to FIGS. 112-113, the configuration engine 106 determines that Family R has no standard feature conditions (S830-S836, FIG. 97; operation 11004, FIG. 110).  The domain of the restricted space identifies two possible choices--R1,\nR4 as referenced by numeral 11204 (S852-S858, FIG. 98; operation 1106, FIG. 110).  Without alternate sequencing, R1 is picked as the Default choice and the space is further restricted (S864, FIG. 99; operation 11008, FIG. 110) as shown in Table 11300 of\nFIG. 113, and referenced by numeral 11302.\nReferring back to FIG. 101, the configuration engine 106 determines that Family K has two standard feature conditions (S830-S836, FIG. 97; operation 11004, FIG. 110).  StdK1 defines K1 as standard for V1 and StdK2 defines K2 as standard for V2\nor V3.  Because V2 has been previously chosen, K2 is the only available standard choice and is added to the configuration.  The configuration engine 106 further restricts the space to reflect this choice (S864, FIG. 99; operation 11008, FIG. 110). \nFamily K is deterministic.  When RelK is restricted to K2, there are two rows remaining.  The main space cannot be quick-restricted and relWork is updated as shown in Table 11400 of FIG. 114.\nWith reference to FIG. 115, the configuration engine 106 adds B2 based on its Standard space and chooses A2 because it is standard with {R1, V2}.  The restricted space after these choices is shown in Table 11500 of FIG. 115.  Table 11500 shows\nthat the configuration engine 106 could restrict relWork to A2, minimize it to one row, use it to restrict the main space and then trivialize it; however, the containsAny optimizations (operation 11004, FIG. 110) dictate that it is actually better to\nwait until relWork is minimized by another deterministic feature.  It is actually counterproductive to restrict relWork for every choice.\nReferring to FIG. 116, the configuration engine 106 determines that Family M has standard feature conditions (S830-S836, FIG. 97; operation 11004, FIG. 110).  M1 is the only standard feature that is still available in the restricted space. \nAfter relWork is updated for M1, only one row remains, i.e., the second row of Table 11500 of FIG. 115.  This row is used to restrict the main space and relWork is trivialized, as shown by Table 11600 of FIG. 116 (S864, FIG. 99; operation 11008, FIG.\n110).  The restricted space after processing family M is shown in Table 11600.\nWith reference to FIG. 117, the configuration engine 106 adds T1 as the Default choice from its Standard Feature Condition and I1 is chosen as the Default from the possible choices I1 and 12 (S830-S836, FIG. 97; operation 11004, FIG. 110).  The\ndeterministic relationship for I shows that I1 maps to S1 or S5.  After T1 and I1 are chosen, S5 remains the only choice for family S, as shown in Table 11700 of FIG. 117.\nThe configuration engine's use of relWork to account for deterministic relationships when quick-restricting the main space, along with the contains AnyParallel operation, allows for a very efficient maximally standard auto completion algorithm. \nThis allows the configuration engine 106 to support maximally standard configurations without requiring feature condition authoring to be modified in order to account for display and no display families.\nComputing devices described herein, generally include computer-executable instructions where the instructions may be executable by one or more computing devices such as those listed above.  Computer-executable instructions may be compiled or\ninterpreted from computer programs created using a variety of programming languages and/or technologies, including, without limitation, and either alone or in combination, Java.TM., C, C++, C#, Visual Basic, Java Script, Perl, etc. In general, a\nprocessor (e.g., a microprocessor) receives instructions, e.g., from a memory, a computer-readable medium, etc., and executes these instructions, thereby performing one or more processes, including one or more of the processes described herein.  Such\ninstructions and other data may be stored and transmitted using a variety of computer-readable media.\nWhile exemplary embodiments are described above, it is not intended that these embodiments describe all possible forms of the invention.  Rather, the words used in the specification are words of description rather than limitation, and it is\nunderstood that various changes may be made without departing from the spirit and scope of the invention.  Additionally, the features of various implementing embodiments may be combined to form further embodiments of the invention.\n<BR><BR><CENTER><b>* * * * *</b></CENTER>\n<HR>\n   <CENTER>\n   <a href=http://pdfpiw.uspto.gov/.piw?Docid=10318703&homeurl=http%3A%2F%2Fpatft.uspto.gov%2Fnetacgi%2Fnph-Parser%3FSect1%3DPTO2%2526Sect2%3DHITOFF%2526p%3D1%2526u%3D%25252Fnetahtml%25252FPTO%25252Fsearch-bool.html%2526r%3D1%2526f%3DG%2526l%3D50%2526co1%3DAND%2526d%3DPTXT%2526s1%3D20170206305%2526OS%3D%2526RS%3D&PageNum=&Rtype=&SectionNum=&idkey=NONE&Input=View+first+page><img src=\"/netaicon/PTO/image.gif\" alt=\"[Image]\" border=\"0\" valign=\"middle\"></A>\n   <TABLE>\n   <TR><TD align=\"center\"><A href=\"https://certifiedcopycenter.uspto.gov/other/patft/view.html?backUrl1=http%3A//patft.uspto.gov/netacgi/nph-Parser?Sect1%3DPTO2%26Sect2%3DHITOFF%26p%3D1%26u%3D%25252Fnetahtml%25252FPTO%25252Fsearch-bool.html%26r%3D1%26f%3DG%26l%3D50%26co1%3DAND%26d%3DPTXT%26s1%3D20170206305%26OS%3D&backLabel1=Back%20to%20Document%3A%2010318703\"><IMG border=\"0\" src=\"/netaicon/PTO/cart.gif\" border=\"0\" valign=\"m\niddle\" alt=\"[View Shopping Cart]\"></A>\n   <A href=\"https://certifiedcopycenter.uspto.gov/other/patft/order.html?docNumber=10318703&backUrl1=http%3A//patft.uspto.gov/netacgi/nph-Parser?Sect1%3DPTO2%26Sect2%3DHITOFF%26p%3D1%26u%3D%25252Fnetahtml%25252FPTO%25252Fsearch-bool.html%26r%3D1%26f%3DG%26l%3D50%26co1%3DAND%26d%3DPTXT%26s1%3D20170206305%26OS%3D&backLabel1=Back%20to%20Document%3A%2010318703\">\n   <IMG border=\"0\" src=\"/netaicon/PTO/order.gif\" valign=\"middle\" alt=\"[Add to Shopping Cart]\"></A>\n   </TD></TR>\n   <TR><TD align=\"center\">\n   <A href=\"#top\"><IMG valign=\"middle\" src=\"/netaicon/PTO/top.gif\" border=\"0\" alt=\"[Top]\"></A>\n   </TD></TR>\n   </TABLE>\n   <A name=\"bottom\"></A>\n   <A href=\"/netahtml/PTO/index.html\"><IMG src=\"/netaicon/PTO/home.gif\" alt=\"[Home]\" border=\"0\" valign=\"middle\"></A>\n   <A href=\"/netahtml/PTO/search-bool.html\"><IMG src=\"/netaicon/PTO/boolean.gif\" alt=\"[Boolean Search]\" border=\"0\" valign=\"middle\"></A>\n   <A href=\"/netahtml/PTO/search-adv.htm\"><IMG border=\"0\" src=\"/netaicon/PTO/manual.gif\" alt=\"[Manual Search]\" valign=\"middle\"></A>\n   <A href=\"/netahtml/PTO/srchnum.htm\"><IMG src=\"/netaicon/PTO/number.gif\" alt=\"[Number Search]\" border=\"0\" valign=\"middle\"></A>\n   <A href=\"/netahtml/PTO/help/help.htm\"><IMG border=\"0\" src=\"/netaicon/PTO/help.gif\" alt=\"[Help]\" valign=\"middle\"></A>\n   </CENTER>\n</BODY>\n</HTML", "application_number": "15294395", "abstract": " A system is provided with a memory device adapted to store at least one\n     multi-valued decision diagram (MDD) that specifies a total buildable\n     space and a processor that is programmed to identify a partial\n     configuration; generate a restricted buildable space of the total\n     buildable space; and identify families to complete. The processor is\n     further programmed to, for each family to complete in priority order, add\n     any available standard features for the family to a possible set, if the\n     possible set is empty, add a domain space of the family to the possible\n     set, select the highest priority feature of the possible set as a Default\n     feature state, and generate a further restricted buildable space of the\n     total buildable space based on the Default feature state. The processor\n     is also further programmed to generate a complete configuration including\n     features having Default feature states for each family to complete.\n", "citations": ["4479197", "4591983", "4827423", "4873643", "4875162", "5119307", "5165015", "5225987", "5233513", "5255356", "5257387", "5260866", "5283865", "5293479", "5295067", "5295242", "5307261", "5311424", "5311437", "5353432", "5367622", "5367627", "5369566", "5394522", "5428791", "5434791", "5487135", "5499357", "5500802", "5515269", "5515524", "5546575", "5552995", "5579529", "5586039", "5590319", "5594651", "5621905", "5630025", "5675748", "5740425", "5745765", "5761063", "5777877", "5781906", "5815395", "5825651", "5844554", "5850539", "5864660", "5877966", "5963953", "5987473", "5991826", "6002854", "6035305", "6055529", "6115547", "6122560", "6125408", "6137499", "6151697", "6167380", "6167383", "6177942", "6192355", "6205446", "6208987", "6223094", "6223170", "6247128", "6259451", "6272390", "6278982", "6282537", "6300948", "6324534", "6349274", "6366922", "6377956", "6405308", "6407761", "6412012", "6430730", "6519588", "6523040", "6536014", "6549908", "6556991", "6557002", "6581068", "6615220", "6633788", "6647305", "6678882", "6687705", "6757678", "6810401", "6836766", "6839711", "6850895", "6850921", "6853996", "6898472", "6918124", "6937966", "6938038", "6965887", "6986104", "6988014", "7003360", "7039602", "7043309", "7050956", "7062478", "7065499", "7069537", "7076507", "7076521", "7082426", "7093010", "7096350", "7096465", "7107297", "7127424", "7188333", "7188335", "7200582", "7225038", "7225197", "7233885", "7237187", "7246087", "7328177", "7337174", "7337179", "7343212", "7343584", "7386562", "7424444", "7461049", "7464064", "7487072", "7509326", "7516103", "7567922", "7580871", "7584079", "7650296", "7698170", "7760746", "7797177", "7809758", "7860690", "7869981", "7873503", "7882057", "7930149", "7953639", "7953767", "7953779", "7992145", "7996329", "8078489", "8249885", "8280700", "8306795", "8463682", "8665731", "8805825", "8918750", "9020880", "9098854", "20020013775", "20020035463", "20020052803", "20020095348", "20020107861", "20020116417", "20020124005", "20020143653", "20020161668", "20020165701", "20020177911", "20020184308", "20030041088", "20030046047", "20030055751", "20030061238", "20030069737", "20030130749", "20030177412", "20030195806", "20030216951", "20040064441", "20040068485", "20040073436", "20040073448", "20040102995", "20040162835", "20040167906", "20050071146", "20050080648", "20050114158", "20050163143", "20050268255", "20060064685", "20000100829", "20060095711", "20070094204", "20090323539", "20110082675", "20120253754", "20140019739", "20150120490", "20150331974", "20150379442"], "related": ["62352463", "62280609"]}, {"id": "20170206576", "patent_code": "10325063", "patent_name": "Multi-valued decision diagram feature state determination", "year": "2019", "inventor_and_country_data": " Inventors: \nHunsaker; Melinda Kaye (Canton, MI), Newton; David Mark (Cologne, DE), Sabbagh; Essam Mahmoud (Dearborn Heights, MI)  ", "description": "<BR><BR>CROSS-REFERENCE TO RELATED APPLICATIONS\nThis application claims the benefit of U.S. provisional application Ser.\n     No. 62/280,609 filed Jan. 19, 2016 and U.S. provisional application Ser.\n     No. 62/352,463 filed Jun. 20, 2016, the disclosures of which are hereby\n     incorporated in their entirety by reference herein.\n         <HR>\n<CENTER><b><i>Claims</b></i></CENTER> <HR> <BR><BR>What is claimed is: 1.  A method to determine feature states comprising: storing data representative of a multi-valued decision diagram (MDD), the MDD indicating a Boolean function specifying a\nbuildable space of all possible configurations of features of a vehicle, the MDD including a root node, a truth node, a false node, and at least one level of intervening nodes between the root node and either the truth node or the false node, each level\nof the MDD corresponding to a family of mutually-exclusive features represented by at least one node, each node except for the truth node and the false node connecting to nodes of a next adjacent level by outgoing edges having labels each indicating one\nor more features of the family that are available for the possible configurations including the node, each node except for the root node connecting to nodes of a prior adjacent level by incoming edges that are outgoing edges of the prior adjacent level,\nsuch that a complete path from the root node through the outgoing edges to the truth node defines one valid configuration, wherein each complete path from the root node to the truth node is of the same length in nodes when there are no long edges; \nreceiving from a user a current selection of a partial configuration comprising one or more families with one feature selected for each family, wherein the partial configuration has been validated as a valid configuration;  generating an availability\nbitset indicative of which features are available for further selection, consistent with the valid configuration and without violating constraints imposed by the current selection;  determining a feature state for all features based on the current\nselection and the availability bitset;  presenting to the user features possible for selection, based on the availability bitset;  receiving from the user, selection of one of the possible features for a next family and setting that feature in the\npartial configuration as Selected resulting in a new partial configuration;  performing validation of the new partial configuration using a configuration engine;  if the new partial configuration is invalid, prompting the user to make changes, or\nallowing the configuration engine to make the changes according to a predefined hierarchy;  setting the new partial configuration as the partial configuration and the current selection: regenerating the availability bitset indicative of which features\nare available for further selection, consistent with the valid configuration and without violating constraints imposed by the current selection;  and repeating the process starting from presenting to the user the features possible for selection by the\nuser until all families are included in the valid configuration.\n2.  The method of claim 1, wherein the availability bitset indicates a first value of `1` for a feature when the feature is available for selection without violating the constraints imposed by the current selection, and a second value of `0` for\nthe feature when the feature is excluded and not available for selection due to violating the constraints imposed by the current selection if selected.\n3.  The method of claim 1, wherein the feature state for each of the features indicates one of: (i) selected for a feature that has been explicitly selected by a user, (ii) available for a feature that is free for selection without violating the\nconstraints imposed by the current selection, (iii) included for a feature that is the only available choice in a family due to user selection of one or more features that require it, (iv) default for a feature that is selected due to automatic\ncompletion of the configuration, (v) excluded for a feature that conflicts with existing constraints, and (vi) forbidden for a feature that violates an external constraint independent of the possible configurations specified by the MDD that cannot be\nresolved if selected.\n4.  The method of claim 3, wherein the external constraint is a feature that is unavailable for manufacture at a particular time.\n5.  The method of claim 1, farther comprising: performing a downward traversal of the MDD from the root node to identify downward-marked nodes that are not excluded by the selection;  performing an upward traversal of the MDD from the truth node\nto identify upward-marked nodes that are not excluded by the selection;  and generating the availability bitset by identifying the features available for further selection, consistent with the valid configuration and without violating constraints imposed\nby the current selection, as the nodes that are both downward-marked and upward-marked.\n6.  The method of claim 1, further comprising: performing a first restricted domain calculation using the feature state to identify which additional feature selections outside of the families having feature selections are compatible with the\ncurrent selection;  performing, for each family in which a feature is selected, a second restricted domain calculation to identify which additional features in that family are compatible with the current selection;  and generating the availability bitset\nby identifying the features available for further selection according to the first and the second restricted domain calculations.\n7.  The method of claim 1, further comprising identifying a feature as excluded by the selection when the feature is not selected or available.\n8.  The method of claim 7.  further comprising identifying an included feature as a feature that is unselected but included in a family having exactly one available feature.\n9.  A system comprising: a memory configured to store data representative of a multi-valued decision diagram (MDD) indicating a Boolean function specifying a buildable space of all possible configurations of features of a vehicle, the MDD\nincluding a root node, a truth node, a false node, and at least one level of intervening nodes between the root node and either the truth node or the false node, each level of the MDD) corresponding to a family of mutually-exclusive features and\nrepresented by at least one node, each node of a level connecting to nodes of a next adjacent level by outgoing edges having labels each indicating one or more features of the family that are available for the possible configurations including the node,\nsuch that a complete path from the root node through the outgoing edges to the truth node defines one valid configuration, wherein each complete path from the root node to the truth node is of the same length in nodes when there are no long edges;  and a\nprocessor in communication with the memory, programmed to receive from a user a current selection of a partial configuration comprising one or more families with one feature selected for each family, wherein the partial configuration has been validated\nas a valid configuration, generate an availability bitset indicative of which features are available for further selection, consistent with the valid configuration and without violating constraints imposed by the current selection, determine a feature\nstate for all features based on the current selection and the availability bitset, present to the user features possible for selection, based on the availability bitset, receive from the user, selection of one of the possible features for a next family\nand set that feature in the partial configuration as Selected resulting in a new partial configuration, perform validation of the new partial configuration using a configuration engine, if the new partial configuration is invalid, prompt the user to make\nchanges, or allow the configuration engine to make the changes according to a predefined hierarchy, set the new partial configuration as the partial configuration and the current selection, regenerate the availability bitset indicative of which features\nare available for further selection, consistent with the valid configuration and without violating constraints imposed by the current selection, and repeat the process starting from presenting to the user the features possible for selection by the user\nuntil all families are included m the valid configuration.\n10.  The system of claim 9, wherein the availability bitset indicates a first value of `1` for a feature when the feature is available for selection without violating the constraints imposed by the current selection, and a second value of `0`\nfor the feature when the feature is excluded and not available for selection due to violating the constraints imposed by the current selection if selected.\n11.  The system of claim 9, wherein the feature state for each of the one or more features indicates one of: (i) selected for a feature that has been explicitly selected by a user, (ii) available for a feature that is free for selection without\nviolating the constraints imposed by the current selection, (iii) included for a feature that is the only available choice in a family due to user selection of one or more features that require it, (iv) default for a feature that is selected due to\nautomatic completion of the configuration, (v) excluded for a feature that conflicts with existing constraints, and (vi) forbidden for a feature that violates an external constraint independent of the possible configurations specified by the MDD that\ncannot be resolved if selected.\n12.  The system of claim 9.  wherein the processor is further programmed to: perform a downward traversal of the MDD from the root node to identify downward-marked nodes that are not excluded by the selection;  perform an upward traversal of the\nMDD from the truth node to identify upward-marked nodes that are not excluded by the selection;  and generate the availability bitset by identifying the features available for further selection, consistent with the valid configuration and without\nviolating constraints imposed by the current selection, as the nodes that are both downward-marked and upward-marked.\n13.  The system of claim 9, wherein the processor is further programmed to: perform a first restricted domain calculation using the feature state to identify which additional feature selections outside of the families having feature selections\nare compatible with the current selection;  perform, for each family in which a feature is selected, a second restricted domain calculation to identify which additional features in that family are compatible with the current selection;  and generate the\navailability bitset by identifying the features available for further selection according to the first and the second restricted domain calculations.\n14.  The system of claim 9, Wherein the processor is further programmed to: identify a feature as excluded by the selection when the feature is not selected or available;  and identify an included feature as a feature that is unselected but\nincluded in a family having exactly one available feature.\n15.  A non-transitory computer-readable medium comprising instructions that, when executed by a processor, cause the processor to: store data representative of a multi-valued decision diagram (MDD) indicating a Boolean function specifying a\nbuildable space of all possible configurations of features of a vehicle, the MDD including a root node, a truth node, a false node, and at least one level of intervening nodes between the root node and either the truth node or the false node, each level\nof the MDD corresponding to a family of mutually-exclusive features and represented by at least one node, each node of a level connecting to nodes of a next adjacent level by outgoing edges having labels each indicating one or more features of the family\nthat are available for the possible configurations including the node, such that a complete path from the root node through the outgoing edges to the truth node defines one valid configuration, wherein each complete path from the root node to the truth\nnode is of the same length in nodes when there are no long edges;  receive from a user a current selection of a partial configuration comprising one or more families with one feature selected for each family, wherein the partial configuration has been\nvalidated as a valid configuration;  generate an availability bitset indicative of which features are available for further selection, consistent with the valid configuration and without violating constraints imposed by the current selection;  determine\na feature state for all features based on the current selection and the availability bitset;  present to the user features possible for selection, based on the availability bitset;  receive from the user selection of one of the possible features for a\nnext family and set that feature in the partial configuration as Selected resulting in a new partial configuration;  perform validation of the new partial configuration using a configuration engine;  if the new partial configuration is invalid, prompt\nthe user to make changes, or allow the configuration engine to make the changes according to a predefined hierarchy;  set the new partial configuration as the partial configuration and the current selection;  regenerate the availability bitset indicative\nof which features are available for further selection, consistent with the valid configuration and without violating constraints imposed by the current selection;  and repeat the process starting from presenting to the user the features possible for\nselection by the user until all families are included in the valid configuration.\n16.  The medium of claim 15, wherein the availability bitset indicates a first value of `1` for a feature when the feature is available for selection without violating the constraints imposed by the current selection, and a second value of `0`\nfor the feature when the feature is excluded and not available for selection due to violating the constraints imposed by the current selection if selected.\n17.  The medium of claim 15, wherein the feature state for each of the one or more features indicates one of: (i) selected for a feature that has been explicitly selected by a user, (ii) available for a feature that is free for selection without\nviolating the constraints imposed by the current selection, (iii) included for a feature that that is the only available choice in a family due to user selection of one or more features that require it, (iv) default for a feature that is selected due to\nautomatic completion of the configuration, (v) excluded for a feature that conflicts with existing constraints, and (vi) forbidden for a feature that violates an external constraint independent of the possible configurations specified by the MDD that\ncannot be resolved if selected.\n18.  The medium of claim 15, further comprising instructions that, when executed by a processor, cause the processor to: perform a downward traversal of the MDD from the root node to identify downward-marked nodes that are not excluded by the\nselection;  perform an upward traversal of the MDD from the truth node to identify upward-marked nodes that are not excluded by the selection;  and generate the availability bitset by identifying the features available for further selection, consistent\nwith the valid configuration and without violating constraints imposed by the current selection, as the nodes that are both downward-marked and upward-marked.\n19.  The medium of claim 15, further comprising instructions that, when executed by a processor, cause the processor to: perform a first restricted domain calculation using the feature stale to identify which additional feature selections\noutside of the families having feature selections are compatible with the current selection;  perform, for each family in which a feature is selected, a second restricted domain calculation to identify which additional features in that family are\ncompatible with the current selection;  and generate the availability bitset by identifying the features available for further selection according to the first and second restricted domain calculations.\n20.  The medium of claim 15, further comprising: instructions that, when executed by a processor, cause the processor to identify a feature as excluded by the selection when the feature is not selected or available;  and instructions that, when\nexecuted by a processor, cause the processor to identify an included feature as a feature that is unselected but included in a family having exactly one available feature. <HR> <CENTER><b><i>Description</b></i></CENTER> <HR> <BR><BR>TECHNICAL FIELD\nOne or more embodiments generally relate to systems and methods for configuring a product.\n<BR><BR>BACKGROUND\nProduct configuration is an aspect of industries that offer customizable products with a wide variety of features.  The process of selecting a configuration, or features that include a configuration, is used in multiple aspects of marketing and\nsales, order management and production planning, and product development.  Examples include virtually constructing an ideal product (e.g., a vehicle) using a build-and-price application or selecting features for a prototype.\nThe product definition or product offering in the automotive industry is often of staggering dimensionality and size.  It is common for a vehicle to be offered with thirty or more optional feature categories, such as paint color, engine size,\nradio type, and wheel style.  Allowing a user to quickly explore a complex space that could include more than 10.sup.30 valid configurations is a challenging problem in constraints programming.\n<BR><BR>SUMMARY\nIn one embodiment, a method to determine feature states is provided for storing data representative of a multi-valued decision diagram (MDD).  The MDD indicates a Boolean function specifying a buildable space of all possible configurations of\nfeatures of a vehicle.  The MDD includes a root node, a truth node, a false node, and at least one level of intervening nodes between the root node and either the truth node or the false node.  Each level of the MDD corresponds to a family of\nmutually-exclusive features represented by at least one node, and each node except for the truth node and the false node connects to nodes of a next adjacent level by outgoing edges having labels each indicating one or more features of the family that\nare available for the valid configurations including the node, when there are no long edges.  Each node except for the root node connects to nodes of a prior adjacent level by incoming edges that are outgoing edges of the prior adjacent level, such that\na complete path from the root node through the outgoing edges to the truth node defines at least one of the valid configurations, when there are no long edges.  And each complete path from the root node to the truth node is of the same length in nodes\nwhen there are no long edges.  A feature state for each of the one or more features is determined based on a current selection and the possible configurations defined by the MDD.  And an availability mapping indicative of which features are available for\nfurther selection is calculated, consistent with the valid configurations and without violating constraints imposed by the current selection.\nIn another embodiment, a system is provided with memory and a processor.  The memory is configured to store data representative of a multi-valued decision diagram (MDD) indicating a Boolean function specifying a buildable space of all possible\nconfigurations of features of a vehicle.  The MDD includes a root node, a truth node, a false node, and at least one level of intervening nodes between the root node and either the truth node or the false node.  Each level of the MDD corresponds to a\nfamily of mutually-exclusive features and is represented by at least one node, when there are no long edges.  Each node of a level connecting to nodes of a next adjacent level by outgoing edges has labels that each indicate one or more features of the\nfamily that are active for the configurations including the node, such that a complete path from the root node through the outgoing edges to the truth node defines at least one of the valid configurations, when there are no long edges.  And each complete\npath from the root node to the truth node is of the same length in nodes when there are no long edges.  The processor is in communication with the memory and is programmed to receive a current selection of one or more of the features, and to determine a\nfeature state for each of the one or more features, based on the current selection and the possible configurations defined by the MDD.  The processor is further programmed to calculate an availability bitset indicative of which features as available for\nfurther selection, consistent with the valid configurations and without violating existing constraints of the current selection.\nIn yet another embodiment, a non-transitory computer-readable medium comprising instructions that are executed by a processor is provided.  The instructions cause the processor to store data representative of a multi-valued decision diagram\n(MDD) indicating a Boolean function specifying a buildable space of all possible configurations of features of a vehicle.  The MDD includes a root node, a truth node, a false node, and at least one level of intervening nodes between the root node and\neither the truth node or the false node.  Each level of the MDD corresponds to a family of mutually-exclusive features and is represented by at least one node, when there are no long edges.  Each node of a level connecting to nodes of a next adjacent\nlevel by outgoing edges having labels each indicating one or more features of the family that are active for the configurations including the node, such that a complete path from the root node through the outgoing edges to the truth node defines at least\none of the valid configurations, when there are no long edges.  Each complete path from the root node to the truth node is of the same length in nodes when there are no long edges.  The instructions further cause the processor to receive a current\nselection of one or more of the features; determine a feature state for each of the one or more features, based on the current selection and the possible configurations defined by the MDD; and calculate an availability bitset indicative of which features\nas available for further selection, consistent with the valid configurations and without violating existing constraints of the current selection. <BR><BR>BRIEF DESCRIPTION OF THE DRAWINGS\nFIG. 1 is a block diagram of a product configuration system, according to one or more embodiments;\nFIG. 2 is an application programming interface illustrating an application of the product configuration system of FIG. 1 including a configuration engine;\nFIG. 3 is a table illustrating configurations expressed in conjunctive normal form;\nFIG. 4 is a table illustrating configurations expressed in conjunctive normal form and in binary form;\nFIG. 5 is a table illustrating mappings of the configurations of FIG. 4;\nFIG. 6 is a table illustrating multiple configurations and a superconfiguration;\nFIG. 7 is a table illustrating multiple superconfigurations;\nFIG. 8 is a table illustrating the interaction of superconfigurations;\nFIG. 9 is another table illustrating the interaction of superconfigurations;\nFIG. 10 is a table depicting a buildable space according to one or more embodiments;\nFIG. 11 is a table depicting overlapping configurations;\nFIG. 12 is a table depicting a feature mask;\nFIG. 13 is a multi-valued decision diagram (MDD) representing the buildable space of FIG. 10, according to one or more embodiments;\nFIG. 14 is a comparison table;\nFIG. 15 is a diagram illustrating a reduction of the MDD of FIG. 13;\nFIG. 16 is a diagram illustrating merging of duplicate MDD nodes;\nFIG. 17 is a diagram illustrating MDD compression with deterministic families;\nFIG. 18 is a window displayed to a user based on a conflict resolution procedure of the configuration engine of FIG. 2 according to one embodiment;\nFIG. 19 is a window displayed to the user based on a conflict resolution procedure of the configuration engine of FIG. 2 according to another embodiment;\nFIG. 20 is a diagram illustrating a containsAny operation performed by the configuration engine according to one embodiment;\nFIG. 21 is another diagram illustrating a containsAny operation performed by the configuration engine according to another embodiment;\nFIG. 22 is a table listing a restricted buildable space of the buildable space in FIG. 10;\nFIG. 23 is a diagram illustrating a restricted buildable space of the buildable space in FIG. 13 and the table of FIG. 22;\nFIG. 24 is a flowchart illustrating a method for evaluating an MDD using reversible restrictions, according to one or more embodiments;\nFIG. 25 is a diagram illustrating an example of various steps of the method of FIG. 24;\nFIG. 26 is a flowchart illustrating a subroutine of the method of FIG. 24;\nFIG. 27 is another flowchart illustrating a subroutine of the method of FIG. 24;\nFIG. 28 is yet another flowchart illustrating a subroutine of the method of FIG. 24;\nFIG. 29 is a comparison table;\nFIG. 30 is a table illustrating a reduction of the buildable space of FIG. 10;\nFIG. 31 is a table illustrating a projected space after the overlap has been removed and the space has been compressed;\nFIG. 32 is a diagram illustrating the table of FIG. 30;\nFIG. 33 is a table illustrating combinations of features of the buildable space of FIG. 13;\nFIG. 34 is a flowchart illustrating a method for determining MDD feature states according to one or more embodiments;\nFIG. 35 is a table illustrating a set of superconfigurations;\nFIG. 36 is an example of a table illustrating a restricted domain after various steps of the method of FIG. 34;\nFIG. 37 is another example of a table illustrating a restricted domain after various steps of the method of FIG. 34;\nFIG. 38 is a table illustrating an example of the results of the method of FIG. 34;\nFIG. 39 is a flowchart illustrating another method for determining MDD feature states according to one or more embodiments;\nFIG. 40 is a flowchart illustrating a subroutine of the method of FIG. 39;\nFIG. 41 is another flowchart illustrating a subroutine of the method of FIG. 39;\nFIG. 42 is yet another flowchart illustrating a subroutine of the method of FIG. 39;\nFIG. 43 is another flowchart illustrating a subroutine of the method of FIG. 39;\nFIG. 44 is yet another flowchart illustrating a subroutine of the method of FIG. 39;\nFIG. 45 is a diagram illustrating an example of various steps of the method of FIG. 39;\nFIG. 46 is another diagram illustrating an example of various steps of the method of FIG. 39;\nFIG. 47 is a flowchart illustrating a method for resolving conflicts between configurations according to one or more embodiments;\nFIG. 48 is a flowchart illustrating a subroutine of the method of FIG. 47;\nFIG. 49 is a diagram illustrating an example of various steps of the method of FIG. 47;\nFIG. 50 is another flowchart illustrating a subroutine of the method of FIG. 47;\nFIG. 51 is yet another flowchart illustrating a subroutine of the method of FIG. 47;\nFIG. 52 is still yet another flowchart illustrating a subroutine of the method of FIG. 47;\nFIG. 53 is a table illustrating an example of additions and subtractions for the diagram of FIG. 49 according to various steps of the method of FIG. 47;\nFIG. 54 is a window illustrating an example of additions and subtractions that are displayed to the user based on various steps of the method of FIG. 47 according to one embodiment;\nFIG. 55 is a window illustrating an example of additions and subtractions that are displayed to the user based on various steps of the method of FIG. 47 according to another embodiment;\nFIG. 56 is a table illustrating a compression of three superconfigurations to two superconfigurations, according to one embodiment;\nFIG. 57 is a window illustrating an example of a resolution object that is displayed to the user based on various steps of the method of FIG. 47 according to another embodiment;\nFIG. 58 is another flowchart illustrating a subroutine of the method of FIG. 47;\nFIG. 59 is yet another flowchart illustrating a subroutine of the method of FIG. 47;\nFIG. 60 is still yet another flowchart illustrating a subroutine of the method of FIG. 47;\nFIG. 61 is another flowchart illustrating a subroutine of the method of FIG. 47;\nFIG. 62 is yet another flowchart illustrating a subroutine of the method of FIG. 47;\nFIG. 63 is still yet another flowchart illustrating a subroutine of the method of FIG. 47;\nFIG. 64 is a diagram illustrating an example of various steps of the method of FIG. 47;\nFIG. 65 is a table listing an invalid configuration as a bitset;\nFIG. 66 is a table illustrating the minimum edit space of the configuration of FIG. 65 converted to a matrix, as determined by various steps of the method of FIG. 47;\nFIG. 67 is a table illustrating a bitwise conjunction (AND) of the domain of the edit space from FIG. 66 with the invalid configuration from FIG. 65;\nFIG. 68 is a table illustrating the minimum edit space from FIG. 66 after it is trimmed to the families to change from FIG. 67;\nFIG. 69 is an example target matrix for a selection of a feature as determined by various steps of the method of FIG. 47;\nFIG. 70 is an example target matrix for a selection of another feature as determined by various steps of the method of FIG. 47;\nFIG. 71 is software code illustrating an example final resolution object, according to one or more embodiments;\nFIG. 72 is a window illustrating an example prompt provided to the user as part of a guided resolution;\nFIG. 73 is a window illustrating an example of another prompt provided to the user as part of the guided resolution;\nFIG. 74 is a window illustrating an example of yet another prompt provided to the user as part of the guided resolution;\nFIG. 75 is a diagram illustrating an example of various steps of the remove partial matches subroutine of FIG. 58;\nFIG. 76 is a table illustrating an example of various steps of the remove partial matches subroutine of FIG. 58;\nFIG. 77 is a table illustrating an example of various steps of the minimum edit space calculation of FIG. 48;\nFIG. 78 is another table illustrating an example of various steps of the minimum edit space calculation of FIG. 48;\nFIG. 79 is yet another table illustrating an example of various steps of the minimum edit space calculation of FIG. 48;\nFIG. 80 is still yet another table illustrating an example of various steps of the minimum edit space calculation of FIG. 48;\nFIG. 81 is another table illustrating an example of various steps of the minimum edit space calculation of FIG. 48;\nFIG. 82 is a flow chart illustrating a method for automatically completing a configuration according to one or more embodiments;\nFIG. 83 is a diagram illustrating a buildable space;\nFIG. 84 is a table that defines an alternate sequence structure for defining path weights of the buildable space of FIG. 83;\nFIG. 85 is a diagram illustrating an example of various steps of the method of FIG. 82 performed on the buildable space of FIG. 83;\nFIG. 86 is table illustrating path weight;\nFIG. 87 is another table illustrating path weight;\nFIG. 88 is yet another table illustrating path weight;\nFIG. 89 is a diagram illustrating an example of various steps of the method of FIG. 82 performed on the buildable space of FIG. 85;\nFIG. 90 is another table illustrating path weight;\nFIG. 91 is a table illustrating a matrix that defines the same buildable space as the diagram of FIG. 17;\nFIG. 92 is a table illustrating the standard feature conditions for the product definition defining the buildable space of FIG. 91;\nFIG. 93 is software code illustrating a method for automatically completing a configuration using a maximally standard algorithm according to one or more embodiments;\nFIG. 94 is a diagram illustrating an example of various steps of the method of FIG. 93;\nFIG. 95 is a flowchart illustrating another method for automatically completing a configuration using a maximally standard algorithm according to one or more embodiments;\nFIG. 96 is a flowchart illustrating a subroutine of the method of FIG. 95;\nFIG. 97 is another flowchart illustrating a subroutine of the method of FIG. 95;\nFIG. 98 is yet another flowchart illustrating a subroutine of the method of FIG. 95;\nFIG. 99 is still yet another flowchart illustrating a subroutine of the method of FIG. 95;\nFIG. 100 is a table illustrating a buildable space;\nFIG. 101 is a table illustrating standard feature conditions;\nFIG. 102 is a table illustrating an example of various steps of the method of FIG. 95;\nFIG. 103 is another table illustrating an example of various steps of the method of FIG. 95;\nFIG. 104 is yet another table illustrating an example of various steps of the method of FIG. 95;\nFIG. 105 is still yet another table illustrating an example of various steps of the method of FIG. 95;\nFIG. 106 is another table illustrating an example of various steps of the method of FIG. 95;\nFIG. 107 is yet another table illustrating an example of various steps of the method of FIG. 95;\nFIG. 108 is still yet another table illustrating an example of various steps of the method of FIG. 95;\nFIG. 109 is another table illustrating an example of various steps of the method of FIG. 95;\nFIG. 110 is software code illustrating an example of various steps of the method of FIG. 95;\nFIG. 111 is another table illustrating an example of various steps of the method of FIG. 95;\nFIG. 112 is yet another table illustrating an example of various steps of the method of FIG. 95;\nFIG. 113 is still yet another table illustrating an example of various steps of the method of FIG. 95;\nFIG. 114 is another table illustrating an example of various steps of the method of FIG. 95;\nFIG. 115 is yet another table illustrating an example of various steps of the method of FIG. 95;\nFIG. 116 is still yet another table illustrating an example of various steps of the method of FIGS. 95; and\nFIG. 117 is another table illustrating an example of various steps of the method of FIG. 95.\n<BR><BR>DETAILED DESCRIPTION\nAs required, detailed embodiments of the present invention are disclosed herein; however, it is to be understood that the disclosed embodiments are merely exemplary of the invention that may be embodied in various and alternative forms.  The\nfigures are not necessarily to scale; some features may be exaggerated or minimized to show details of particular components.  Therefore, specific structural and functional details disclosed herein are not to be interpreted as limiting, but merely as a\nrepresentative basis for teaching one skilled in the art to variously employ the present invention.\nWith reference to FIG. 1, a product configuration system is illustrated in accordance with one or more embodiments and generally referenced by numeral 100.  The product configuration system 100 includes a server 102 and a configurator\napplication 104.  The configurator application 104 includes a configuration engine 106.  The server 102 includes memory 108 and a processor 110 for storing and operating the configurator application 104.  The product configuration system 100 communicates\nwith a user device, such as a personal computer 112 and/or a mobile device 114 (e.g., a tablet, a mobile phone, and the like), each of which include memory and a processor.  The configurator application 104 includes a \"front-end\" application (shown in\nFIG. 2) that may be installed to the user device 112, 114 from a computer-readable storage medium such as a CD-ROM, DVD or USB thumb drive.  Alternatively, the front-end application may be downloaded from the server 102 to the client device 112, 114 via\nan internet connection 116.  The design and efficiency of the application 104 therefore allows it to be optimized to run on multiple various operating system platforms and on devices having varying levels of processing capability and memory storage.\nThe configurator application 104 allows a user to explore a product offering, where the product is defined by selecting multiple features.  A common example is a build-and-price website that allows a user to customize a product by choosing\nfeatures such as size and color.  The configuration engine 106 validates the customized product (i.e., the configuration) as the user selects different features.\nThe product offering, or product definition, includes all of the allowed ways of combining features (or parts, options, or attributes) in order to make a complete product.  For example, a company might sell a product in two levels (e.g., base\nand luxury), A1 and A2, and in three colors, B1, B2 and B3.  Further, the company only offers the base model, A1, in one color, B1.  Features are grouped into families, in this case family A-\"level\" and family B-\"color.\" The product configuration space\nincludes the following four configurations: A1B1, A2B1, A2B2, and A2B3.  Product definition often comprises rules or constraints that limit or allow relationships between features.  In this example the rule might be \"A1 requires B1.\" A complex product\ncan be defined by thousands or even tens of thousands of rules.\nThe configurator application 104 allows the user to select options or features to create or modify a configuration.  When a user changes a configuration by adding and/or removing a feature, the configuration engine 106 validates the new\nconfiguration.  To perform this validation, the configuration engine 106 determines if the selected configuration fits within the allowed product space.  If the new configuration is invalid, the configuration engine 106 either prompts the user to make\nchanges, or make the changes itself according to a predefined hierarchy.  For example, the monitor of the personal computer 112 shown in FIG. 1 depicts a message window that is displayed to the user indicating changes to resolve the conflict between\nselected features.  The validation and conflict resolution is performed quickly (e.g., less than 2 seconds) and uses little memory and processing.  Ideally, this allows the user to explore the buildable space of allowable product configurations, often\nwhile viewing information associated with the configuration such as price or images.\nUsers interact with front-end applications that present the product information, e.g., on the monitor of their pc 112, and allow them to explore the buildable space.  Although, the configuration engine 106 is different from the front-end\napplication that is displayed on the pc 112, the applications interact closely with each other.  Examples of front-end applications include build-and-price websites, mobile shopping applications, interactive shopping kiosks, and back-office order entry\nand management systems.  When these front-end applications populate product information, they can communicate with the configuration engine 106.  The only people who interact directly with the configuration engine 106 are back-office users tending to the\ndata stored in the server 102.  The product configuration application 104 primarily interacts with other applications.\nIn the computer science field, exploration of a configuration space that is defined by rules or constraints is called constraint programming.  A configuration space can also be defined by a model that is a representation of the possible product\nconfigurations.  Many methods exist in the literature to solve configuration problems, with some using a constraints programming approach and others operating on product definition models.\nReferring to FIG. 2, an application programming interface (API) is illustrated in accordance with one or more embodiments, and generally referenced by numeral 120.  The API 120 illustrates the inputs, steps, and outputs of the configurator\napplication 104.  The configurator application 104 is contained within the server 102 and the user device (pc 112 and/or mobile device 114) according to one embodiment, and may be implemented using hardware and/or software control logic as described in\ngreater detail herein.\nThe configurator application 104 includes a database (DB) 122 for storing data as a catalog entry.  Each catalog entry will store the vehicle attributes (make, model, year, etc.), buildable product space, and extended feature attributes (images,\nprices, detailed descriptions, sales codes, etc.).  The data may be directly processed as is shown by a product definition data source 124, or it may come through a catalog management API 126.  The configurator application 104 also includes an extract,\ntransform and load (ETL) process 128 that provides an interface between the DB 122 and the product definition data source 124 and the catalog management API 126.  The configurator application 104 accesses data from the DB 122 and temporarily saves a copy\nof it in cache memory 130.\nThe configurator application 104 includes one or more \"front-end\" applications or \"top hats\" 132 that are accessible from the user device 112, 114.  Examples of such \"front-end\" applications 132 include consumer build and price sites, management\nlease ordering sites, and dealer ordering applications.\nThe configurator application 104 includes a service API 134 and a web service controller 136 for coordinating the user's requests.  The service API 134 includes a configuration service 138, an enumeration service 140 and a configuration details\nservice 142.\nThe configurator application 104 includes a plurality of processing engines 144, for optimizing the data provided to the front-end applications 132.  The engines include: the configuration engine 106, an image engine 146, a mapping engine 148\nand a pricing engine 150.  The image engine 146 provides one or more images associated with features of the configuration.  The mapping engine 148 provides feature codes from one or more feature code dictionaries.  For example, manufacturing systems and\nsales systems may use different codes for the same feature, and the mapping engine translates between the different coding schemes.  The pricing engine 150 provides pricing associated with the complete configurations and with individual features.  The\npricing engine 150 can also provide changes in pricing associated with changes in the configuration or features.\nThe configurator application 104 also includes a catalog controller 152 that lists which product definitions are available.  The catalog controller 152 receives a catalog request (e.g., what products are available), and provides a response\n(e.g., product A, product B and product C).  Then the user selects a product, and the front end application 132 submits a configuration load request.  Then the web service controller 136 returns a default configuration.\nThe web service controller 136 is a simple object access protocol (SOAP) web service using XML messages, according to one embodiment.  The service API 134 provides an XML request to the web service controller 136 based on each user selection\nmade in the front-end applications 132.  In other embodiments the web service controller 136 uses other protocol.\nThe web service controller 136 provides an XML response to the service API 134 in response to each XML request.  The web service controller 136 parses each XML request, makes appropriate calls to the processing engines 144 or catalog controller\n152, and transforms the output of the configuration engine 106, the image engine 146, the mapping engine 148 and the pricing engine 150 into the appropriate XML response.  The web service controller 136 includes author decorators 154 that are responsible\nfor building up each portion of the response, and includes logic to retrieve data from the database 122 via the cache 130 and save the data as a working copy.\nThe configuration engine 106 operates with reference to a valid buildable space.  The buildable space is also referred to as the product offering and is defined in terms of features that are grouped into mutually exclusive family sets.  All of\nthe possible features are grouped into families such that a valid configuration will contain one and only one feature from each family.\nIn one example product definition of a vehicle, (Vehicle A), exterior paint color is defined by the family PAA and its features are Green (PNWAD), Magnetic (PN4DQ), Blue1 (PNMAE), Red1 (PN4A7), Red2 (PNEAM), Black (PN3KQ), Silver (PN4AG), Orange\n(PN4AH), White (PNYW3), and Blue2 (PN4MAG).\nThe configurator application 104 uses extended feature attributes, or metadata associated with a feature, such as feature name and feature description when presenting the information to a user.  However, the configuration engine 106 uses feature\nand family codes.  A fully qualified feature is its \"family dot feature\" code, such as PAA.PNEAM to represent the paint family with paint color Red2.\nEach point of variation in the product specification can be considered a dimension where a value is selected.  The large number of these variation points on a motor vehicle results in many valid configurations.  Traditionally the large number of\nvalid configurations in this buildable space has been responsible for much computational effort to perform the configuration process, which may be referred to as \"the curse of dimensionality.\" The configuration system 100 provides improvements over\ntraditional systems because it operates efficiently even on highly complex buildable spaces, e.g. those containing more than 10.sup.24 valid configurations.\nA configuration is a particular product instance specified by a set of features.  Each feature belongs to exactly one family.  There may be at most one feature selected from each family.  A complete configuration contains exactly one feature\nfrom each and every family.  A partial configuration will include features from a subset of the families, and one or more families will not have a feature choice specified.\nIn a build and price application, the configuration engine 106 will typically work in complete configurations.  Partial configurations are useful for searching or filtering configurations, as would be done to find and amend orders in an order\nmanagement system.\nSome features are optional, such as moonroof, and a user may order a vehicle without the feature.  But, a complete configuration must still contain a choice for the family.  A \"less feature\" is used to specify the absence of an option.  For\nexample, Vehicle A, which has an optional power moonroof, the family (CHA) contains two features: without the moonroof (i.e., \"less moonroof\"-CHAAA) and with the moonroof (i.e., \"moonroof\"-CHAAC).  The buildable space defines all valid configurations.\nWith reference to FIGS. 3-5, a configuration can be expressed in a variety of different forms.  A configuration can be expressed in conjunctive normal form (CNF).  For example, in one embodiment, a product is defined by four families: A, B, C\nand D; where A, C, and D each have two possible choices, and B has three possible choices.  If there are no restrictions on what features can occur together (other than a single feature choice for each family), the set of choices can be defined as\n(A1|A2) & (B1|B2|B3) & (C1|C2) & (D1|D2).  For a full configuration, each clause will reduce to a single literal or selection for each family (e.g., A1, B1, C1, D1).\nFIG. 3 depicts a CNF Table 300 with two possible configurations.  The CNF table 300 includes a first CNF configuration 302 and a second CNF configuration 304.\nWith reference to FIG. 4, a configuration can also be expressed in binary form by a string of 0's and 1's, as depicted by Table 400.  In binary form, a zero (0) indicates the absence of a feature in a configuration, and a one (1) indicates the\npresence of a feature in the configuration.  For example, a first binary configuration 402 illustrates the first CNF configuration 302 in binary form, and a second binary configuration 404 illustrates the second CNF configuration 304 in binary form.  The\nliteral A2 is replaced with \"01\", as generally referenced by numeral 406.  Each column maps to a feature in the family: `0` in the first position indicates the feature A1 is not present in the first binary configuration 402, and `1` in the second\nposition indicates the feature A2 is present in the first binary configuration 402.  The first CNF configuration 302 (A2 & B2 & C1 & D2) is represented by the first binary configuration 402, where the ampersand (&) symbol is replaced by a space as a\ndelimiter between each family, i.e., \"01 010 10 01.\"\nA configuration space can be very large.  For example, a product definition with around 100 independent features could have over 10.sup.27 possible configurations.  If each configuration was stored as an uncompressed set of 0's and 1's, it would\ntake more than 12 billion Exabytes of memory to represent them all--which is not practical with the present day state of the art computer hardware.  Therefore the configurator application 104 uses compressed representation to facilitate computational\ntractability and efficiency within available memory.\nA bit is the basic unit of information in computing.  It can only have one of two values and is commonly represented as 0 or 1, or the Boolean values of false and true.  A bit set represents a vector or array of bits.  For example, Java has a\nnative utility class called \"BitSet\" that stores a set of bits with an array of values of a primitive 64-bit datatype called long.\nWith the rightmost position of the bit set index 0 and leftmost position index 8, 100101001 is equal to 1*2.sup.8+1*2.sup.5+1*2.sup.3+1*2.sup.0=256+32+8+1=297.  Thus the bit set 100101001 can be stored using the long (or integer) 297.  An array\nof 2 long values (-8929791190748339525, 8791258171646) can represent a bit set of 107 features: 11 01 11 010 100 01 10 00010 00010 111 01 010 01 11 000100 000011 00100 00010 00010 11111 1100 01000001 001 01 11 11 11 01 10 11 11 11.\nThe Java BitSet class allows for varying bit set lengths.  But, for the configurator application 104, the set of features is fixed for a given vehicle.  Thus, the configuration engine 106 defines its own fixed length bit set object.  To store a\nconfiguration, a feature bit set is used.  The feature bit set associates a feature object with each bit position.  This mapping is defined in a structure object that defines a list of families with each family defining a list of features.\nFIG. 5 illustrates a table 500 that defines the mappings for the bit sets in table 400.  The bit sets shown in table 400 are printed in blocked format.  The bits for each family are grouped together with no delimiter and family blocks are\nseparated by a space.  The bit sets can also be printed in strict binary format with no extra spacing, e.g., the first binary configuration 402 of Table 400 could be rewritten as 010101001.  Alternatively, the bit sets can be printed in strict binary\nformat with the same delimiter between every feature and no extra delimiter between families, e.g., the first binary configuration 402 of Table 400 could be rewritten as 0 1 0 1 0 1 0 0 1.  Blocked format allows for better human readability; however,\nspace-delimited is a viable option when viewing the data in a table with labeled columns and importing bit set data into an Excel worksheet for analysis.\nWith reference to FIGS. 6-10, one or more configurations may be compressed and represented by a \"superconfiguration.\" FIG. 6 includes a table 600 listing a first configuration 602: (A2, B2, C1, D2), and a second configuration 604: (Al, B2, C1,\nD2).  Because the values are identical in all but one family `A`, the configurations 602, 604 can be compressed into a single superconfiguration 606.  The table 600 shows both the CNF and bit set forms of the configurations and superconfigurations. \nThus, a configuration is just a superconfiguration with only one possible value per family.\nReferring to FIG. 7, two superconfigurations can also be compressed as shown in table 700.  A first superconfiguration 702 and a second superconfiguration 704 are compressed into a third superconfiguration 706.\nWith reference to FIG. 8, bit sets, configurations and superconfigurations can be interacted using bitwise steps as shown in table 800.  Referring to \"OR\" step 802, when OR-ing two superconfigurations the resulting value for each family is the\nunion of the family set from each superconfiguration.  Thus, if any value in a family set (column) is \"1\", then the union of the family set is \"1.\" And referring to \"AND\" step 804, when AND-ing two superconfigurations the resulting value for each family\nis the intersection of the family set from each superconfiguration.  Thus, if all values in a family set (column) are \"1\", then the union of the family set is \"1.\"\nReferring to FIG. 9, when AND-ing two superconfigurations, the resulting superconfiguration is invalid if any family has no active bits, as shown in table 900.  The intersection for family B is empty causing the configuration to be invalid, as\nreferenced by numeral 902.\nWith reference to FIG. 10, the configuration system 100 expresses buildable space with a set of superconfigurations that define all valid configurations, according to one or more embodiments.  This compressed representation allows for more\nefficient storing and processing of a buildable space.  A non-overlapping set of super configurations can be stored in a matrix 1000, with each row stored as a bit set.\nReferring to FIG. 11, the configuration engine 106 does not use overlapping superconfigurations because they include redundant information which could lead to incorrect calculations.  Thus, all basic steps performed by the configuration engine\n106 rely on the fact that the buildable space contains no overlap.  Two superconfigurations are said to overlap if there exists one or more configurations that are defined by both superconfigurations.  Table 1100 shows a first superconfiguration 1102\nthat overlaps with a second superconfiguration 1104.  Row 1106 identifies all of the overlapping features.  For example, both superconfigurations 1102, 1104 include feature A2, as represented by numeral 1108, and therefore overlap.\nWith reference to FIG. 12, a superconfiguration can be used to define a feature mask.  A feature mask for a single family is created by setting the active bits in the family to zero to define the constrained features and setting all bits to 1\nfor the remaining families.  A feature mask for multiple families is the AND of the masks for each family.  Table 1200 shows several examples.  A feature mask can be used to search a configuration space (contains) or limit a configuration space\n(restrict).  Feature masks can be used to encode a feature condition in order to associate data with features, such as descriptions, prices and images.\nReferring to FIG. 13, the configuration system 100 uses a multi-valued decision diagram (MDD) to represent the buildable space, according to one or more embodiments.  An MDD representing the same buildable space as the superconfigurations matrix\n1000 (FIG. 10) is shown in accordance with one or more embodiments, and generally referenced by numeral 1300.  An MDD is capable of representing the configuration space for large and highly complex product offerings much more compactly than a matrix.\nThe MDD 1300 includes nodes, such as a root node (2), a terminal, Truth or True node (T) and a plurality of intervening nodes (3-16) arranged on a plurality of paths.  Each path includes the root node (2), the true node (T) and some of the\nintervening nodes connected by \"edges\" or arrows.  In terms of superconfigurations, a complete path from the root node (2) to the true node (T) defines a superconfiguration.  The superconfiguration shown in the top row 1308 of the matrix 1000 in FIG. 10\n(i.e., 100 100 110 100 10), is defined by a right path (2-3-4-5-6-T) in the MDD 1300.\nEach level of the MDD 1300 is associated with one family and the edges define the path for each feature.  Each node will have at most one outgoing path for each feature, thus the features are mutually exclusive.  Where there is a path between\ntwo nodes for more than one feature, a single edge is shown, but the edge label includes more than one (\"1\").  The edge labels correspond to a family's superconfiguration bits, where a \"1\" indicates the presence of a feature and a \"0\" indicates the\nabsence of a feature.  Where a feature is inactive, its edge points to the false terminal node, which is not shown in the diagram.  Each complete path from the root node to the truth node is of the same length in nodes when the nodes are expanded, e.g.,\nthere are no long edges.  An MDD that does not include any long edges may be referred to as a quasi-reduced MDD.\nThe MDD 1300 includes five different families 1302: package (Pkg), radio (Radio), paint (Paint), trim (Trim) and moonroof (MoonRf).  Each family includes multiple features.  For example, the package (Pkg) family includes a 400 package, a 401\npackage and a 402 package; and the radio family includes: a Standard (Std) radio, a Deluxe (Dlx) radio and a Navigation (Nav) radio.  The root node (2) is connected to intervening node 13 by edge label \"001\", which indicates the presence of the third\npackage (402) and the absence of the first two packages (400 and 401).  Again, some edge labels include more than one \"1\", which means that more than one feature is available.  For example, intervening node (7) is connected to intervening node (8) by an\nedge with a label \"011.\" This indicates that path 2, 7, 8 is a superconfiguration that includes the 401 package, and the Deluxe (Dlx) and/or the Navigation (Nav) radio.\nFIG. 14 is a table 1400 that illustrates a comparison of the size of a matrix based product configuration (e.g., table 1000, FIG. 10) and an MDD based product configuration (e.g., MDD 1300, FIG. 13).  For small product definitions (e.g., Vehicle\nA with 28 families) a matrix and an MDD have comparable size (20 KB).  However, for medium product definitions (e.g., Vehicle B with 84 families) the matrix size (23,026 KB) is much larger than the MDD size (766 KB).  For large product definitions (e.g.,\nVehicle C with 92 families) the matrix runs out of memory, but the MDD size (313 KB) is sufficient.  Therefore table 1400 illustrates that an MDD is a useful tool when analyzing large product configurations.  Using the MDD format, the minimum number of\nsuperconfigurations required to represent the buildable space of all possible configurations may be calculated.  For complex products that number exceeds reasonably available memory.\nWith reference to FIG. 15, the configuration engine 106 performs steps using reduced MDDs, such as reduced MDD 1500, in one or more embodiments.  FIG. 15 includes the MDD 1300 of FIG. 13 and a reduced MDD 1500.  In an MDD, a redundant node may\nbe removed and its incoming and outgoing edges may be combined to form a \"long edge.\" A redundant node is a node that corresponds to a family in which all features are active, i.e., its outgoing edge label includes only \"1\"s. For example, intervening\nnode 16 in MDD 1300 corresponds to the moonroof (MoonRf) family, and its outgoing edge label \"11\" indicates that both the moonroof (Vista) and no moonroof (Less) features are active.  Therefore node 16 is redundant and it can be removed, as depicted by\nthe \"X\" disposed over it in FIG. 15.  Nodes 10 and 12 of MDD 1300 are also redundant and may be removed, as depicted by the X's over them in FIG. 15.  The reduced MDD 1500 shows the result of removing redundant nodes 16, 10 and 12 and collapsing their\nrespective incoming and outgoing edges into long edges.  The paths from 13-T, 9-T, and 10-T do not include a node for the moonroof (MoonRf) family.  By collapsing the long edges, the reduced MDD 1300 has 3 fewer nodes, and some of its nodes have been\nrenumbered.  For example, since node 10 of MDD 1300 was removed, node 11 of MDD 1300 was renumbered as node 10 in reduced MDD 1500.  By reducing MDDs, the configuration system 100 reduces memory and processing usage.\nIn one or more embodiments, the configuration engine 106 performs steps using an expanded (not reduced) MDD, such as MDD 1300, e.g., during a \"Quick-Restrict\" step, as described below.  For a very large buildable space, the number of nodes added\nto expand long edges can be quite significant.  As an example, an MDD may have 17,283 nodes when long edges are compressed, but grow to 47,799 nodes when long edges are expanded.  Therefore good compression reduces the number of long edges significantly. However, the savings generated by the quick-restrict step are generally sufficient to justify the long edge expansion.\nIn the expanded MDD 1300, nodes 10, 12, and 16 are not only redundant; they are also duplicated.  Duplicate nodes are two nodes for a family (i.e., within a common row) that have identical outgoing edge labels.  The reduced MDD 1500 is in\ncanonical form, i.e., there are no duplicated nodes.  The configuration engine 106 creates MDDs in canonical form.  Canonical form helps to minimize the number of nodes required to represent the buildable space.\nFIG. 16 includes a non-canonical MDD 1600 with duplicate nodes.  Node 6 and node 8 include identical outgoing edge labels, and therefore are duplicates of each other, as referenced by numeral 1602.  Similarly, node 5 and node 7 are duplicates,\nas referenced by numeral 1604.  FIG. 16 also includes a canonical MDD 1610.  The duplicate nodes of MDD 1600 are merged in the canonical MDD 1610.  For example, the first duplicate nodes 1602 are merged to form a canonical node 6, as referenced by\nnumeral 1612.  And the second duplicate nodes 1604 are merged to form a canonical node 5, as referenced by numeral 1614.  The MDDs, e.g., MDD 1600, 1610, are serialized as plain text for storage in a database, such as the DB 122 shown in FIG. 2.  Such\ntext serialization ensures backwards compatibility across software versions and implementations.\nWith reference to FIG. 17, when a family's values in the configuration space can be determined by the values from one or more other families, the family is said to be deterministic.  Deterministic relationships are used to minimize the size of\nan MDD to allow for scaling to complex vehicle configurations.\nFIG. 17 includes an MDD 1700 that is similar to the MDD 1300 of FIG. 13, with the addition of two deterministic families: seat temperature control (Temp) and the presence of dice (Dice).  The presence of dice is determined by the paint color. \nThus, once the paint color (Paint) is known, there is just one choice for dice.  If paint is White, then dice are not present (NoDice); however if paint is Red or Blue, then Fuzzy dice are present (FuzzyDice).  The seat temperature control (Temp) is\ndetermined by the package (Pkg).  If Pkg is 400, then the seat temperature control is not available (LessTemp); if Pkg is 401, then heated seat temperature control is included (Heat); and if Pkg is 402, then heat and cool temperature control (HeatCool)\nis included.  In these examples Paint color and Pkg are the determinant families while Dice and Seat temp are deterministic.  This is because their state is fully specified by the state of the determinant.\nThe presence of deterministic features has a negative impact on MDD compression.  The MDD 1700 represents twenty-four configurations.  However, the deterministic families cause the MDD 1700 to increase from sixteen nodes to twenty-four nodes. \nGenerally, the number of nodes in an MDD is a good predictor of its performance.  Thus, it is ideal to have an MDD with as few nodes as possible.  To aid in MDD compression, the configuration system 100 extracts the relationship defining a deterministic\nfamily's values to form one or more external relationship MDDs, which allows for greater compression in the main MDD, i.e., MDD 1700.\nThe configuration system 100 extracts the two deterministic families (Temp and Dice) from MDD 1700 to form reduced an MDD 1702, a first external relationship MDD 1704 corresponding to the Dice family, and a second external relationship MDD 1706\ncorresponding to the Temp family.  The deterministic families (Temp and Dice) remain in the MDD 1702, but are trivialized--made all 1s--allowing the main MDD 1702 and the external relationship MDDs 1704, 1706 to share the same structure.\nThe combination of the main MDD 1702 and all its external relationship MDDs 1704, 1706 is referred to as a Global MDD.  A Global MDD can be operated in the same way as an MDD; but, each step must account for both the main space and the\nrelationships.\nThe configuration service 138 abstracts the implementation from any specific application and state management does not depend on the implementation being either \"stateful\" or \"stateless\", according to one or more embodiments.  The configuration\nservice 138 remembers a user's session history in a stateful implementation, and does not remember a user's session history in a stateless implementation.  However, the front-end application 132 treats the configuration service 138 as stateless in so far\nas it does not need to handle session synchronization.\nEach XML response to the front-end application 132 from the configuration service 138 includes a state object that is included in the next call.  The content of the state object is not dictated by the configuration service 138, but it contains\nany information necessary to maintain a user session.  The state object is not modified by the front-end application 132.\nA configuration session begins with an XML request to load initial content (i.e., a \"Load Request\") to populate a starting point of initial screens on the front-end applications 132.  This is followed by additional XML requests to update the\ncontent (\"Update Request\") as user changes the configuration by selecting different options in the front-end application.  The web service controller 136 responds with an XML configuration response that includes updated configuration content.\nEach feature included in such configuration responses includes a selection or feature state attribute.  In one embodiment, there are six different feature state values: Selected, Available, Included, Default, Excluded and Forbidden.\nA Selected feature state is a feature that has been explicitly selected by the user and generated in response to a Load or Update XML request.  The configuration service 138 cannot unselect this feature as a result of another selection without\nperforming a conflict resolution procedure, except for features in a mutually exclusive feature group.\nAn Available feature state is a feature that is not currently selected by the user.  But the user is free to select it without causing a conflict resolution procedure to be triggered.  In a mutually exclusive group of features (e.g. exterior\ncolor), although only one feature can be selected at a time, the other features in that group will be marked as \"Available\"--they will only be marked as \"Excluded\" if they conflict with a user selected feature in another family.\nAn Included feature state is a feature which is the only available choice in the family.  For example, this can occur when a selection of a feature requires another feature.  This can be the result of either a package selection that includes\nthis feature (e.g. \"Climate Pack\" includes \"Air Conditioning\"), or a \"must\"/\"requires\" relationship (e.g. \"Heated Seats\" requires \"Leather Seats).\nA Default feature state is a feature that was selected by the configuration service 138 as part of an automatic completion function, as described in detail below with reference to FIGS. 82-117.\nAn Excluded feature state is a feature that conflicts with another user selection.  Selecting this feature will prompt a conflict resolution procedure.\nA Forbidden feature state is a feature that violates a constraint that cannot be resolved if selected.  Attempting to select this feature will result in an error.  This state has been introduced to support external constraints that restrict the\nvalid buildable configurations.\nThe front-end application 132 alters the display of features based on their configuration state, in one or more embodiments.  For example, in one embodiment, the front-end application 132 shows a symbol next to an excluded feature to indicate\nthat it conflicts with a prior selection or it may choose not to display excluded or forbidden features.\nIn one embodiment, the configuration system 100 changes a feature from the Default feature state to the Selected feature in response to a user implicitly selecting the feature.  For example, if Default features are presented as checkboxes or\nradio buttons, there is no action the user can take to check an already checked item.  This means that while the user intended to select the feature, it is still marked as Default.  Such an implicitly selected Default feature may complicate conflict\nresolution strategies.  Thus, the configuration system 100 includes an option to change a feature from a Default feature state to the Selected feature state in response to a user viewing a default selection and not changing it.\nThe configuration service 138 will return a complete configuration to the front-end application 132 in response to any load or update request, according to one or more embodiments.  This feature is referred to as \"automatic completion.\" Default\nfeature selections will be added to any Selected features or Included features to create a complete configuration with respect to displayable families.  A feature is \"displayable\" if it can be displayed to the user, e.g. on the user's pc 112; whereas a\nfeature that cannot be displayed to the user is described as \"no-display\" or \"not displayable.\" The front-end application 132 may choose to distinguish the automatic feature selections from those explicitly selected by the user, using each feature's\nstate value returned in the configuration response.\nAlternatively, in other embodiments the automatic completion feature is disabled.  When the automatic completion feature is disabled, no default selections are made and the response will typically include an incomplete configuration.  This\nenables different front-end application 132 designs where a user is prompted to actively select each feature in the configuration.\nThe configurator application 104 includes a conflict resolution procedure in which, in response to an update request to select a feature that leads to an invalid configuration; the configuration service 138 returns a new valid configuration with\nthe newly selected feature and the minimum other changed features required to make the configuration valid.  If the auto completion feature is enabled, the new configuration will include any necessary Default features.  The web service controller 136\nimplements the conflict resolution feature to provide details on what features must be added and removed to resolve the conflict, as well as a \"reject state\" that is used if the user cancels the requested change.\nWith reference to FIG. 18, the configurator application 104 includes a \"single\" conflict resolution strategy, according to one or more embodiments.  The configuration service 138 resolves the conflict by finding a single valid configuration\ncontaining the new selection.  FIG. 18 depicts a user interface 1800 that is displayed to the user on the user device (e.g., on the monitor of the PC 112) by the front-end application 132 as part of the conflict resolution procedure.  The user interface\n1800 includes a message 1802 that alerts the user of a conflict (i.e., by selecting the adaptive cruise control feature, the Zetec package and the solar reflect windscreen features must be removed, and the titanium package must be added) and asks for\nconfirmation that they still want to make the change.  If the user cancels the change, e.g., by selecting the decline button 1804, the subsequent view request includes a reject state to undo the prior selection (i.e., adaptive cruise control) in the\nconfigurator application 104.  The update request may unselect a feature.  Since all families must have one feature selected to form a valid configuration, unselecting a feature is often equivalent to selecting the \"less\" feature in the family.  Removing\na feature from the configuration can also lead to a conflict.  For example, if the user removes an included feature, the selected feature which includes it will also be removed.\nReferring to FIG. 19, the configurator application 104 includes a branched conflict resolution strategy, according to one or more embodiments.  In branched conflict resolution, the configuration service 138 presents the user with a series of\nchoices to help them select from a set of valid configurations.  For example, FIG. 19 depicts a user interface 1900 that is displayed to the user on the user device (e.g., on the monitor of the PC 112) by the front-end application 132.  The user\ninterface 1900 includes a series of choices for a remote starter option (e.g., with or without (less) the remote starter), as referenced by numeral 1902, and a series of choices for the color of the seats (e.g., Charcoal Black or Medium Light Stone), as\nreferenced by numeral 1904.  In one embodiment, the branched conflict resolution strategy may be enabled by setting a return guided resolution flag (not shown), which is included in the communication between the front-end application 132 and the service\nAPI 134.\nWith respect to state management, when a branched conflict resolution is returned in the response to the service API 134, there will be no feature state because the new configuration isn't known until the user traverses the resolution tree,\n(i.e., selects from the options shown in the user interface 1900).  Once selections have been made, the front-end application 132 sends a second update request with all the changes made during resolution.  At this time the response will include the new\nconfiguration state.  Optionally, if there is only one target configuration, the response could include the new configuration state to save one call to the service.\nIn one or more embodiments, the conflict resolution strategy employed by the configurator application 104, may add a feature or subtract a feature, which is referred to as \"return delta\" functionality.  In one or more embodiments, the conflict\nresolution subtractions only contain Selected features removed from the configuration; and conflict resolution additions only contain Included features added to the configuration.  If the new configuration caused a change in a Default feature, this is\nnot included in the prompt to the user (e.g., not shown in the user interfaces 1800, 1900).  If all changes are for default choices, there are no changes to report, and the response will not include conflict resolution.\nAlternatively, in other embodiments, the response will include all additions and subtractions regardless of feature state when the request has set the return delta flag to true.  This allows the front-end application 132 to inspect the\nresolution and apply some additional logic when deciding whether to prompt the user for a conflict or to silently make the changes.\nThe configuration engine 106 \"validates\" each configuration.  A load request from the services API 134 may include a full or partial configuration as a starting point.  When a configuration is submitted to the configuration engine 106 with the\nload request, it is validated.  By default, or when a validate flag is True, conflict resolution will be triggered and the response will include a valid configuration.  However, if the request has set the validate flag to False, conflict resolution is\nnot performed and an error message will be included in the response if the submitted configuration is not valid.\nThe configuration engine 106 performs steps on a buildable space in order to process a configuration request and generate data to build a response.  The configuration engine 106 uses data structures and algorithms, including those based on\nmultivalued decision diagrams (MDD) to perform the configuration steps.  For comparison, some matrix based steps are also described.\nIn many cases the configuration engine 106 uses MDD steps to search the product space in the same way a structured query language (SQL) query searches a database.  Both are preforming relational algebra.  As appropriate, the SQL equivalent of\neach MDD step is described.\nThe configuration engine 106 checks if the buildable space defines a specific full configuration or a partial configuration, which is referred to as a \"contains any\" step.\nIn terms of SQL, this step is equivalent to performing a search and evaluating if there is at least one row in the result set.  For example, consider the partial configuration (Dlx, Vista).  If a database stored each configuration as a separate\nrow, and each family choice as a string column, the SQL query would be SELECT * FROM mdd WHERE Radio='Dlx' AND Moonrf='Vista'.\nFor efficient storage, matrix and MDDs represent the product with superconfigurations.  If each row in the database stored a superconfiguration with each feature as a Boolean column, the SQL would be SELECT * FROM mdd WHERE Dlx=TRUE AND\nVista=TRUE.\nFor example, in one embodiment, the configuration engine 106 searches an MDD by stating the query as a feature mask.  For example, to search for the partial configuration (Dlx, Vista) the mask would be 111 010 111 111 01.  The radio family\nincludes the following features: Standard (Std), Deluxe (Dlx) and Navigation (Nav).  Since the search is limited to (Dlx), the only active bit corresponds to Dlx (i.e., 010) for the radio family.  Additionally, the moonroof family includes: without a\nmoonroof (Less) and with a moonroof (Vista).  Since the search is limited to (Vista), the only active bit corresponds to Vista (i.e., 01).  All other families are all 1s.\nWhen the configuration engine 106 is performing a step to check for a partial configuration, one or more families will have all 1s.  This means that the mask defines multiple configurations.  The configuration engine 106 is querying the space to\ndetermine if any of the individual configurations defined in the feature mask superconfiguration are contained in the space.  Thus the step is called \"containsAny.\"\nWith reference to FIGS. 20 and 21, the configuration engine 106 performs an MDD-based \"containsAny\" step using a depth-first search of the space to look for the first valid path defining at least one of the configurations from the mask.  In a\ndepth-first search, the configuration engine 106 starts at the root node, and traverses the edges in descending order of its features; an edge of 011 will be processed by first inspecting 001 and then 010.\nFIG. 20 is an MDD 2000 that illustrates an example of the configuration engine 106 performing an MDD-based \"containsAny\" step for the partial configuration (Dlx, Vista).  To determine if this partial configuration is valid, the configuration\nengine 106 performs a depth-first search using the feature mask 111 010 111 111 01.  The search begins with the path 2-13.  This path is aborted when the Radio feature Dlx is inactive on edge 13-14, as shown by the dashed edge 2002.  Next, the\nconfiguration engine 106 searches path 2-13-8-11-12-T. This path, highlighted by nodes in solid line, ends in True node 2004, indicating a valid path has been found containing the partial configuration (Dlx, Vista).  Note there are three additional paths\ncontaining (Dlx, Vista), 2-13-8-9-10-T, 2-7-8-11-12-T, 2-7-8-9-10-T; but, the configuration engine 106 stops the \"containsAny\" step after the first path is found.\nFIG. 21 is an MDD 2100 that illustrates an example of the configuration engine 106 performing an MDD-based \"containsAny\" step for the partial configuration (Std, Vista).  To determine if this partial configuration is valid, the configuration\nengine 106 performs a depth-first search using the feature mask 111 100 111 111 01.  The search begins with path 2-13 which is aborted because neither edge 13-14, nor 13-8 is active for the standard radio feature (i.e., neither of the edge labels include\na \"1\" in their first digit), as shown by dashed edges 2102.  Next the configuration engine 106 searches path 2-7, which is also aborted because Std is not active, as shown by dashed edges 2104.  Finally, the configuration engine 106 searches path\n2-3-4-5-6 and aborts the search because 6-T is not valid for MoonRf.Vista, as shown by dashed edge 2106.  No paths are found containing both Std and Vista, thus this combination is found to be invalid.\nThe domain of a buildable space defines all the Available features--those features contained in one or more configurations.  The domain can be represented as a bit set where each 1 (active feature) denotes a feature contained in the domain and\neach zero (inactive feature) denotes a feature absent from the domain.  For any active bit in the domain, the space contains one or more configurations with that feature.  If there is an inactive bit in the domain, the space contains no configurations\nwith that feature.  For a matrix, the domain is calculated by the OR of all superconfigurations in the space.  The domain of the space shown in FIG. 10 is 111 111 111 111 11, because every feature is available in at least one configuration.\nWith an MDD, the configuration engine 106 calculates the domain by traversing the MDD in either a breadth-first or a depth-first manner, and using the active features on the edges to define the domain.  In a breadth-first search, the\nconfiguration engine 106 starts with a root node, then explores neighbor nodes first before evaluating the next family.  For example, the configuration engine 106 evaluates the MDD 2100 of FIG. 21 using a breadth-first strategy by starting with the root\nnode 2 and evaluating path 2-13.  Although path 2-13 is valid, the configuration engine evaluates neighbor nodes 7 and 3, i.e., paths: 2-7 and 2-3, before evaluating the next family, i.e., nodes: 14, 8 and 4.  Once a path is determined to be invalid, the\nconfiguration engine 106 stops evaluating nodes farther down the path.  For example, once path 13-14 is found to be invalid, the configuration engine 106 does not continue along the path to evaluate nodes 15 and 16.  And as described above, in a\ndepth-first search, the configuration engine 106 starts at the root node, and traverses the edges in descending order of its features.  In the depth-first search, levels (families) are not back-tracked until an invalid path, or the truth node, is\nencountered.  In the configuration engine 106, the full domain is not usually called, but rather domain is called on a restricted space.  The domain of a restricted space is used in determining feature states.\nThe configuration engine 106 restricts a space by keeping only those configurations containing a specific feature or combination of features.  With respect to a database query, the restrict step is equivalent to searching the table to find only\nthose rows that match the query.  The restricted features define the WHERE clause.  Consider the partial configuration (Nav, Ruby, Vista).  In terms of SQL, the query would be SELECT * FROM mdd WHERE Radio=`Nav` AND Trim=`Ruby` AND MoonRf=`Vista`.  In\nterms of superconfigurations, the step begins with creating a feature mask defining the query.  This is the same feature mask that would be used for a containsAny step.  For restrict, a space is created with the feature mask as its only\nsuperconfiguration.  Then, the restricted space is created by the AND of the original space with the feature combination space.\nFIGS. 22 and 23 show restrictions of the space defined in FIGS. 10 and 13.  In the table 1000 shown in FIG. 10, the last two rows of superconfigurations contain the radio feature (Nav), the trim feature (Ruby) and both moonroof features (Vista\nand Less), which indicates that Nav and Ruby are available with the moonroof (Vista) or without the moonroof (Less).  FIG. 22 is a table 2200 that depicts a restricted version of table 1000 , in which the five superconfigurations of table 1000 are\nrestricted to two superconfigurations, and the Moonrf.Less bit is set to zero to remove the configurations for (Nav and Ruby and MoonRf.Less).  FIG. 23 is a restricted MDD 2300 illustrating the restricted superconfigurations of table 2200.\nFor some algorithms, successive restricts will be performed on the same space.  When an MDD is restricted, a new set of nodes is created and the edges are updated for the nodes to keep only the constrained features.  When many restrict\noperations are performed, many node objects must be created as the MDD is replicated.  For large MDDs, this can cause the memory usage or \"footprint\" to increase, and may also incur performance problems from \"garbage collection\", i.e., reclaiming memory\noccupied by objects that are no longer in use by the program.  The configuration engine 106 addresses these issues using a \"quick-restrict\" strategy.\nWith reference to FIG. 24, a method for evaluating an MDD using reversible restrictions (i.e., \"quick-restrict\") is illustrated in accordance with one or more embodiments and generally referenced by S100.  The quick-restrict method S100 is\nimplemented as an algorithm within the configuration engine 106 using software code contained within the server 102, according to one or more embodiments.  In other embodiments the software code is shared between the server 102 and the user devices 112,\n114.  FIG. 25 illustrates an original MDD 2500, and an MDD 2502 after it is \"quick-restricted\" to the partial configuration (Nav, Ruby, Vista) by the configuration engine 106 according to the quick-restrict method S100 of FIG. 24.\nAt S102, the configuration engine 106 saves a copy of the root node identity and a set of the node edges to the memory 108 (shown in FIG. 2).  The subroutine of S102 is shown in the flowchart of FIG. 26.  At step S104 the configuration engine\nidentifies each node (y).  Then at step S106 the configuration engine copies or clones each outgoing edge of the node (y), and returns to step S104 until each node (y) in the MDD 2500 is copied.  Then at step S108, the configuration engine 106 returns\nthe edge set and the identity of the root node to the main routine of FIG. 24.\nAt step S110, the configuration engine 106 performs the quick-restrict subroutine for the given selected features.  The subroutine of step S110 is shown in the flowchart of FIG. 27.  At step S112 the configuration engine 106 examines the cache\nmemory for source (SRC) node (y) to determine if the quick-restrict subroutine has already been performed on node (y), (i.e., does cache(y) exist?) If cache(y) exists, then the configuration engine 106 proceeds to step S114 and returns to the main\nroutine.  If cache(y) does not exist, the configuration engine 106 proceeds to step S116.\nAt step S116, the configuration engine 106 starts with array index zero, and sets the empty flag to true.  By setting the empty flag to true, the configuration engine 106 assumes that there are no valid paths from the node, i.e., that all edges\npoint to the false node.  At step S118, the configuration engine 106 evaluates the array index (z) to determine if (z) is less than the number of node (y)'s children.  A positive determination at step S118 indicates that the configuration engine 106 has\nnot analyzed all array indexes of node (y).  If the determination is positive, the configuration engine 106 proceeds to step S120.\nAt step S120, the configuration engine 106 checks if y's child, or destination (DST) node, at array index (z) is false.  If the configuration engine 106 determines that the child is false, then it proceeds to step S122, increments the array\nindex (z) by one, and returns to step S118.  With reference to FIG. 25, the MDD 2500 does not show false nodes, but they are still present.  For example, node 9 shows only one outgoing edge with the label \"001.\" This indicates that array indexes zero and\none are both false, but they are not shown extending to the false node on the MDD 2500 to avoid clutter.  When analyzing node 9, the configuration engine 106 makes a positive determination at S120 for array indexes zero and one, but makes a negative\ndetermination for array index two.  If the determination at step S120 is negative, the configuration engine 106 proceeds to step S124.\nAt step S124, the configuration engine 106 evaluates the quick-restricted features list for node (y) to determine if it contains feature (z).  Otherwise, the configuration engine 106 sets y's child node along z to false at S126 and then proceeds\nto step S122 to increment the array index(z) by one.\nAt step S128, the configuration engine 106 check's if y's child (DST) at array index (z) is true.  For example, with reference to MDD 2500, node 16 connects to the true node (T) along array indexes zero and one.  If the configuration engine 106\ndetermines that the child node is the true node, then it proceeds to step S130 and sets the empty flag to false (empty=false), which indicates that there is at least one edge that is connected to the true node (T), and then proceeds to step S122.  If the\ndetermination at step S128 is negative, the configuration engine proceeds to step S132.\nFor example, referring to MDD 2500, node 3 is illustrated with one outgoing edge with the label \"100\", which indicates that node 3 includes the Standard radio, but does not include the Deluxe radio or the Navigation radio.  Since the Navigation\nradio was selected by the user, the configuration engine 106 determines that none of node 3's outgoing edges contain (z)'s corresponding feature.  Therefore the configuration engine 106 sets node 3's children to false at S126, which is illustrated by\ndisconnecting the outgoing edge to node 4 (as shown in MDD 2502) and the edge label for path 3-4 is replaced with an edge label of \"000.\" However, referring to MDD 2500, node 7 includes two array indexes (011), which indicate that node 7 includes the\nDeluxe radio and the Navigation radio.  Since the Navigation radio was selected by the user, the configuration engine 106 determines that one of node 7's outgoing edges contain (z)'s corresponding feature at S124, therefore the outgoing edge is not\ndisconnected from node 8 (as shown in MDD 2502) and the edge label for path 7-8 is replaced with an edge label of \"001\".\nAs shown in MDD 2502, the configuration engine 106 removes the edge pointer for path 13-8 because Navigation is not an active feature for the Radio family (i.e., there was not a \"1\" in the third digit of the edge label); and removes the edge\npointer for path 15-16 because Ruby is not an active feature for the Trim family at S126.  Since only Vista is constrained for the moonroof family; the configuration engine 106 modifies the edge labels for paths 10-T and 12-T from \"11\" to \"01\".  If the\ndetermination at step S128 is negative, the configuration engine 106 proceeds to step S132.\nAt step S132, y's children, or (DST) nodes, are rewritten by the result of recursive invocation of the quick-restrict method on the child.  All nodes of the MDD are processed in this manner.\nAt step S134, the configuration engine 106 checks y's child at array index (z) to determine if it's not a false node.  If the determination is positive (e.g., if node (y) is connected to a valid node), then the configuration engine 106 proceeds\nto step S136 and sets the empty flag to false, before incrementing the array index (z) at S122.  However, if node (y) is connected to the false node along array index (z) then then the configuration engine 106 proceeds directly to S122 to increment the\narray index (z).\nThe quick restrict method S110 operates on the nodes in a depth first search fashion.  Steps S118-S136 demonstrate an iterative process that operates on each array index (z) of a node (y) before proceeding to the next node.  Once the\nconfiguration engine 106 has evaluated all array indexes (z) for a node (y), it will make a negative determination at step S118 (i.e., z will be greater than or equal to the number of y's children), and proceeds to step S138.\nAt step S138 the configuration engine 106 checks if all children (DST) of node (y) are false, i.e., it evaluates the empty flag to determine if any valid configurations were found.  If all of y's children are false, the configuration engine 106\nproceeds to step S140, sets node (y) to the false node, set cache(y) to y, and then returns the cache(y), i.e., saves the analysis of node (y) and returns to the main routine of FIG. 24.  Further, if the node does not contain any edges that conform to\nthe constraint, then the edge pointer is disconnected from the child node in the MDD.  If not all of the children nodes are false, then the configuration engine 106 proceeds to step S142, sets the cache(y) to (y), and then returns the cache(y), i.e.,\nsaves the analysis of node (y) and returns to the main routine of FIG. 24.\nFor example, referring to FIG. 25, the configuration engine 106 determines that node 3's features do not contain the Selected radio feature (Nav) at S124, and therefore sets node 3's child (node 4) to false at S126.  Setting node 4 to false is\nrepresented by disconnecting the edge pointer between node 3 and node 4 in MDD 2502.  The configuration engine 106 determined that all of node 3's children were set to false at S138, and therefore set node 3 to false at S140.  Setting node 3 to false is\nrepresented by disconnecting the incoming edge pointer to node 3 in the MDD 2502.\nSimilarly, the configuration engine 106 disconnects the incoming edge pointer to node 15 at S140, because all of node 15's children were set to false at S126, which is depicted by the disconnected outgoing edge pointer of node 15 in MDD 2502. \nAlthough the edge label for path 7-8 was revised at S126, the edge pointer was not disconnected.  Therefore the configuration engine 106 determines that not all of node's 7 children are false at S138, and proceeds to S142 without setting node 7 to false\nor disconnecting its incoming edge pointer in the MDD 2502.\nThe quick-restrict subroutine S110 is a recursive process.  This process continues until all nodes are analyzed.  The edges for complete paths from the root node (node 2) to the truth node (T) define the restricted configuration space.\nAt step S144 the configuration engine 106 performs additional steps on the restricted MDD 2502.  In one embodiment, after completing a traversal of the MDD in a first direction (e.g., downward), the configuration engine 106 determines the domain\nfor a restricted space by traversing the MDD again in the same direction (i.e., the configuration engine repeats S110 for all nodes).\nIn another embodiment, the configuration engine 106 determines the domain at the same time as traversing the MDD in the first direction (i.e., during S110).  Then at step S144, the configuration engine 106 changes direction (i.e., reverses) and\ntraverses the MDD in a second direction, e.g., upwards from the truth node (T) to the root node (2).  On the downward traversal, the configuration engine 106 trims the edges to conform to the constraint.  On the upward traversal, the domain bit set is\ncreated from the remaining edges.  Combining quick-restrict and domain in a single operation saves one traversal of the MDD.  However, the operation modifies the MDD and the edges must be reset to undo the quick-restrict.\nAt S146, the configuration engine 106 restores the original set of node edges to the memory 108 (shown in FIG. 2).  The subroutine of S146 is shown in the flowchart of FIG. 28.  At S148 the configuration engine identifies each node (y).  Then at\nstep S150 the configuration engine 106 copies each outgoing edge of the node (y), and returns to step S148 until each node (y) in the MDD 2500 is copied.  Then at step S152, the configuration engine 106 sets the MDD to the identity of the root node and\nreturns to the main routine of FIG. 24.\nAt step S154 the configuration engine 106 determines if the user has selected different features.  If the user has selected new features, the configuration engine 106 returns to S110.  If the user has not selected new features, then the\nconfiguration engine 106 proceeds to step S156 and deletes the copy of each node from S102 to free memory.\nAs shown in MDD 2502, paths 9-10-T and 11-12-T are duplicate paths, because they include the same features.  As described above with reference to FIGS. 22-23, the restrict operation will reuse nodes to avoid duplicate nodes or sub-paths. \nAlthough, the quick-restricted MDD 2502 may contain more nodes than the restricted MDD 2300, the configuration spaces defined by each are identical.\nThe quick-restrict method S100 provides advantages over existing methods by performing successive restricts without creating a new MDD for every step.  The configuration engine 106 saves the original edge pointers at S102 and then quickly resets\nthe MDD 2500 using the original edge pointers.\nThere are some cases, where a more efficient algorithm can perform the same operation without having to do the quick-restrict method, eliminating the time needed to reset the edge pointers.  This time savings, while small, can be significant\nwhen working with extremely large configuration spaces.  A \"Restricted Domain\" algorithm is one such algorithm.\nIn other embodiments, the configuration engine 106 determines a read-only restricted domain using an external set of edges (not shown).  Instead of modifying the original MDD node edges the external edges are modified to reflect the restricted\nspace.  The configuration engine 106 restricts on the downward traversal and then updates the domain on the upward traversal.  Such a method is a read-only, thread-safe operation, because the MDD is not modified.\nThe quick-restrict with domain operation method S100 is slightly slower than this read-only approach for the same calculation; however, the time saved in the read-only operation is due to not having to reset the edges.  FIG. 29 is a table 2900\nillustrating a comparison of the performance of the quick-restrict with domain operation method S100 to the read-only method.  The larger and more complex the buildable space, the more nodes in the MDD, and the more time it requires to reset the edges\nafter the quick-restrict method S100.\nWith reference to FIGS. 30-32, the configuration engine 106 performs a \"project\" operation of an MDD to trim a space to a subset of the families while keeping all unique configurations, according to one or more embodiments.  In terms of SQL, the\nprojection operation is equivalent to specifying which columns of a table are returned in the query.  To project the space to the package (Pkg) and the trim (Trim) families, the equivalent SQL would be: SELECT DISTINCT Pkg and Trim FROM mdd.\nSelecting distinct configurations means that the resulting space should contain no duplicated configurations.  During the MDD project operation, the configuration engine 106 removes any duplicated configurations (also called overlapping\nsuperconfigurations).\nFIG. 30 is a table 3000 that shows the result of the configuration engine 106 reducing the buildable space in FIG. 10 to keep only the columns for the package and trim families.  This space contains duplicate configurations.  For example a\nconfiguration including the 401 package and Ruby trim is defined in Row 3 and in Row 4.  Likewise a configuration including the 402 package and Ruby trim is defined in Row 3 and in Row 5.  Therefore Row 4 and Row 5 are duplicates of Row 3 and can be\nremoved.  Further, Row 2 and Row 3 can be compressed to a single row.  FIG. 31 is a table 3100 that shows the projected space after the overlap (duplicated configurations) has been removed and the space has been compressed.  FIG. 32 is an MDD 3200 that\nrepresents table 3000.\nWith reference to FIG. 33, the configuration engine 106 lists, or enumerates all valid configurations that are utilized in conjunction with a constraint restricting the families to a subset of all families, according to one or more embodiments. \nGiven a subset of families, enumeration will return all valid combinations of the features in those families.  In terms of superconfigurations, enumeration is the opposite of compression.\nThe configuration engine 106 works with individual features which are added or removed from a current single configuration.  While this suits the requirements of most ordering and build and price applications, in some cases, the configuration\nengine 106 enumerates the valid combinations of those features without working through all the possible paths.\nThe total number of possible permutations of features in a configuration model can be very large, so this configuration service is restricted to enumerating a reasonable subset of feature families.  The configuration engine 106 can impose limits\non the number of families that can be enumerated, however, it should be expected that a request resulting in more products than can be stored in a storage medium will not succeed.\nFIG. 33 is a table 3300 that shows all valid combinations of paint and trim defined in FIG. 13.  The configuration engine 106 generates this list by first projecting the space to paint and trim.  Next the configuration engine 106 traverses the\nMDD paths and expands each superconfiguration into individual configurations.\nThe configuration engine 106 determines if a new configuration is valid, in response to every configuration request.  Where auto-completion is enabled, the configuration request will contain a full configuration, otherwise it will be a partial\nconfiguration.  In either case, the configuration engine 106 validates the configuration request using the MDD \"containsAny\" operation.  A configuration is valid if the containsAny operation returns true.\nEach feature included in the configuration response will have a feature state attribute, e.g. Selected, Available, Included, Default, Excluded or Forbidden.  For a given set of selected features, the configuration engine 106 calculates the\nfeature states for the remaining features.\nThere are multiple approaches for calculating feature states.  In one embodiment, the configuration engine 106 calculates feature states using a basic algorithm that includes restricted domain steps which can be applied to both Matrices and\nMDDs.  In another embodiment, the configuration engine 106 calculates feature states for MDDs using dynamic programming techniques.\nWith reference to FIG. 34, a method for determining feature states using a restricted domain is illustrated in accordance with one or more embodiments and generally referenced by S200.  The method S200 is implemented as an algorithm within the\nconfiguration engine 106 using software code contained within the server 102, according to one or more embodiments.  In other embodiments the software code is shared between the server 102 and the user devices 112, 114.\nFirst the configuration engine 106 identifies Forbidden features and Excluded features.  At step S202 the configuration engine 106 determines the restricted domain with respect to any initial locked features imposed on the user.  For example,\nthe initial restriction can be timing point feature(s) which are features used to control the effectivity and visibility of configurations.  For example, a new feature (e.g., new engine x) may be available only after the start of a new model year.  Thus\nthe first day of the new model year would be such a visible timing point.  At step S204, the configuration engine 106 identifies features that are absent from the restricted domain, and classifies them as Forbidden features at S206.  At step S208, the\nconfiguration engine 106 classifies any feature that is not Forbidden, as an Excluded feature unless it is assigned another feature state (i.e., Available, Included or Default) in the remaining steps of the algorithm.\nAt step S210, the configuration engine 106 first determines the restricted domain of all selections to identify an initial set of Available features.  Then, for each selection F.sub.j, the configuration engine 106 checks the restricted domain\n(selected--F.sub.j) to identify Available features for Family j.\nFor example, FIG. 35 is a table 3500 illustrating a set of superconfigurations that define all valid configurations.  FIG. 36 is a table 3600 that depicts the restricted domains used to determine the Available features and the Excluded features\nwhen the Selected features are Red paint and Ruby trim.  A bit value of zero in table 3600 indicates that a feature is not Available, whereas a bit value of one indicates that the feature is Available.\nFirst, the configuration engine 106 determines the restricted domain of all selections to identify an initial set of Available features at S210.  For example, Red paint and Ruby trim are both available for the configurations listed in rows 3-5\nof the table 3500.  Packages 401 and 402 are Available, but package 400 is not Available for the configuration listed in rows 3-5, as referenced by numeral 3502.  Therefore the restricted domain for the package family is \"011\", as referenced by numeral\n3602, which indicates that package 400 is not Available (i.e., \"0\"), and package 401 and 402 are Available (i.e., \"11\").  Any feature that is active in this domain is set as active in the availability bit set.  Thus, the configuration engine 106\nidentifies package 401 and package 402 as being Available features, as referenced by numeral 3604, and these features are set as active (\"1\") in the availability bit set, as referenced by numeral 3606.\nNext, the configuration engine 106 evaluates the restricted domain (selected--Ruby) to identify Available features for the trim family.  To evaluate (selected--Ruby), the configuration evaluates configurations in which Red paint is Available. \nFor example, Red paint is Available for the configurations listed in rows 1 and 3-5 of the table 3500.  Stone trim and Ruby trim are Available for the configurations listed in rows 1, and 3-5; but Charcoal trim is not Available, as referenced by numeral\n3508.  Therefore the restricted domain for the trim family is \"101\", as referenced by numeral 3608.  The availability bit set for the trim family is revised to \"101\" based on this step, as referenced by numeral 3610.\nThen, the configuration engine 106 evaluates the restricted domain (selected--Red) to identify Available features for the paint family.  To evaluate (selected--Red), the configuration evaluates configurations in which Ruby trim is Available. \nFor example, Ruby trim is Available for the configurations listed in rows 3-5 of the table 3500.  Red paint and Blue paint are Available for the configurations listed in rows 3-5, but White paint is not Available, as referenced by numeral 3512. \nTherefore the restricted domain for the trim family is \"011\", as referenced by numeral 3612.  The availability bit set for the paint family is revised to \"011\" based on this step, as referenced by numeral 3614.\nAs shown in the availability bit set of table 3600, the restricted domain for Red paint includes both Stone trim and Ruby trim.  Both of these selections are Available without having to change the Red paint selection.  The selection of Ruby trim\nexcludes White paint, and shows that both Red and Blue paint are Available.  Thus White paint would require the trim selection to be changed to something other than Ruby.\nThe resulting availability can be defined as bit set 011 011 011 101 11.  The state of Red paint and Ruby trim will be Selected, all other active features will be Available and the inactive features, such as White paint and Charcoal trim, will\nbe Excluded.\nReferring back to FIG. 34, the configuration engine 106 identifies any Included features at step S212.  A feature is Included if there is only one Available feature for a non-Selected feature family.  The non-Selected feature families listed in\ntable 3600 are packaging (Pkg), radio (Radio) and moonroof (MoonRf).  All of these feature families include more than one Available feature (i.e., each family includes more than one \"1\" in each cell).  Thus, table 3600 shows no such Included features for\na selection of Red paint and Ruby trim.\nFIG. 37 is a table 3700 that depicts the restricted domains used to determine the Available features and the Excluded features when the Selected features are the 401 package (Pkg.401) and Red paint (Paint.Red).  An Included feature can be the\nresult of the interactions between multiple features.  For example, table 3700 shows that if the 401 package and Red paint are Selected, then Ruby trim is an Included feature, as referenced by numeral 3720, because it is the only possible trim choice\nthat is compatible with the 401 package and Red paint.\nThus, the configuration engine 106 determines the feature states e.g. Selected, Available, Included, Excluded and Forbidden for a given set of selections using the method S200.  This initial feature state determination is referred to as \"Minimum\nCompletion.\" FIG. 38 is a table 3800 that summarizes the results of the Minimum Completion determination when Red paint and Ruby trim have been selected from the product definition in FIG. 35.\nThe configuration engine 106 determines the restricted domain by traversing the MDD.  Performing the Minimum Completion operation using restricted domain means that for each additional selection, another restricted domain operation is performed. Thus, for N selections, N+2 restricted domain determinations are performed.  These restricted domain operations include an initial restriction at S202, a restriction for the initial available set, followed by one for each feature at S210.\nFor MDDs, there is an alternate approach for determining the Available features using dynamic programming principles with a single operation that includes one downward traversal and one upward traversal of the MDD.  This approach is more memory\nefficient and faster, especially for larger MDDs.\nWith reference to FIG. 39, a method for determining feature states using dynamic programming is illustrated in accordance with one or more embodiments and generally referenced by S300.  The method S300 is implemented as an algorithm within the\nconfiguration engine 106 using software code contained within the server 102, according to one or more embodiments.  In other embodiments the software code is shared between the server 102 and the user devices 112, 114.\nAt S302, the configuration engine 106 organizes the data into nodes by family and level.  The subroutine of S302 is shown in the flowchart of FIG. 40.  At step S304, the configuration engine 106 determines if a level node object exists, i.e., if\nthe nodes are already organized by level.  Otherwise, the configuration engine 106 proceeds to step S306 and organizes the nodes into a level node array where the length of the array is equal to the number of families.  The configuration engine 106\ninitializes each level array with an empty nodes list, i.e., sets the empty flag to true.  At step S308, for each node (y) analyzed, the configuration engine 106 appends a node (e.g., adds a child node) to the analyzed node's level node list.  Step S308\nis a recursive step, therefore the configuration engine 106 repeats S308 until it finds the True node.  After step S308 the configuration engine 106 proceeds to step S310 and returns to the main routine of FIG. 39 to analyze the nodes by level.\nFIG. 45 is an MDD 4500 illustrating the data organized by level according to S302 and a selection of Red paint and Ruby trim.  The MDD 400 includes five levels.  Level zero represents the package (Pkg) family, which includes three package\nfeatures: 400, 401 and 402 that are depicted by edges (level arrays) 001, 010 and 100, respectively, that extend from node 2.  Level one represents the Radio family, which includes three radio features: Std, Dlx and Nav that are depicted by edges (level\narrays) 001, 010 and 100, respectively, that extend from nodes 3-5.  Level two represents the Paint family, which includes three paint features: White, Red and Blue, that are depicted by edges (level arrays) 001, 010 and 100, respectively, that extend\nfrom nodes 6-8.  Level three represents the trim family, which includes three trim features: Stone, Charcoal and Ruby, that are depicted by edges (level arrays) 001, 010 and 100, respectively, that extend from nodes 9-12.  Level four represents the\nmoonroof (MoonRf) family, which includes two moonroof features: Less and Vista, that are depicted by edges (level arrays) 01 and 10, respectively, that extend from nodes 13-16.  Node 1 is the true node and node 0 is the false node (not shown).\nAt step S312, the configuration engine 106 initializes the state, or marking of each node, by creating a place for each value.  For example, by default, all features are initially set to false (i.e., not marked) except the root node 2 and the\ntrue node 1.  The root node 2 is set to true for the downward traversal (i.e., marked with a downward arrow); and the true node 1 is set to true for the upward traversal (i.e., marked with an upward arrow).  Marking a node with a downward arrow indicates\na valid partial configuration from the root node 2 down to the marked node and any intervening downward marked nodes along the path.  Similarly, marking a node with an upward arrow indicates a valid partial configuration from the true node 1 up to the\nmarked node and any intervening upward marked nodes along the path.\nAt S314, the configuration engine 106 creates a constraint object.  The subroutine of S314 is shown in the flowchart of FIG. 41.  The configuration engine 106 starts analyzing family level zero of the MDD 4500 (i.e., the package family) at step\nS316.  At step S318, the configuration engine 106 determines if the family level (x) is less than the total number of families included in the MDD.  If so, the configuration engine 106 proceeds to step S320.\nAt step S320 the configuration engine 106 determines if the user has selected a feature for family level (x).  If the user has selected a feature for family level (x), the configuration engine 106 proceeds to step S322 and sets the Selected\nfeature to the Allowed feature state and sets the non-selected features for family level (x) to not allowed.  If no features are selected for family level (x), the configuration engine 106 proceeds to step S324 and sets all features to the Allowed\nfeature state.  After steps S322 and S324, the configuration engine 106 proceeds to step S326 to evaluate the next family by incrementing family level (x) by one (i.e. x=x+1), then returns to step S318.\nOnce the configuration engine 106 has created a full constraint object using subroutine S314, the family level (x) will no longer be less than the total number of families, and the configuration engine 106 will make a negative determination at\nstep S318.  For example, after the configuration engine 106 evaluates the moonroof family (level 4), it will set x to five at step S326.  Since there are five families in the MDD 4500, the configuration engine 106 will determine that x (5) is not less\nthan the number of families (5) at step S318 and then proceed to step S328 and then return to the main routine of FIG. 39.\nAt step S330 the configuration engine 106 initializes an availability bit set.  The configuration engine 106 initializes the availability bit set by setting all bits to zero, which indicates that the features are Excluded.  Whereas a bit set\nvalue of one indicates that a feature is Available.\nAt S332, the configuration engine 106 traverses the MDD 4500 in a downward direction.  The subroutine of S332 is shown in the flowchart of FIG. 42.  The configuration engine 106 starts analyzing the nodes included in family level zero of the MDD\n4500 (i.e., the package family) at step S334.  At step S336, the configuration engine 106 determines if the family level (x) is less than the total number of families included in the MDD.  If so, the configuration engine 106 proceeds to step S338.\nAt step S338, the configuration engine 106 starts analyzing node zero.  At step S340 the configuration engine 106 compares the node number (y) to the number of nodes at the current level (x) to determine if y&lt;Level (x) number of nodes.  For\nexample, initially, x is equal to zero and Level (0) has one node, therefore y is less than 1.  If y is not less than the number of nodes at level (x), the configuration engine proceeds to step S342 and increments the level (x) by one.\nAfter a positive determination at step S340, the configuration engine 106 proceeds to step S344 and sets the currently analyzed node or source node (SRC) to level(x) node (y); and sets the array index (z) extending from SRC to zero.  The array\nindex (z) corresponds to a feature of the family (x).  At step S346 the configuration engine 106 compares the array index (z) to the SRC's number of children.  If z is not less than SRC's number of children, the configuration engine 106 proceeds to step\nS348 and increments the node (y) by one.  If the determination at step S346 is positive, the configuration engine 106 proceeds to step S350.\nAt step S350, the configuration engine 106 sets the destination node (DST) to be the child node of node (y) along array index (z) (DST =SRC.child(z)).  The configuration engine 106 analyzes three conditions to determine whether or not to mark\nthe destination node with a downward arrow: 1) the destination node is not a false node; 2) the source node was previously marked with a downward arrow; and 3) the feature of array index (z) is allowed by constraint.  These three conditions are\nillustrated by steps S352-S358 in FIG. 42.\nAt step S352, the configuration engine 106 evaluates the DST node to determine if it is a false node.  Otherwise, the configuration engine 106 proceeds to step S354 to determine if the source node (i.e., the parent of the currently analyzed\ndestination node) was previously marked with a downward arrow.\nAfter a positive determination at S354, the configuration engine 106 determines if the feature of array index (z) is allowed by constraint at step S356, which was previously determined in steps S320-S324 (FIG. 41).  If the conditions of steps\nS352, S354 and S356 are met, the configuration engine 106 proceeds to step S358 and marks the destination node with a downward marker, by setting mark.down(DST) to true.  If any of the conditions of steps S352, S354 and S356 are not met, the\nconfiguration engine 106 proceeds to step S360 and increments the array index (z) by one.\nReferring to FIG. 45, the MDD 4500 illustrates the marked nodes after the downward traversal subroutine S332 of FIG. 42 for a selection of Red paint and Ruby trim.  The configuration engine 106 marks Node 2 with a downward marker at S312 because\nthe root node is a special case that always has a valid downward path.  On the downward traversal of the MDD 4500, a node is marked at S358 if the conditions of steps S352-S356 are met for the analyzed node.  For example, the configuration engine 106\nmarks destination node 3 with a downward marker or arrow 4502 at S356 because node 3 was determined to not be a false node at S352; node 3's source node (node 2) was previously marked with a downward arrow at S354; and the feature of the array index\nconnecting node 2 and node 3 (i.e., Pkg.400) was determined to be allowed by constraint at S356.  Since the user has not selected a packaging feature for this example, all packaging features are set to Allowed (see steps S320, S324 of FIG. 45.)\nSimilarly, the configuration engine 106 determines that the remaining radio nodes and the paint family nodes (nodes 4, 5, 6, 7, and 8) have valid downward markers because the package (Pkg) family and the Radio family are not constrained.  With respect to\nthe partial configurations of Pkg and Radio, all features are Available because the user has not selected a feature from either family.\nRegarding the trim level nodes (9-12), nodes 9 and 10 have downward markers because they were determined to not be false nodes at S352; their source nodes were marked with a downward arrow at S354; and they were determined to be on a valid path\nwith Red paint at S356.  However, nodes 11 and 12 do not have downward markers because they are not on a valid path with Red paint.  Since the user has selected Red paint, the non-selected paint features (White and Blue) are set to not allowed at step\nS322 (FIG. 41) and thus the condition of step S356 is not met for nodes 11 and 12.\nRegarding the moonroof level nodes (13-16), node 14 has a downward marker because it is valid with Ruby trim; however node 13 does not have a downward marker because it is not on a valid path with Ruby trim.  Since the user has selected Ruby\ntrim, the non-selected trim features (Stone and Charcoal) are set to not allowed at step S322 (FIG. 41) and thus the condition of step S356 is not met.  Additionally, nodes 15 and 16 are not marked because their source nodes (11 and 12) were not marked,\nand thus nodes 15 and 16 do not satisfy the condition of step S354.\nThe downward traversal subroutine S332 includes three for-loops.  Once the configuration engine 106 has analyzed all paths it will make a negative determination at step S336, i.e., the level (x) will not be less than the number of families; and\nthe configuration engine 106 will proceed to step S362 and return to the main routine of FIG. 39.\nAt S364, the configuration engine 106 traverses the MDD of FIG. 45 in an upward direction, which is illustrated by MDD 4600 in FIG. 46.  The subroutine of S364 is shown in the flowchart of FIG. 43.  The configuration engine 106 starts analyzing\nthe nodes included in the last family level of the MDD 4600 (i.e., the moonroof family) at step S366.  At step S368, the configuration engine 106 determines if the family level (x) is greater than or equal to zero (i.e., not negative).  If so, the\nconfiguration engine 106 proceeds to step S370.\nAt step S370, the configuration engine 106 starts analyzing node zero.  At step S372 the configuration engine 106 compares the node number (y) to the number of nodes at the current level (x) to determine if y&lt;Level (x) number of nodes.  For\nexample, initially, x is equal to zero and Level (0) has one node, and therefore y is less than 1.  If y is not less than the number of nodes at level (x), the configuration engine proceeds to step S374 and decreases the level (x) by one.\nAfter a positive determination at step S372, the configuration engine 106 proceeds to step S376 and sets the currently analyzed node or source node (SRC) to Level(x)(y); and sets the array index (z) extending from SRC to zero.  At step S378 the\nconfiguration engine 106 compares the array index (z) to the SRC's number of children.  If z is not less than SRC's number of children, the configuration engine 106 proceeds to step S380 and increments the node (y) by one.  If the determination at step\nS378 is positive, the configuration engine 106 proceeds to step S382.\nAt step S382, the configuration engine 106 sets the destination node (DST) to be the child node of node (y) along array index (z) (DST=SRC.child(z)).  The configuration engine 106 analyzes three conditions to determine whether or not to mark the\ndestination node with an upward arrow: 1) the destination node is not a false node; 2) the destination node was previously marked with an upward arrow; and 3) the feature of array index (z) is allowed by constraint.  These three conditions are\nillustrated by steps S384-S388 in FIG. 43.\nAt step S384, the configuration engine 106 evaluates the DST node to determine if it is a false node.  Otherwise, the configuration engine 106 proceeds to step S386 to determine if the destination node (i.e., the child of the currently analyzed\nsource node) was previously marked with an upward arrow.\nAfter a positive determination at S386, the configuration engine 106 determines if the feature of array index (z) is allowed by constraint at step S388, which was previously determined in steps S320-S324 (FIG. 41).  If the conditions of steps\nS384, S386 and S388 are met, the configuration engine 106 proceeds to step S390 and marks the source node with an upward marker, by setting mark.up(SRC) to true.\nAt steps S392 and S394, the configuration engine 106 identifies Available features.  The configuration engine 106 evaluates the source node to determine if it was previously marked with a downward arrow at S392; and if so it proceeds to step\nS394 and sets the feature (z) of node (y) to Available.  Thus, Available features are identified by inspecting each node on the upward traversal.  If there is a valid downward path to the node, and a valid upward path from one of its destinations, the\nconfiguration engine 106 identifies this node as part of a valid path with respect to selections from other families.  Any feature that is on the edge from the node to the destination is identified as Available, because it can be selected without\nrequiring a change to the constrained features.  If any of the conditions of steps S384-S388 and S392 are not met, the configuration engine 106 proceeds to step S396 and increments the array index (z) by one.\nOnce the configuration engine 106 has analyzed all paths it will make a negative determination at step S368, i.e., the level (x) will not be greater than or equal to zero; and the configuration engine 106 will proceed to step S398 and return to\nthe main routine of FIG. 39.\nReferring to FIG. 39, after determining the availability of all features at S364, the configuration engine 106 proceeds to step S400 to determine the feature states.  The subroutine of S400 is shown in the flowchart of FIG. 44.  The\nconfiguration engine 106 starts analyzing the features included in family level zero of the MDD 4600 (e.g., the package family) at step S402.  At step S404, the configuration engine 106 determines if the family level (x) is less than the total number of\nfamilies included in the MDD.  If so, the configuration engine 106 proceeds to step S406.  At step S406, the configuration engine 106 starts analyzing node zero.  At step S408 the configuration engine 106 compares the node number (y) to the number of\nfeatures at the current family level (x) to determine if y&lt;family (x) number of features.\nAfter a positive determination at step S408, the configuration engine 106 proceeds to step S410 and sets the currently analyzed feature (FEAT) to Family(x).Feature(y).  At step S412, the configuration engine 106 evaluates all of the features of\na family, one at a time, to determine if a feature is selected.  If a feature (FEAT) is selected, the configuration engine 106 sets the state of the feature to Selected at S414.  If the feature is not selected, the configuration engine 106 proceeds to\nS416 to determine if the feature was set to Available at S394.  If the feature is Available, the configuration engine 106 proceeds to operation S418 and sets the state of the feature to Available.  If the feature is not Selected and not Available, the\nconfiguration engine 106 sets its state to Excluded at S420.  After steps S414, S418 and S420 the configuration engine 106 proceeds to step S422 to increment the analyzed feature (y) by one.  After evaluating each feature of family (x) to determine if it\nis Available, Selected or Excluded, the configuration engine 106 will make a negative determination at S408 and then proceed to step S424.\nAt steps S424-S428 the configuration engine 106 determines if family (x) has Included features.  First the configuration engine 106 determines if family (x) has any Selected features at S424.  Otherwise, the configuration determines if the\nfamily has exactly one Available feature at S426.  If only one feature of a given family is Available, then the sole Available feature is set to Included at S428.  After steps S424, S426 and S428 the configuration engine proceeds to step S430 and\nincrements the family level (x) by one, then repeats steps S404-S428 for the next family level.  Once the configuration engine 106 has determined the feature states for all families of the MDD, it makes a negative determination at S404 and then returns\nto the main routine at S432.\nJust as the restricted domain method S200 can be performed as a read only step, the dynamic programming method S300 is also read-only and thread safe when the downward and upward markers are kept externally.  Because feature state calculation\noperation is thread safe, multiple configuration requests could be handled simultaneously using the same MDD.  Each request has its own copy of external downward and upward markers, and shares the MDD.  Thread safety is a property that allows code to run\nin multi-threaded environments by re-establishing some of the correspondences between the actual flow of control and the text of the program, by means of synchronization.  For N selections, the restricted domain calculation requires N+2 MDD traversals. \nAn advantage of the dynamic programming method S300 over the restricted domain method S200 is that only two MDD traversals are required regardless of the number of selections.  This provides the dynamic programming method S300 with superior scalability\nfor large and complex MDDs.\nReferring to FIG. 46, the MDD 4600 illustrates the marked nodes after the configuration engine 106 has performed the dynamic programming method S300 including the downward traversal subroutine of FIG. 42 and the upward traversal subroutine of\nFIG. 43 for a selection of Red paint and Ruby trim.  The configuration engine 106 marks the truth node (T) with an upward marker at S312 because the truth node is a special case that always has a valid upward path.\nOn the upward traversal of the MDD 4600, a node is marked at S390 if the conditions of steps S384-S388 are met for the analyzed node.  Regarding the moonroof level of nodes, the configuration engine 106 marks node 13 with a upward marker or\narrow at S390 because its destination node (truth node) was determined to not be a false node at S384; node 13's destination node (truth node) was previously marked with an upward arrow at S386; and the feature of the array index connecting node 13 and\nthe truth node (i.e., MoonRf.Less) was determined to be allowed by constraint at S388.  Since the user has not selected a moonroof feature for this example, all moonroof features are set to Allowed (see steps S320, S324 of FIG. 41.) Similarly, the\nconfiguration engine 106 determines that the remaining moonroof level nodes (nodes 14, 15 and 16) have valid upward markers.\nThe configuration engine 106 determines the availability of the moonroof family features by evaluating the downward markers on the source moonroof nodes at S392 after evaluating the upward markers on the destination truth node (T) at S386. \nSince all of the moonroof nodes (13-16) were marked with a downward arrow and the truth node was marked with an upward arrow, the configuration engine 106 sets all of the moonroof features to Available at S394 and determines the initial availability bit\nset to be 000 000 000 000 11.\nRegarding the trim level nodes (9-12), the configuration engine 106 marks node 10 with a upward marker or arrow at S390 because its destination node (node 14) was determined to not be a false node at S384; node 10's destination node (node 14)\nwas previously marked with an upward arrow at S386; and the feature of the array index connecting node 10 and node 14 (i.e., Trim.Ruby) was determined to be allowed by constraint at S388, because it was selected by the user at S322.  Similarly, the\nconfiguration engine 106 marks node 11 with an upward marker or arrow at S390.  However, the configuration engine 106 does not mark nodes 9 and 12 with an upward arrow at S390 because they are not on a valid path with Ruby trim.  Since the user has\nselected Ruby trim, the non-selected trim features (Stone and Charcoal) are set to not allowed at step S322 (FIG. 41) and thus the condition of step S388 is not met for nodes 9 and 12.\nThe configuration engine 106 determines the availability of the trim family features by evaluating the downward markers on the source trim nodes S392, after evaluating the upward markers on the destination moonroof nodes (13-16) at S386.  Trim\nnodes 9 and 10 each have a downward marker and a destination with a valid upward marker (i.e., moonroof nodes 13 and 14).  Therefore Ruby trim along path 10-14 and Stone trim along path 9-13 are marked as Available features at S394 because either can be\non a path (in a configuration) with Red paint.  However, trim nodes 11 and 12 do not have a downward marker and therefore are not marked as Available.  The Trim selection can change from Ruby to Stone without requiring a change to the paint selection\n(Red).  However, the Trim selection cannot change from Ruby to Charcoal without requiring a change to the paint (Red).  Therefore the configuration engine 106 determines the Charcoal trim to be Excluded at S420.  The configuration engine 106 determines\nthe updated availability bit set to be 000 000 000 101 11.\nRegarding the paint level nodes (6-8), the configuration engine 106 marks node 7 with an upward marker because its destination node (10) was determined to not be the false node at S384; its destination node (10) was previously marked with an\nupward arrow (S386); and the features of the array indexes connecting node 7 and node 10 (i.e., Paint.Red) were determined to be allowed by constraint at S388 because it was selected by the user at S322.  Similarly, the configuration engine 106 marks\nnode 8 with an upward marker or arrow at S390.  However, the configuration engine 106 does not mark node 6 with an upward arrow at S390 because its destination node (9) was not marked with an upward arrow, and thus node 9 does not satisfy the condition\nof step S386.\nThe configuration engine 106 determines the availability of the paint family features by evaluating the downward markers on the source paint nodes (6-8) at S392, and by evaluating the upward markers on the destination trim level nodes (9-12) at\nS386.  Paint nodes 7 and 8 each have a downward marker and a destination with a valid upward marker (i.e., trim nodes 10 and 11).  Therefore Red paint along path 8-10 and path 7-10, and Blue paint along path 7-11 are marked as Available features at S394. White paint along path 6-9 is not marked as an Available feature at S394, because node 9 was not marked with an upward marker at S386.  Since Red paint and Blue paint are both Available, the paint selection can be changed between Red and Blue, without\nrequiring a change to the trim selection (Ruby).  The configuration engine 106 determines the updated availability bit set to be 000 000 011 101 11.\nWith respect to the partial configurations of the package and radio families, all features are allowed at S324 because the user has not selected a feature from either family.  Therefore nodes 2, 4 and 5 are marked with an upward arrow.  But node\n3 is not marked with an upward marker at S390 because its destination node (6) was not marked with an upward arrow, and thus node 3 does not satisfy the condition of step S386.\nThe configuration engine 106 determines the availability of the radio family by evaluating the downward markers on the source radio nodes (3-5) at S392, and by evaluating the upward markers on the destination paint nodes (6-8) at S386.  Radio\nnodes 4 and 5 each have a downward marker and a destination with a valid upward marker (i.e., paint nodes 7 and 8).  Therefore Navigation radio along path 5-8 and path 4-7, and Deluxe radio along path 5-7 and path 4-7 are marked as Available features at\nS394.  The Standard radio along path 3-6 is not marked as an Available feature at S394, because node 6 was not marked with an upward marker at S386.  Since the Navigation radio and the Deluxe radio are both Available, the radio selection can be changed\nbetween Navigation and Deluxe, without requiring a change to the paint selection (Red) or the trim selection (Ruby).  The configuration engine 106 determines the updated availability bit set to be 000 011 011 101 11.\nThe configuration engine 106 determines the availability of the package family by evaluating the downward markers on the source package node (2) at S392, and by evaluating the upward markers on the destination radio nodes (3-5) at S386.  The\npackage node 2 has a downward marker and destinations with valid upward markers (i.e., radio nodes 4 and 5).  Therefore the 401 package along path 2-4 and the 402 package along path 2-5 are marked as Available features at S394.  The 400 package along\npath 2-3 is not marked as an Available feature at S394, because node 3 was not marked with an upward marker at S386.  Since the 401 package and the 402 package are both Available, the package selection can be changed between 401 and 402, without\nrequiring a change to the paint selection (Red) or the trim selection (Ruby).  The configuration engine 106 determines the full availability bit set to be 011 011 011 101 11 using the dynamic programming method S300, which is consistent with its\ndetermination using the restricted domain method S200 as described above with reference to FIG. 34 and shown in FIG. 36.\nEach time the user selects a feature, the configuration engine 106 updates the configuration by adding the new feature and removing the sibling features of the same family.  Then the configuration engine 106 performs a \"containsAny\" operation,\nas described above with reference to FIGS. 20-21, to see if the MDD contains the new configuration.  If the MDD does not contain the new configuration, then the new configuration is invalid and the configuration engine 106 performs a conflict resolution\nstrategy.\nGenerally, there are two types of conflict resolution strategies invoked when a user selection, or change in selection, leads to a conflict: single conflict resolution and branched conflict resolution.\nIn single conflict resolution, the configuration engine 106 returns the single \"next-closest\" valid configuration and the feature additions and subtractions necessary to change the invalid configuration to a valid configuration in its response. \nThe \"closest\" valid configuration would typically be determined by simply changing the newly requested feature back to its prior state.  However, such a change would be inconsistent with the user's selection.  Therefore the configuration engine 106\ndetermines the next-closest valid configuration using a constraint that the newly requested feature is \"locked\" and not allowed to be changed, according to one or more embodiments.\nIn branched conflict resolution, the configuration engine 106 presents a set of configurations to the user in a resolution tree that are closest to the invalid configuration, and the user is prompted to make changes to the configuration to get\nto a valid configuration.  When resolving conflicts there may be multiple valid configurations all at the same distance from the initial configuration.  In this case there are a set of possible answers when finding the next-closest valid configuration. \nAn option then is to use branched conflict resolution.\nA strategy that is used to determine the closeness between configurations is referred to as the \"minimum edit distance.\" In a configurator application 104, the configuration engine 106 determines the minimum edit distance between an invalid\nconfiguration selected by the user and one or more valid configurations.  The minimum edit distance refers to the number of features in the configuration that must be changed in order to transform the invalid configuration into a valid configuration. \nWhen comparing the invalid configuration to a valid configuration, the configuration engine 106 considers substitute operations to identify what features must change to create a valid configuration without changing the newly requested locked feature.\nWith reference to FIG. 47, a method for resolving conflicts between a user selected invalid configuration and one or more valid configurations is illustrated in accordance with one or more embodiments and generally referenced by S500.  The\nmethod S500 is implemented as an algorithm within the configuration engine 106 using software code contained within the server 102, according to one or more embodiments.  In other embodiments the software code is shared between the server 102 and the\nuser devices 112, 114.\nAt step S502, the configuration engine 106 saves a copy of the root node identity and a set of the node edges to the memory 108 (shown in FIG. 2).  S502 is similar to subroutine S102 described above with reference to FIG. 26.  The configuration\nengine identifies each node (y), copies or clones each outgoing edge of each node (y) in an MDD, and then returns the edge set and the identity of the root node.\nAt step S504 the configuration engine 106 performs a minimum edit calculation of an MDD that is restricted to the configurations that contain the feature selection that triggered the conflict.  In one embodiment the configuration engine 106\nrestricts the MDD using the restrict method as described above with reference to FIGS. 22-23.  In other embodiments, the configuration engine 106 restricts the MDD using the quick-restrict method S100 described above with reference to FIGS. 24-28.  The\nquick-restrict based minimum edit calculation subroutine of S504 is shown in the flowchart of FIG. 48.\nAt step S506 the configuration engine 106 examines the cache memory for source (SRC) node (y) to determine if the quick-restrict subroutine has already been performed on node (y).  If cache (y) exists, then the configuration engine 106 proceeds\nto step S508 and returns to the main routine of FIG. 47.  If cache (y) does not exist, the configuration engine 106 proceeds to step S510.\nAt step S510, the configuration engine 106 starts with array index zero, and sets the empty flag to true.  By setting the empty flag to true, the configuration engine 106 assumes that there are no valid paths from the node, i.e., that all edges\npoint to the false node.  The configuration engine 106 also sets the minimum or best (Best) edit distance as the maximum allowable integer value (Integer Max Value).\nAt step S512, the configuration engine 106 evaluates the array index (z) to determine if (z) is less than the number of node (y)'s children.  A positive determination at step S512 indicates that the configuration engine 106 has not analyzed all\narray indexes of node (y).  If the determination is positive, the configuration engine 106 proceeds to step S514.\nAt step S514, the configuration engine 106 checks if y's child, or destination (DST) node, at array index (z) is false.  If the configuration engine 106 determines that the child is false, then it proceeds to step S516, increments the array\nindex (z) by one, and returns to step S512.  If the determination at step S514 is negative, the configuration engine 106 proceeds to step S518.\nAt step S518 the configuration engine 106 initializes the edits for feature (z) to the maximum integer value, e.g., by setting the total edit distance (cacheBot (z)) for the path from the truth node to the source node to the Integer Max Value.\nAt step S520, the configuration engine 106 evaluates the quick-restricted features list for node (y) to determine if it contains feature (z).  Otherwise, the configuration engine 106 sets y's child node along z to false at S522 and then proceeds\nto step S516 to increment the array index (z) by one.\nAt step S524, the configuration engine 106 sets the edit value (EDIT) for the source node at feature (z).  If the configuration includes feature (z), then the configuration engine sets EDIT to zero.  If the configuration does not include feature\n(z), then the configuration engine sets EDIT to one.\nAt step S528, the configuration engine 106 check's if y's child (DST) at array index (z) is true.  If DST is true, the configuration engine 106 proceeds to step S530 and sets the empty flag to false.  At S532, the configuration engine 106\ncalculates and stores the edit distance or cost (EDIT) for this feature.  Then the configuration engine 106 calculates the total edit distance (cacheBot (z)) for the path from the truth node to the source node, as the sum of a previously calculated edit\ndistance for the path (cacheMid (DST)) and EDIT.  At step S534, the configuration engine 106 compares the total edit distance (cacheBot(z)) to the minimum edit distance (Best) for the given invalid configuration.  If the total edit distance for the\ncurrent feature (cacheBot (z)) is less than Best, the configuration engine 106 proceeds to step S536 and sets cacheBot (z) as Best.  Then the configuration engine 106 proceeds to step S516 and increments feature (z) by one.  If the configuration engine\n106 determines that DST is not the true node at S528, it proceeds to step S538.\nAt step S538, y's children, or (DST) nodes, are rewritten by the result of recursive invocation of the quick-restrict method on the child.  All nodes of the MDD are processed in this manner.  At step S540, the configuration engine 106 checks DST\nto determine if it's not a false node.  If the determination is negative, i.e., DST is the false node, then then the configuration engine 106 proceeds directly to S516 to increment the array index (z).  If the determination is positive (e.g., if node (y)\nis connected to a valid node), then the configuration engine 106 proceeds to steps S530-S536 to update the EDIT distance and compare it to the Best minimum edit distance.\nThe quick restrict based minimum edit calculation subroutine S504 operates on the nodes in a depth first search fashion.  Steps S512-S540 demonstrate an iterative process that operates on each array index (z) of a node (y) before proceeding to\nthe next node.  Once the configuration engine 106 has evaluated all array indexes (z) for a node (y), it will make a negative determination at step S512 (i.e., z will be greater than or equal to the number of y's children), and proceeds to step S542.\nAt step S542 the configuration engine 106 checks if all children (DST) of node (y) are false, i.e., it evaluates the empty flag to determine if any valid configurations were found.  If all of y's children are false, the configuration engine 106\nproceeds to step S544, sets node (y) to the false node, and then returns the cache (y), i.e., saves the analysis of node (y) and returns to the main routine of FIG. 47.  Further, if the node does not contain any edges that conform to the constraint, then\nthe edge pointer is disconnected from the child node in the MDD.  If not all of the children nodes are false, then the configuration engine 106 proceeds to step S546, sets the cacheMid (SRC Node) to Best, and then sets feature (z) to zero.\nAt step S548, the configuration engine 106 again evaluates the array index (z) to determine if (z) is less than the number of node (y)'s children.  Otherwise, the configuration engine 106 proceeds to step S550, sets the cache (y) to (y), and\nthen returns the cache (y), i.e., saves the analysis of node (y) and returns to the main routine of FIG. 47.  A positive determination at step S548 indicates that the configuration engine 106 has not analyzed all array indexes of node (y).  If the\ndetermination is positive, the configuration engine 106 proceeds to step S552.\nAt step S552, the configuration engine 106 compares the total edit distance (cacheBot (z)) to the minimum edit distance (Best) for the given invalid configuration.  If the total edit distance for the current feature (cacheBot (z)) is greater\nthan Best, the configuration engine 106 proceeds to step S554 and sets DST node to false at step S554, and then increments feature (z) by one at step S556 and then returns to S548.\nThe quick-restrict based minimum edit calculation subroutine S504 is a recursive process.  This process continues until all nodes are analyzed, then the configuration engine 106 returns to the main routine of FIG. 47.  The edges for complete\npaths from the root node (node 2) to the truth node (T) define the restricted configuration space.\nThus, the configuration engine 106 calculates the minimum edit distance of all paths, and identifies the minimum edit distance using subroutine S504.  The configuration engine 106 calculates the minimum edit distance on the way back up the MDD,\ni.e., during an upward traversal.  When a new minimum edit distance is found, prior minimum edit paths are trimmed from the MDD by setting the minimum edit distance (Best) to the currently analyzed path (cacheBot (z)) at S536.  The minimum edit distance\nof a path refers to the sum of the edit distances of each edge.  The edit distance for each feature change is 1.  Where there is more than one active feature on an edge, the path for each feature is considered separately when calculating the minimum edit\ndistance.  Then the configuration engine 106 restricts the MDD to the paths that have the minimum edit distance by setting child or destination (DST) nodes to false if the edit distance for their path (cacheBot (z)) is greater than the minimum edit\ndistance (Best) at S554.\nFIG. 49 includes an original or unrestricted MDD 4900, an intermediate MDD 4902 and a final restricted MDD 4904 illustrating the impact of various steps of subroutine S504.\nIn one example, the user selects the 400 package.  Then the configuration engine 106 determines that the Standard (Std) radio, Stone trim and no moonroof (Less) are Included features; and that White paint is a Default feature.  The states of\nthese features are represented by underlined text, boxed text and circled text, respectively in FIG. 49.  Next the user selects Charcoal trim.  The new selected set (400, Charcoal) is not a valid combination because the 400 package can only occur with\nStone trim.  So the new configuration (400, Std, White, Charcoal, Less) is invalid.\nThe intermediate MDD 4902 illustrates the original MDD 4900 after the configuration engine 106 has performed the minimum edit calculation S504 on paths 2-13-.  . T with respect to a newly selected Charcoal trim feature.  The configuration engine\n106 first traverses path 2-13-14-15-16-T. No restrict is needed on the downward traversal because the only active trim feature on partial path 15-16 is Charcoal.\nThe configuration engine 106 calculates the minimum edit distance at steps S530-S536 (FIG. 48) during an upward traversal of the MDD.  The configuration engine 106 considers two edges for the partial path T-16: one edge with the moonroof (Vista)\nand one edge without the moonroof (Less).  The configuration engine 106 determines the edit distance for the partial path T-Vista-16 (i.e., with the moonroof (Vista)) to be one because it requires a change in the moonroof feature.  For the partial path\nT-Less-16 without the moonroof (Less), no change is required, so the edit distance is zero.  Because one path (T-Less-16) has a smaller edit distance than the other (T-Vista-16), the edge is restricted to keep the minimum edit path of T-Less-16.  The\nedge from 16-T now shows \"10\", and the edit cost for Node 16 is 0, as referenced by numeral 4906.\nContinuing on the upward traversal, the configuration engine 106 calculates the edit distance of the remaining partial paths to be: zero for 16-15, because it contains Charcoal trim; one for 15-14, because it contains Blue paint, not the Default\nWhite paint; one for 14-13, because it contains the Navigation radio, not the Included Standard radio; and one for 2-13, because it contains the 402 package, not the Selected 400 package.  Therefore the configuration engine 106 calculates the cumulative\nminimum edit distance for path 2-13-14-15-16-T to be three, as referenced by numeral 4908.\nThen the configuration engine 106 restricts the partial path 14-9-10-T because node 9 does not contain the selected Charcoal trim feature.\nNext, the configuration engine 106 considers path 2-13-8-11-12-T. First, partial path 8-11-12-T is considered, and found to have edit distance of 1 because node 8 contains Blue paint and not the Default White paint.  Then the configuration\nengine 106 restricts path 12-T to 12-Less-T; and restricts path 11-12 to 11-Charcoal-12 so that the edit distance for each is zero.\nThen the configuration engine 106 considers partial path 8-9-10-T; but, because of its previous analysis of node 9, it knows that this partial path has been restricted and the 8-9 edge is removed.  The cost of T-12-11-8-13 is 2.  At this point\nthe configuration engine 106 keeps both of the outgoing edges from 13 (i.e., 13-14 .  .-T, and 13-8-.  .-T) because they each require 2 edits.  The edit distance for partial path 13-2 is 1.  Thus, after traversing 2-13-.  .-T, the configuration engine\n106 determines that the current minimum edit distance for Node 2 is 3.\nThe final restricted MDD 4904 illustrates the original MDD 4900 after the configuration engine 106 has quick-restricted it to Charcoal trim at S504 and performed the minimum edit calculation for all paths.\nNext the configuration engine 106 considers path 2-7-8-11-12-T. The configuration engine 106 previously determined that the minimum edit distance at node 8 is 1.  The configuration engine 106 calculates the edit distance for partial path 8-7 to\nbe one because it contains Deluxe and Navigation radio features and not the Included Standard radio feature; and calculates the edit distance for partial path 7-2 to be one, because it contains the 401 package and not the selected 400 package.  The\nconfiguration engine 106 calculates the total edit distance for path 2-7-8-11-12-T to be three.  Since this total edit distance is the same as that of paths 2-13-.  .-T, the configuration engine 106 keeps all three paths.\nNext the configuration engine 106 considers path 2-3-4-5-6-T. This path is restricted once the configuration engine 106 determines that partial path 5-6 is not compatible with the Selected Charcoal trim constraint.\nThe final MDD 4904 illustrates the final minimum edit space for the invalid configuration (400, Std, White, Charcoal, Less) with the Charcoal trim feature locked, after the configuration engine 106 has completed the minimum edit calculation\nsubroutine S504.  As shown in FIG. 49, the MDD 4904 contains three paths that each have a minimum edit distance of three: 2-1-14-15-16-T; 2-13-8-11-12; and 2-7-8-11-12-T.\nWith reference to FIG. 47, at step S558, the configuration engine 106 determines if the conflict resolution strategy selected for the application is a guided strategy, i.e., a branched resolution strategy.  If a guided conflict resolution is not\nselected, the configuration engine 106 proceeds to operation S560.  At step S560 the configuration engine 106 selects a single target configuration from the minimum edit space using an auto-completion technique such as sequence based or maximally\nstandard.  In one embodiment, the configuration engine 106 selects a single target configuration using a maximally standard auto-completion technique as described below with reference to FIGS. 93-117.  In another embodiment, the configuration engine 106\nselects a single target configuration using a maximum weight quick-restrict technique.\nThe maximum weight quick-restrict based single target configuration calculation subroutine of S560 is shown in the flowchart of FIG. 50.  The weights used in the weight calculation are based on priorities for features such that when there is\nmore than one feature available, the highest priority, or feature having the maximum weight, is chosen as the default.  S560 is similar to the minimum edit quick restrict calculation S504 of FIG. 48.  The only difference is that when the configuration\nengine 106 calculates the maximum weight, it 1) maximizes value instead of minimizing value (which changes the initial value of Best); and 2) calculates the weight for each path instead of the number of edits, where the weight is defined by a priority of\nthe features.\nReferring to FIG. 47, the configuration engine 106 resets or restores the original set of node edges to the memory 108 (shown in FIG. 2) at step S574.  S574 is similar to S146 described above with reference to FIG. 28.  At S574 the configuration\nengine 106 identifies each node (y), copies the outgoing edges of each node in the MDD.  Then the configuration engine 106 sets the MDD to the identity of the root node.\nAt step S576, the configuration engine 106 determines the feature states for the prior configuration.  The prior configuration refers to the prior valid configuration before the configuration engine 106 changed a feature based on a user\nselection; where the addition of the new feature led to an invalid configuration.  S576 is similar to subroutine S300 described above with reference to FIGS. 39-44.  At step S578, the configuration engine 106 determines the feature states for the new\ntarget configuration.  S578 is also similar to S300.\nWith reference to FIG. 49, in one embodiment the configuration engine 106 selects a single target configuration (401, Dlx, Blue, Charcoal, Less) from the minimum edit space of MDD 4904 as S560.  Once the target is identified, the configuration\nengine 106 determines feature states for the prior configuration at S576 and for the new target configuration at S578.  All features start as Default features.  Next, Selected features are determined by adding the previous selections that are still valid\nto the newly selected feature.  Then, the Available, Excluded and Available calculations are determined using the new selections.  In this example the new target configuration states are: Selected (Charcoal), Included (Blue) and Default (401, Dlx, Less).\nAt step S580 of FIG. 47, the configuration engine 106 generates a response that includes the feature additions and subtractions to resolve the conflict.  These features include feature state information--the new state for additions and the prior\nstate for subtractions.  The configuration engine 106 returns raw data including the new and prior feature state maps, the new configuration state (ConfigState), and the list of additions and subtractions.  The author decorator 154 will use this data to\ncompose the response.  The derivation of additions and subtractions subroutine S580 is shown in the flowchart of FIG. 51.\nAt S582, the configuration engine 106 starts analyzing feature (z).  At step S584, the configuration engine 106 determines if the feature (z) is less than the total number of features for the source node.  If so, the configuration engine 106\nproceeds to step S586.  At step S586, the configuration engine 106 defines the term \"Prior\" as the prior feature state of feature (z) and the term \"State\" as the new feature state of feature (z).\nAt step S588, the configuration engine 106 evaluates the feature state term Prior (determined at S576) to determine if feature (z) was present in the prior configuration.  S588 is illustrated in the flow chart of FIG. 52.  If the Prior term is\nequal to Selected, Included or Default, then the configuration engine 106 determines that the Prior term defines a State of a feature that is present in the Prior configuration and returns true at step S592.  Otherwise, the configuration engine 106\nreturns false at S594.  Then the configuration engine 106 sets a boolean before value (BEF) equal to the determination at steps S590-S592, i.e., true or false.\nAlso at step S588, the configuration engine 106 evaluates the feature state term State to determine if it is present in the New configuration.  If the State term is equal to Selected, Included or Default, then the configuration engine 106\nreturns TRUE at step S592.  Otherwise, the configuration engine 106 returns false at S594.  Then the configuration engine 106 sets a boolean after value (AFT) equal to the determination at steps S590-S592, i.e., true or false.\nAt step S594, the configuration engine 106 compares BEF to AFT for feature (z) to see if it has changed.  Otherwise, i.e. if BEF equals AFT, the configuration engine 106 proceeds to step S596 and increments the family level (x) by one.  If the\ndetermination is negative, then the feature was either added or subtracted, and the configuration engine 106 proceeds to step S598 to evaluate \"Return Delta.\"\n\"Return Delta\" refers to the amount of information provided to the user in response to a conflict.  The front-end application 132 determines this level of information by setting the return delta feature to true or false.  Enabling the return\ndelta feature (i.e., setting return delta to true) results in more information being provided to the user.  Conversely, setting return delta to false results in less information being provided to the user.\nWhen the Return Delta flag is set to true, the response will include all additions and subtractions regardless of feature state.  This could allow the front-end application 132 to inspect the resolution and apply some additional logic when\ndeciding whether to prompt the user in response to a conflict or to silently make the changes.  When the Return Delta flag is set to false, the conflict resolution subtractions will only contain Selected features removed from the configuration and\nadditions will only contain Included features added to the configuration.  If the new configuration caused a change in a Default feature, this is not included in the prompt to the user.  If all changes are for Default choices, there are no changes to\nreport, and the response will not include conflict resolution.  The Return Delta flag is set to false by default, in one or more embodiments.\nAt S598, if Return Delta is set to true, the configuration engine 106 proceeds to step S600 to evaluate BEF.  If BEF is set to false at S588 (which indicates that feature (z) was contained in AFT but not in BEF), the configuration engine 106\nadds feature (z) to the list of additions (additions.add(feat(x))) at step S602.  If BEF is set to true (which indicates that feature (z) was contained in AFT but not in BEF), the configuration engine 106 adds feature (z) to the list of subtractions\n(subtractions.add(feat(x))) at step S604.\nIf Return Delta is set to false, the configuration engine 106 proceeds to step S606.  At S606, the configuration engine 106 evaluates BEF and the state of (z).  If BEF is false and the state of (z) is Default, the configuration engine 106\nreturns to S596 to increment the family level (x) by one.  If the determination at S606 is negative, the configuration engine 106 proceeds to step S608.  At S608, if BEF is true and the state of (z) is Selected, the configuration engine 106 returns to\nS596.  Otherwise, the configuration engine 106 returns to S600.\nFIG. 53 is a table 5300 that illustrates the additions and subtractions for the MDD 4900 of FIG. 49 when Return Delta is true and when Return Delta is false.  The MDD 4900 had a Prior configuration of Selected (400), Included (Std, Stone, Less)\nand Default (White), as referenced by numeral 5302.  The configuration engine 106 selected a new target configuration of Selected (Charcoal), Included (Blue) and Default (401, Dlx, Less) at step S578, as referenced by numeral 5304.  When Return Delta is\nfalse, the configuration engine 106 does not show changes (additions or subtractions) to Default Features, but when return delta is true, all changes are shown, as referenced by numeral 5306.\nFIG. 54 is a window 5400 that is displayed to the user to convey the additions and subtractions of features to their prior configuration to accommodate the new configuration triggered by their selection of Charcoal trim, using a single target\nconfiguration when Return Delta is false.  Again, when Return Delta is false, the configuration engine 106 does not show changes (additions or subtractions) to Default features.\nFIG. 55 is a window 5500 that is displayed to the user to convey the additions and subtractions of features to their prior configuration when Return Delta is true.  Since Return Delta is true, the configuration engine 106 shows all changes,\nincluding changes to the Default features.\nReferring to FIG. 47, the configuration engine 106 determines if guided resolution (i.e., branched conflict resolution) is selected at step S558.  If so, it proceeds to step S610.\nIn contrast to single conflict resolution, which only presents a single next-closest configuration to the user, branched conflict resolution can present the entire minimum edit space to the user, in tree format.  This allows the front-end\napplication 132 to present the user with a series of prompts to drive towards a valid configuration.\nIn the minimum edit example described above with reference to FIGS. 49 and 53-55, the minimum edit space contains three superconfigurations defining four configurations.  This space can be compressed to two superconfigurations as shown in FIG.\n56.\nFIG. 56 is a table 5600 that illustrates an example in which the paint family has just one choice (Blue) and the package and radio families each have two choices (401, 402 and Dlx, Nav), but, the choices are not dependent one each other.  The\nchoice of package (401 or 402) does not change the choice of radio (Dlx, Nav).  When all the family choices are independent, the configuration engine 106 can resolve the conflicts in a single step.\nThe configuration engine 106 derives a resolution object that describes the actions to change the invalid configuration to a valid configuration, which is transformed by the author decorators 154 into a SOAP xml response (not shown) which can be\npresented to a user in a single pop up window 5700, as shown in FIG. 57.\nThis example illustrates the advantages offered by branched conflict resolution, as compared to single conflict resolution.  The configuration engine 106 presents the user with more information about how to resolve a conflict and asks them to\nchoose the valid package and radio features, rather than the application silently selecting a valid configuration.\nWhen there are no dependent choices, it is a relatively simple process to transform the target matrix into the conflict resolution response.  However, the resolution object is more complicated when one family's choice is dependent on another\nfamily.\nThe configuration engine 106 makes a series of prompts or inquiries to the user when the guided choices are dependent on a prior choice.  However, each prompt can include more than one independent choice.  When there is a nested or dependent\nchoice, the configuration engine 106 lists the divergent branch as the last feature group in the list.\nIn branched conflict resolution, the minimum edit space may include some partial matches, where a choice is present in some, but not all of the target configurations.  Partial matches in the configuration space can cause the target space to be\ntoo large, and it can lead to awkward user prompts.  In one or more embodiments, the configuration engine 106 trims the minimum edit space to remove partial matches.\nWith reference to FIG. 47, at step S610, the configuration engine 106 determines if removing partial matches functionality is enabled.  If the determination at S610 is positive, the configuration engine 106 proceeds to S612.  The algorithm for\nremoving partial matches S612 is shown in the flowchart of FIG. 58.\nWith reference to FIG. 58, at step S614 the configuration engine 106 creates a weight object, with positive weights for features that are contained within the configuration, and zero weight for features that are not contained within the\nconfiguration.\nAt step S616, the configuration engine 106 creates cache objects.  The configuration engine 106 returns data from cache for node (Y) for weightFeature and for weightNode, if it already exists.  WeightFeature refers to the weight from the node to\nthe bottom of the MDD (i.e., the true node)--for a specified feature.  WeightNode is a Node-based lookup instead of feature based lookup.  Thus, for each node, the configuration engine 106 determines the maximum weight path feature for a given node,\nstores the weight for each feature.  Once the configuration engine 106 knows the maximum feature weight for a node and trims its edges, then it stores the maximum node weight.  The maximum node weight is used as a cache for when the configuration engine\n106 analyzes subsequent nodes.  It can use the previously calculated maximum weight for that node and trim the outgoing edges from the node to only those edges with the maximum weight.\nAt step S618, the configuration engine 106 performs the maximum weight quick-restrict operation.  The maximum weight quick-restrict operation of S618 is the same as the maximum weight quick-restrict subroutine S560 described above with reference\nto FIG. 50.  After the quick restrict operation has removed partial matches, the configuration engine 106 proceeds to S620 (FIG. 47) to derive a resolution object.\nReferring back to FIG. 47, if the configuration engine 106 determines that removing partial matches functionality is not enabled at S610, it proceeds to S620 to derive a resolution object.  The algorithm for deriving a resolution object S620 is\nshown in the flowcharts of FIGS. 59-63.\nReferring to FIG. 59, the configuration engine 106 identifies families to change at step S622.  The algorithm for identifying families to change S622 is shown in the flowchart of FIG. 60.  Referring to FIG. 60, the configuration engine creates a\nbitset of the invalid configuration at step S624.  Next, the configuration engine calculates the domain bitset of the minimum edit space at step S626.  Then at step S628, the configuration engine ANDs the configuration bitset and the domain bitset.\nFIGS. 64-74 are examples illustrating the impact of various steps of the derive resolution object subroutine S620 of the branched conflict resolution method.  Referring to FIG. 64, in one example, a configuration of Default (400, Std, White,\nStone, Less) is modified when the user selects the 401 package.  The configuration engine 106 determines the new invalid configuration to be (401, Std, White, Stone, Less) with a minimum edit space depicted by MDD 6400.\nFIG. 65 is a table 6500 listing the invalid configuration (401, Std, White, Stone, Less) as a bitset (010 100 100 100 10).  FIG. 66 is a table 6600 that depicts the minimum edit space of the configuration converted to a matrix, as determined in\nstep S626 (FIG. 60).\nReferring back to FIG. 60, the configuration engine 106 starts analyzing the nodes included in family level zero (x) of the MDD at step S630.  At step S632, the configuration engine 106 determines if the family level (x) is less than the total\nnumber of families included in the MDD.  If so, the configuration engine 106 proceeds to step S634.\nAt S634, the configuration engine 106 evaluates the number of active features in the intersection, or bitwise conjunction, or \"ANDed\" bitset for family (x).  If there is at least one active feature in the ANDed bitset for family(x), the\nconfiguration engine 106 proceeds to step S636 and increments the family level (x) by one.  However, if there are no active features in the ANDed bitset for family(x), the configuration engine 106 proceeds to step S638 and adds family(x) to the list of\nfamilies to change, and then proceeds to step S636.\nFIG. 67 is a table 6700 illustrating the bitwise conjunction (AND) of the domain of the edit space in the example from table 6600 with the invalid configuration from table 6500.  The configuration engine 106 identifies any family with no active\nbits (i.e., only \"0\"s) in the sum, as referenced by numeral 6702, as a family to change to transform the invalid configuration into a valid one.  Thus, the configuration engine 106 determines that the radio, paint and trim families are families to\nchange.\nWith reference to FIG. 60, once the configuration engine 106 has analyzed all families, it will make a negative determination at step S632, i.e., the level (x) will not be less than the number of families.  Then the configuration engine 106\nproceeds to step S640 and returns to the routine of FIG. 59.\nReferring to FIG. 59, at step S642 the configuration engine 106 trims the edit space to the families identified in S622.  Then at step S644, the configuration engine 106 converts the trimmed space to a matrix, which is represented by table 6600\n(FIG. 66).\nFIG. 68 is a table 6800 that illustrates the minimum edit space from table 6600 after it is trimmed to the families to change (i.e., radio, paint and trim) from table 6700.\nAt step S646 (FIG. 59), the configuration engine 106 creates a resolution object that describes the actions to change the invalid configuration to a valid configuration.  The algorithm for creating a resolution object S646 is shown in the\nflowchart of FIG. 61.\nIn creating a resolution object S646, the configuration engine takes as input the invalid configuration, a target matrix (i.e., the edit space), the list of families to change and the list of families that have been processed so far.  The list\nof families to change is sorted in priority order, according to one or more embodiments.  This sort can be provided by an alternate sequence, or default to the minimum edit space family structure shown in FIG. 68.\nThe configuration engine 106 divides the families to change into No-Branch and Branch lists.  The configuration engine 106 identifies any family that is not identical in all rows of the target matrix as a Branch family.  Each resolution contains\na list of actions for any number of No-Branch families and a single Branch family.\nAn action specifies the family to change, its prior choice, and its possible choice(s).  To simplify parsing of a resolution, the configuration engine 106 organizes the Branch action to be the last action.  The Branch items lead to a divergent\nchoice and the choices for the remaining families are unknown until the Branch family choice is made.  Each choice of the Branch family will have an associated nested resolution object defined in a feature choice that results in resolution mapping.  The\nnested resolution objects are derived by with a new target matrix that is restricted to the feature choice of the branching family, the original families list, and the updated processed families list.\nReferring to FIG. 61, step S648 is a recursive call in which the configuration engine 106 sets the families to consider changing (Families to Consider) equal to the families list minus the families that were already processed (Families\nProcessed).\nAt step S650, the configuration engine 106 divides the families to consider changing (Families to Consider) into Branch and No-Branch lists.  A Branch family is a family whose bit pattern is not identical in all rows of the target matrix,\nwhereas a No-Branch family's bit pattern is identical in all rows.  The algorithm for dividing families into Branch and No-Branch S650 is shown in the flowchart of FIG. 62.\nWith reference to FIG. 62, the configuration engine 106 derives a unique bit pattern for each family based on the target matrix at S652.  The configuration engine 106 starts analyzing the nodes included in family level zero of the MDD at step\nS654.  At step S655, the configuration engine 106 determines if the family level (x) is less than the total number of families to consider changing in the MDD.  If so, the configuration engine 106 proceeds to step S656.\nAt step S656 the configuration engine 106 evaluates the number of unique patterns for family (x).  If there is more than one unique pattern, the configuration engine 106 proceeds to step S658 and adds the family to the Branch category.  If there\nis only one unique pattern, the configuration engine 106 proceeds to step S660 and adds family level (x) to the No-Branch list.  After steps S658 and S660, the configuration engine 106 increments the family level (x) by one and then returns to S655. \nOnce the configuration engine 106 has organized all families into the Branch and No-Branch lists, it makes a negative determination at S655, and then sorts the families within each list by priority at step S662, with the highest priority family listed\nfirst.  The priority of each family is based on its family weight and is determined by a separate system, according to one or more embodiments.  After S662, the configuration engine 106 returns to the create resolution object subroutine S646 of FIG. 61.\nReferring back to FIG. 68, the first call to derive the resolution method object S620 will use the invalid configuration from FIG. 65, the target matrix from FIG. 68, and will pass an empty list for the processed families list--deriveResolution\n(Cfg65, Matrix68, [Radio, Paint, Trim], []).  As shown in table 6800, the bit pattern for radio (i.e., \"011\") is the same in both rows, but is different for both paint and trim.  Therefore the configuration engine 106 identifies radio as a No-Branch\nfamily at S656 and S660, because it only has one unique pattern.  And the configuration engine 106 identifies paint and trim as Branch families at S656 and S658, because they each have more than one unique pattern.\nReferring back to FIG. 61, the configuration engine 106 initializes a resolution object at S664 by creating an empty object.  The configuration engine 106 starts analyzing the first No-Branch family (b=0) at step S666.  At step S668, the\nconfiguration engine 106 determines if the No-Branch family index (b) is less than the total number of No-Branch families.  If so, the configuration engine 106 proceeds to S670.  At step S670, the configuration engine 106 creates an action for No-Branch\nfamily index (b) and adds the action to the Resolution Object.  The algorithm for S670 is shown in the flowchart of FIG. 63.\nWith reference to FIG. 63, the configuration engine 106 initializes an empty Action object at step S672.  Next the configuration engine 106 sets a current feature (z) equal to the family feature (Family) in the invalid configuration at step\nS674.\nAt step S676, the configuration engine 106 sets the group of valid features for the user to choose from (Choices) equal to the active features for the No-Branch family index (b) in the target matrix domain.  Then at step S678, the configuration\nengine 106 returns the Action object to the subroutine S646 of FIG. 61.  With reference to FIG. 61, the configuration engine 106 adds the No-Branch family index (b) to the families processed list at step S679, then it increments the No-Branch family\nindex (b) by one and then returns to step S668.\nReferring to FIGS. 65-71, the configuration engine 106 initializes an empty resolution and adds an action for all No-Branch families, which in this case is radio--the only No-Branch family identified from table 6800.  As shown in table 6500, the\ninvalid configuration includes the Standard radio (i.e., \"100\") and the trimmed minimum edit space of table 6800 shows the possible valid choices for radio include Deluxe and Navigation (i.e., \"011\").  The Action for radio in this example specifies the\nfamily to change (i.e., radio), its prior choice (Standard), and its possible choices (Deluxe and Navigation), which may be represented by: Action {Radio, [Std], [Dlx, Nav]} as shown in FIG. 71.\nReferring back to FIG. 61, once the configuration engine 106 has analyzed all of the No-Branch families, it will make a negative determination at step S668 (i.e., the No-Branch family index (b) is greater than or equal to the number of No-Branch\nfamilies) and then proceed to step S680.  At S680 the configuration engine 106 evaluates the number of Branch families.  If there are zero Branch families, the configuration engine 106 returns to the derive resolution subroutine S620 of FIG. 59.  If\nthere are Branch families (i.e., Branch families&gt;0), the configuration engine 106 proceeds to step S682.\nAt S682 the configuration engine 106 sets Family equal to the first family (i.e., the highest priority family) in the Branch list.  At step S684 the configuration engine 106 creates Action for the Family.  The configuration engine 106\ninitializes an empty Action Object and sets the current feature equal to the Family configuration feature.  Next the configuration engine updates the Action to set Choices equal to the active features for Family in the target matrix domain.  At S688, the\nconfiguration engine 106 creates a new Families Processed list by appending Family to the Families Processed list.\nAt step S690, the configuration engine 106 starts analyzing Choice (c=0).  At step S692, the configuration engine 106 compares Choice (c) to the number of choices.  If Choice (c) is less than the number of choices, then the configuration engine\n106 proceeds to step S694 and creates a new target matrix that is restricted to Choice (c).\nAt step S696, the configuration engine 106 creates a Resolution Object for Choice (c) using the new target matrix and the new Families Processed list by the result of recursive invocation.  At step S698, the configuration engine 106 updates the\nAction to set Branch for Choice (c) equal to the nested Resolution Object.  At step S700, the configuration engine 106 increments Choice (c) by one and returns to step S692.  Once the configuration engine 106 has analyzed all Choices, it determines that\nChoice (c) is equal to the total number of choices at S692 (i.e., C is not less than # Choices).  In response to a negative determination at S692, the configuration engine 106 proceeds to step S702 and adds the Action object to the Resolution.  Then it\nreturns to subroutine S620 (FIG. 59) and then back to the main conflict resolution routine S500 of FIG. 47.\nWith reference to FIGS. 65-71, the configuration engine 106 generates the Action for the highest priority Branch family, which in this case is the Paint family because it defaulted to using MDD/Matrix structure/family ordering where the right to\nleft ordering defines priority values.  As shown in table 6700, paint oriented to the left of trim, so paint is higher priority.  For each paint Choice, the configuration engine derives a nested resolution by first creating a new target matrix by\nrestricting to the paint choice, and making a call to derive resolution.\nAs shown in the trimmed minimum edit space of table 6800, there are two possible Choices for the paint family--Red (i.e., \"010\") and Blue (\"001\").  There will be two additional calls to derive resolution: one for Red\npaint--deriveResolution(Cfg65, Matrix.Red, [Radio, Paint, Trim], [Radio, Paint]); and one for Blue paint--deriveResolution(Cfg65, Matrix.Blue, [Radio, Paint, Trim], [Radio, Paint]).  As shown in FIG. 71, the Action for paint in this example specifies the\nfamily to change (i.e., paint), its prior choice (White, i.e., \"100\" in table 6500), and its possible choices (Red and Blue), which may be represented by: Action {Paint, [White], [Red, Blue] }.\nIn both cases (Red paint and Blue paint), the configuration engine 106 uses a trimmed target matrix and the families list contains only one family (trim) because there is only one other Branch family in this example.  FIG. 69 is a target matrix\n6900 for the Red paint choice.  The target matrix 6900 shows that there is just one choice for trim (i.e., Ruby, \"001\").  FIG. 70 is a target matrix 7000 for the Blue paint choice.  The target matrix 7000 shows that there are two choices for trim (i.e.,\nCharcoal and Ruby, \"011\").  The configuration engine 106 determines the resulting resolution of each target matrix 6900 and 7000 and adds the nested resolutions for paint to its action to determine a final resolution object 7100 (FIG. 71).\nAs shown in FIG. 71, the Action for the nested resolution for Red paint in this example specifies the family to change (i.e., trim), its prior choice (Stone, i.e., \"100\" in table 6500), and its possible choice (Ruby), which is represented by:\nAction {Trim, [Stone], [Ruby] }.  The Action for the nested resolution for Blue paint in this example specifies the family to change (i.e., trim), its prior choice (Stone, i.e., \"100\" in table 6500), and its possible choices (Charcoal and Ruby), which is\nrepresented by: Action {Trim, [Stone], [Charcoal, Ruby] }.\nReferring back to FIG. 47, at S704, the configuration engine 106 restores the original set of node edges to the memory 108 (shown in FIG. 2).  S704 is similar to subroutine S146 of FIG. 28.  The configuration engine identifies each node (y),\ncopies each outgoing edge of each node.  Then, the configuration engine 106 sets the MDD to the identity of the root node.  At step S706, the configuration engine 106 returns a response by providing the resolution object 7100 to the author decorator 154;\nwho in turn transforms the resolution object 7100 into a SOAP xml response (FIG. 2) which is presented to the user in a series of windows, as shown in FIGS. 72-74.\nAs described above with reference to resolution object 7100 (FIG. 71), the configuration engine 106 determined a guided resolution that includes a nested choice for trim.  The Available choices for trim depend on the user's selection for paint. \nFIG. 72 depicts a window 7200 with a first prompt that is displayed to the user.  FIG. 73 and FIG. 74 show the next prompt displayed as determined by the choice of Red or Blue paint.\nIf the user selects Red paint in response to the prompt shown in window 7200, the configuration engine 106 will guide them along partial path 8-9-10 (FIG. 64) and then display window 7300 to instruct them to change the trim from Stone to Ruby.\nHowever, if the user selects Blue paint in response to the prompt shown in window 7200, the configuration engine 106 will guide them along partial path 8-11-12 (FIG. 64) and then display window 7400 to instruct them to change the trim from Stone\nto one of Charcoal and Ruby.\nAs described above with reference to FIG. 58, in branched conflict resolution the minimum edit space may include some partial matches, where a choice is present in some, but not all of the target configurations.  Partial matches in the\nconfiguration space can cause the target space to be too large, and it can lead to awkward user prompts.  The configuration engine 106 may trim the minimum edit space using the removing partial matches subroutine S612.  This is done using the maximum\nweight quick-restrict operation, according to one or more embodiments.  However, only the partial match features are provided with relative non-zero weights; all other features are given an equal weight of zero at S614.\nFIGS. 75-76 are examples illustrating the impact of various steps of the remove partial matches subroutine S612.  In the illustrated embodiment, a selection of D2 leads to the invalid configuration (A1, B2, C3, D2, E3, F1) with the minimum edit\nspace shown in MDD 7500 of FIG. 75.  There are two partial matches--B2 (i.e., the outgoing edge \"010\" from node 12) and E3 (i.e., the outgoing edge \"001\" from node 11)--where a user selection could remain the same or be changed.  If B2 remains unchanged,\nthen E3 must change to E2, because E3 is not located along the same path as B2 (i.e., partial path 11-12-13-14).  But, E3 can remain unchanged if B2 changes to B3, because E3 is located on the same path as B3 (i.e., partial path 11-15-16-14).\nWith an alternate sequence {A1 A2 B1 B2 B3 D1 D2 C1 C2 C3 C4 E1 E2 E3 F1 F2}, and an invalid configuration of {D2 A1 E3 B2 C3 F1}, the structure used for path weights is {A1 B2 C3 D2 E3 F1}.  The maximum weight operation will ignore any edges\nwith negative weights (A2 B1 C1 C2 C4 D1 E1 E2 F2).  The weights for the two paths in the minimum edit space are shown in Table 7600 of FIG. 76.  The first row shows path 2-10-11-12-13-14-1.  This path defines the configuration of {D2 A1 E2 B2 C2 F2} and\na path weight bit set of 010100.  There are two active bits in the path weight which correspond to the features B2 and D2--the two features on this path with non-negative weights.  There are no active bits for the other features (A1, C2, E2, F2) because\nthey have negative weights and are ignored.  The second row shows path 2-10-11-15-16-13-1.  This path defines the configuration of {D2 A1 E3 B3 C2 F2} and a path weight bit set of 000110.  There are two active bits in the path weight which correspond to\nthe features D2 and E3.  Based on these weights, the configuration engine 106 trims the space to a single path of 2-10-11-12-13-14-T. The higher priority family B will remain unchanged, and the resolution will include a change for family E.\nWhen an update request is made, the configuration engine 106 modifies the prior configuration by adding the newly Selected feature (while also removing the prior choice for the feature's family).  As described above with reference to FIGS. 47\nand 48, if the updated configuration is invalid, conflict resolution is triggered and the configuration engine 106 calculates the minimum edit space at S504.  The service API 134 does not dictate how the minimum edit space is calculated.  The\nconfiguration engine 106 determines the level of precedence to be given to prior Selected features.\nIn one embodiment, the configuration engine 106 treats all features in the invalid configuration equally, regardless of feature state.  In this instance the minimum edit calculation S504 is performed using the full invalid configuration.\nIn another embodiment, the configuration engine 106 gives precedence to keeping the maximum number of previously selected features.  The configuration engine 106 performs this strategy by performing the minimum edit calculation S504 using a\npartial configuration that ignores any feature whose prior state is Included or Default.  Only the new and previous Selected features are kept when making the minimum edit space calculation.  In one embodiment the configuration engine 106 performs the\nminimum edit calculation S504 after determining whether or not the resolution is guided at S558.  If the resolution is not guided, the configuration engine 106 performs the minimum edit space calculation S504 using only the Selected features.  However,\nif the resolution is guided, the configuration engine 106 performs the minimum edit space calculation S504 using the full invalid configuration.\nFIGS. 77-81 are examples illustrating the impact of various steps of the minimum edit space calculation S504 using a full configuration and using a partial configuration.  In the illustrated embodiments, the configuration engine 106 analyzes the\nfull buildable space shown in Table 7700 of FIG. 77, where the features are numerically named--e.g. Family E has two features E1 and E2.  If the previous configuration is Selected (F1, E2) and Included (A2, T1, R1) and Default (S5, P1, Y3) and an update\nrequest is received to select T2.  The configuration engine 106 determines that the updated configuration is invalid because (F1, E2, T2) is not a valid combination.  As shown in Table 7700, row 1 is the only configuration that includes both F1 and E2,\nbut it includes T1 not T2.\nThe two possible minimum edit spaces are shown in Table 7800 of FIG. 78 and Table 7900 of FIG. 79.  The first minimum edit space (7800) considers the partial configuration where only the new set of selected features is used in the minimum edit\nspace calculation (F1, E2, T2) and the second minimum edit space (7900) considers the full configuration where the complete invalid configuration is used in the minimum edit space calculation (F1, E2, A2, T2, R1, S5, P1, Y3).\nUsing the matrix structure as the priority sequence, the configuration engine 106 identifies a single target configuration from each minimum edit space.  The priority sequence is based on the matrix as is with left most bit being highest\npriority.  So in this case, the configuration engine 106 selects a configuration by choosing features for each family in a left-to right fashion, and choosing the left-most available feature for each family.  With reference to FIG. 78, since the E and F\nfamilies are the same for all configurations; and the configuration in the bottom row has the highest priority feature for family Y, the first space will result in a target of E1, F2, Y1, T2, R3, P1, S1, A2 which corresponds to the bottom row of Table\n7800.  The second space will result in a target of E1, F2, Y3, T2, R1, P1, S5, A2.  The decision on how to calculate the minimum edit space will affect the target configuration, and thus affects the number of feature edits required.\nTable 8000 of FIG. 80 shows the changes required (i.e., the shaded features in target 1) when the configuration engine 106 makes the minimum edit space calculation with only the selected features, based on the minimum edit space in Table 7800. \nAs shown in Table 8000, the features to change are: E1, F2, Y1, R3 and S1.\nTable 8100 of FIG. 81 shows the changes required (i.e., the shaded features in target 2) when the minimum edit space calculation is made with the full invalid configuration, based on the minimum edit space in Table 7900.  As shown in Table 8000,\nthe features to change are: E1 and F2.  In both cases the changes to families E and F are the same because T2 is only available with E1 and F2.  But, if the minimum edit space calculation considers only the Selected features, there are three other\nrequired changes (i.e., Y1, R3 and S1, as shown in Table 8000).\nWhen the configuration engine 106 performs the calculation with the full configuration, it minimizes the total edits, as shown in Table 8100.  It gives no special precedence to previous Selected features.\nWhen the configuration engine 106 performs the calculation with only the new selected set, it is attempting to minimize the changes to prior selections by giving precedence to Selected features.  The side effect is that this increases the total\nnumber of edits required, as shown in Table 8000.\nThe other motivation to perform the minimum edit space calculation on only Selected features is to ensure that the maximally standard default is always driven by the Selected set.\nThe configuration engine 106 results include a Boolean flag to indicate if there is a conflict.  When there is a conflict, the configuration engine 106 determines either a single conflict resolution object or a branched conflict resolution\nobject, depending on the guided resolution flag.\nBecause the services API 134 dictates that a conflict resolution is returned only if there are changes required to the previous selected features, it is possible that the same configuration request will return conflict=true when guided=true, but\nwill return conflict=false when guided=false.\nUsing the product definition from FIG. 10, in one example the configuration engine 106 considers a configuration where the user has selected Red paint, and autocomplete is true.  One such configuration is Selected (Red) and Default (400, Std,\nStone, Less).  If the user updates the configuration by selecting the navigation (Nav) radio, the new configuration (Nav, Red, 400, Stone, Less) is invalid.\nWhen guided resolution is true, the configuration engine 106 returns a conflict of false and a returns resolution such as {Actions [Action {Pkg, [400], [401,402] }, Action {Trim, [Stone], [Ruby]}]}.\nHowever, when guided resolution is false, the API dictates that there is no conflict because the new Selected features (Nav, Red) are compatible.  Even though changes are required for Pkg and Trim, because these were default choices, no conflict\nis reported.  The configuration engine 106 will return conflict of false even though the new configuration and associated feature states show that there is a necessary change to prior default choices for the 400 package, and Stone trim--{Std=AVAILABLE,\nNav=SELECTED, Stone=EXCLUDED, White=EXCLUDED, Charcoal=EXCLUDED, Vista=AVAILABLE, Dlx=AVAILABLE, Red=SELECTED, 400=EXCLUDED, 401=DEFAULT, 402=AVAILABLE, Less=DEFAULT, Blue=AVAILABLE, Ruby=INCLUDED}.\nThe service API 134 specifies that a request can select or unselect a feature.  Selecting a feature adds it to the configuration.  When a feature is unselected, the API dictates only that the feature state is no longer Selected.  It does not\nrequire that the feature be removed from the configuration.\nThere are at least two embodiments.  In a first embodiment, the configuration engine 106 removes the unselected feature from the Selected set and proceeds normally.  In a second embodiment, the configuration engine 106 removes the unselected\nfeature from the configuration entirely.\nRemoving the unselected feature from the Selected set follows the API specification that the feature is no longer Selected.  However, the feature may not actually be removed from the configuration.  In a configurator application, this could mean\nthat the user unchecks the box to remove the feature only to have the checkbox checked again because it is not removed from the configuration.  This behavior can be difficult because no matter what the user does to try and remove the feature, the feature\nkeeps getting added back.\nIn this first embodiment, if a Default or Included feature is unselected, there will be no change in the configuration or feature states.  The Selected set does not change because the feature being unselected wasn't in the Selected set.  As\nsuch, an Included feature will remain Included and a default will remain default.  Included state depends on the Selected set which did not change and auto completion is designed to give repeatable results for the same minimally complete configuration\nwhich did not change.\nIf a Selected feature is unselected, the feature state may change to Included or Default.  If the feature is Included by the remaining Selected features, its state will change from Selected to Included.  Otherwise, it is possible that the\nremoved feature is added back during auto completion.\nDepending on the front-end application 132, the user is most likely unaware of the feature states of Selected, Included and Default.  If the user is unaware of feature states, it can be quite perplexing to unselect a feature only to have it\nremain in the configuration.\nTo avoid this confusion, in the second embodiment, the configuration engine 106 removes the feature from the configuration regardless of its state.  This implementation will trigger conflict resolution when a feature from the configuration is\nunselected.  To ensure the unselected feature remains absent from the new configuration, the configuration engine 106 restricts the buildable space to only those configurations that do not contain the unselected feature prior to the minimum edit\ncalculation.  This approach ensures that the unselected feature is removed from the configuration.\nWhen auto completion is enabled, the configuration engine 106 makes Default choices until the configuration is complete with respect to displayable families.  This is done by making determinations for each incomplete family that is consistent\nwith prior Selected and Included feature states.\nIn one embodiment, the configuration engine 106 makes Default feature state determinations based on a priority sequence for each family and feature.  Incomplete families are processed in priority order, and where more than one feature is valid\nwith prior Selected, Included and Default feature states, the feature priority is used to make the Default determination.\nWith reference to FIG. 82, a method for automatically completing a configuration using a sequence-based approach is illustrated in accordance with one or more embodiments and generally referenced by S750.  The method S750 is implemented as an\nalgorithm within the configuration engine 106 using software code contained within the server 102, according to one or more embodiments.  In other embodiments the software code is shared between the server 102 and the user devices 112, 114.  The method\nS750 uses quick-restrict and domain to make default selections.\nAt S752, the configuration engine 106 starts with an MDD restricted to Selected features, and a configuration defined by the Selected and Included features.  At S754, the configuration engine 106 sorts families by priority.  Then, at S756, for\neach family without Selected or Included features, that are sorted by priority, the configuration engine 106 calculates the domain of the current restricted space.  At S758, the configuration engine determines the highest priority feature for the family,\nmarks it as a Default feature, and further restricts the restricted space to this feature.\nAlternatively, in another embodiment, after S752, the configuration engine 106 proceeds to S760 and uses sequences to determine the maximally weighted path in the MDD that contains the Selected and Included features, which identifies default\nchoices for families to complete.\nPath weight can be represented by a feature Bitset, where the families are ordered left to right according to priority (with the leftmost family being the highest priority), and features are also ordered left to right according to priority\nwithin each family (with the feature corresponding to the leftmost bit being the highest priority).  This is analogous to sorting the features in descending priority and assigning weights by powers of 2,--1 2 4 8 16.  . . . , and ensures that each path\nwill be uniquely weighted, and that there will be exactly one maximally weighted path when each family and feature is assigned a sequence.  To compare two paths, the Bitsets are sorted in descending bit order.\nInitially the path weight is 0, and as an edge is added during MDD traversal, edge weight is added to the path by simply setting a corresponding bit associated with the feature on that edge.\nIdeally, the MDD structure would reflect the priority sequence for features and families.  However, compression of the MDD requires the family ordering to be determined by the compression algorithm, and the feature order is arbitrarily\ndetermined by feature conditions of the MDD algorithm.  While the MDD structure can't be used to store priority sequence, a secondary structure can be created to store this sequencing.  The MDD structure is used to determine the feature for each edge,\nand the alternate/secondary structure is used to set the feature's bits in the path weight Bitset.\nFIG. 83 shows an MDD 8300 that defines the same buildable space as MDD 1300 (FIG. 13), except that the features within each family are sorted alphabetically and the family order is based on MDD compression.  For example, the radio features are\nsorted as STD, DLX and NAV in MDD 1300 and as DLX, NAV and STD in MDD 8300.  FIG. 84 is a table 8400 that defines the alternate sequence structure defining path weights, which is the same as the structure of MDD 1300.\nReferring back to FIG. 82, the configuration engine 106 begins the weighted operation with a minimally completed configuration, and starts with a quick-restrict operation (S752).  In another embodiment, the configuration engine 106 combines the\nquick-restrict operation with the weighted operation (S760), as is done in Minimum Edit Distance subroutine described with reference to FIG. 48 regarding resolving configuration conflicts.  On the downward traversal, no additional action is taken.  On\nthe upward traversal, the configuration engine 106 calculates the path weight with the aid of the alternate sequence structure 8400.  Where a node has more than one outgoing edge, the weight is calculated separately for each feature that has a valid\noutgoing edge.  When a new maximally weighted path is found, lesser weighted paths are trimmed from the MDD.\nFIG. 85 illustrates an MDD 8500 after the configuration engine 106 restricts the MDD 8300 (FIG. 83) to a selection of Blue paint and no Included or Default features, i.e., a minimally complete configuration: Selected{Blue}+Included{ }+Default{\n}, as described with reference to S752.  Then configuration engine 106 starts the weighted operation, i.e., S760, with the quick-restricted space shown in MDD 8500.  Using depth-first search and traversing child edges in descending bit order, the first\npath traversed is 2-8-9-10-6-T.\nThe configuration engine 106 calculates path weight on the upward traversal beginning with partial path T-6-10-9.  This path weight, along with the weight of its partial paths, is shown in Table 8600 of FIG. 86.\nThe configuration engine 106 continues the downward traversal from Node 9 with the 401 package (Pkg.401).  There are two partial paths to consider: 9-5-7-T and 9-5-6-T. The two partial paths from Node 5 to the truth node are compared to find the\nmaximum weight between Ruby and Charcoal Trim, as shown in Table 8700 (FIG. 87).  The configuration engine 106 determines that Charcoal Trim (path 9-5-6-T) is the maximum, because 000 000 001 010 00 is greater than 000 000 001 001 00, as referenced by\nnumeral 8702, and the edge 5-7 (Ruby Trim) is removed (shown in FIG. 89).\nNext, the configuration engine 106 compares the paths from Node 9 to the Truth node, as shown in Table 8800 (FIG. 88).  The configuration engine 106 determines that the partial path for the 401 Package is the maximum because the corresponding\nbits (010) are greater than the corresponding bits of the 402 package (i.e., 001), as referenced by numeral 8802; and trims edge 9-10 from the MDD 8500.  At this point the MDD will look like MDD 8900, as shown in FIG. 89.\nThe maximum weight path for edge 8-9 is MoonRf.Less, because the corresponding bits for Less (10) are greater than the corresponding bits for Vista (01).  The configuration engine 106 determines that the configuration {Dlx,Less,401,\nCharcoal,Blue} is the maximum weight for path 2-8-.  . .-T and that the maximum weight configuration for path 2-3-.  . .-T is {Std,Less,401,Charcoal,Blue}.  The edge weights for these paths are shown in Table 9000 in FIG. 90, and the maximum weight\noutgoing edge from node 2 is Dlx, because 010 is greater than 001 (Nav), as referenced by numeral 9002.\nThe configuration engine 106 trims edges 2-8-9-5, 10-6 and 7-T as shown in MDD 8900 (FIG. 89).  This leaves the maximum weight path as 2-3-4-5-6-T, and the configuration engine 106 marks Radio.Dlx, MoonRf.Less, Pkg.401 and Trim.Charcoal as\nDefault features at S760 to generate an autocompleted configuration of: Selected {Blue}+Included{ }+Default{ Dlx,Less,401,Charcoal }.\nA problem with sequence based auto completion is that it requires additional data to define the priority sequence.  This requires manual setup for every vehicle in the catalog.  Furthermore, it is not guaranteed to provide the maximally standard\nconfiguration.\nSequence-based auto completion is attempting to supplement the MDD with data that will allow the autocompleted configuration to be maximally standard.  A \"maximally standard\" configuration is one where a configuration contains the most possibly\nstandard content, where standard content is determined by the product definition.  A standard feature is generally a feature that is included in the base price for a product, such as a vehicle.  Whereas an optional feature is typically an upgrade and\nwill increase the price of the product.\nFor simpler product definition, it is may be possible to ensure maximally standard configurations using the alternate sequence approach.  However, for more complex product definition, this approach will not work.\nThe product definition defines a set of feature conditions that determine when a feature is available.  There are three types of availability-13 as a standard feature, as an included feature, and as an optional feature.  A feature could have\ndifferent availability depending on the current configuration.  A standard feature is a feature that is included in the base product (vehicle) configuration and an optional feature is a feature that is not included in the base product.  An optional\nfeature is typically an upgrade that will add cost to the base price, but this is not always the case as a feature could be a zero-cost option or even a less expensive option than the standard feature.  An included feature is generally a feature that is\nassociated with another feature (e.g., a package) and was added to the product by selecting the other feature.  For example, leather seats and fuzzy dice may be included in the 401 package.  When the user selects the 401 package, they see one change in\nprice for the package, but the change includes both features (i.e., leather seats and fuzzy dice).\nThe configuration engine 106 uses the maximally standard algorithm to distinguish feature availability based on standard or optional feature conditions.  A feature included in a package is a special case of a standard feature.  In addition to\nthe valid buildable space, the product definition also defines the standard feature conditions for each family.  When the configuration engine 106 selects Default features using the maximally standard algorithm, it is configured to select as many\nstandard features as possible to avoid or limit adding optional content and potentially increasing the price when the user has not explicitly selected the feature.\nFIG. 91 is a Table 9100 that shows a matrix that defines the same buildable space as MDD 1700 (FIG. 17).  FIG. 92 is a Table 9200 that shows the standard feature conditions for the product definition defining the buildable space.\nFor the package (Pkg) family, there is a single feature condition defining Pkg.400 as the standard package, as referenced by numeral 9202.  For the Radio family, there are two standard feature conditions, as referenced by numeral 9204.  The\nfirst (upper row) defines Radio.Std as the standard Radio for Pkg.400.  The second (lower row) defines Radio.Dlx as the standard Radio for Pkg.401 and Pkg.402.  The buildable space shows that Radio.Nav is also available.  Because this feature condition\nis not included in the Standard feature conditions (i.e., Radio.Nav is not active (1) in condition 9204), the navigation radio (Nav) is defined as an optional choice that can be added in place of the deluxe radio (Dlx) for the 401 or 402 package.  There\nis a single feature condition for the moonroof family defining no moonroof (Less) as the standard package, as referenced by numeral 9206.  There are two standard feature conditions for the dice family, as referenced by numeral 9208; the first defines no\ndice as the standard feature for white paint; and the second defines fuzzy dice as the standard feature for red and blue paint.  There are three standard features for the seat temperature (Temp) family, as referenced by numeral 9210; the first defines no\nseat temperature feature (LessTemp) as the standard feature for the 400 package; the second defines heated seat control (Heat) as the standard feature for the 401 package; and the third defines heated and cooled seat control (HeatCool) as the standard\nfeature for the 402 package.\nWith reference to FIG. 93, a method for automatically completing a configuration using a maximally standard algorithm is illustrated as software code in accordance with one or more embodiments and generally referenced by 9300.\nTo automatically complete the configuration using standard feature conditions, the configuration engine 106 first restricts the buildable space to the minimally complete configuration at operation 9301.  Families absent from the configuration\nare processed in priority order, and the space is restricted for each successive choice.  To make the default choice for a family, its standard feature conditions are inspected to see what standard choice(s) are still possible at operation 9304.  If no\nstandard choices are possible, the domain of the restricted space will define possible optional choices at operation 9306.  Where more than one possible choice exists for a family, alternate sequencing is used to choose the highest priority feature as\nthe default at operation 9308.\nIt is uncommon, but valid, for a family to have to no standard feature conditions.  This is handled as if no standard features are available, and the choice will be made from the optional content.\nIt is also valid for the standard feature conditions to define more than one standard feature for the same partial configuration.  Where more than one standard feature is available, the highest priority feature will be chosen.\nWhere all feature conditions for a family are stored in a single MDD, the standard features that are still allowed with prior choices can be identified by an AND operation of this MDD with the current restricted buildable space.  An AND\noperation generates a new MDD for each inspection of a feature condition MDD.  As discussed in the Quick-Restrict section, this will incur performance problems from garbage collection.  The alternate approach, as shown in FIG. 93, is to divide the\nstandard feature conditions by feature (and not just family) and use the containsAny operation.  The containsAny operation is the same logic as an AND operation, however the new space is not created.\nWith reference to FIG. 94, in one embodiment, the configuration engine 106 considers a scenario where a user has selected the Vista moonroof and Ruby trim.  With these two selections, Fuzy Dice is included.  Given a priority order of [Pkg,\nRadio, Moonrf, Temp, Paint, Dice, Trim], the families to autocomplete, in order are [Pkg, Radio, Temp, Paint].  The configuration engine 106 does not auto-complete the Dice, Trim and Moonroof families because they are already \"complete\", i.e., they have\nfeatures with Selected or Included feature states.\nThe configuration engine 106 restricts the MDD to the minimally complete configuration Vista, Ruby, and Fuzzy Dice as shown by MDD 9400 in FIG. 94.\nFirst, the configuration engine 106 processes the package family (Pkg) because it has the highest priority.  As described with reference to FIG. 92, there is one standard feature condition for the package family (i.e., Pkg 400, 9202).  Because\nthe 400 package (i.e., the left-most feature of Pkg) is not contained in the restricted space illustrated by MDD 9400, the standard feature is not available.  MDD 9400 shows that the domain of the package family is 011 showing that both the 401 and 402\npackages are available in the restricted space.  The configuration engine 106 chooses the 401 package based on priority and the space is further restricted to package 401 (i.e., nodes 9 and 10 are removed) as shown by MDD 9402.  The restricted space now\ncontains a single superconfiguration.\nNext, the configuration engine processes the radio family.  As described with reference to FIG. 92, there are two standard feature conditions for the radio family: one for Radio.Std and one for Radio.Dlx (9204, FIG. 92).  At this point the\ndeluxe (Dlx) radio and the navigation (Nav) radio are available in the restricted space illustrated by MDD 9402.  The configuration engine 106 selects Dlx as a Default feature, because it is the only standard feature remaining in the restricted space,\nand further restricts the buildable space to Dlx, as indicated by the modified edge label from 011 to 010 and reference by numeral 9404.  However, this restriction will not change availability for other families since the space is already a single\nsuperconfiguration.\nNext, the configuration engine 106 processes the seat temperature (Temp) family.  There are three standard feature conditions for Temp (9210, FIG. 92).  But, since Pkg 401 has already been selected, only Temp.Heat will be available, as indicated\nby edge label 010 in MDD 9402.  Therefore the configuration engine 106 adds heated seats (Heat) to the configuration as a Default feature.\nNext, the configuration engine 106 processes the paint family.  There are no standard feature conditions for paint (Table 9200, FIG. 92).  The domain of the restricted space has two choices--Red and Blue, as indicated by edge label 011 in MDD\n9402.  The configuration engine 106 adds Red as the Default choice, and further restricts the MDD 9402 to Red (010) as referenced by numeral 9406, because Red (010) has more weight than Blue (001).\nFinally, the configuration engine 106 processes the dice family.  There are two feature conditions for Dice (9208, FIG. 92).  Because Red paint has been added to the configuration, only Fuzzy Dice is available, and fuzzy dice is already an\nIncluded feature.  Therefore the configuration engine 106 does not change its feature state.\nWith reference to FIGS. 95-99, another method for automatically completing a configuration using a maximally standard algorithm is illustrated in accordance with one or more embodiments and generally referenced by S800.  The maximally standard\nauto-completion method S800 is implemented as an algorithm within the configuration engine 106 using software code contained within the server 102, according to one or more embodiments.  In other embodiments the software code is shared between the server\n102 and the user devices 112, 114.\nAt S802, the configuration engine 106 generates a maximally standard data space (MsDataSpace) based on a total or global buildable space and a relationships work object (relWork).  The total buildable space includes a main space that defines all\npossible configurations of non-deterministic features and relationships spaces that define the availability of deterministic features in terms of non-deterministic features.  The intersection of the main space and the relationships spaces define all\npossible configurations.  The main space and relationship spaces are specified by MDDs, according to one or more embodiments.  The total buildable space includes the main MDD and a relationships MDD, and is quick-restricted to any Selected and Included\nfeatures.  RelWork is a temporary object that is used to process a specific condition that may occur based on the order families are processed.  As discussed below, relWork is nontrivial if after selecting a Default feature from a deterministic family,\nthere is more than one defining feature condition such that the configuration engine 106 cannot quick restrict the main MDD.  Then at S804, the configuration engine 106 identifies any family without any Selected or Included features as a family to\ncomplete.\nWith reference to steps S806-811, the configuration engine 106 analyzes each family of the MDD in priority order.  The configuration engine 106 starts analyzing the first family in the sorted families to complete list at step S806.  At step\nS808, the configuration engine 106 determines if the index (x) is less than the total number of families included in the families to complete list.  If not, the configuration engine 106 proceeds to S810 (Done).  If so, the configuration engine 106\nproceeds to step S812 to determine the possible available standard features for family (x) within the restricted buildable space (MsDataSpace).  Once the configuration engine 106 has completed its analysis of family (x), it returns to S811 and starts\nanalyzing the next family by incrementing x by 1.  The subroutine of S812 is shown in the flowchart of FIG. 96.\nWith reference to FIG. 96, at S814 the configuration engine 106 initializes the list of possible standard features by setting it to empty.  With reference to steps S816, S818 and S842, the configuration engine 106 analyzes each feature of\nfamily(x).  The configuration engine 106 starts analyzing feature zero (z=0) at S816.  At step S818 the configuration engine 106 compares feature (z) to the number of features at the current family (x) to determine if z&lt;the number of features in\nfamily (x).  If the determination is positive, the configuration engine 106 proceeds to S820 to determine the essential sets for feature availability.  Once the configuration engine 106 has completed its analysis of feature (z) of family (x), it returns\nto S842 and starts analyzing the next feature of family (x) by incrementing z by 1.  The subroutine of S820 is shown in the flowchart of FIG. 97.\nReferring to FIG. 97, the configuration engine 106 determines a setlist of \"essential sets\" for the availability of feature (z) at S820-S848.  At S824 the configuration engine 106 initializes the setlist by adding the main MDD of the current\nbuildable space (buildableSpace).  Then at S826, the configuration engine 106 evaluates relWork to determine if it is not trivial (i.e., not all 1).  If relWork is not all trivial, (i.e., a previous Default selection was made from a deterministic family\nsuch that the relationship defined more than one determinant condition) then the configuration engine 106 proceeds to S828 and adds relWork to the setlist.  After S828, or in response to a negative determination at S826, the configuration engine 106\nproceeds to S830 to determine if there are not any standard feature conditions defined for this feature.  If there are no standard feature conditions defined for feature (z), then its standard space is null.  If there are standard feature conditions\ndefined for feature (z), then a negative determination is made at S830, and the configuration engine 106 proceeds to S832 and adds the standard space to the setlist.  After S832, or in response to a positive determination at S830, the configuration\nengine 106 proceeds to S834 to determine if the family of feature (z) is deterministic.  If family (x) is deterministic, the configuration engine 106 adds the relationship space for family (x) to the setlist at S836.  After S836, or in response to a\nnegative determination at S834, the configuration engine 106 proceeds to S838 and returns the setlist to the subroutine of FIG. 96.\nReferring to FIG. 96, at S840 the configuration engine 106 determines if the intersection of all spaces in the setlist for feature (z) is empty (i.e., if feature (z) is not a standard feature or it is a standard feature that is not available\nwith the current configuration).  If the determination at S840 is negative, the configuration engine 106 proceeds to S844 and adds feature (z) to the list of possible available standard features (POSSIBLE).  After S844, or after a positive determination\nat S840, the configuration engine 106 proceeds to S842 to analyze the next feature (z) of family (x).  Once the configuration engine 106 has analyzed all features of family (x), it makes a negative determination at S818 and proceeds to S846 to return the\npossible available standard features for family (x) to the main maximally standard routine of FIG. 95.\nWith reference to FIG. 95, at S848 the configuration engine determines if there are any standard features for family (x).  If there are no standard features, i.e., if POSSIBLE is empty, then the configuration engine 106 proceeds to S850 to find\nthe domain of family (x) in the maximally standard data space (MsDataSpace).  The subroutine of S850 is shown in the flowchart of FIG. 98.\nWith reference to FIG. 98, the configuration engine 106 determines the domain of family (x) at S850-S858.  At S852, the configuration engine 106 calculates the domain space of family (x) as the intersection of the main space and the relWork.  If\nthe configuration engine 106 determines that family (x) is deterministic at S854 based on the product definition, then it proceeds to S856.  At S856 the configuration engine 106 sets the domain space equal to the intersection of the domain space and\nrelationship space for that family.  After S856, or in response to a determination that family (x) is not deterministic at S854, the configuration engine 106 proceeds to S858 and sets the Domain to the domain of the domain space, adds any feature from\nfamily (x) that is present to the Domain to the list of possible features and returns to the main maximally standard routine of FIG. 95.\nReferring to FIG. 95, after determining the domain of family (x) at S850, or in response to a negative determination at S848, the configuration engine 106 proceeds to S860 and sorts POSSIBLE by an alternate sequence that defines the priority of\nthe features.  At S862 the configuration engine 106 selects the first feature in the sorted list as the Default feature for Family (x).  Then the configuration engine 106 proceeds to S864 to restrict the maximally standard data space to the new Default\nfeature.  The subroutine of S864 is shown in the flowchart of FIG. 99.\nWith reference to FIG. 99, at S864-S880, the configuration engine 106 further restricts the maximally standard data space to the new Default feature.  At S866 the configuration engine 106 restricts the main space to the new Default feature. \nThen if family (x) is deterministic, the configuration engine 106 proceeds to S870 and defines a temporary relationship (relTemp) by restricting the family relationship space to the new Default feature choice.  Then at S872, the configuration engine 106\nsets relWork to the intersection of relWork and relTemp.  At S874, the configuration engine 106 evaluates relWork to determine if it has a single path, i.e., a \"singleton.\" If the standard features (relWork) is a singleton, the configuration engine 106\nproceeds to S876 and uses quick restrict to restrict the main space using the single bitmask from relWork; and then resets relWork to be trivial (all 1s) at S878.  After S878, or in response to a negative determination at S868 or S874, the configuration\nengine 106 proceeds to S880 and returns to the main maximally standard routine of FIG. 95.\nWith reference to FIGS. 100-101, deterministic relationships are used to enable efficient creation and storage of the full buildable space.  As described previously, the global buildable space can be stored in a Global MDD that has a main space\n(e.g., an MDD) and a set of relationship spaces (e.g., MDDs).  Maximally standard auto completion requires standard feature conditions.  The buildable space (FIG. 100) and Standard Feature Conditions (FIG. 101) are shown as Tables 10000 and 10100,\nrespectfully, and combined in a single Buildable object.\nThere is no concept of displayable and non-displayable families during MDD generation.  Displayable families refer to content this is displayed to the user, for example paint color is displayed to a user in a build and price application. \nWhereas non-displayable families refer to content that is not displayed to the user, such as an electrical harness in a build and price application.  A Superconfiguration Generator (SCG) library (not shown) is a component of the ETL 128 (FIG. 2).  The\nSCG library simply finds all relationships in order to generate the smallest possible main space.\nSome algorithms that target displayable content (e.g., validation and feature state mapper) have been optimized to work on a single MDD, and others require all displayable content to be in a single MDD (e.g., minimum edit).  Valid input for the\nconfigurator is a global space where no displayable families have been pulled to an external relationship, even if it is deterministic.\nOne possible way to build a global space that conforms to the configurator input is to control which families can be deterministic.  The SCG algorithm includes an argument called relignore which can be used to specify which families are not\nallowed to be deterministic.  This argument can be used to specify that displayable families are not allowed to be deterministic.\nAnother approach is to allow SCG to build the MDD by pulling out whatever relationships it finds.  Then, an extra step is used before the space can be used by the configurator.  Any relationship that defines a display family dependence on the\nmain MDD is flattened back into the main MDD.  To do this efficiently, the MDD is recompressed as the relationships are flattened.\nGenerally both approaches will take the same amount of processing time.  In the second approach, the MDD may be generated much faster, but that any time savings is used in the extra flattening step.\nThe configuration engine 106 will be validating two types of configurations--a configuration of displayable features only or an expanded configuration of displayable and no display features.\nTo validate a configuration of displayable features the relationships can be ignored because the configuration engine 106 does not allow any displayable family to be deterministic.  This means that the main MDD contains all of the information\nnecessary to define feature combinations from the displayable families.  There is no information in the relationships that will shrink the space of displayable families that is defined in the main MDD.  Thus, only the main MDD is used to validate a\nconfiguration of display family features.  To validate a configuration of displayable families, simply call contains operation on the main MDD.\nTo validate a configuration that contains displayable and no-display features, both the main MDD and the relationships are inspected.  Just as the MDD containsAny operation is used to validate a configuration against an MDD, the Global MDD also\nhas a containsAny operation that can validate a configuration against a Global MDD.  The Global MDD operation utilizes the MDD containsAnyParallel operation, to validate a fully expanded configuration, the parallel operation will turn the mask into its\nown MDD and inspect that space along with the main space and all relationship MDDs.  To validate a partial configuration of both display and no display features, the parallel operation inspects the mask MDD, the main MDD and the relationships associated\nwith each deterministic feature in the configuration.  When processing a partial configuration, relationships for families that have no feature in the configuration can be ignored.\nFIG. 102 is a table 10200 that shows several example configurations, the relevant MDDs, and the containsAny call that the configuration engine 106 uses to validate the configuration.\nConflict resolution is also limited to displayable content.  As with the \"contains\" operation, when dealing with configurations that do not contain deterministic features, the main MDD contains sufficient information for the conflict resolution\nwithout including the relationships.\nAs described with reference to FIG. 47, conflict resolution begins with a minimum edit distance calculation that is performed on the main MDD.\nFor Single Conflict Resolution, the target configuration is identified by performing auto completion in the minimum edit space.  Because the main MDD includes no display content, the target configuration will also include no display content. \nThe no-display content is stripped from the configuration engine response.  Alternatively, the author decorators can be modified to ignore no-display features when adding conflict resolution to the xml response.\nFor Branched Conflict Resolution, the entire minimum edit space is used to build the response.  The minimum edit space is projected to displayable content before building the response.\nThere is no concept of displayable and non-displayable families during the first stage of authoring or determining the feature conditions.  As such, the feature conditions for displayable families may be determined with a dependency on\nno-display families.  This means that when the maximally standard auto completion algorithm uses the full configuration space; it accounts for the external relationship MDDs in addition to the main MDD.\nWhen using a Global Space (main space+relationships spaces) for maximally standard auto completion, the basic logic is the same as using an MDD.  Instead of checking a single MDD, the algorithm checks the global space--both the main MDD and the\nrelationship MDDs.  The basic operations of restrict, containsAny and domain accounts for both the main space and external relationships.\nDuring auto completion, the configuration engine 106 restricts the main space for each feature choice (S864).  When the choice is deterministic, the external relationship defines the determinant conditions for each feature.  The deterministic\nrelationship space is restricted to the feature choice to determine the determinant conditions and then the main space is restricted to the corresponding determinant conditions.\nWhen a deterministic feature has a single determinant condition, the configuration engine 106 quick-restricts the main space using the determinant condition, according to one or more embodiments (S874-S876).  The buildable space as shown in\nTable 10000 (FIG. 100) includes a main space 10002 and a relationships space 10004.  The relationships space 10004 shows that features Y2, Y5 and Y6 map to B1 as referenced by numeral 10006, and that features Y1, Y3, and Y4 map to B2 as referenced by\nnumeral 10008.  Table 10300 of FIG. 103 shows only one row remains after the relationship is restricted to the choice B1 (S870).  The configuration engine 106 quick-restricts the main space using this single superconfiguration as the bitmask.  After B1\nis chosen, the main space is restricted to B1 (S866) and is also restricted to Y2, Y5, and Y6 (S876), as shown in Table 10400 of FIG. 104, and referenced by numeral 10402.\nThe quick-restrict operation accepts a single bit mask.  This means that the main space cannot be quick-restricted to reflect a deterministic choice whenever a deterministic feature has multiple determinant conditions.  Table 10000 (FIG. 100)\nshows that family K is determined by two families [A,S] as referenced by numeral 10010.  Table 10500 of FIG. 105 shows the two rows defining the determinant conditions for feature K2.  The first row of Table 10500 shows that A2,S3; A2,S5; A2,S6 all map\nto K2 and the second row shows that A1,53 also maps to K2.  When K2 is chosen, the main space is restricted to K2, but the configuration engine 106 cannot quick-restrict it with the K2 determinants because the restricted relationship space defines two\nsuperconfigurations.  Instead, the configuration engine 106 adds a special relWork space, as referenced by numeral 10602, to store the determinant conditions as shown FIG. 106.  After restricting to K2, relWork contains the two determinant conditions for\nK2.\nJust as the global space requires both the main MDD and all its relationships to fully define the space, relWork is necessary to fully define the restricted space.  However, if relWork is trivial (i.e., all 1s) then the configuration engine 106\ncan ignore it because it isn't further restricting the space.\nThe configuration engine 106 initializes the relWork space as a trivial space, with a single superconfiguration of all 1s, according to one or more embodiments.  When a deterministic choice is made that has multiple determinant conditions,\nrelWork is AND'ed with the restricted relationship space (S872).  If the result of the AND operation is a single superconfiguration (S874), the main space is restricted with that superconfiguration (S876) and relWork is trivialized (S878).\nReferring to FIG. 107, if the configuration engine 106 further restricts the space to M2, then there is just one row remaining in relationship M as shown in Table 10700.  When this restricted relationship space is ANDed with relWork (from FIG.\n106), just one row remains as shown in Table 10800 of FIG. 108.  This is used to restrict the main space, and then relWork is reset, with the final result shown in Table 10900 of FIG. 109.\nThe configuration engine 106 uses the containsAny operation of the maximally standard auto completion algorithm to determine if a Standard feature condition space is still valid in the restricted space, according to one or more embodiments.\nFor two MDDs, the operation mdd1.containsAny(mdd2) is equivalent to not(isEmpty(mdd1.and(mdd2)).  The ContainsAny operation can be extended to operate on two or more MDDs and is called containsAnyParallel.  For three MDDs, the operation\nmdd1.containsAnyParallel([mdd2,mdd3]) is equivalent to not(isEmpty(mdd1.and(mdd2).and(mdd3)).\nWhen dealing with deterministic relationships, this contains any operation may need to include the relWork MDD.\nIn order for the configuration engine 106 to determine if a standard feature is available in the restricted space (S812), the containsAny operation must always operate on the standard space and the main space and may need to account for the\nrelWork space and an external relationship space.  When the family is deterministic and relWork is not trivial the operation will be standardSpace.containsAny(mainSpace, rel, relWork).  The operation can skip relWork if it is trivial and will only\ninclude a relationship if the feature is deterministic (S822).\nThe configuration engine 106 determines if any standard features for A are still valid in the space from FIG. 103, by accounting for the A standard space and the main space in the containsAny operation.  There is no relationship space because A\nis not deterministic and the relWork is ignored because it is trivial (i.e., A is all 1s in Table 10300).\nIn order for the configuration engine 106 to determine if any standard features for B are still valid in the space from FIG. 103, the containsAny operation must account for the B standard space, the main space and relationship B space.  The\nconfiguration engine 106 ignores relWork because it is trivial.\nThe configuration engine 106 determines if any standard features for M are still valid in the space from FIG. 106, by accounting for the M standard Space, main Space, Relationship M space, and relWork in the containsAny operation.\nThe maximally standard auto completion algorithm uses domain calculation when the standard feature conditions do not identify a possible choice.  Because only the domain of a single family is needed, not all of the relationships must be\nincluded.  The domain calculation must consider the main space, the relWork space, and, if the family is deterministic, the external relationship space.  This is done by first ANDing the spaces, and then calculating the domain on the resulting space\n(S850).\nThe algorithm for maximally standard auto completion without deterministic relationships was shown previously in FIG. 93.\nThe modifications to account for deterministic relationships are: 1) Change mdd.quickRestrict to SPACE.RESTRICT; 2) Change mdd.containsAny with SPACE.containsAny, where space defines the main MDD, the relationship MDDs, and the relWork MDD\ndiscussed above in the Restrict Global Space section; and 3) Change mdd.findDomain.toListActive(Fa) to SPACE.findDomain(Fa).  The new algorithm is shown as flowcharts in FIGS. 95-99 and as software code in FIG. 110.\nThe following example illustrates the modified algorithm and references steps in the flow charts and operations in the software code where applicable.  This example will use the global space and standard feature conditions defined previously in\nTable 10000 (FIG. 100) and Table 10100 (FIG. 101).  Table 10100 also lists the family priority order, as generally referenced by numeral 10102.\nWith reference to FIG. 111, the configuration engine 106 restricts the space starting with a minimally complete configuration of Selected {Y3,E1,P1}+Included {F2} (11001, FIG. 110; S802, FIG. 95).  The configuration engine 106 makes Default\nchoices for the remaining families in priority order as defined in Table 10100 (FIG. 101), i.e.: V, R, K, B, A, M, T, I, S (S804, FIG. 95).\nReferring to FIG. 112, the configuration engine 106 determines that Family V is deterministic and includes a single standard feature condition.  To determine if standard feature V3 is available, the configuration engine 106 checks the main\nspace, standard space and deterministic relationship (S820, FIG. 97).  Operation 11004 (FIG. 110) stdV3.containsAnyParallel(mainSpace, relV) returns false because V3 is not available with the current choice Y3 (see also S840, FIG. 96).  The domain of V,\nfrom operation 1106 (FIG. 110) AND(relV,mainSpace), will identify only one possible choice (see also S852-S858, FIG. 98).  V2 is added and the newly restricted space, as determined at S864, FIG. 96 and operation 11008, FIG. 110, is shown in Table 11200\nof FIG. 112 and referenced by numeral 11202.\nWith reference to FIGS. 112-113, the configuration engine 106 determines that Family R has no standard feature conditions (S830-S836, FIG. 97; operation 11004, FIG. 110).  The domain of the restricted space identifies two possible choices--R1,\nR4 as referenced by numeral 11204 (S852-S858, FIG. 98; operation 1106, FIG. 110).  Without alternate sequencing, R1 is picked as the Default choice and the space is further restricted (S864, FIG. 99; operation 11008, FIG. 110) as shown in Table 11300 of\nFIG. 113, and referenced by numeral 11302.\nReferring back to FIG. 101, the configuration engine 106 determines that Family K has two standard feature conditions (S830-S836, FIG. 97; operation 11004, FIG. 110).  StdK1 defines K1 as standard for V1 and StdK2 defines K2 as standard for V2\nor V3.  Because V2 has been previously chosen, K2 is the only available standard choice and is added to the configuration.  The configuration engine 106 further restricts the space to reflect this choice (S864, FIG. 99; operation 11008, FIG. 110). \nFamily K is deterministic.  When RelK is restricted to K2, there are two rows remaining.  The main space cannot be quick-restricted and relWork is updated as shown in Table 11400 of FIG. 114.\nWith reference to FIG. 115, the configuration engine 106 adds B2 based on its Standard space and chooses A2 because it is standard with {R1, V2}.  The restricted space after these choices is shown in Table 11500 of FIG. 115.  Table 11500 shows\nthat the configuration engine 106 could restrict relWork to A2, minimize it to one row, use it to restrict the main space and then trivialize it; however, the containsAny optimizations (operation 11004, FIG. 110) dictate that it is actually better to\nwait until relWork is minimized by another deterministic feature.  It is actually counterproductive to restrict relWork for every choice.\nReferring to FIG. 116, the configuration engine 106 determines that Family M has standard feature conditions (S830-S836, FIG. 97; operation 11004, FIG. 110).  M1 is the only standard feature that is still available in the restricted space. \nAfter relWork is updated for M1, only one row remains, i.e., the second row of Table 11500 of FIG. 115.  This row is used to restrict the main space and relWork is trivialized, as shown by Table 11600 of FIG. 116 (S864, FIG. 99; operation 11008, FIG.\n110).  The restricted space after processing family M is shown in Table 11600.\nWith reference to FIG. 117, the configuration engine 106 adds T1 as the Default choice from its Standard Feature Condition and I1 is chosen as the Default from the possible choices I1 and I2 (S830-S836, FIG. 97; operation 11004, FIG. 110).  The\ndeterministic relationship for I shows that I1 maps to S1 or S5.  After T1 and I1 are chosen, S5 remains the only choice for family S, as shown in Table 11700 of FIG. 117.\nThe configuration engine's use of relWork to account for deterministic relationships when quick-restricting the main space, along with the containsAnyParallel operation, allows for a very efficient maximally standard auto completion algorithm. \nThis allows the configuration engine 106 to support maximally standard configurations without requiring feature condition authoring to be modified in order to account for display and no display families.\nComputing devices described herein, generally include computer-executable instructions where the instructions may be executable by one or more computing devices such as those listed above.  Computer-executable instructions may be compiled or\ninterpreted from computer programs created using a variety of programming languages and/or technologies, including, without limitation, and either alone or in combination, Java.TM., C, C++, C#, Visual Basic, Java Script, Perl, etc. In general, a\nprocessor (e.g., a microprocessor) receives instructions, e.g., from a memory, a computer-readable medium, etc., and executes these instructions, thereby performing one or more processes, including one or more of the processes described herein.  Such\ninstructions and other data may be stored and transmitted using a variety of computer-readable media.\nWhile exemplary embodiments are described above, it is not intended that these embodiments describe all possible forms of the invention.  Rather, the words used in the specification are words of description rather than limitation, and it is\nunderstood that various changes may be made without departing from the spirit and scope of the invention.  Additionally, the features of various implementing embodiments may be combined to form further embodiments of the invention.\n<BR><BR><CENTER><b>* * * * *</b></CENTER>\n<HR>\n   <CENTER>\n   <a href=http://pdfpiw.uspto.gov/.piw?Docid=10325063&homeurl=http%3A%2F%2Fpatft.uspto.gov%2Fnetacgi%2Fnph-Parser%3FSect1%3DPTO2%2526Sect2%3DHITOFF%2526p%3D1%2526u%3D%25252Fnetahtml%25252FPTO%25252Fsearch-bool.html%2526r%3D1%2526f%3DG%2526l%3D50%2526co1%3DAND%2526d%3DPTXT%2526s1%3D20170206576%2526OS%3D%2526RS%3D&PageNum=&Rtype=&SectionNum=&idkey=NONE&Input=View+first+page><img src=\"/netaicon/PTO/image.gif\" alt=\"[Image]\" border=\"0\" valign=\"middle\"></A>\n   <TABLE>\n   <TR><TD align=\"center\"><A href=\"https://certifiedcopycenter.uspto.gov/other/patft/view.html?backUrl1=http%3A//patft.uspto.gov/netacgi/nph-Parser?Sect1%3DPTO2%26Sect2%3DHITOFF%26p%3D1%26u%3D%25252Fnetahtml%25252FPTO%25252Fsearch-bool.html%26r%3D1%26f%3DG%26l%3D50%26co1%3DAND%26d%3DPTXT%26s1%3D20170206576%26OS%3D&backLabel1=Back%20to%20Document%3A%2010325063\"><IMG border=\"0\" src=\"/netaicon/PTO/cart.gif\" border=\"0\" valign=\"m\niddle\" alt=\"[View Shopping Cart]\"></A>\n   <A href=\"https://certifiedcopycenter.uspto.gov/other/patft/order.html?docNumber=10325063&backUrl1=http%3A//patft.uspto.gov/netacgi/nph-Parser?Sect1%3DPTO2%26Sect2%3DHITOFF%26p%3D1%26u%3D%25252Fnetahtml%25252FPTO%25252Fsearch-bool.html%26r%3D1%26f%3DG%26l%3D50%26co1%3DAND%26d%3DPTXT%26s1%3D20170206576%26OS%3D&backLabel1=Back%20to%20Document%3A%2010325063\">\n   <IMG border=\"0\" src=\"/netaicon/PTO/order.gif\" valign=\"middle\" alt=\"[Add to Shopping Cart]\"></A>\n   </TD></TR>\n   <TR><TD align=\"center\">\n   <A href=\"#top\"><IMG valign=\"middle\" src=\"/netaicon/PTO/top.gif\" border=\"0\" alt=\"[Top]\"></A>\n   </TD></TR>\n   </TABLE>\n   <A name=\"bottom\"></A>\n   <A href=\"/netahtml/PTO/index.html\"><IMG src=\"/netaicon/PTO/home.gif\" alt=\"[Home]\" border=\"0\" valign=\"middle\"></A>\n   <A href=\"/netahtml/PTO/search-bool.html\"><IMG src=\"/netaicon/PTO/boolean.gif\" alt=\"[Boolean Search]\" border=\"0\" valign=\"middle\"></A>\n   <A href=\"/netahtml/PTO/search-adv.htm\"><IMG border=\"0\" src=\"/netaicon/PTO/manual.gif\" alt=\"[Manual Search]\" valign=\"middle\"></A>\n   <A href=\"/netahtml/PTO/srchnum.htm\"><IMG src=\"/netaicon/PTO/number.gif\" alt=\"[Number Search]\" border=\"0\" valign=\"middle\"></A>\n   <A href=\"/netahtml/PTO/help/help.htm\"><IMG border=\"0\" src=\"/netaicon/PTO/help.gif\" alt=\"[Help]\" valign=\"middle\"></A>\n   </CENTER>\n</BODY>\n</HTML", "application_number": "15294217", "abstract": " A system is provided with memory and a processor. The memory is\n     configured to store data representative of a multi-valued decision\n     diagram (MDD). The processor is in communication with the memory and is\n     programmed to receive a current selection of one or more of the features,\n     and to determine a feature state for each of the one or more features,\n     based on the current selection and the possible configurations defined by\n     the MDD. The processor is further programmed to calculate an availability\n     bitset indicative of which features as available for further selection,\n     consistent with the valid configurations and without violating existing\n     constraints of the current selection.\n", "citations": ["4479197", "4591983", "4827423", "4873643", "4875162", "5119307", "5165015", "5225987", "5233513", "5255356", "5257387", "5260866", "5283865", "5293479", "5295067", "5295242", "5307261", "5311424", "5311437", "5353432", "5367622", "5367627", "5369566", "5394522", "5428791", "5434791", "5487135", "5499357", "5500802", "5515269", "5515524", "5546575", "5552995", "5579529", "5586039", "5590319", "5594651", "5621905", "5630025", "5675748", "5740425", "5745765", "5761063", "5777877", "5781906", "5815395", "5825651", "5844554", "5850539", "5864660", "5877966", "5963953", "5987473", "5991826", "6002854", "6035305", "6055529", "6115547", "6122560", "6125408", "6137499", "6151697", "6167380", "6167383", "6177942", "6192355", "6205446", "6208987", "6223094", "6223170", "6247128", "6259451", "6272390", "6278982", "6282537", "6300948", "6324534", "6349274", "6366922", "6377956", "6405308", "6407761", "6412012", "6430730", "6519588", "6523040", "6536014", "6549908", "6556991", "6557002", "6581068", "6615220", "6633788", "6647305", "6678882", "6687705", "6757678", "6810401", "6836766", "6839711", "6850895", "6850921", "6853996", "6898472", "6918124", "6937966", "6938038", "6965887", "6986104", "6988014", "7003360", "7039602", "7043309", "7050956", "7062478", "7065499", "7069537", "7076507", "7076521", "7082426", "7093010", "7096350", "7096465", "7107297", "7127424", "7188333", "7188335", "7200582", "7225038", "7225197", "7233885", "7237187", "7246087", "7328177", "7337174", "7337179", "7343212", "7343584", "7386562", "7424444", "7461049", "7464064", "7487072", "7509326", "7516103", "7567922", "7580871", "7584079", "7650296", "7698170", "7760746", "7797177", "7809758", "7860690", "7869981", "7873503", "7882057", "7930149", "7953639", "7953767", "7953779", "7992145", "7996329", "8078489", "8249885", "8280700", "8306795", "8463682", "8665731", "8805825", "8918750", "9020880", "9098854", "20020013775", "20020035463", "20020052803", "20020095348", "20020107861", "20020116417", "20020124005", "20020143653", "20020161668", "20020165701", "20020177911", "20020184308", "20030041088", "20030046047", "20030055751", "20030061238", "20030069737", "20030130749", "20030177412", "20030195806", "20030216951", "20040064441", "20040068485", "20040073436", "20040073448", "20040102995", "20040162835", "20040167906", "20050071146", "20050080648", "20050114158", "20050163143", "20050268255", "20060064685", "20060095711", "20060100829", "20070094204", "20090323539", "20110082675", "20120253754", "20140019739", "20150120490", "20150331974", "20150379442"], "related": ["62352463", "62280609"]}, {"id": "20170206577", "patent_code": "10318702", "patent_name": "Multi-valued decision diagram reversible restriction", "year": "2019", "inventor_and_country_data": " Inventors: \nHunsaker; Melinda Kaye (Canton, MI), Sprague; Rickie Allan (Gladwin, MI)  ", "description": "<BR><BR>CROSS-REFERENCE TO RELATED APPLICATIONS\nThis application claims the benefit of U.S. provisional application Ser.\n     No. 62/280,609 filed Jan. 19, 2016 and U.S. provisional application Ser.\n     No. 62/352,463 filed Jun. 20, 2016, the disclosures of which are hereby\n     incorporated in their entirety by reference herein.\n         <HR>\n<CENTER><b><i>Claims</b></i></CENTER> <HR> <BR><BR>What is claimed is: 1.  A method comprising: storing, in a memory, a cached copy of data representative of a multi-valued decision diagram (MDD), the MDD indicating a Boolean function specifying\na buildable space of all possible configurations of features of a vehicle, the MDD including a root node, a truth node, a false node, and at least one level of intervening nodes between the root node and either the truth node or the false node, each\nlevel of the MDD corresponding to a family of mutually-exclusive features represented by at least one node, each node except for the truth node and the false node connecting to nodes of a next adjacent level by outgoing edges having labels each\nindicating one or more features of the family that are available for the possible configurations including the node, each node except for the root node connecting to nodes of a prior adjacent level by incoming edges that are outgoing edges of the prior\nadjacent level, such that a complete path from the root node through the outgoing edges to the truth node defines one valid configuration, wherein each complete path from the root node to the truth node is of the same length in nodes when there are no\nlong edges;  generating a working copy of the data from the cache;  and generating a restricted buildable space in the working copy of the data while traversing the MDD by receiving from a user a current selection of a partial configuration comprising\none or more families with one feature selected for each family, wherein the partial configuration has been validated as a valid configuration, identifying from the labels of the outgoing edges those features that would result in an invalid configuration\nof the vehicle, removing those identified features from the MDD by pointing corresponding outgoing edges to the false node, disconnecting outgoing edges having no remaining available features, and replacing nodes that have no outgoing edges with the\nfalse node by pointing corresponding incoming edges to the false node;  generating a domain for the restricted buildable space as defining all of the available features of the vehicle according to the remaining connected nodes of the MDD;  presenting to\nthe user features available for selection;  receiving from the user, selection of one of the available features for a next family and setting that feature in the partial configuration as Selected resulting in a new partial configuration;  performing\nvalidation of the new partial configuration using a configuration engine;  if the new partial configuration is invalid, prompting the user to make changes, or allowing the configuration engine to make the changes according to a predefined hierarchy; \nsetting the new partial configuration as the partial configuration and the current selection;  and repeating the process starting from generating a restricted buildable space in the working copy of the data until all families are included in the valid\nconfiguration.\n2.  The method of claim 1, wherein generating the domain is performed within the same traversal of the MDD generating the restricted buildable space.\n3.  The method of claim 2, wherein generating the domain and restricted buildable space is performed using a single depth-first traversal of the MDD.\n4.  The method of claim 1, wherein for each level of intermediate nodes, each outgoing label of a node indicates a bitset specifying a bit for each mutually-exclusive feature of the family of features of the level of the node, such that\navailable feature are indicated in the bitset by a first value, and unavailable features are indicated in the bitset by a second value.\n5.  The method of claim 4, wherein disconnecting outgoing edges having no remaining available features includes disconnecting outgoing edges having outgoing labels indicating bitsets where the value of each feature in the bitset is the second\nvalue.\n6.  The method of claim 1, further comprising: saving, to the memory, the edges of the working copy of the MDD before generating the restricted buildable space;  and restoring the buildable space of all possible configurations by copying the\nsaved edges from the memory back to the working copy of the MDD.\n7.  The method of claim 1, further comprising responsive to a request to a configurator application, creating the working copy of the MDD by copying each node and each outgoing edge of the MDD.\n8.  A system comprising: a memory configured to store a cached copy of data representative of a multi-valued decision diagram (MDD), the MDD indicating a Boolean function specifying a buildable space of all possible configurations of features of\na vehicle, the MDD including a root node, a truth node, a false node, and at least one level of intervening nodes between the root node and either the truth node or the false node, each level of the MDD corresponding to a family of mutually-exclusive\nfeatures represented by at least one node, each node except for the truth node and the false node connecting to nodes of a next adjacent level by outgoing edges having labels each indicating one or more features of the family that are available for the\npossible configurations including the node, each node except for the root node connecting to nodes of a prior adjacent level by incoming edges that are outgoing edges of the prior adjacent level, such that a complete path from the root node through the\noutgoing edges to the truth node defines one valid configuration, wherein each complete path from the root node to the truth node is of the same length in nodes when there are no long edges;  and a processor in communication with the memory, programmed\nto: generate a working copy of the data from the cache;  and generate a restricted buildable space in the working copy of the data while traversing the MDD by receiving from a user a current selection of a partial configuration comprising one or more\nfamilies with one feature selected for each family, wherein the partial configuration has been validated as a valid configuration, identifying from the labels of the outgoing edges those features that would result in an invalid configuration of the\nvehicle, removing those identified features from the MDD by pointing corresponding outgoing edges to the false node, disconnecting outgoing edges having no remaining available features, and replacing nodes that have no outgoing edges with the false node\nby pointing corresponding incoming edges to the false node;  generating a domain for the restricted buildable space as defining all of the available features of the vehicle according to the remaining connected nodes of the MDD;  presenting to the user\nfeatures available for selection;  receiving from the user, selection of one of the possible features for a next family and setting that feature in the partial configuration as Selected resulting in a new partial configuration;  performing validation of\nthe new partial configuration using a configuration engine;  if the new partial configuration is invalid, prompting the user to make changes, or allowing the configuration engine to make the changes according to a predefined hierarchy;  setting the new\npartial configuration as the partial configuration and the current selection;  and repeating the process starting from generating a restricted buildable space in the working copy of the data until all families are included in the valid configuration.\n9.  The system of claim 8, wherein the processor is further programmed to generate the domain, within the same traversal of the MDD generating the restricted buildable space.\n10.  The system of claim 8, wherein generating the domain and restricted buildable space is performed using a single depth-first traversal of the MDD.\n11.  The system of claim 8, wherein for each level of intermediate nodes, each outgoing label of a node indicates a bitset specifying a bit for each mutually-exclusive feature of the family of features of the level of the node, such that\navailable feature are indicated in the bitset by a first value, and unavailable features are indicated in the bitset by a second value.\n12.  The system of claim 11, wherein disconnecting outgoing edges having no remaining available features includes to disconnect outgoing edges having outgoing labels indicating bitsets where the value of each feature in the bitset is the second\nvalue.\n13.  The system of claim 8, wherein the processor is further programmed to: save, to the memory, the edges of the working copy of the MDD before generating the restricted buildable space;  and restore the buildable space of all possible\nconfigurations by copying the saved edges from the memory back to the working copy of the MDD.\n14.  The system of claim 8, wherein the processor is further programmed to, responsive to a request to a configurator application, create the working copy of the MDD by copying each node and each outgoing edge of the MDD.\n15.  The system of claim 8, wherein the processor is further programmed to expand long edges of the working copy prior to generating the restricted buildable space. <HR> <CENTER><b><i>Description</b></i></CENTER> <HR> <BR><BR>TECHNICAL FIELD\nOne or more embodiments generally relate to systems and methods for configuring a product.\n<BR><BR>BACKGROUND\nProduct configuration is an aspect of industries that offer customizable products with a wide variety of features.  The process of selecting a configuration, or features that include a configuration, is used in multiple aspects of marketing and\nsales, order management and production planning, and product development.  Examples include virtually constructing an ideal product (e.g., a vehicle) using a build-and-price application or selecting features for a prototype.\nThe product definition or product offering in the automotive industry is often of staggering dimensionality and size.  It is common for a vehicle to be offered with thirty or more optional feature categories, such as paint color, engine size,\nradio type, and wheel style.  Allowing a user to quickly explore a complex space that could include more than 10.sup.30 valid configurations is a challenging problem in constraints programming.\n<BR><BR>SUMMARY\nIn one embodiment, a method is provided for storing, in a memory, a cached copy of data representative of a multi-valued decision diagram (MDD).  The MDD indicates a Boolean function specifying a buildable space of all possible configurations of\nfeatures of a vehicle.  The MDD includes a root node, a truth node, a false node, and at least one level of intervening nodes between the root node and either the truth node or the false node.  Each level of the MDD corresponds to a family of\nmutually-exclusive features represented by at least one node.  And each node except for the truth node and the false node connects to nodes of a next adjacent level by outgoing edges having labels each indicating one or more features of the family that\nare available for the valid configurations including the node.  Each node except for the root node connects to nodes of a prior adjacent level by incoming edges that are outgoing edges of the previous level, such that a complete path from the root node\nthrough the outgoing edges to the truth node defines at least one of the valid configurations.  And each complete path from the root node to the truth node is of the same length in nodes when there are no long edges.  A working copy of the data is\ngenerated from the cache.  A restricted buildable space is generated in the working copy of the data while traversing the MDD by removing available features from the labels of the outgoing edges deemed invalid according to a feature selection,\ndisconnecting outgoing edges having no remaining available features, and replace nodes that have no outgoing edges with the false node.\nIn another embodiment, a system is provided with a memory and a processor.  The memory is configured to store a cached copy of data representative of a multi-valued decision diagram (MDD).  The MDD indicates a Boolean function specifying a\nbuildable space of all possible configurations of features of a vehicle.  The MDD includes a root node, a truth node, a false node, and at least one level of intervening nodes between the root node and either the truth node or the false node.  Each level\nof the MDD corresponds to a family of mutually-exclusive features represented by at least one node.  Each node except for the truth node and the false node connects to nodes of a next adjacent level by outgoing edges having labels each indicating one or\nmore features of the family that are available for the valid configurations including the node.  Each node except for the root node connecting to nodes of a prior adjacent level by incoming edges that are outgoing edges of the previous level, such that a\ncomplete path from the root node through the outgoing edges to the truth node defines at least one of the valid configurations.  And each complete path from the root node to the truth node is of the same length in nodes when there are no long edges.  The\nprocessor is in communication with the memory, and programmed to generate a working copy of the data from the cache.  The processor is further programmed to generate a restricted buildable space in the working copy of the data while traversing the MDD\nincluding to remove available features from the labels of the outgoing edges deemed invalid according to a feature selection, disconnect outgoing edges having no remaining available features, and replace nodes that have no outgoing edges with the false\nnode. <BR><BR>BRIEF DESCRIPTION OF THE DRAWINGS\nFIG. 1 is a block diagram of a product configuration system, according to one or more embodiments;\nFIG. 2 is an application programming interface illustrating an application of the product configuration system of FIG. 1 including a configuration engine;\nFIG. 3 is a table illustrating configurations expressed in conjunctive normal form;\nFIG. 4 is a table illustrating configurations expressed in conjunctive normal form and in binary form;\nFIG. 5 is a table illustrating mappings of the configurations of FIG. 4;\nFIG. 6 is a table illustrating multiple configurations and a superconfiguration;\nFIG. 7 is a table illustrating multiple superconfigurations;\nFIG. 8 is a table illustrating the interaction of superconfigurations;\nFIG. 9 is another table illustrating the interaction of superconfigurations;\nFIG. 10 is a table depicting a buildable space according to one or more embodiments;\nFIG. 11 is a table depicting overlapping configurations;\nFIG. 12 is a table depicting a feature mask;\nFIG. 13 is a multi-valued decision diagram (MDD) representing the buildable space of FIG. 10, according to one or more embodiments;\nFIG. 14 is a comparison table;\nFIG. 15 is a diagram illustrating a reduction of the MDD of FIG. 13;\nFIG. 16 is a diagram illustrating merging of duplicate MDD nodes;\nFIG. 17 is a diagram illustrating MDD compression with deterministic families;\nFIG. 18 is a window displayed to a user based on a conflict resolution procedure of the configuration engine of FIG. 2 according to one embodiment;\nFIG. 19 is a window displayed to the user based on a conflict resolution procedure of the configuration engine of FIG. 2 according to another embodiment;\nFIG. 20 is a diagram illustrating a containsAny operation performed by the configuration engine according to one embodiment;\nFIG. 21 is another diagram illustrating a containsAny operation performed by the configuration engine according to another embodiment;\nFIG. 22 is a table listing a restricted buildable space of the buildable space in FIG. 10;\nFIG. 23 is a diagram illustrating a restricted buildable space of the buildable space in FIG. 13 and the table of FIG. 22;\nFIG. 24 is a flowchart illustrating a method for evaluating an MDD using reversible restrictions, according to one or more embodiments;\nFIG. 25 is a diagram illustrating an example of various steps of the method of FIG. 24;\nFIG. 26 is a flowchart illustrating a subroutine of the method of FIG. 24;\nFIG. 27 is another flowchart illustrating a subroutine of the method of FIG. 24;\nFIG. 28 is yet another flowchart illustrating a subroutine of the method of FIG. 24;\nFIG. 29 is a comparison table;\nFIG. 30 is a table illustrating a reduction of the buildable space of FIG. 10;\nFIG. 31 is a table illustrating a projected space after the overlap has been removed and the space has been compressed;\nFIG. 32 is a diagram illustrating the table of FIG. 30;\nFIG. 33 is a table illustrating combinations of features of the buildable space of FIG. 13;\nFIG. 34 is a flowchart illustrating a method for determining MDD feature states according to one or more embodiments;\nFIG. 35 is a table illustrating a set of superconfigurations;\nFIG. 36 is an example of a table illustrating a restricted domain after various steps of the method of FIG. 34;\nFIG. 37 is another example of a table illustrating a restricted domain after various steps of the method of FIG. 34;\nFIG. 38 is a table illustrating an example of the results of the method of FIG. 34;\nFIG. 39 is a flowchart illustrating another method for determining MDD feature states according to one or more embodiments;\nFIG. 40 is a flowchart illustrating a subroutine of the method of FIG. 39;\nFIG. 41 is another flowchart illustrating a subroutine of the method of FIG. 39;\nFIG. 42 is yet another flowchart illustrating a subroutine of the method of FIG. 39;\nFIG. 43 is another flowchart illustrating a subroutine of the method of FIG. 39;\nFIG. 44 is yet another flowchart illustrating a subroutine of the method of FIG. 39;\nFIG. 45 is a diagram illustrating an example of various steps of the method of FIG. 39;\nFIG. 46 is another diagram illustrating an example of various steps of the method of FIG. 39;\nFIG. 47 is a flowchart illustrating a method for resolving conflicts between configurations according to one or more embodiments;\nFIG. 48 is a flowchart illustrating a subroutine of the method of FIG. 47;\nFIG. 49 is a diagram illustrating an example of various steps of the method of FIG. 47;\nFIG. 50 is another flowchart illustrating a subroutine of the method of FIG. 47;\nFIG. 51 is yet another flowchart illustrating a subroutine of the method of FIG. 47;\nFIG. 52 is still yet another flowchart illustrating a subroutine of the method of FIG. 47;\nFIG. 53 is a table illustrating an example of additions and subtractions for the diagram of FIG. 49 according to various steps of the method of FIG. 47;\nFIG. 54 is a window illustrating an example of additions and subtractions that are displayed to the user based on various steps of the method of FIG. 47 according to one embodiment;\nFIG. 55 is a window illustrating an example of additions and subtractions that are displayed to the user based on various steps of the method of FIG. 47 according to another embodiment;\nFIG. 56 is a table illustrating a compression of three superconfigurations to two superconfigurations, according to one embodiment;\nFIG. 57 is a window illustrating an example of a resolution object that is displayed to the user based on various steps of the method of FIG. 47 according to another embodiment;\nFIG. 58 is another flowchart illustrating a subroutine of the method of FIG. 47;\nFIG. 59 is yet another flowchart illustrating a subroutine of the method of FIG. 47;\nFIG. 60 is still yet another flowchart illustrating a subroutine of the method of FIG. 47;\nFIG. 61 is another flowchart illustrating a subroutine of the method of FIG. 47;\nFIG. 62 is yet another flowchart illustrating a subroutine of the method of FIG. 47;\nFIG. 63 is still yet another flowchart illustrating a subroutine of the method of FIG. 47;\nFIG. 64 is a diagram illustrating an example of various steps of the method of FIG. 47;\nFIG. 65 is a table listing an invalid configuration as a bitset;\nFIG. 66 is a table illustrating the minimum edit space of the configuration of FIG. 65 converted to a matrix, as determined by various steps of the method of FIG. 47;\nFIG. 67 is a table illustrating a bitwise conjunction (AND) of the domain of the edit space from FIG. 66 with the invalid configuration from FIG. 65;\nFIG. 68 is a table illustrating the minimum edit space from FIG. 66 after it is trimmed to the families to change from FIG. 67;\nFIG. 69 is an example target matrix for a selection of a feature as determined by various steps of the method of FIG. 47;\nFIG. 70 is an example target matrix for a selection of another feature as determined by various steps of the method of FIG. 47;\nFIG. 71 is software code illustrating an example final resolution object, according to one or more embodiments;\nFIG. 72 is a window illustrating an example prompt provided to the user as part of a guided resolution;\nFIG. 73 is a window illustrating an example of another prompt provided to the user as part of the guided resolution;\nFIG. 74 is a window illustrating an example of yet another prompt provided to the user as part of the guided resolution;\nFIG. 75 is a diagram illustrating an example of various steps of the remove partial matches subroutine of FIG. 58;\nFIG. 76 is a table illustrating an example of various steps of the remove partial matches subroutine of FIG. 58;\nFIG. 77 is a table illustrating an example of various steps of the minimum edit space calculation of FIG. 48;\nFIG. 78 is another table illustrating an example of various steps of the minimum edit space calculation of FIG. 48;\nFIG. 79 is yet another table illustrating an example of various steps of the minimum edit space calculation of FIG. 48;\nFIG. 80 is still yet another table illustrating an example of various steps of the minimum edit space calculation of FIG. 48;\nFIG. 81 is another table illustrating an example of various steps of the minimum edit space calculation of FIG. 48;\nFIG. 82 is a flow chart illustrating a method for automatically completing a configuration according to one or more embodiments;\nFIG. 83 is a diagram illustrating a buildable space;\nFIG. 84 is a table that defines an alternate sequence structure for defining path weights of the buildable space of FIG. 83;\nFIG. 85 is a diagram illustrating an example of various steps of the method of FIG. 82 performed on the buildable space of FIG. 83;\nFIG. 86 is table illustrating path weight;\nFIG. 87 is another table illustrating path weight;\nFIG. 88 is yet another table illustrating path weight;\nFIG. 89 is a diagram illustrating an example of various steps of the method of FIG. 82 performed on the buildable space of FIG. 85;\nFIG. 90 is another table illustrating path weight;\nFIG. 91 is a table illustrating a matrix that defines the same buildable space as the diagram of FIG. 17;\nFIG. 92 is a table illustrating the standard feature conditions for the product definition defining the buildable space of FIG. 91;\nFIG. 93 is software code illustrating a method for automatically completing a configuration using a maximally standard algorithm according to one or more embodiments;\nFIG. 94 is a diagram illustrating an example of various steps of the method of FIG. 93;\nFIG. 95 is a flowchart illustrating another method for automatically completing a configuration using a maximally standard algorithm according to one or more embodiments;\nFIG. 96 is a flowchart illustrating a subroutine of the method of FIG. 95;\nFIG. 97 is another flowchart illustrating a subroutine of the method of FIG. 95;\nFIG. 98 is yet another flowchart illustrating a subroutine of the method of FIG. 95;\nFIG. 99 is still yet another flowchart illustrating a subroutine of the method of FIG. 95;\nFIG. 100 is a table illustrating a buildable space;\nFIG. 101 is a table illustrating standard feature conditions;\nFIG. 102 is a table illustrating an example of various steps of the method of FIG. 95;\nFIG. 103 is another table illustrating an example of various steps of the method of FIG. 95;\nFIG. 104 is yet another table illustrating an example of various steps of the method of FIG. 95;\nFIG. 105 is still yet another table illustrating an example of various steps of the method of FIG. 95;\nFIG. 106 is another table illustrating an example of various steps of the method of FIG. 95;\nFIG. 107 is yet another table illustrating an example of various steps of the method of FIG. 95;\nFIG. 108 is still yet another table illustrating an example of various steps of the method of FIG. 95;\nFIG. 109 is another table illustrating an example of various steps of the method of FIG. 95;\nFIG. 110 is software code illustrating an example of various steps of the method of FIG. 95;\nFIG. 111 is another table illustrating an example of various steps of the method of FIG. 95;\nFIG. 112 is yet another table illustrating an example of various steps of the method of FIG. 95;\nFIG. 113 is still yet another table illustrating an example of various steps of the method of FIG. 95;\nFIG. 114 is another table illustrating an example of various steps of the method of FIG. 95;\nFIG. 115 is yet another table illustrating an example of various steps of the method of FIG. 95;\nFIG. 116 is still yet another table illustrating an example of various steps of the method of FIG. 95; and\nFIG. 117 is another table illustrating an example of various steps of the method of FIG. 95.\n<BR><BR>DETAILED DESCRIPTION\nAs required, detailed embodiments of the present invention are disclosed herein; however, it is to be understood that the disclosed embodiments are merely exemplary of the invention that may be embodied in various and alternative forms.  The\nfigures are not necessarily to scale; some features may be exaggerated or minimized to show details of particular components.  Therefore, specific structural and functional details disclosed herein are not to be interpreted as limiting, but merely as a\nrepresentative basis for teaching one skilled in the art to variously employ the present invention.\nWith reference to FIG. 1, a product configuration system is illustrated in accordance with one or more embodiments and generally referenced by numeral 100.  The product configuration system 100 includes a server 102 and a configurator\napplication 104.  The configurator application 104 includes a configuration engine 106.  The server 102 includes memory 108 and a processor 110 for storing and operating the configurator application 104.  The product configuration system 100 communicates\nwith a user device, such as a personal computer 112 and/or a mobile device 114 (e.g., a tablet, a mobile phone, and the like), each of which include memory and a processor.  The configurator application 104 includes a \"front-end\" application (shown in\nFIG. 2) that may be installed to the user device 112, 114 from a computer-readable storage medium such as a CD-ROM, DVD or USB thumb drive.  Alternatively, the front-end application may be downloaded from the server 102 to the client device 112, 114 via\nan internet connection 116.  The design and efficiency of the application 104 therefore allows it to be optimized to run on multiple various operating system platforms and on devices having varying levels of processing capability and memory storage.\nThe configurator application 104 allows a user to explore a product offering, where the product is defined by selecting multiple features.  A common example is a build-and-price website that allows a user to customize a product by choosing\nfeatures such as size and color.  The configuration engine 106 validates the customized product (i.e., the configuration) as the user selects different features.\nThe product offering, or product definition, includes all of the allowed ways of combining features (or parts, options, or attributes) in order to make a complete product.  For example, a company might sell a product in two levels (e.g., base\nand luxury), A1 and A2, and in three colors, B1, B2 and B3.  Further, the company only offers the base model, A1, in one color, B1.  Features are grouped into families, in this case family A-\"level\" and family B-\"color.\" The product configuration space\nincludes the following four configurations: A1B1, A2B1, A2B2, and A2B3.  Product definition often comprises rules or constraints that limit or allow relationships between features.  In this example the rule might be \"A1 requires B1.\" A complex product\ncan be defined by thousands or even tens of thousands of rules.\nThe configurator application 104 allows the user to select options or features to create or modify a configuration.  When a user changes a configuration by adding and/or removing a feature, the configuration engine 106 validates the new\nconfiguration.  To perform this validation, the configuration engine 106 determines if the selected configuration fits within the allowed product space.  If the new configuration is invalid, the configuration engine 106 either prompts the user to make\nchanges, or make the changes itself according to a predefined hierarchy.  For example, the monitor of the personal computer 112 shown in FIG. 1 depicts a message window that is displayed to the user indicating changes to resolve the conflict between\nselected features.  The validation and conflict resolution is performed quickly (e.g., less than 2 seconds) and uses little memory and processing.  Ideally, this allows the user to explore the buildable space of allowable product configurations, often\nwhile viewing information associated with the configuration such as price or images.\nUsers interact with front-end applications that present the product information, e.g., on the monitor of their pc 112, and allow them to explore the buildable space.  Although, the configuration engine 106 is different from the front-end\napplication that is displayed on the pc 112, the applications interact closely with each other.  Examples of front-end applications include build-and-price websites, mobile shopping applications, interactive shopping kiosks, and back-office order entry\nand management systems.  When these front-end applications populate product information, they can communicate with the configuration engine 106.  The only people who interact directly with the configuration engine 106 are back-office users tending to the\ndata stored in the server 102.  The product configuration application 104 primarily interacts with other applications.\nIn the computer science field, exploration of a configuration space that is defined by rules or constraints is called constraint programming.  A configuration space can also be defined by a model that is a representation of the possible product\nconfigurations.  Many methods exist in the literature to solve configuration problems, with some using a constraints programming approach and others operating on product definition models.\nReferring to FIG. 2, an application programming interface (API) is illustrated in accordance with one or more embodiments, and generally referenced by numeral 120.  The API 120 illustrates the inputs, steps, and outputs of the configurator\napplication 104.  The configurator application 104 is contained within the server 102 and the user device (pc 112 and/or mobile device 114) according to one embodiment, and may be implemented using hardware and/or software control logic as described in\ngreater detail herein.\nThe configurator application 104 includes a database (DB) 122 for storing data as a catalog entry.  Each catalog entry will store the vehicle attributes (make, model, year, etc.), buildable product space, and extended feature attributes (images,\nprices, detailed descriptions, sales codes, etc.).  The data may be directly processed as is shown by a product definition data source 124, or it may come through a catalog management API 126.  The configurator application 104 also includes an extract,\ntransform and load (ETL) process 128 that provides an interface between the DB 122 and the product definition data source 124 and the catalog management API 126.  The configurator application 104 accesses data from the DB 122 and temporarily saves a copy\nof it in cache memory 130.\nThe configurator application 104 includes one or more \"front-end\" applications or \"top hats\" 132 that are accessible from the user device 112, 114.  Examples of such \"front-end\" applications 132 include consumer build and price sites, management\nlease ordering sites, and dealer ordering applications.\nThe configurator application 104 includes a service API 134 and a web service controller 136 for coordinating the user's requests.  The service API 134 includes a configuration service 138, an enumeration service 140 and a configuration details\nservice 142.\nThe configurator application 104 includes a plurality of processing engines 144, for optimizing the data provided to the front-end applications 132.  The engines include: the configuration engine 106, an image engine 146, a mapping engine 148\nand a pricing engine 150.  The image engine 146 provides one or more images associated with features of the configuration.  The mapping engine 148 provides feature codes from one or more feature code dictionaries.  For example, manufacturing systems and\nsales systems may use different codes for the same feature, and the mapping engine translates between the different coding schemes.  The pricing engine 150 provides pricing associated with the complete configurations and with individual features.  The\npricing engine 150 can also provide changes in pricing associated with changes in the configuration or features.\nThe configurator application 104 also includes a catalog controller 152 that lists which product definitions are available.  The catalog controller 152 receives a catalog request (e.g., what products are available), and provides a response\n(e.g., product A, product B and product C).  Then the user selects a product, and the front end application 132 submits a configuration load request.  Then the web service controller 136 returns a default configuration.\nThe web service controller 136 is a simple object access protocol (SOAP) web service using XML messages, according to one embodiment.  The service API 134 provides an XML request to the web service controller 136 based on each user selection\nmade in the front-end applications 132.  In other embodiments the web service controller 136 uses other protocol.\nThe web service controller 136 provides an XML response to the service API 134 in response to each XML request.  The web service controller 136 parses each XML request, makes appropriate calls to the processing engines 144 or catalog controller\n152, and transforms the output of the configuration engine 106, the image engine 146, the mapping engine 148 and the pricing engine 150 into the appropriate XML response.  The web service controller 136 includes author decorators 154 that are responsible\nfor building up each portion of the response, and includes logic to retrieve data from the database 122 via the cache 130 and save the data as a working copy.\nThe configuration engine 106 operates with reference to a valid buildable space.  The buildable space is also referred to as the product offering and is defined in terms of features that are grouped into mutually exclusive family sets.  All of\nthe possible features are grouped into families such that a valid configuration will contain one and only one feature from each family.\nIn one example product definition of a vehicle, (Vehicle A), exterior paint color is defined by the family PAA and its features are Green (PNWAD), Magnetic (PN4DQ), Blue1 (PNMAE), Red1 (PN4A7), Red2 (PNEAM), Black (PN3KQ), Silver (PN4AG), Orange\n(PN4AH), White (PNYW3), and Blue2 (PN4MAG).\nThe configurator application 104 uses extended feature attributes, or metadata associated with a feature, such as feature name and feature description when presenting the information to a user.  However, the configuration engine 106 uses feature\nand family codes.  A fully qualified feature is its \"family dot feature\" code, such as PAA.PNEAM to represent the paint family with paint color Red2.\nEach point of variation in the product specification can be considered a dimension where a value is selected.  The large number of these variation points on a motor vehicle results in many valid configurations.  Traditionally the large number of\nvalid configurations in this buildable space has been responsible for much computational effort to perform the configuration process, which may be referred to as \"the curse of dimensionality.\" The configuration system 100 provides improvements over\ntraditional systems because it operates efficiently even on highly complex buildable spaces, e.g. those containing more than 10.sup.24 valid configurations.\nA configuration is a particular product instance specified by a set of features.  Each feature belongs to exactly one family.  There may be at most one feature selected from each family.  A complete configuration contains exactly one feature\nfrom each and every family.  A partial configuration will include features from a subset of the families, and one or more families will not have a feature choice specified.\nIn a build and price application, the configuration engine 106 will typically work in complete configurations.  Partial configurations are useful for searching or filtering configurations, as would be done to find and amend orders in an order\nmanagement system.\nSome features are optional, such as moonroof, and a user may order a vehicle without the feature.  But, a complete configuration must still contain a choice for the family.  A \"less feature\" is used to specify the absence of an option.  For\nexample, Vehicle A, which has an optional power moonroof, the family (CHA) contains two features: without the moonroof (i.e., \"less moonroof\"--CHAAA) and with the moonroof (i.e., \"moonroof\"--CHAAC).  The buildable space defines all valid configurations.\nWith reference to FIGS. 3-5, a configuration can be expressed in a variety of different forms.  A configuration can be expressed in conjunctive normal form (CNF).  For example, in one embodiment, a product is defined by four families: A, B, C\nand D; where A, C, and D each have two possible choices, and B has three possible choices.  If there are no restrictions on what features can occur together (other than a single feature choice for each family), the set of choices can be defined as\n(A1|A2) & (B1|B2|B3) & (C1|C2) & (D1|D2).  For a full configuration, each clause will reduce to a single literal or selection for each family (e.g., A1, B1, C1, D1).\nFIG. 3 depicts a CNF Table 300 with two possible configurations.  The CNF table 300 includes a first CNF configuration 302 and a second CNF configuration 304.\nWith reference to FIG. 4, a configuration can also be expressed in binary form by a string of 0's and 1's, as depicted by Table 400.  In binary form, a zero (0) indicates the absence of a feature in a configuration, and a one (1) indicates the\npresence of a feature in the configuration.  For example, a first binary configuration 402 illustrates the first CNF configuration 302 in binary form, and a second binary configuration 404 illustrates the second CNF configuration 304 in binary form.  The\nliteral A2 is replaced with \"01\", as generally referenced by numeral 406.  Each column maps to a feature in the family: `0` in the first position indicates the feature A1 is not present in the first binary configuration 402, and `1` in the second\nposition indicates the feature A2 is present in the first binary configuration 402.  The first CNF configuration 302 (A2 & B2 & C1 & D2) is represented by the first binary configuration 402, where the ampersand (&) symbol is replaced by a space as a\ndelimiter between each family, i.e., \"01 010 10 01.\"\nA configuration space can be very large.  For example, a product definition with around 100 independent features could have over 10.sup.27 possible configurations.  If each configuration was stored as an uncompressed set of 0's and 1's, it would\ntake more than 12 billion Exabytes of memory to represent them all--which is not practical with the present day state of the art computer hardware.  Therefore the configurator application 104 uses compressed representation to facilitate computational\ntractability and efficiency within available memory.\nA bit is the basic unit of information in computing.  It can only have one of two values and is commonly represented as 0 or 1, or the Boolean values of false and true.  A bit set represents a vector or array of bits.  For example, Java has a\nnative utility class called \"BitSet\" that stores a set of bits with an array of values of a primitive 64-bit datatype called long.\nWith the rightmost position of the bit set index 0 and leftmost position index 8, 100101001 is equal to 1*2.sup.8+1*2.sup.5+1*2.sup.3+1*2.sup.0=256+32+8+1=297.  Thus the bit set 100101001 can be stored using the long (or integer) 297.  An array\nof 2 long values (-8929791190748339525, 8791258171646) can represent a bit set of 107 features: 11 01 11 010 100 01 10 00010 00010 111 01 010 01 11 000100 000011 00100 00010 00010 11111 1100 01000001 001 01 11 11 11 01 10 11 11 11.\nThe Java BitSet class allows for varying bit set lengths.  But, for the configurator application 104, the set of features is fixed for a given vehicle.  Thus, the configuration engine 106 defines its own fixed length bit set object.  To store a\nconfiguration, a feature bit set is used.  The feature bit set associates a feature object with each bit position.  This mapping is defined in a structure object that defines a list of families with each family defining a list of features.\nFIG. 5 illustrates a table 500 that defines the mappings for the bit sets in table 400.  The bit sets shown in table 400 are printed in blocked format.  The bits for each family are grouped together with no delimiter and family blocks are\nseparated by a space.  The bit sets can also be printed in strict binary format with no extra spacing, e.g., the first binary configuration 402 of Table 400 could be rewritten as 010101001.  Alternatively, the bit sets can be printed in strict binary\nformat with the same delimiter between every feature and no extra delimiter between families, e.g., the first binary configuration 402 of Table 400 could be rewritten as 0 1 0 1 0 1 0 0 1.  Blocked format allows for better human readability; however,\nspace-delimited is a viable option when viewing the data in a table with labeled columns and importing bit set data into an Excel worksheet for analysis.\nWith reference to FIGS. 6-10, one or more configurations may be compressed and represented by a \"superconfiguration.\" FIG. 6 includes a table 600 listing a first configuration 602: (A2, B2, C1, D2), and a second configuration 604: (A1, B2, C1,\nD2).  Because the values are identical in all but one family `A`, the configurations 602, 604 can be compressed into a single superconfiguration 606.  The table 600 shows both the CNF and bit set forms of the configurations and superconfigurations. \nThus, a configuration is just a superconfiguration with only one possible value per family.\nReferring to FIG. 7, two superconfigurations can also be compressed as shown in table 700.  A first superconfiguration 702 and a second superconfiguration 704 are compressed into a third superconfiguration 706.\nWith reference to FIG. 8, bit sets, configurations and superconfigurations can be interacted using bitwise steps as shown in table 800.  Referring to \"OR\" step 802, when OR-ing two superconfigurations the resulting value for each family is the\nunion of the family set from each superconfiguration.  Thus, if any value in a family set (column) is \"1\", then the union of the family set is \"1.\" And referring to \"AND\" step 804, when AND-ing two superconfigurations the resulting value for each family\nis the intersection of the family set from each superconfiguration.  Thus, if all values in a family set (column) are \"1\", then the union of the family set is \"1.\"\nReferring to FIG. 9, when AND-ing two superconfigurations, the resulting superconfiguration is invalid if any family has no active bits, as shown in table 900.  The intersection for family B is empty causing the configuration to be invalid, as\nreferenced by numeral 902.\nWith reference to FIG. 10, the configuration system 100 expresses buildable space with a set of superconfigurations that define all valid configurations, according to one or more embodiments.  This compressed representation allows for more\nefficient storing and processing of a buildable space.  A non-overlapping set of super configurations can be stored in a matrix 1000, with each row stored as a bit set.\nReferring to FIG. 11, the configuration engine 106 does not use overlapping superconfigurations because they include redundant information which could lead to incorrect calculations.  Thus, all basic steps performed by the configuration engine\n106 rely on the fact that the buildable space contains no overlap.  Two superconfigurations are said to overlap if there exists one or more configurations that are defined by both superconfigurations.  Table 1100 shows a first superconfiguration 1102\nthat overlaps with a second superconfiguration 1104.  Row 1106 identifies all of the overlapping features.  For example, both superconfigurations 1102, 1104 include feature A2, as represented by numeral 1108, and therefore overlap.\nWith reference to FIG. 12, a superconfiguration can be used to define a feature mask.  A feature mask for a single family is created by setting the active bits in the family to zero to define the constrained features and setting all bits to 1\nfor the remaining families.  A feature mask for multiple families is the AND of the masks for each family.  Table 1200 shows several examples.  A feature mask can be used to search a configuration space (contains) or limit a configuration space\n(restrict).  Feature masks can be used to encode a feature condition in order to associate data with features, such as descriptions, prices and images.\nReferring to FIG. 13, the configuration system 100 uses a multi-valued decision diagram (MDD) to represent the buildable space, according to one or more embodiments.  An MDD representing the same buildable space as the superconfigurations matrix\n1000 (FIG. 10) is shown in accordance with one or more embodiments, and generally referenced by numeral 1300.  An MDD is capable of representing the configuration space for large and highly complex product offerings much more compactly than a matrix.\nThe MDD 1300 includes nodes, such as a root node (2), a terminal, Truth or True node (T) and a plurality of intervening nodes (3-16) arranged on a plurality of paths.  Each path includes the root node (2), the true node (T) and some of the\nintervening nodes connected by \"edges\" or arrows.  In terms of superconfigurations, a complete path from the root node (2) to the true node (T) defines a superconfiguration.  The superconfiguration shown in the top row 1308 of the matrix 1000 in FIG. 10\n(i.e., 100 100 110 100 10), is defined by a right path (2-3-4-5-6-T) in the MDD 1300.\nEach level of the MDD 1300 is associated with one family and the edges define the path for each feature.  Each node will have at most one outgoing path for each feature, thus the features are mutually exclusive.  Where there is a path between\ntwo nodes for more than one feature, a single edge is shown, but the edge label includes more than one (\"1\").  The edge labels correspond to a family's superconfiguration bits, where a \"1\" indicates the presence of a feature and a \"0\" indicates the\nabsence of a feature.  Where a feature is inactive, its edge points to the false terminal node, which is not shown in the diagram.  Each complete path from the root node to the truth node is of the same length in nodes when the nodes are expanded, e.g.,\nthere are no long edges.  An MDD that does not include any long edges may be referred to as a quasi-reduced MDD.\nThe MDD 1300 includes five different families 1302: package (Pkg), radio (Radio), paint (Paint), trim (Trim) and moonroof (MoonRf).  Each family includes multiple features.  For example, the package (Pkg) family includes a 400 package, a 401\npackage and a 402 package; and the radio family includes: a Standard (Std) radio, a Deluxe (Dlx) radio and a Navigation (Nav) radio.  The root node (2) is connected to intervening node 13 by edge label \"001\", which indicates the presence of the third\npackage (402) and the absence of the first two packages (400 and 401).  Again, some edge labels include more than one \"1\", which means that more than one feature is available.  For example, intervening node (7) is connected to intervening node (8) by an\nedge with a label \"011.\" This indicates that path 2, 7, 8 is a superconfiguration that includes the 401 package, and the Deluxe (Dlx) and/or the Navigation (Nav) radio.\nFIG. 14 is a table 1400 that illustrates a comparison of the size of a matrix based product configuration (e.g., table 1000, FIG. 10) and an MDD based product configuration (e.g., MDD 1300, FIG. 13).  For small product definitions (e.g., Vehicle\nA with 28 families) a matrix and an MDD have comparable size (20 KB).  However, for medium product definitions (e.g., Vehicle B with 84 families) the matrix size (23,026 KB) is much larger than the MDD size (766 KB).  For large product definitions (e.g.,\nVehicle C with 92 families) the matrix runs out of memory, but the MDD size (313 KB) is sufficient.  Therefore table 1400 illustrates that an MDD is a useful tool when analyzing large product configurations.  Using the MDD format, the minimum number of\nsuperconfigurations required to represent the buildable space of all possible configurations may be calculated.  For complex products that number exceeds reasonably available memory\nWith reference to FIG. 15, the configuration engine 106 performs steps using reduced MDDs, such as reduced MDD 1500, in one or more embodiments.  FIG. 15 includes the MDD 1300 of FIG. 13 and a reduced MDD 1500.  In an MDD, a redundant node may\nbe removed and its incoming and outgoing edges may be combined to form a \"long edge.\" A redundant node is a node that corresponds to a family in which all features are active, i.e., its outgoing edge label includes only \"1\"s. For example, intervening\nnode 16 in MDD 1300 corresponds to the moonroof (MoonRf) family, and its outgoing edge label \"11\" indicates that both the moonroof (Vista) and no moonroof (Less) features are active.  Therefore node 16 is redundant and it can be removed, as depicted by\nthe \"X\" disposed over it in FIG. 15.  Nodes 10 and 12 of MDD 1300 are also redundant and may be removed, as depicted by the X's over them in FIG. 15.  The reduced MDD 1500 shows the result of removing redundant nodes 16, 10 and 12 and collapsing their\nrespective incoming and outgoing edges into long edges.  The paths from 13-T, 9-T, and 10-T do not include a node for the moonroof (MoonRf) family.  By collapsing the long edges, the reduced MDD 1300 has 3 fewer nodes, and some of its nodes have been\nrenumbered.  For example, since node 10 of MDD 1300 was removed, node 11 of MDD 1300 was renumbered as node 10 in reduced MDD 1500.  By reducing MDDs, the configuration system 100 reduces memory and processing usage.\nIn one or more embodiments, the configuration engine 106 performs steps using an expanded (not reduced) MDD, such as MDD 1300, e.g., during a \"Quick-Restrict\" step, as described below.  For a very large buildable space, the number of nodes added\nto expand long edges can be quite significant.  As an example, an MDD may have 17,283 nodes when long edges are compressed, but grow to 47,799 nodes when long edges are expanded.  Therefore good compression reduces the number of long edges significantly. However, the savings generated by the quick-restrict step are generally sufficient to justify the long edge expansion.\nIn the expanded MDD 1300, nodes 10, 12, and 16 are not only redundant; they are also duplicated.  Duplicate nodes are two nodes for a family (i.e., within a common row) that have identical outgoing edge labels.  The reduced MDD 1500 is in\ncanonical form, i.e., there are no duplicated nodes.  The configuration engine 106 creates MDDs in canonical form.  Canonical form helps to minimize the number of nodes required to represent the buildable space.\nFIG. 16 includes a non-canonical MDD 1600 with duplicate nodes.  Node 6 and node 8 include identical outgoing edge labels, and therefore are duplicates of each other, as referenced by numeral 1602.  Similarly, node 5 and node 7 are duplicates,\nas referenced by numeral 1604.  FIG. 16 also includes a canonical MDD 1610.  The duplicate nodes of MDD 1600 are merged in the canonical MDD 1610.  For example, the first duplicate nodes 1602 are merged to form a canonical node 6, as referenced by\nnumeral 1612.  And the second duplicate nodes 1604 are merged to form a canonical node 5, as referenced by numeral 1614.  The MDDs, e.g., MDD 1600, 1610, are serialized as plain text for storage in a database, such as the DB 122 shown in FIG. 2.  Such\ntext serialization ensures backwards compatibility across software versions and implementations.\nWith reference to FIG. 17, when a family's values in the configuration space can be determined by the values from one or more other families, the family is said to be deterministic.  Deterministic relationships are used to minimize the size of\nan MDD to allow for scaling to complex vehicle configurations.\nFIG. 17 includes an MDD 1700 that is similar to the MDD 1300 of FIG. 13, with the addition of two deterministic families: seat temperature control (Temp) and the presence of dice (Dice).  The presence of dice is determined by the paint color. \nThus, once the paint color (Paint) is known, there is just one choice for dice.  If paint is White, then dice are not present (NoDice); however if paint is Red or Blue, then Fuzzy dice are present (FuzzyDice).  The seat temperature control (Temp) is\ndetermined by the package (Pkg).  If Pkg is 400, then the seat temperature control is not available (LessTemp); if Pkg is 401, then heated seat temperature control is included (Heat); and if Pkg is 402, then heat and cool temperature control (HeatCool)\nis included.  In these examples Paint color and Pkg are the determinant families while Dice and Seat temp are deterministic.  This is because their state is fully specified by the state of the determinant.\nThe presence of deterministic features has a negative impact on MDD compression.  The MDD 1700 represents twenty-four configurations.  However, the deterministic families cause the MDD 1700 to increase from sixteen nodes to twenty-four nodes. \nGenerally, the number of nodes in an MDD is a good predictor of its performance.  Thus, it is ideal to have an MDD with as few nodes as possible.  To aid in MDD compression, the configuration system 100 extracts the relationship defining a deterministic\nfamily's values to form one or more external relationship MDDs, which allows for greater compression in the main MDD, i.e., MDD 1700.\nThe configuration system 100 extracts the two deterministic families (Temp and Dice) from MDD 1700 to form reduced an MDD 1702, a first external relationship MDD 1704 corresponding to the Dice family, and a second external relationship MDD 1706\ncorresponding to the Temp family.  The deterministic families (Temp and Dice) remain in the MDD 1702, but are trivialized--made all is--allowing the main MDD 1702 and the external relationship MDDs 1704, 1706 to share the same structure.\nThe combination of the main MDD 1702 and all its external relationship MDDs 1704, 1706 is referred to as a Global MDD.  A Global MDD can be operated in the same way as an MDD; but, each step must account for both the main space and the\nrelationships.\nThe configuration service 138 abstracts the implementation from any specific application and state management does not depend on the implementation being either \"stateful\" or \"stateless\", according to one or more embodiments.  The configuration\nservice 138 remembers a user's session history in a stateful implementation, and does not remember a user's session history in a stateless implementation.  However, the front-end application 132 treats the configuration service 138 as stateless in so far\nas it does not need to handle session synchronization.\nEach XML response to the front-end application 132 from the configuration service 138 includes a state object that is included in the next call.  The content of the state object is not dictated by the configuration service 138, but it contains\nany information necessary to maintain a user session.  The state object is not modified by the front-end application 132.\nA configuration session begins with an XML request to load initial content (i.e., a \"Load Request\") to populate a starting point of initial screens on the front-end applications 132.  This is followed by additional XML requests to update the\ncontent (\"Update Request\") as user changes the configuration by selecting different options in the front-end application.  The web service controller 136 responds with an XML configuration response that includes updated configuration content.\nEach feature included in such configuration responses includes a selection or feature state attribute.  In one embodiment, there are six different feature state values: Selected, Available, Included, Default, Excluded and Forbidden.\nA Selected feature state is a feature that has been explicitly selected by the user and generated in response to a Load or Update XML request.  The configuration service 138 cannot unselect this feature as a result of another selection without\nperforming a conflict resolution procedure, except for features in a mutually exclusive feature group.\nAn Available feature state is a feature that is not currently selected by the user.  But the user is free to select it without causing a conflict resolution procedure to be triggered.  In a mutually exclusive group of features (e.g. exterior\ncolor), although only one feature can be selected at a time, the other features in that group will be marked as \"Available\"--they will only be marked as \"Excluded\" if they conflict with a user selected feature in another family.\nAn Included feature state is a feature which is the only available choice in the family.  For example, this can occur when a selection of a feature requires another feature.  This can be the result of either a package selection that includes\nthis feature (e.g. \"Climate Pack\" includes \"Air Conditioning\"), or a \"must\"/\"requires\" relationship (e.g. \"Heated Seats\" requires \"Leather Seats).\nA Default feature state is a feature that was selected by the configuration service 138 as part of an automatic completion function, as described in detail below with reference to FIGS. 82-117.\nAn Excluded feature state is a feature that conflicts with another user selection.  Selecting this feature will prompt a conflict resolution procedure.\nA Forbidden feature state is a feature that violates a constraint that cannot be resolved if selected.  Attempting to select this feature will result in an error.  This state has been introduced to support external constraints that restrict the\nvalid buildable configurations.\nThe front-end application 132 alters the display of features based on their configuration state, in one or more embodiments.  For example, in one embodiment, the front-end application 132 shows a symbol next to an excluded feature to indicate\nthat it conflicts with a prior selection or it may choose not to display excluded or forbidden features.\nIn one embodiment, the configuration system 100 changes a feature from the Default feature state to the Selected feature in response to a user implicitly selecting the feature.  For example, if Default features are presented as checkboxes or\nradio buttons, there is no action the user can take to check an already checked item.  This means that while the user intended to select the feature, it is still marked as Default.  Such an implicitly selected Default feature may complicate conflict\nresolution strategies.  Thus, the configuration system 100 includes an option to change a feature from a Default feature state to the Selected feature state in response to a user viewing a default selection and not changing it.\nThe configuration service 138 will return a complete configuration to the front-end application 132 in response to any load or update request, according to one or more embodiments.  This feature is referred to as \"automatic completion.\" Default\nfeature selections will be added to any Selected features or Included features to create a complete configuration with respect to displayable families.  A feature is \"displayable\" if it can be displayed to the user, e.g. on the user's pc 112; whereas a\nfeature that cannot be displayed to the user is described as \"no-display\" or \"not displayable.\" The front-end application 132 may choose to distinguish the automatic feature selections from those explicitly selected by the user, using each feature's\nstate value returned in the configuration response.\nAlternatively, in other embodiments the automatic completion feature is disabled.  When the automatic completion feature is disabled, no default selections are made and the response will typically include an incomplete configuration.  This\nenables different front-end application 132 designs where a user is prompted to actively select each feature in the configuration.\nThe configurator application 104 includes a conflict resolution procedure in which, in response to an update request to select a feature that leads to an invalid configuration; the configuration service 138 returns a new valid configuration with\nthe newly selected feature and the minimum other changed features required to make the configuration valid.  If the auto completion feature is enabled, the new configuration will include any necessary Default features.  The web service controller 136\nimplements the conflict resolution feature to provide details on what features must be added and removed to resolve the conflict, as well as a \"reject state\" that is used if the user cancels the requested change.\nWith reference to FIG. 18, the configurator application 104 includes a \"single\" conflict resolution strategy, according to one or more embodiments.  The configuration service 138 resolves the conflict by finding a single valid configuration\ncontaining the new selection.  FIG. 18 depicts a user interface 1800 that is displayed to the user on the user device (e.g., on the monitor of the PC 112) by the front-end application 132 as part of the conflict resolution procedure.  The user interface\n1800 includes a message 1802 that alerts the user of a conflict (i.e., by selecting the adaptive cruise control feature, the Zetec package and the solar reflect windscreen features must be removed, and the titanium package must be added) and asks for\nconfirmation that they still want to make the change.  If the user cancels the change, e.g., by selecting the decline button 1804, the subsequent view request includes a reject state to undo the prior selection (i.e., adaptive cruise control) in the\nconfigurator application 104.  The update request may unselect a feature.  Since all families must have one feature selected to form a valid configuration, unselecting a feature is often equivalent to selecting the \"less\" feature in the family.  Removing\na feature from the configuration can also lead to a conflict.  For example, if the user removes an included feature, the selected feature which includes it will also be removed.\nReferring to FIG. 19, the configurator application 104 includes a branched conflict resolution strategy, according to one or more embodiments.  In branched conflict resolution, the configuration service 138 presents the user with a series of\nchoices to help them select from a set of valid configurations.  For example, FIG. 19 depicts a user interface 1900 that is displayed to the user on the user device (e.g., on the monitor of the PC 112) by the front-end application 132.  The user\ninterface 1900 includes a series of choices for a remote starter option (e.g., with or without (less) the remote starter), as referenced by numeral 1902, and a series of choices for the color of the seats (e.g., Charcoal Black or Medium Light Stone), as\nreferenced by numeral 1904.  In one embodiment, the branched conflict resolution strategy may be enabled by setting a return guided resolution flag (not shown), which is included in the communication between the front-end application 132 and the service\nAPI 134.\nWith respect to state management, when a branched conflict resolution is returned in the response to the service API 134, there will be no feature state because the new configuration isn't known until the user traverses the resolution tree,\n(i.e., selects from the options shown in the user interface 1900).  Once selections have been made, the front-end application 132 sends a second update request with all the changes made during resolution.  At this time the response will include the new\nconfiguration state.  Optionally, if there is only one target configuration, the response could include the new configuration state to save one call to the service.\nIn one or more embodiments, the conflict resolution strategy employed by the configurator application 104, may add a feature or subtract a feature, which is referred to as \"return delta\" functionality.  In one or more embodiments, the conflict\nresolution subtractions only contain Selected features removed from the configuration; and conflict resolution additions only contain Included features added to the configuration.  If the new configuration caused a change in a Default feature, this is\nnot included in the prompt to the user (e.g., not shown in the user interfaces 1800, 1900).  If all changes are for default choices, there are no changes to report, and the response will not include conflict resolution.\nAlternatively, in other embodiments, the response will include all additions and subtractions regardless of feature state when the request has set the return delta flag to true.  This allows the front-end application 132 to inspect the\nresolution and apply some additional logic when deciding whether to prompt the user for a conflict or to silently make the changes.\nThe configuration engine 106 \"validates\" each configuration.  A load request from the services API 134 may include a full or partial configuration as a starting point.  When a configuration is submitted to the configuration engine 106 with the\nload request, it is validated.  By default, or when a validate flag is True, conflict resolution will be triggered and the response will include a valid configuration.  However, if the request has set the validate flag to False, conflict resolution is\nnot performed and an error message will be included in the response if the submitted configuration is not valid.\nThe configuration engine 106 performs steps on a buildable space in order to process a configuration request and generate data to build a response.  The configuration engine 106 uses data structures and algorithms, including those based on\nmultivalued decision diagrams (MDD) to perform the configuration steps.  For comparison, some matrix based steps are also described.\nIn many cases the configuration engine 106 uses MDD steps to search the product space in the same way a structured query language (SQL) query searches a database.  Both are preforming relational algebra.  As appropriate, the SQL equivalent of\neach MDD step is described.\nThe configuration engine 106 checks if the buildable space defines a specific full configuration or a partial configuration, which is referred to as a \"contains any\" step.\nIn terms of SQL, this step is equivalent to performing a search and evaluating if there is at least one row in the result set.  For example, consider the partial configuration (Dlx, Vista).  If a database stored each configuration as a separate\nrow, and each family choice as a string column, the SQL query would be SELECT * FROM mdd WHERE Radio=`Dlx` AND Moonrf=`Vista`.\nFor efficient storage, matrix and MDDs represent the product with superconfigurations.  If each row in the database stored a superconfiguration with each feature as a Boolean column, the SQL would be SELECT * FROM mdd WHERE Dlx=TRUE AND\nVista=TRUE.\nFor example, in one embodiment, the configuration engine 106 searches an MDD by stating the query as a feature mask.  For example, to search for the partial configuration (Dlx, Vista) the mask would be 111 010 111 111 01.  The radio family\nincludes the following features: Standard (Std), Deluxe (Dlx) and Navigation (Nay).  Since the search is limited to (Dlx), the only active bit corresponds to Dlx (i.e., 010) for the radio family.  Additionally, the moonroof family includes: without a\nmoonroof (Less) and with a moonroof (Vista).  Since the search is limited to (Vista), the only active bit corresponds to Vista (i.e., 01).  All other families are all 1s.\nWhen the configuration engine 106 is performing a step to check for a partial configuration, one or more families will have all 1s.  This means that the mask defines multiple configurations.  The configuration engine 106 is querying the space to\ndetermine if any of the individual configurations defined in the feature mask superconfiguration are contained in the space.  Thus the step is called \"containsAny.\"\nWith reference to FIGS. 20 and 21, the configuration engine 106 performs an MDD-based \"containsAny\" step using a depth-first search of the space to look for the first valid path defining at least one of the configurations from the mask.  In a\ndepth-first search, the configuration engine 106 starts at the root node, and traverses the edges in descending order of its features; an edge of 011 will be processed by first inspecting 001 and then 010.\nFIG. 20 is an MDD 2000 that illustrates an example of the configuration engine 106 performing an MDD-based \"containsAny\" step for the partial configuration (Dlx, Vista).  To determine if this partial configuration is valid, the configuration\nengine 106 performs a depth-first search using the feature mask 111 010 111 111 01.  The search begins with the path 2-13.  This path is aborted when the Radio feature Dlx is inactive on edge 13-14, as shown by the dashed edge 2002.  Next, the\nconfiguration engine 106 searches path 2-13-8-11-12-T. This path, highlighted by nodes in solid line, ends in True node 2004, indicating a valid path has been found containing the partial configuration (Dlx, Vista).  Note there are three additional paths\ncontaining (Dlx, Vista), 2-13-8-9-10-T, 2-7-8-11-12-T, 2-7-8-9-10-T; but, the configuration engine 106 stops the \"containsAny\" step after the first path is found.\nFIG. 21 is an MDD 2100 that illustrates an example of the configuration engine 106 performing an MDD-based \"containsAny\" step for the partial configuration (Std, Vista).  To determine if this partial configuration is valid, the configuration\nengine 106 performs a depth-first search using the feature mask 111 100 111 111 01.  The search begins with path 2-13 which is aborted because neither edge 13-14, nor 13-8 is active for the standard radio feature (i.e., neither of the edge labels include\na \"1\" in their first digit), as shown by dashed edges 2102.  Next the configuration engine 106 searches path 2-7, which is also aborted because Std is not active, as shown by dashed edges 2104.  Finally, the configuration engine 106 searches path\n2-3-4-5-6 and aborts the search because 6-T is not valid for MoonRf.Vista, as shown by dashed edge 2106.  No paths are found containing both Std and Vista, thus this combination is found to be invalid.\nThe domain of a buildable space defines all the Available features--those features contained in one or more configurations.  The domain can be represented as a bit set where each 1 (active feature) denotes a feature contained in the domain and\neach zero (inactive feature) denotes a feature absent from the domain.  For any active bit in the domain, the space contains one or more configurations with that feature.  If there is an inactive bit in the domain, the space contains no configurations\nwith that feature.  For a matrix, the domain is calculated by the OR of all superconfigurations in the space.  The domain of the space shown in FIG. 10 is 111 111 111 111 11, because every feature is available in at least one configuration.\nWith an MDD, the configuration engine 106 calculates the domain by traversing the MDD in either a breadth-first or a depth-first manner, and using the active features on the edges to define the domain.  In a breadth-first search, the\nconfiguration engine 106 starts with a root node, then explores neighbor nodes first before evaluating the next family.  For example, the configuration engine 106 evaluates the MDD 2100 of FIG. 21 using a breadth-first strategy by starting with the root\nnode 2 and evaluating path 2-13.  Although path 2-13 is valid, the configuration engine evaluates neighbor nodes 7 and 3, i.e., paths: 2-7 and 2-3, before evaluating the next family, i.e., nodes: 14, 8 and 4.  Once a path is determined to be invalid, the\nconfiguration engine 106 stops evaluating nodes farther down the path.  For example, once path 13-14 is found to be invalid, the configuration engine 106 does not continue along the path to evaluate nodes 15 and 16.  And as described above, in a\ndepth-first search, the configuration engine 106 starts at the root node, and traverses the edges in descending order of its features.  In the depth-first search, levels (families) are not back-tracked until an invalid path, or the truth node, is\nencountered.  In the configuration engine 106, the full domain is not usually called, but rather domain is called on a restricted space.  The domain of a restricted space is used in determining feature states.\nThe configuration engine 106 restricts a space by keeping only those configurations containing a specific feature or combination of features.  With respect to a database query, the restrict step is equivalent to searching the table to find only\nthose rows that match the query.  The restricted features define the WHERE clause.  Consider the partial configuration (Nay, Ruby, Vista).  In terms of SQL, the query would be SELECT * FROM mdd WHERE Radio=`Nav` AND Trim=`Ruby` AND MoonRf=`Vista`.  In\nterms of superconfigurations, the step begins with creating a feature mask defining the query.  This is the same feature mask that would be used for a containsAny step.  For restrict, a space is created with the feature mask as its only\nsuperconfiguration.  Then, the restricted space is created by the AND of the original space with the feature combination space.\nFIGS. 22 and 23 show restrictions of the space defined in FIGS. 10 and 13.  In the table 1000 shown in FIG. 10, the last two rows of superconfigurations contain the radio feature (Nav), the trim feature (Ruby) and both moonroof features (Vista\nand Less), which indicates that Nav and Ruby are available with the moonroof (Vista) or without the moonroof (Less).  FIG. 22 is a table 2200 that depicts a restricted version of table 1000, in which the five superconfigurations of table 1000 are\nrestricted to two superconfigurations, and the Moonrf Less bit is set to zero to remove the configurations for (Nav and Ruby and MoonRf.Less).  FIG. 23 is a restricted MDD 2300 illustrating the restricted superconfigurations of table 2200.\nFor some algorithms, successive restricts will be performed on the same space.  When an MDD is restricted, a new set of nodes is created and the edges are updated for the nodes to keep only the constrained features.  When many restrict\noperations are performed, many node objects must be created as the MDD is replicated.  For large MDDs, this can cause the memory usage or \"footprint\" to increase, and may also incur performance problems from \"garbage collection\", i.e., reclaiming memory\noccupied by objects that are no longer in use by the program.  The configuration engine 106 addresses these issues using a \"quick-restrict\" strategy.\nWith reference to FIG. 24, a method for evaluating an MDD using reversible restrictions (i.e., \"quick-restrict\") is illustrated in accordance with one or more embodiments and generally referenced by S100.  The quick-restrict method S100 is\nimplemented as an algorithm within the configuration engine 106 using software code contained within the server 102, according to one or more embodiments.  In other embodiments the software code is shared between the server 102 and the user devices 112,\n114.  FIG. 25 illustrates an original MDD 2500, and an MDD 2502 after it is \"quick-restricted\" to the partial configuration (Nay, Ruby, Vista) by the configuration engine 106 according to the quick-restrict method S100 of FIG. 24.\nAt S102, the configuration engine 106 saves a copy of the root node identity and a set of the node edges to the memory 108 (shown in FIG. 2).  The subroutine of S102 is shown in the flowchart of FIG. 26.  At step S104 the configuration engine\nidentifies each node (y).  Then at step S106 the configuration engine copies or clones each outgoing edge of the node (y), and returns to step S104 until each node (y) in the MDD 2500 is copied.  Then at step S108, the configuration engine 106 returns\nthe edge set and the identity of the root node to the main routine of FIG. 24.\nAt step S110, the configuration engine 106 performs the quick-restrict subroutine for the given selected features.  The subroutine of step S110 is shown in the flowchart of FIG. 27.  At step S112 the configuration engine 106 examines the cache\nmemory for source (SRC) node (y) to determine if the quick-restrict subroutine has already been performed on node (y), (i.e., does cache(y) exist?) If cache(y) exists, then the configuration engine 106 proceeds to step S114 and returns to the main\nroutine.  If cache(y) does not exist, the configuration engine 106 proceeds to step S116.\nAt step S116, the configuration engine 106 starts with array index zero, and sets the empty flag to true.  By setting the empty flag to true, the configuration engine 106 assumes that there are no valid paths from the node, i.e., that all edges\npoint to the false node.  At step S118, the configuration engine 106 evaluates the array index (z) to determine if (z) is less than the number of node (y)'s children.  A positive determination at step S118 indicates that the configuration engine 106 has\nnot analyzed all array indexes of node (y).  If the determination is positive, the configuration engine 106 proceeds to step S120.\nAt step S120, the configuration engine 106 checks if y's child, or destination (DST) node, at array index (z) is false.  If the configuration engine 106 determines that the child is false, then it proceeds to step S122, increments the array\nindex (z) by one, and returns to step S118.  With reference to FIG. 25, the MDD 2500 does not show false nodes, but they are still present.  For example, node 9 shows only one outgoing edge with the label \"001.\" This indicates that array indexes zero and\none are both false, but they are not shown extending to the false node on the MDD 2500 to avoid clutter.  When analyzing node 9, the configuration engine 106 makes a positive determination at S120 for array indexes zero and one, but makes a negative\ndetermination for array index two.  If the determination at step S120 is negative, the configuration engine 106 proceeds to step S124.\nAt step S124, the configuration engine 106 evaluates the quick-restricted features list for node (y) to determine if it contains feature (z).  Otherwise, the configuration engine 106 sets y's child node along z to false at S126 and then proceeds\nto step S122 to increment the array index(z) by one.\nAt step S128, the configuration engine 106 check's if y's child (DST) at array index (z) is true.  For example, with reference to MDD 2500, node 16 connects to the true node (T) along array indexes zero and one.  If the configuration engine 106\ndetermines that the child node is the true node, then it proceeds to step S130 and sets the empty flag to false (empty=false), which indicates that there is at least one edge that is connected to the true node (T), and then proceeds to step S122.  If the\ndetermination at step S128 is negative, the configuration engine proceeds to step S132.\nFor example, referring to MDD 2500, node 3 is illustrated with one outgoing edge with the label \"100\", which indicates that node 3 includes the Standard radio, but does not include the Deluxe radio or the Navigation radio.  Since the Navigation\nradio was selected by the user, the configuration engine 106 determines that none of node 3's outgoing edges contain (z)'s corresponding feature.  Therefore the configuration engine 106 sets node 3's children to false at S126, which is illustrated by\ndisconnecting the outgoing edge to node 4 (as shown in MDD 2502) and the edge label for path 3-4 is replaced with an edge label of \"000.\" However, referring to MDD 2500, node 7 includes two array indexes (011), which indicate that node 7 includes the\nDeluxe radio and the Navigation radio.  Since the Navigation radio was selected by the user, the configuration engine 106 determines that one of node 7's outgoing edges contain (z)'s corresponding feature at S124, therefore the outgoing edge is not\ndisconnected from node 8 (as shown in MDD 2502) and the edge label for path 7-8 is replaced with an edge label of \"001\".\nAs shown in MDD 2502, the configuration engine 106 removes the edge pointer for path 13-8 because Navigation is not an active feature for the Radio family (i.e., there was not a \"1\" in the third digit of the edge label); and removes the edge\npointer for path 15-16 because Ruby is not an active feature for the Trim family at S126.  Since only Vista is constrained for the moonroof family; the configuration engine 106 modifies the edge labels for paths 10-T and 12-T from \"11\" to \"01\".  If the\ndetermination at step S128 is negative, the configuration engine 106 proceeds to step S132.\nAt step S132, y's children, or (DST) nodes, are rewritten by the result of recursive invocation of the quick-restrict method on the child.  All nodes of the MDD are processed in this manner.\nAt step S134, the configuration engine 106 checks y's child at array index (z) to determine if it's not a false node.  If the determination is positive (e.g., if node (y) is connected to a valid node), then the configuration engine 106 proceeds\nto step S136 and sets the empty flag to false, before incrementing the array index (z) at S122.  However, if node (y) is connected to the false node along array index (z) then the configuration engine 106 proceeds directly to S122 to increment the array\nindex (z).\nThe quick restrict method S110 operates on the nodes in a depth first search fashion.  Steps S118-S136 demonstrate an iterative process that operates on each array index (z) of a node (y) before proceeding to the next node.  Once the\nconfiguration engine 106 has evaluated all array indexes (z) for a node (y), it will make a negative determination at step S118 (i.e., z will be greater than or equal to the number of y's children), and proceeds to step S138.\nAt step S138 the configuration engine 106 checks if all children (DST) of node (y) are false, i.e., it evaluates the empty flag to determine if any valid configurations were found.  If all of y's children are false, the configuration engine 106\nproceeds to step S140, sets node (y) to the false node, set cache(y) to y, and then returns the cache(y), i.e., saves the analysis of node (y) and returns to the main routine of FIG. 24.  Further, if the node does not contain any edges that conform to\nthe constraint, then the edge pointer is disconnected from the child node in the MDD.  If not all of the children nodes are false, then the configuration engine 106 proceeds to step S142, sets the cache(y) to (y), and then returns the cache(y), i.e.,\nsaves the analysis of node (y) and returns to the main routine of FIG. 24.\nFor example, referring to FIG. 25, the configuration engine 106 determines that node 3's features do not contain the Selected radio feature (Nav) at S124, and therefore sets node 3's child (node 4) to false at S126.  Setting node 4 to false is\nrepresented by disconnecting the edge pointer between node 3 and node 4 in MDD 2502.  The configuration engine 106 determined that all of node 3's children were set to false at S138, and therefore set node 3 to false at S140.  Setting node 3 to false is\nrepresented by disconnecting the incoming edge pointer to node 3 in the MDD 2502.\nSimilarly, the configuration engine 106 disconnects the incoming edge pointer to node 15 at S140, because all of node 15's children were set to false at S126, which is depicted by the disconnected outgoing edge pointer of node 15 in MDD 2502. \nAlthough the edge label for path 7-8 was revised at S126, the edge pointer was not disconnected.  Therefore the configuration engine 106 determines that not all of node's 7 children are false at S138, and proceeds to S142 without setting node 7 to false\nor disconnecting its incoming edge pointer in the MDD 2502.\nThe quick-restrict subroutine S110 is a recursive process.  This process continues until all nodes are analyzed.  The edges for complete paths from the root node (node 2) to the truth node (T) define the restricted configuration space.\nAt step S144 the configuration engine 106 performs additional steps on the restricted MDD 2502.  In one embodiment, after completing a traversal of the MDD in a first direction (e.g., downward), the configuration engine 106 determines the domain\nfor a restricted space by traversing the MDD again in the same direction (i.e., the configuration engine repeats S110 for all nodes).\nIn another embodiment, the configuration engine 106 determines the domain at the same time as traversing the MDD in the first direction (i.e., during S110).  Then at step S144, the configuration engine 106 changes direction (i.e., reverses) and\ntraverses the MDD in a second direction, e.g., upwards from the truth node (T) to the root node (2).  On the downward traversal, the configuration engine 106 trims the edges to conform to the constraint.  On the upward traversal, the domain bit set is\ncreated from the remaining edges.  Combining quick-restrict and domain in a single operation saves one traversal of the MDD.  However, the operation modifies the MDD and the edges must be reset to undo the quick-restrict.\nAt S146, the configuration engine 106 restores the original set of node edges to the memory 108 (shown in FIG. 2).  The subroutine of S146 is shown in the flowchart of FIG. 28.  At S148 the configuration engine identifies each node (y).  Then at\nstep S150 the configuration engine 106 copies each outgoing edge of the node (y), and returns to step S148 until each node (y) in the MDD 2500 is copied.  Then at step S152, the configuration engine 106 sets the MDD to the identity of the root node and\nreturns to the main routine of FIG. 24.\nAt step S154 the configuration engine 106 determines if the user has selected different features.  If the user has selected new features, the configuration engine 106 returns to S110.  If the user has not selected new features, then the\nconfiguration engine 106 proceeds to step S156 and deletes the copy of each node from S102 to free memory.\nAs shown in MDD 2502, paths 9-10-T and 11-12-T are duplicate paths, because they include the same features.  As described above with reference to FIGS. 22-23, the restrict operation will reuse nodes to avoid duplicate nodes or sub-paths. \nAlthough, the quick-restricted MDD 2502 may contain more nodes than the restricted MDD 2300, the configuration spaces defined by each are identical.\nThe quick-restrict method S100 provides advantages over existing methods by performing successive restricts without creating a new MDD for every step.  The configuration engine 106 saves the original edge pointers at S102 and then quickly resets\nthe MDD 2500 using the original edge pointers.\nThere are some cases, where a more efficient algorithm can perform the same operation without having to do the quick-restrict method, eliminating the time needed to reset the edge pointers.  This time savings, while small, can be significant\nwhen working with extremely large configuration spaces.  A \"Restricted Domain\" algorithm is one such algorithm.\nIn other embodiments, the configuration engine 106 determines a read-only restricted domain using an external set of edges (not shown).  Instead of modifying the original MDD node edges the external edges are modified to reflect the restricted\nspace.  The configuration engine 106 restricts on the downward traversal and then updates the domain on the upward traversal.  Such a method is a read-only, thread-safe operation, because the MDD is not modified.\nThe quick-restrict with domain operation method S100 is slightly slower than this read-only approach for the same calculation; however, the time saved in the read-only operation is due to not having to reset the edges.  FIG. 29 is a table 2900\nillustrating a comparison of the performance of the quick-restrict with domain operation method S100 to the read-only method.  The larger and more complex the buildable space, the more nodes in the MDD, and the more time it requires to reset the edges\nafter the quick-restrict method S100.\nWith reference to FIGS. 30-32, the configuration engine 106 performs a \"project\" operation of an MDD to trim a space to a subset of the families while keeping all unique configurations, according to one or more embodiments.  In terms of SQL, the\nprojection operation is equivalent to specifying which columns of a table are returned in the query.  To project the space to the package (Pkg) and the trim (Trim) families, the equivalent SQL would be: SELECT DISTINCT Pkg and Trim FROM mdd.\nSelecting distinct configurations means that the resulting space should contain no duplicated configurations.  During the MDD project operation, the configuration engine 106 removes any duplicated configurations (also called overlapping\nsuperconfigurations).\nFIG. 30 is a table 3000 that shows the result of the configuration engine 106 reducing the buildable space in FIG. 10 to keep only the columns for the package and trim families.  This space contains duplicate configurations.  For example a\nconfiguration including the 401 package and Ruby trim is defined in Row 3 and in Row 4.  Likewise a configuration including the 402 package and Ruby trim is defined in Row 3 and in Row 5.  Therefore Row 4 and Row 5 are duplicates of Row 3 and can be\nremoved.  Further, Row 2 and Row 3 can be compressed to a single row.  FIG. 31 is a table 3100 that shows the projected space after the overlap (duplicated configurations) has been removed and the space has been compressed.  FIG. 32 is an MDD 3200 that\nrepresents table 3000.\nWith reference to FIG. 33, the configuration engine 106 lists, or enumerates all valid configurations that are utilized in conjunction with a constraint restricting the families to a subset of all families, according to one or more embodiments. \nGiven a subset of families, enumeration will return all valid combinations of the features in those families.  In terms of superconfigurations, enumeration is the opposite of compression.\nThe configuration engine 106 works with individual features which are added or removed from a current single configuration.  While this suits the requirements of most ordering and build and price applications, in some cases, the configuration\nengine 106 enumerates the valid combinations of those features without working through all the possible paths.\nThe total number of possible permutations of features in a configuration model can be very large, so this configuration service is restricted to enumerating a reasonable subset of feature families.  The configuration engine 106 can impose limits\non the number of families that can be enumerated, however, it should be expected that a request resulting in more products than can be stored in a storage medium will not succeed.\nFIG. 33 is a table 3300 that shows all valid combinations of paint and trim defined in FIG. 13.  The configuration engine 106 generates this list by first projecting the space to paint and trim.  Next the configuration engine 106 traverses the\nMDD paths and expands each superconfiguration into individual configurations.\nThe configuration engine 106 determines if a new configuration is valid, in response to every configuration request.  Where auto-completion is enabled, the configuration request will contain a full configuration, otherwise it will be a partial\nconfiguration.  In either case, the configuration engine 106 validates the configuration request using the MDD \"containsAny\" operation.  A configuration is valid if the containsAny operation returns true.\nEach feature included in the configuration response will have a feature state attribute, e.g. Selected, Available, Included, Default, Excluded or Forbidden.  For a given set of selected features, the configuration engine 106 calculates the\nfeature states for the remaining features.\nThere are multiple approaches for calculating feature states.  In one embodiment, the configuration engine 106 calculates feature states using a basic algorithm that includes restricted domain steps which can be applied to both Matrices and\nMDDs.  In another embodiment, the configuration engine 106 calculates feature states for MDDs using dynamic programming techniques.\nWith reference to FIG. 34, a method for determining feature states using a restricted domain is illustrated in accordance with one or more embodiments and generally referenced by S200.  The method S200 is implemented as an algorithm within the\nconfiguration engine 106 using software code contained within the server 102, according to one or more embodiments.  In other embodiments the software code is shared between the server 102 and the user devices 112, 114.\nFirst the configuration engine 106 identifies Forbidden features and Excluded features.  At step S202 the configuration engine 106 determines the restricted domain with respect to any initial locked features imposed on the user.  For example,\nthe initial restriction can be timing point feature(s) which are features used to control the effectivity and visibility of configurations.  For example, a new feature (e.g., new engine x) may be available only after the start of a new model year.  Thus\nthe first day of the new model year would be such a visible timing point.  At step S204, the configuration engine 106 identifies features that are absent from the restricted domain, and classifies them as Forbidden features at S206.  At step S208, the\nconfiguration engine 106 classifies any feature that is not Forbidden, as an Excluded feature unless it is assigned another feature state (i.e., Available, Included or Default) in the remaining steps of the algorithm.\nAt step S210, the configuration engine 106 first determines the restricted domain of all selections to identify an initial set of Available features.  Then, for each selection F.sub.j, the configuration engine 106 checks the restricted domain\n(selected--F.sub.j) to identify Available features for Family j.\nFor example, FIG. 35 is a table 3500 illustrating a set of superconfigurations that define all valid configurations.  FIG. 36 is a table 3600 that depicts the restricted domains used to determine the Available features and the Excluded features\nwhen the Selected features are Red paint and Ruby trim.  A bit value of zero in table 3600 indicates that a feature is not Available, whereas a bit value of one indicates that the feature is Available.\nFirst, the configuration engine 106 determines the restricted domain of all selections to identify an initial set of Available features at S210.  For example, Red paint and Ruby trim are both available for the configurations listed in rows 3-5\nof the table 3500.  Packages 401 and 402 are Available, but package 400 is not Available for the configuration listed in rows 3-5, as referenced by numeral 3502.  Therefore the restricted domain for the package family is \"011\", as referenced by numeral\n3602, which indicates that package 400 is not Available (i.e., \"0\"), and package 401 and 402 are Available (i.e., \"11\").  Any feature that is active in this domain is set as active in the availability bit set.  Thus, the configuration engine 106\nidentifies package 401 and package 402 as being Available features, as referenced by numeral 3604, and these features are set as active (\"1\") in the availability bit set, as referenced by numeral 3606.\nNext, the configuration engine 106 evaluates the restricted domain (selected--Ruby) to identify Available features for the trim family.  To evaluate (selected--Ruby), the configuration evaluates configurations in which Red paint is Available. \nFor example, Red paint is Available for the configurations listed in rows 1 and 3-5 of the table 3500.  Stone trim and Ruby trim are Available for the configurations listed in rows 1, and 3-5; but Charcoal trim is not Available, as referenced by numeral\n3508.  Therefore the restricted domain for the trim family is \"101\", as referenced by numeral 3608.  The availability bit set for the trim family is revised to \"101\" based on this step, as referenced by numeral 3610.\nThen, the configuration engine 106 evaluates the restricted domain (selected--Red) to identify Available features for the paint family.  To evaluate (selected--Red), the configuration evaluates configurations in which Ruby trim is Available. \nFor example, Ruby trim is Available for the configurations listed in rows 3-5 of the table 3500.  Red paint and Blue paint are Available for the configurations listed in rows 3-5, but White paint is not Available, as referenced by numeral 3512. \nTherefore the restricted domain for the trim family is \"011\", as referenced by numeral 3612.  The availability bit set for the paint family is revised to \"011\" based on this step, as referenced by numeral 3614.\nAs shown in the availability bit set of table 3600, the restricted domain for Red paint includes both Stone trim and Ruby trim.  Both of these selections are Available without having to change the Red paint selection.  The selection of Ruby trim\nexcludes White paint, and shows that both Red and Blue paint are Available.  Thus White paint would require the trim selection to be changed to something other than Ruby.\nThe resulting availability can be defined as bit set 011 011 011 101 11.  The state of Red paint and Ruby trim will be Selected, all other active features will be Available and the inactive features, such as White paint and Charcoal trim, will\nbe Excluded.\nReferring back to FIG. 34, the configuration engine 106 identifies any Included features at step S212.  A feature is Included if there is only one Available feature for a non-Selected feature family.  The non-Selected feature families listed in\ntable 3600 are packaging (Pkg), radio (Radio) and moonroof (MoonRf).  All of these feature families include more than one Available feature (i.e., each family includes more than one \"1\" in each cell).  Thus, table 3600 shows no such Included features for\na selection of Red paint and Ruby trim.\nFIG. 37 is a table 3700 that depicts the restricted domains used to determine the Available features and the Excluded features when the Selected features are the 401 package (Pkg.401) and Red paint (Paint.Red).  An Included feature can be the\nresult of the interactions between multiple features.  For example, table 3700 shows that if the 401 package and Red paint are Selected, then Ruby trim is an Included feature, as referenced by numeral 3720, because it is the only possible trim choice\nthat is compatible with the 401 package and Red paint.\nThus, the configuration engine 106 determines the feature states e.g. Selected, Available, Included, Excluded and Forbidden for a given set of selections using the method S200.  This initial feature state determination is referred to as \"Minimum\nCompletion.\" FIG. 38 is a table 3800 that summarizes the results of the Minimum Completion determination when Red paint and Ruby trim have been selected from the product definition in FIG. 35.\nThe configuration engine 106 determines the restricted domain by traversing the MDD.  Performing the Minimum Completion operation using restricted domain means that for each additional selection, another restricted domain operation is performed. Thus, for N selections, N+2 restricted domain determinations are performed.  These restricted domain operations include an initial restriction at S202, a restriction for the initial available set, followed by one for each feature at S210.\nFor MDDs, there is an alternate approach for determining the Available features using dynamic programming principles with a single operation that includes one downward traversal and one upward traversal of the MDD.  This approach is more memory\nefficient and faster, especially for larger MDDs.\nWith reference to FIG. 39, a method for determining feature states using dynamic programming is illustrated in accordance with one or more embodiments and generally referenced by S300.  The method S300 is implemented as an algorithm within the\nconfiguration engine 106 using software code contained within the server 102, according to one or more embodiments.  In other embodiments the software code is shared between the server 102 and the user devices 112, 114.\nAt S302, the configuration engine 106 organizes the data into nodes by family and level.  The subroutine of S302 is shown in the flowchart of FIG. 40.  At step S304, the configuration engine 106 determines if a level node object exists, i.e., if\nthe nodes are already organized by level.  Otherwise, the configuration engine 106 proceeds to step S306 and organizes the nodes into a level node array where the length of the array is equal to the number of families.  The configuration engine 106\ninitializes each level array with an empty nodes list, i.e., sets the empty flag to true.  At step S308, for each node (y) analyzed, the configuration engine 106 appends a node (e.g., adds a child node) to the analyzed node's level node list.  Step S308\nis a recursive step, therefore the configuration engine 106 repeats S308 until it finds the True node.  After step S308 the configuration engine 106 proceeds to step S310 and returns to the main routine of FIG. 39 to analyze the nodes by level.\nFIG. 45 is an MDD 4500 illustrating the data organized by level according to S302 and a selection of Red paint and Ruby trim.  The MDD 400 includes five levels.  Level zero represents the package (Pkg) family, which includes three package\nfeatures: 400, 401 and 402 that are depicted by edges (level arrays) 001, 010 and 100, respectively, that extend from node 2.  Level one represents the Radio family, which includes three radio features: Std, Dlx and Nav that are depicted by edges (level\narrays) 001, 010 and 100, respectively, that extend from nodes 3-5.  Level two represents the Paint family, which includes three paint features: White, Red and Blue, that are depicted by edges (level arrays) 001, 010 and 100, respectively, that extend\nfrom nodes 6-8.  Level three represents the trim family, which includes three trim features: Stone, Charcoal and Ruby, that are depicted by edges (level arrays) 001, 010 and 100, respectively, that extend from nodes 9-12.  Level four represents the\nmoonroof (MoonRf) family, which includes two moonroof features: Less and Vista, that are depicted by edges (level arrays) 01 and 10, respectively, that extend from nodes 13-16.  Node 1 is the true node and node 0 is the false node (not shown).\nAt step S312, the configuration engine 106 initializes the state, or marking of each node, by creating a place for each value.  For example, by default, all features are initially set to false (i.e., not marked) except the root node 2 and the\ntrue node 1.  The root node 2 is set to true for the downward traversal (i.e., marked with a downward arrow); and the true node 1 is set to true for the upward traversal (i.e., marked with an upward arrow).  Marking a node with a downward arrow indicates\na valid partial configuration from the root node 2 down to the marked node and any intervening downward marked nodes along the path.  Similarly, marking a node with an upward arrow indicates a valid partial configuration from the true node 1 up to the\nmarked node and any intervening upward marked nodes along the path.\nAt S314, the configuration engine 106 creates a constraint object.  The subroutine of S314 is shown in the flowchart of FIG. 41.  The configuration engine 106 starts analyzing family level zero of the MDD 4500 (i.e., the package family) at step\nS316.  At step S318, the configuration engine 106 determines if the family level (x) is less than the total number of families included in the MDD.  If so, the configuration engine 106 proceeds to step S320.\nAt step S320 the configuration engine 106 determines if the user has selected a feature for family level (x).  If the user has selected a feature for family level (x), the configuration engine 106 proceeds to step S322 and sets the Selected\nfeature to the Allowed feature state and sets the non-selected features for family level (x) to not allowed.  If no features are selected for family level (x), the configuration engine 106 proceeds to step S324 and sets all features to the Allowed\nfeature state.  After steps S322 and S324, the configuration engine 106 proceeds to step S326 to evaluate the next family by incrementing family level (x) by one (i.e. x=x+1), then returns to step S318.\nOnce the configuration engine 106 has created a full constraint object using subroutine S314, the family level (x) will no longer be less than the total number of families, and the configuration engine 106 will make a negative determination at\nstep S318.  For example, after the configuration engine 106 evaluates the moonroof family (level 4), it will set x to five at step S326.  Since there are five families in the MDD 4500, the configuration engine 106 will determine that x (5) is not less\nthan the number of families (5) at step S318 and then proceed to step S328 and then return to the main routine of FIG. 39.\nAt step S330 the configuration engine 106 initializes an availability bit set.  The configuration engine 106 initializes the availability bit set by setting all bits to zero, which indicates that the features are Excluded.  Whereas a bit set\nvalue of one indicates that a feature is Available.\nAt S332, the configuration engine 106 traverses the MDD 4500 in a downward direction.  The subroutine of S332 is shown in the flowchart of FIG. 42.  The configuration engine 106 starts analyzing the nodes included in family level zero of the MDD\n4500 (i.e., the package family) at step S334.  At step S336, the configuration engine 106 determines if the family level (x) is less than the total number of families included in the MDD.  If so, the configuration engine 106 proceeds to step S338.\nAt step S338, the configuration engine 106 starts analyzing node zero.  At step S340 the configuration engine 106 compares the node number (y) to the number of nodes at the current level (x) to determine if y&lt;Level (x) number of nodes.  For\nexample, initially, x is equal to zero and Level (0) has one node, therefore y is less than 1.  If y is not less than the number of nodes at level (x), the configuration engine proceeds to step S342 and increments the level (x) by one.\nAfter a positive determination at step S340, the configuration engine 106 proceeds to step S344 and sets the currently analyzed node or source node (SRC) to level(x) node (y); and sets the array index (z) extending from SRC to zero.  The array\nindex (z) corresponds to a feature of the family (x).  At step S346 the configuration engine 106 compares the array index (z) to the SRC's number of children.  If z is not less than SRC's number of children, the configuration engine 106 proceeds to step\nS348 and increments the node (y) by one.  If the determination at step S346 is positive, the configuration engine 106 proceeds to step S350.\nAt step S350, the configuration engine 106 sets the destination node (DST) to be the child node of node (y) along array index (z) (DST=SRC.child(z)).  The configuration engine 106 analyzes three conditions to determine whether or not to mark the\ndestination node with a downward arrow:\n1) the destination node is not a false node;\n2) the source node was previously marked with a downward arrow; and\n3) the feature of array index (z) is allowed by constraint.\nThese three conditions are illustrated by steps S352-S358 in FIG. 42.\nAt step S352, the configuration engine 106 evaluates the DST node to determine if it is a false node.  Otherwise, the configuration engine 106 proceeds to step S354 to determine if the source node (i.e., the parent of the currently analyzed\ndestination node) was previously marked with a downward arrow.\nAfter a positive determination at S354, the configuration engine 106 determines if the feature of array index (z) is allowed by constraint at step S356, which was previously determined in steps S320-S324 (FIG. 41).  If the conditions of steps\nS352, S354 and S356 are met, the configuration engine 106 proceeds to step S358 and marks the destination node with a downward marker, by setting mark.down(DST) to true.  If any of the conditions of steps S352, S354 and S356 are not met, the\nconfiguration engine 106 proceeds to step S360 and increments the array index (z) by one.\nReferring to FIG. 45, the MDD 4500 illustrates the marked nodes after the downward traversal subroutine S332 of FIG. 42 for a selection of Red paint and Ruby trim.  The configuration engine 106 marks Node 2 with a downward marker at S312 because\nthe root node is a special case that always has a valid downward path.  On the downward traversal of the MDD 4500, a node is marked at S358 if the conditions of steps S352-S356 are met for the analyzed node.  For example, the configuration engine 106\nmarks destination node 3 with a downward marker or arrow 4502 at S356 because node 3 was determined to not be a false node at S352; node 3's source node (node 2) was previously marked with a downward arrow at S354; and the feature of the array index\nconnecting node 2 and node 3 (i.e., Pkg.400) was determined to be allowed by constraint at S356.  Since the user has not selected a packaging feature for this example, all packaging features are set to Allowed (see steps S320, S324 of FIG. 45.)\nSimilarly, the configuration engine 106 determines that the remaining radio nodes and the paint family nodes (nodes 4, 5, 6, 7, and 8) have valid downward markers because the package (Pkg) family and the Radio family are not constrained.  With respect to\nthe partial configurations of Pkg and Radio, all features are Available because the user has not selected a feature from either family.\nRegarding the trim level nodes (9-12), nodes 9 and 10 have downward markers because they were determined to not be false nodes at S352; their source nodes were marked with a downward arrow at S354; and they were determined to be on a valid path\nwith Red paint at S356.  However, nodes 11 and 12 do not have downward markers because they are not on a valid path with Red paint.  Since the user has selected Red paint, the non-selected paint features (White and Blue) are set to not allowed at step\nS322 (FIG. 41) and thus the condition of step S356 is not met for nodes 11 and 12.\nRegarding the moonroof level nodes (13-16), node 14 has a downward marker because it is valid with Ruby trim; however node 13 does not have a downward marker because it is not on a valid path with Ruby trim.  Since the user has selected Ruby\ntrim, the non-selected trim features (Stone and Charcoal) are set to not allowed at step S322 (FIG. 41) and thus the condition of step S356 is not met.  Additionally, nodes 15 and 16 are not marked because their source nodes (11 and 12) were not marked,\nand thus nodes 15 and 16 do not satisfy the condition of step S354.\nThe downward traversal subroutine S332 includes three for-loops.  Once the configuration engine 106 has analyzed all paths it will make a negative determination at step S336, i.e., the level (x) will not be less than the number of families; and\nthe configuration engine 106 will proceed to step S362 and return to the main routine of FIG. 39.\nAt S364, the configuration engine 106 traverses the MDD of FIG. 45 in an upward direction, which is illustrated by MDD 4600 in FIG. 46.  The subroutine of S364 is shown in the flowchart of FIG. 43.  The configuration engine 106 starts analyzing\nthe nodes included in the last family level of the MDD 4600 (i.e., the moonroof family) at step S366.  At step S368, the configuration engine 106 determines if the family level (x) is greater than or equal to zero (i.e., not negative).  If so, the\nconfiguration engine 106 proceeds to step S370.\nAt step S370, the configuration engine 106 starts analyzing node zero.  At step S372 the configuration engine 106 compares the node number (y) to the number of nodes at the current level (x) to determine if y&lt;Level (x) number of nodes.  For\nexample, initially, x is equal to zero and Level (0) has one node, and therefore y is less than 1.  If y is not less than the number of nodes at level (x), the configuration engine proceeds to step S374 and decreases the level (x) by one.\nAfter a positive determination at step S372, the configuration engine 106 proceeds to step S376 and sets the currently analyzed node or source node (SRC) to Level(x)(y); and sets the array index (z) extending from SRC to zero.  At step S378 the\nconfiguration engine 106 compares the array index (z) to the SRC's number of children.  If z is not less than SRC's number of children, the configuration engine 106 proceeds to step S380 and increments the node (y) by one.  If the determination at step\nS378 is positive, the configuration engine 106 proceeds to step S382.\nAt step S382, the configuration engine 106 sets the destination node (DST) to be the child node of node (y) along array index (z) (DST=SRC.child(z)).  The configuration engine 106 analyzes three conditions to determine whether or not to mark the\ndestination node with an upward arrow:\n1) the destination node is not a false node;\n2) the destination node was previously marked with an upward arrow; and\n3) the feature of array index (z) is allowed by constraint.\nThese three conditions are illustrated by steps S384-S388 in FIG. 43.\nAt step S384, the configuration engine 106 evaluates the DST node to determine if it is a false node.  Otherwise, the configuration engine 106 proceeds to step S386 to determine if the destination node (i.e., the child of the currently analyzed\nsource node) was previously marked with an upward arrow.\nAfter a positive determination at S386, the configuration engine 106 determines if the feature of array index (z) is allowed by constraint at step S388, which was previously determined in steps S320-S324 (FIG. 41).  If the conditions of steps\nS384, S386 and S388 are met, the configuration engine 106 proceeds to step S390 and marks the source node with an upward marker, by setting mark.up(SRC) to true.\nAt steps S392 and S394, the configuration engine 106 identifies Available features.  The configuration engine 106 evaluates the source node to determine if it was previously marked with a downward arrow at S392; and if so it proceeds to step\nS394 and sets the feature (z) of node (y) to Available.  Thus, Available features are identified by inspecting each node on the upward traversal.  If there is a valid downward path to the node, and a valid upward path from one of its destinations, the\nconfiguration engine 106 identifies this node as part of a valid path with respect to selections from other families.  Any feature that is on the edge from the node to the destination is identified as Available, because it can be selected without\nrequiring a change to the constrained features.  If any of the conditions of steps S384-S388 and S392 are not met, the configuration engine 106 proceeds to step S396 and increments the array index (z) by one.\nOnce the configuration engine 106 has analyzed all paths it will make a negative determination at step S368, i.e., the level (x) will not be greater than or equal to zero; and the configuration engine 106 will proceed to step S398 and return to\nthe main routine of FIG. 39.\nReferring to FIG. 39, after determining the availability of all features at S364, the configuration engine 106 proceeds to step S400 to determine the feature states.  The subroutine of S400 is shown in the flowchart of FIG. 44.  The\nconfiguration engine 106 starts analyzing the features included in family level zero of the MDD 4600 (e.g., the package family) at step S402.  At step S404, the configuration engine 106 determines if the family level (x) is less than the total number of\nfamilies included in the MDD.  If so, the configuration engine 106 proceeds to step S406.  At step S406, the configuration engine 106 starts analyzing node zero.  At step S408 the configuration engine 106 compares the node number (y) to the number of\nfeatures at the current family level (x) to determine if y&lt;family (x) number of features.\nAfter a positive determination at step S408, the configuration engine 106 proceeds to step S410 and sets the currently analyzed feature (FEAT) to Family(x).Feature(y).  At step S412, the configuration engine 106 evaluates all of the features of\na family, one at a time, to determine if a feature is selected.  If a feature (FEAT) is selected, the configuration engine 106 sets the state of the feature to Selected at S414.  If the feature is not selected, the configuration engine 106 proceeds to\nS416 to determine if the feature was set to Available at S394.  If the feature is Available, the configuration engine 106 proceeds to operation S418 and sets the state of the feature to Available.  If the feature is not Selected and not Available, the\nconfiguration engine 106 sets its state to Excluded at S420.  After steps S414, S418 and S420 the configuration engine 106 proceeds to step S422 to increment the analyzed feature (y) by one.  After evaluating each feature of family (x) to determine if it\nis Available, Selected or Excluded, the configuration engine 106 will make a negative determination at S408 and then proceed to step S424.\nAt steps S424-S428 the configuration engine 106 determines if family (x) has Included features.  First the configuration engine 106 determines if family (x) has any Selected features at S424.  Otherwise, the configuration determines if the\nfamily has exactly one Available feature at S426.  If only one feature of a given family is Available, then the sole Available feature is set to Included at S428.  After steps S424, S426 and S428 the configuration engine proceeds to step S430 and\nincrements the family level (x) by one, then repeats steps S404-S428 for the next family level.  Once the configuration engine 106 has determined the feature states for all families of the MDD, it makes a negative determination at S404 and then returns\nto the main routine at S432.\nJust as the restricted domain method S200 can be performed as a read only step, the dynamic programming method S300 is also read-only and thread safe when the downward and upward markers are kept externally.  Because feature state calculation\noperation is thread safe, multiple configuration requests could be handled simultaneously using the same MDD.  Each request has its own copy of external downward and upward markers, and shares the MDD.  Thread safety is a property that allows code to run\nin multi-threaded environments by re-establishing some of the correspondences between the actual flow of control and the text of the program, by means of synchronization.  For N selections, the restricted domain calculation requires N+2 MDD traversals. \nAn advantage of the dynamic programming method S300 over the restricted domain method S200 is that only two MDD traversals are required regardless of the number of selections.  This provides the dynamic programming method S300 with superior scalability\nfor large and complex MDDs.\nReferring to FIG. 46, the MDD 4600 illustrates the marked nodes after the configuration engine 106 has performed the dynamic programming method S300 including the downward traversal subroutine of FIG. 42 and the upward traversal subroutine of\nFIG. 43 for a selection of Red paint and Ruby trim.  The configuration engine 106 marks the truth node (T) with an upward marker at S312 because the truth node is a special case that always has a valid upward path.\nOn the upward traversal of the MDD 4600, a node is marked at S390 if the conditions of steps S384-S388 are met for the analyzed node.  Regarding the moonroof level of nodes, the configuration engine 106 marks node 13 with a upward marker or\narrow at S390 because its destination node (truth node) was determined to not be a false node at S384; node 13's destination node (truth node) was previously marked with an upward arrow at S386; and the feature of the array index connecting node 13 and\nthe truth node (i.e., MoonRf.  Less) was determined to be allowed by constraint at S388.  Since the user has not selected a moonroof feature for this example, all moonroof features are set to Allowed (see steps S320, S324 of FIG. 41.) Similarly, the\nconfiguration engine 106 determines that the remaining moonroof level nodes (nodes 14, 15 and 16) have valid upward markers.\nThe configuration engine 106 determines the availability of the moonroof family features by evaluating the downward markers on the source moonroof nodes at S392 after evaluating the upward markers on the destination truth node (T) at S386. \nSince all of the moonroof nodes (13-16) were marked with a downward arrow and the truth node was marked with an upward arrow, the configuration engine 106 sets all of the moonroof features to Available at S394 and determines the initial availability bit\nset to be 000 000 000 000 11.\nRegarding the trim level nodes (9-12), the configuration engine 106 marks node 10 with a upward marker or arrow at S390 because its destination node (node 14) was determined to not be a false node at S384; node 10's destination node (node 14)\nwas previously marked with an upward arrow at S386; and the feature of the array index connecting node 10 and node 14 (i.e., Trim.Ruby) was determined to be allowed by constraint at S388, because it was selected by the user at S322.  Similarly, the\nconfiguration engine 106 marks node 11 with an upward marker or arrow at S390.  However, the configuration engine 106 does not mark nodes 9 and 12 with an upward arrow at S390 because they are not on a valid path with Ruby trim.  Since the user has\nselected Ruby trim, the non-selected trim features (Stone and Charcoal) are set to not allowed at step S322 (FIG. 41) and thus the condition of step S388 is not met for nodes 9 and 12.\nThe configuration engine 106 determines the availability of the trim family features by evaluating the downward markers on the source trim nodes S392, after evaluating the upward markers on the destination moonroof nodes (13-16) at S386.  Trim\nnodes 9 and 10 each have a downward marker and a destination with a valid upward marker (i.e., moonroof nodes 13 and 14).  Therefore Ruby trim along path 10-14 and Stone trim along path 9-13 are marked as Available features at S394 because either can be\non a path (in a configuration) with Red paint.  However, trim nodes 11 and 12 do not have a downward marker and therefore are not marked as Available.  The Trim selection can change from Ruby to Stone without requiring a change to the paint selection\n(Red).  However, the Trim selection cannot change from Ruby to Charcoal without requiring a change to the paint (Red).  Therefore the configuration engine 106 determines the Charcoal trim to be Excluded at S420.  The configuration engine 106 determines\nthe updated availability bit set to be 000 000 000 101 11.\nRegarding the paint level nodes (6-8), the configuration engine 106 marks node 7 with an upward marker because its destination node (10) was determined to not be the false node at S384; its destination node (10) was previously marked with an\nupward arrow (S386); and the features of the array indexes connecting node 7 and node 10 (i.e., Paint.Red) were determined to be allowed by constraint at S388 because it was selected by the user at S322.  Similarly, the configuration engine 106 marks\nnode 8 with an upward marker or arrow at S390.  However, the configuration engine 106 does not mark node 6 with an upward arrow at S390 because its destination node (9) was not marked with an upward arrow, and thus node 9 does not satisfy the condition\nof step S386.\nThe configuration engine 106 determines the availability of the paint family features by evaluating the downward markers on the source paint nodes (6-8) at S392, and by evaluating the upward markers on the destination trim level nodes (9-12) at\nS386.  Paint nodes 7 and 8 each have a downward marker and a destination with a valid upward marker (i.e., trim nodes 10 and 11).  Therefore Red paint along path 8-10 and path 7-10, and Blue paint along path 7-11 are marked as Available features at S394. White paint along path 6-9 is not marked as an Available feature at S394, because node 9 was not marked with an upward marker at S386.  Since Red paint and Blue paint are both Available, the paint selection can be changed between Red and Blue, without\nrequiring a change to the trim selection (Ruby).  The configuration engine 106 determines the updated availability bit set to be 000 000 011 101 11.\nWith respect to the partial configurations of the package and radio families, all features are allowed at S324 because the user has not selected a feature from either family.  Therefore nodes 2, 4 and 5 are marked with an upward arrow.  But node\n3 is not marked with an upward marker at S390 because its destination node (6) was not marked with an upward arrow, and thus node 3 does not satisfy the condition of step S386.\nThe configuration engine 106 determines the availability of the radio family by evaluating the downward markers on the source radio nodes (3-5) at S392, and by evaluating the upward markers on the destination paint nodes (6-8) at S386.  Radio\nnodes 4 and 5 each have a downward marker and a destination with a valid upward marker (i.e., paint nodes 7 and 8).  Therefore Navigation radio along path 5-8 and path 4-7, and Deluxe radio along path 5-7 and path 4-7 are marked as Available features at\nS394.  The Standard radio along path 3-6 is not marked as an Available feature at S394, because node 6 was not marked with an upward marker at S386.  Since the Navigation radio and the Deluxe radio are both Available, the radio selection can be changed\nbetween Navigation and Deluxe, without requiring a change to the paint selection (Red) or the trim selection (Ruby).  The configuration engine 106 determines the updated availability bit set to be 000 011 011 101 11.\nThe configuration engine 106 determines the availability of the package family by evaluating the downward markers on the source package node (2) at S392, and by evaluating the upward markers on the destination radio nodes (3-5) at S386.  The\npackage node 2 has a downward marker and destinations with valid upward markers (i.e., radio nodes 4 and 5).  Therefore the 401 package along path 2-4 and the 402 package along path 2-5 are marked as Available features at S394.  The 400 package along\npath 2-3 is not marked as an Available feature at S394, because node 3 was not marked with an upward marker at S386.  Since the 401 package and the 402 package are both Available, the package selection can be changed between 401 and 402, without\nrequiring a change to the paint selection (Red) or the trim selection (Ruby).  The configuration engine 106 determines the full availability bit set to be 011 011 011 101 11 using the dynamic programming method S300, which is consistent with its\ndetermination using the restricted domain method S200 as described above with reference to FIG. 34 and shown in FIG. 36.\nEach time the user selects a feature, the configuration engine 106 updates the configuration by adding the new feature and removing the sibling features of the same family.  Then the configuration engine 106 performs a \"containsAny\" operation,\nas described above with reference to FIGS. 20-21, to see if the MDD contains the new configuration.  If the MDD does not contain the new configuration, then the new configuration is invalid and the configuration engine 106 performs a conflict resolution\nstrategy.\nGenerally, there are two types of conflict resolution strategies invoked when a user selection, or change in selection, leads to a conflict: single conflict resolution and branched conflict resolution.\nIn single conflict resolution, the configuration engine 106 returns the single \"next-closest\" valid configuration and the feature additions and subtractions necessary to change the invalid configuration to a valid configuration in its response. \nThe \"closest\" valid configuration would typically be determined by simply changing the newly requested feature back to its prior state.  However, such a change would be inconsistent with the user's selection.  Therefore the configuration engine 106\ndetermines the next-closest valid configuration using a constraint that the newly requested feature is \"locked\" and not allowed to be changed, according to one or more embodiments.\nIn branched conflict resolution, the configuration engine 106 presents a set of configurations to the user in a resolution tree that are closest to the invalid configuration, and the user is prompted to make changes to the configuration to get\nto a valid configuration.  When resolving conflicts there may be multiple valid configurations all at the same distance from the initial configuration.  In this case there are a set of possible answers when finding the next-closest valid configuration. \nAn option then is to use branched conflict resolution.\nA strategy that is used to determine the closeness between configurations is referred to as the \"minimum edit distance.\" In a configurator application 104, the configuration engine 106 determines the minimum edit distance between an invalid\nconfiguration selected by the user and one or more valid configurations.  The minimum edit distance refers to the number of features in the configuration that must be changed in order to transform the invalid configuration into a valid configuration. \nWhen comparing the invalid configuration to a valid configuration, the configuration engine 106 considers substitute operations to identify what features must change to create a valid configuration without changing the newly requested locked feature.\nWith reference to FIG. 47, a method for resolving conflicts between a user selected invalid configuration and one or more valid configurations is illustrated in accordance with one or more embodiments and generally referenced by S500.  The\nmethod S500 is implemented as an algorithm within the configuration engine 106 using software code contained within the server 102, according to one or more embodiments.  In other embodiments the software code is shared between the server 102 and the\nuser devices 112, 114.\nAt step S502, the configuration engine 106 saves a copy of the root node identity and a set of the node edges to the memory 108 (shown in FIG. 2).  S502 is similar to subroutine S102 described above with reference to FIG. 26.  The configuration\nengine identifies each node (y), copies or clones each outgoing edge of each node (y) in an MDD, and then returns the edge set and the identity of the root node.\nAt step S504 the configuration engine 106 performs a minimum edit calculation of an MDD that is restricted to the configurations that contain the feature selection that triggered the conflict.  In one embodiment the configuration engine 106\nrestricts the MDD using the restrict method as described above with reference to FIGS. 22-23.  In other embodiments, the configuration engine 106 restricts the MDD using the quick-restrict method S100 described above with reference to FIGS. 24-28.  The\nquick-restrict based minimum edit calculation subroutine of S504 is shown in the flowchart of FIG. 48.\nAt step S506 the configuration engine 106 examines the cache memory for source (SRC) node (y) to determine if the quick-restrict subroutine has already been performed on node (y).  If cache (y) exists, then the configuration engine 106 proceeds\nto step S508 and returns to the main routine of FIG. 47.  If cache (y) does not exist, the configuration engine 106 proceeds to step S510.\nAt step S510, the configuration engine 106 starts with array index zero, and sets the empty flag to true.  By setting the empty flag to true, the configuration engine 106 assumes that there are no valid paths from the node, i.e., that all edges\npoint to the false node.  The configuration engine 106 also sets the minimum or best (Best) edit distance as the maximum allowable integer value (Integer Max Value).\nAt step S512, the configuration engine 106 evaluates the array index (z) to determine if (z) is less than the number of node (y)'s children.  A positive determination at step S512 indicates that the configuration engine 106 has not analyzed all\narray indexes of node (y).  If the determination is positive, the configuration engine 106 proceeds to step S514.\nAt step S514, the configuration engine 106 checks if y's child, or destination (DST) node, at array index (z) is false.  If the configuration engine 106 determines that the child is false, then it proceeds to step S516, increments the array\nindex (z) by one, and returns to step S512.  If the determination at step S514 is negative, the configuration engine 106 proceeds to step S518.\nAt step S518 the configuration engine 106 initializes the edits for feature (z) to the maximum integer value, e.g., by setting the total edit distance (cacheBot (z)) for the path from the truth node to the source node to the Integer Max Value.\nAt step S520, the configuration engine 106 evaluates the quick-restricted features list for node (y) to determine if it contains feature (z).  Otherwise, the configuration engine 106 sets y's child node along z to false at S522 and then proceeds\nto step S516 to increment the array index (z) by one.\nAt step S524, the configuration engine 106 sets the edit value (EDIT) for the source node at feature (z).  If the configuration includes feature (z), then the configuration engine sets EDIT to zero.  If the configuration does not include feature\n(z), then the configuration engine sets EDIT to one.\nAt step S528, the configuration engine 106 check's if y's child (DST) at array index (z) is true.  If DST is true, the configuration engine 106 proceeds to step S530 and sets the empty flag to false.  At S532, the configuration engine 106\ncalculates and stores the edit distance or cost (EDIT) for this feature.  Then the configuration engine 106 calculates the total edit distance (cacheBot (z)) for the path from the truth node to the source node, as the sum of a previously calculated edit\ndistance for the path (cacheMid (DST)) and EDIT.  At step S534, the configuration engine 106 compares the total edit distance (cacheBot(z)) to the minimum edit distance (Best) for the given invalid configuration.  If the total edit distance for the\ncurrent feature (cacheBot (z)) is less than Best, the configuration engine 106 proceeds to step S536 and sets cacheBot (z) as Best.  Then the configuration engine 106 proceeds to step S516 and increments feature (z) by one.  If the configuration engine\n106 determines that DST is not the true node at S528, it proceeds to step S538.\nAt step S538, y's children, or (DST) nodes, are rewritten by the result of recursive invocation of the quick-restrict method on the child.  All nodes of the MDD are processed in this manner.  At step S540, the configuration engine 106 checks DST\nto determine if it's not a false node.  If the determination is negative, i.e., DST is the false node, then the configuration engine 106 proceeds directly to S516 to increment the array index (z).  If the determination is positive (e.g., if node (y) is\nconnected to a valid node), then the configuration engine 106 proceeds to steps S530-S536 to update the EDIT distance and compare it to the Best minimum edit distance.\nThe quick restrict based minimum edit calculation subroutine S504 operates on the nodes in a depth first search fashion.  Steps S512-S540 demonstrate an iterative process that operates on each array index (z) of a node (y) before proceeding to\nthe next node.  Once the configuration engine 106 has evaluated all array indexes (z) for a node (y), it will make a negative determination at step S512 (i.e., z will be greater than or equal to the number of y's children), and proceeds to step S542.\nAt step S542 the configuration engine 106 checks if all children (DST) of node (y) are false, i.e., it evaluates the empty flag to determine if any valid configurations were found.  If all of y's children are false, the configuration engine 106\nproceeds to step S544, sets node (y) to the false node, and then returns the cache (y), i.e., saves the analysis of node (y) and returns to the main routine of FIG. 47.  Further, if the node does not contain any edges that conform to the constraint, then\nthe edge pointer is disconnected from the child node in the MDD.  If not all of the children nodes are false, then the configuration engine 106 proceeds to step S546, sets the cacheMid (SRC Node) to Best, and then sets feature (z) to zero.\nAt step S548, the configuration engine 106 again evaluates the array index (z) to determine if (z) is less than the number of node (y)'s children.  Otherwise, the configuration engine 106 proceeds to step S550, sets the cache (y) to (y), and\nthen returns the cache (y), i.e., saves the analysis of node (y) and returns to the main routine of FIG. 47.  A positive determination at step S548 indicates that the configuration engine 106 has not analyzed all array indexes of node (y).  If the\ndetermination is positive, the configuration engine 106 proceeds to step S552.\nAt step S552, the configuration engine 106 compares the total edit distance (cacheBot (z)) to the minimum edit distance (Best) for the given invalid configuration.  If the total edit distance for the current feature (cacheBot (z)) is greater\nthan Best, the configuration engine 106 proceeds to step S554 and sets DST node to false at step S554, and then increments feature (z) by one at step S556 and then returns to S548.\nThe quick-restrict based minimum edit calculation subroutine S504 is a recursive process.  This process continues until all nodes are analyzed, then the configuration engine 106 returns to the main routine of FIG. 47.  The edges for complete\npaths from the root node (node 2) to the truth node (T) define the restricted configuration space.\nThus, the configuration engine 106 calculates the minimum edit distance of all paths, and identifies the minimum edit distance using subroutine S504.  The configuration engine 106 calculates the minimum edit distance on the way back up the MDD,\ni.e., during an upward traversal.  When a new minimum edit distance is found, prior minimum edit paths are trimmed from the MDD by setting the minimum edit distance (Best) to the currently analyzed path (cacheBot (z)) at S536.  The minimum edit distance\nof a path refers to the sum of the edit distances of each edge.  The edit distance for each feature change is 1.  Where there is more than one active feature on an edge, the path for each feature is considered separately when calculating the minimum edit\ndistance.  Then the configuration engine 106 restricts the MDD to the paths that have the minimum edit distance by setting child or destination (DST) nodes to false if the edit distance for their path (cacheBot (z)) is greater than the minimum edit\ndistance (Best) at S554.\nFIG. 49 includes an original or unrestricted MDD 4900, an intermediate MDD 4902 and a final restricted MDD 4904 illustrating the impact of various steps of subroutine S504.\nIn one example, the user selects the 400 package.  Then the configuration engine 106 determines that the Standard (Std) radio, Stone trim and no moonroof (Less) are Included features; and that White paint is a Default feature.  The states of\nthese features are represented by underlined text, boxed text and circled text, respectively in FIG. 49.  Next the user selects Charcoal trim.  The new selected set (400, Charcoal) is not a valid combination because the 400 package can only occur with\nStone trim.  So the new configuration (400, Std, White, Charcoal, Less) is invalid.\nThe intermediate MDD 4902 illustrates the original MDD 4900 after the configuration engine 106 has performed the minimum edit calculation S504 on paths 2-13- .  . . T with respect to a newly selected Charcoal trim feature.  The configuration\nengine 106 first traverses path 2-13-14-15-16-T. No restrict is needed on the downward traversal because the only active trim feature on partial path 15-16 is Charcoal.\nThe configuration engine 106 calculates the minimum edit distance at steps S530-S536 (FIG. 48) during an upward traversal of the MDD.  The configuration engine 106 considers two edges for the partial path T-16: one edge with the moonroof (Vista)\nand one edge without the moonroof (Less).  The configuration engine 106 determines the edit distance for the partial path T-Vista-16 (i.e., with the moonroof (Vista)) to be one because it requires a change in the moonroof feature.  For the partial path\nT-Less-16 without the moonroof (Less), no change is required, so the edit distance is zero.  Because one path (T-Less-16) has a smaller edit distance than the other (T-Vista-16), the edge is restricted to keep the minimum edit path of T-Less-16.  The\nedge from 16-T now shows \"10\", and the edit cost for Node 16 is 0, as referenced by numeral 4906.\nContinuing on the upward traversal, the configuration engine 106 calculates the edit distance of the remaining partial paths to be: zero for 16-15, because it contains Charcoal trim; one for 15-14, because it contains Blue paint, not the Default\nWhite paint; one for 14-13, because it contains the Navigation radio, not the Included Standard radio; and one for 2-13, because it contains the 402 package, not the Selected 400 package.  Therefore the configuration engine 106 calculates the cumulative\nminimum edit distance for path 2-13-14-15-16-T to be three, as referenced by numeral 4908.\nThen the configuration engine 106 restricts the partial path 14-9-10-T because node 9 does not contain the selected Charcoal trim feature.\nNext, the configuration engine 106 considers path 2-13-8-11-12-T. First, partial path 8-11-12-T is considered, and found to have edit distance of 1 because node 8 contains Blue paint and not the Default White paint.  Then the configuration\nengine 106 restricts path 12-T to 12-Less-T; and restricts path 11-12 to 11-Charcoal-12 so that the edit distance for each is zero.\nThen the configuration engine 106 considers partial path 8-9-10-T; but, because of its previous analysis of node 9, it knows that this partial path has been restricted and the 8-9 edge is removed.  The cost of T-12-11-8-13 is 2.  At this point\nthe configuration engine 106 keeps both of the outgoing edges from 13 (i.e., 13-14 .  . . -T, and 13-8- .  . . -T) because they each require 2 edits.  The edit distance for partial path 13-2 is 1.  Thus, after traversing 2-13- .  . . -T, the\nconfiguration engine 106 determines that the current minimum edit distance for Node 2 is 3.\nThe final restricted MDD 4904 illustrates the original MDD 4900 after the configuration engine 106 has quick-restricted it to Charcoal trim at S504 and performed the minimum edit calculation for all paths.\nNext the configuration engine 106 considers path 2-7-8-11-12-T. The configuration engine 106 previously determined that the minimum edit distance at node 8 is 1.  The configuration engine 106 calculates the edit distance for partial path 8-7 to\nbe one because it contains Deluxe and Navigation radio features and not the Included Standard radio feature; and calculates the edit distance for partial path 7-2 to be one, because it contains the 401 package and not the selected 400 package.  The\nconfiguration engine 106 calculates the total edit distance for path 2-7-8-11-12-T to be three.  Since this total edit distance is the same as that of paths 2-13- .  . . -T, the configuration engine 106 keeps all three paths.\nNext the configuration engine 106 considers path 2-3-4-5-6-T. This path is restricted once the configuration engine 106 determines that partial path 5-6 is not compatible with the Selected Charcoal trim constraint.\nThe final MDD 4904 illustrates the final minimum edit space for the invalid configuration (400, Std, White, Charcoal, Less) with the Charcoal trim feature locked, after the configuration engine 106 has completed the minimum edit calculation\nsubroutine S504.  As shown in FIG. 49, the MDD 4904 contains three paths that each have a minimum edit distance of three: 2-1-14-15-16-T; 2-13-8-11-12; and 2-7-8-11-12-T.\nWith reference to FIG. 47, at step S558, the configuration engine 106 determines if the conflict resolution strategy selected for the application is a guided strategy, i.e., a branched resolution strategy.  If a guided conflict resolution is not\nselected, the configuration engine 106 proceeds to operation S560.  At step S560 the configuration engine 106 selects a single target configuration from the minimum edit space using an auto-completion technique such as sequence based or maximally\nstandard.  In one embodiment, the configuration engine 106 selects a single target configuration using a maximally standard auto-completion technique as described below with reference to FIGS. 93-117.  In another embodiment, the configuration engine 106\nselects a single target configuration using a maximum weight quick-restrict technique.\nThe maximum weight quick-restrict based single target configuration calculation subroutine of S560 is shown in the flowchart of FIG. 50.  The weights used in the weight calculation are based on priorities for features such that when there is\nmore than one feature available, the highest priority, or feature having the maximum weight, is chosen as the default.  S560 is similar to the minimum edit quick restrict calculation S504 of FIG. 48.  The only difference is that when the configuration\nengine 106 calculates the maximum weight, it 1) maximizes value instead of minimizing value (which changes the initial value of Best); and 2) calculates the weight for each path instead of the number of edits, where the weight is defined by a priority of\nthe features.\nReferring to FIG. 47, the configuration engine 106 resets or restores the original set of node edges to the memory 108 (shown in FIG. 2) at step S574.  S574 is similar to S146 described above with reference to FIG. 28.  At S574 the configuration\nengine 106 identifies each node (y), copies the outgoing edges of each node in the MDD.  Then the configuration engine 106 sets the MDD to the identity of the root node.\nAt step S576, the configuration engine 106 determines the feature states for the prior configuration.  The prior configuration refers to the prior valid configuration before the configuration engine 106 changed a feature based on a user\nselection; where the addition of the new feature led to an invalid configuration.  S576 is similar to subroutine S300 described above with reference to FIGS. 39-44.  At step S578, the configuration engine 106 determines the feature states for the new\ntarget configuration.  S578 is also similar to S300.\nWith reference to FIG. 49, in one embodiment the configuration engine 106 selects a single target configuration (401, Dlx, Blue, Charcoal, Less) from the minimum edit space of MDD 4904 as S560.  Once the target is identified, the configuration\nengine 106 determines feature states for the prior configuration at S576 and for the new target configuration at S578.  All features start as Default features.  Next, Selected features are determined by adding the previous selections that are still valid\nto the newly selected feature.  Then, the Available, Excluded and Available calculations are determined using the new selections.  In this example the new target configuration states are: Selected (Charcoal), Included (Blue) and Default (401, Dlx, Less).\nAt step S580 of FIG. 47, the configuration engine 106 generates a response that includes the feature additions and subtractions to resolve the conflict.  These features include feature state information--the new state for additions and the prior\nstate for subtractions.  The configuration engine 106 returns raw data including the new and prior feature state maps, the new configuration state (ConfigState), and the list of additions and subtractions.  The author decorator 154 will use this data to\ncompose the response.  The derivation of additions and subtractions subroutine S580 is shown in the flowchart of FIG. 51.\nAt S582, the configuration engine 106 starts analyzing feature (z).  At step S584, the configuration engine 106 determines if the feature (z) is less than the total number of features for the source node.  If so, the configuration engine 106\nproceeds to step S586.  At step S586, the configuration engine 106 defines the term \"Prior\" as the prior feature state of feature (z) and the term \"State\" as the new feature state of feature (z).\nAt step S588, the configuration engine 106 evaluates the feature state term Prior (determined at S576) to determine if feature (z) was present in the prior configuration.  S588 is illustrated in the flow chart of FIG. 52.  If the Prior term is\nequal to Selected, Included or Default, then the configuration engine 106 determines that the Prior term defines a State of a feature that is present in the Prior configuration and returns true at step S592.  Otherwise, the configuration engine 106\nreturns false at S594.  Then the configuration engine 106 sets a boolean before value (BEF) equal to the determination at steps S590-S592, i.e., true or false.\nAlso at step S588, the configuration engine 106 evaluates the feature state term State to determine if it is present in the New configuration.  If the State term is equal to Selected, Included or Default, then the configuration engine 106\nreturns TRUE at step S592.  Otherwise, the configuration engine 106 returns false at S594.  Then the configuration engine 106 sets a boolean after value (AFT) equal to the determination at steps S590-S592, i.e., true or false.\nAt step S594, the configuration engine 106 compares BEF to AFT for feature (z) to see if it has changed.  Otherwise, i.e. if BEF equals AFT, the configuration engine 106 proceeds to step S596 and increments the family level (x) by one.  If the\ndetermination is negative, then the feature was either added or subtracted, and the configuration engine 106 proceeds to step S598 to evaluate \"Return Delta.\"\n\"Return Delta\" refers to the amount of information provided to the user in response to a conflict.  The front-end application 132 determines this level of information by setting the return delta feature to true or false.  Enabling the return\ndelta feature (i.e., setting return delta to true) results in more information being provided to the user.  Conversely, setting return delta to false results in less information being provided to the user.\nWhen the Return Delta flag is set to true, the response will include all additions and subtractions regardless of feature state.  This could allow the front-end application 132 to inspect the resolution and apply some additional logic when\ndeciding whether to prompt the user in response to a conflict or to silently make the changes.  When the Return Delta flag is set to false, the conflict resolution subtractions will only contain Selected features removed from the configuration and\nadditions will only contain Included features added to the configuration.  If the new configuration caused a change in a Default feature, this is not included in the prompt to the user.  If all changes are for Default choices, there are no changes to\nreport, and the response will not include conflict resolution.  The Return Delta flag is set to false by default, in one or more embodiments.\nAt S598, if Return Delta is set to true, the configuration engine 106 proceeds to step S600 to evaluate BEF.  If BEF is set to false at S588 (which indicates that feature (z) was contained in AFT but not in BEF), the configuration engine 106\nadds feature (z) to the list of additions (additions.add(feat(x))) at step S602.  If BEF is set to true (which indicates that feature (z) was contained in AFT but not in BEF), the configuration engine 106 adds feature (z) to the list of subtractions\n(subtractions.add(feat(x))) at step S604.\nIf Return Delta is set to false, the configuration engine 106 proceeds to step S606.  At S606, the configuration engine 106 evaluates BEF and the state of (z).  If BEF is false and the state of (z) is Default, the configuration engine 106\nreturns to S596 to increment the family level (x) by one.  If the determination at S606 is negative, the configuration engine 106 proceeds to step S608.  At S608, if BEF is true and the state of (z) is Selected, the configuration engine 106 returns to\nS596.  Otherwise, the configuration engine 106 returns to S600.\nFIG. 53 is a table 5300 that illustrates the additions and subtractions for the MDD 4900 of FIG. 49 when Return Delta is true and when Return Delta is false.  The MDD 4900 had a Prior configuration of Selected (400), Included (Std, Stone, Less)\nand Default (White), as referenced by numeral 5302.  The configuration engine 106 selected a new target configuration of Selected (Charcoal), Included (Blue) and Default (401, Dlx, Less) at step S578, as referenced by numeral 5304.  When Return Delta is\nfalse, the configuration engine 106 does not show changes (additions or subtractions) to Default Features, but when return delta is true, all changes are shown, as referenced by numeral 5306.\nFIG. 54 is a window 5400 that is displayed to the user to convey the additions and subtractions of features to their prior configuration to accommodate the new configuration triggered by their selection of Charcoal trim, using a single target\nconfiguration when Return Delta is false.  Again, when Return Delta is false, the configuration engine 106 does not show changes (additions or subtractions) to Default features.\nFIG. 55 is a window 5500 that is displayed to the user to convey the additions and subtractions of features to their prior configuration when Return Delta is true.  Since Return Delta is true, the configuration engine 106 shows all changes,\nincluding changes to the Default features.\nReferring to FIG. 47, the configuration engine 106 determines if guided resolution (i.e., branched conflict resolution) is selected at step S558.  If so, it proceeds to step S610.\nIn contrast to single conflict resolution, which only presents a single next-closest configuration to the user, branched conflict resolution can present the entire minimum edit space to the user, in tree format.  This allows the front-end\napplication 132 to present the user with a series of prompts to drive towards a valid configuration.\nIn the minimum edit example described above with reference to FIGS. 49 and 53-55, the minimum edit space contains three superconfigurations defining four configurations.  This space can be compressed to two superconfigurations as shown in FIG.\n56.\nFIG. 56 is a table 5600 that illustrates an example in which the paint family has just one choice (Blue) and the package and radio families each have two choices (401, 402 and Dlx, Nav), but, the choices are not dependent one each other.  The\nchoice of package (401 or 402) does not change the choice of radio (Dlx, Nav).  When all the family choices are independent, the configuration engine 106 can resolve the conflicts in a single step.\nThe configuration engine 106 derives a resolution object that describes the actions to change the invalid configuration to a valid configuration, which is transformed by the author decorators 154 into a SOAP xml response (not shown) which can be\npresented to a user in a single pop up window 5700, as shown in FIG. 57.\nThis example illustrates the advantages offered by branched conflict resolution, as compared to single conflict resolution.  The configuration engine 106 presents the user with more information about how to resolve a conflict and asks them to\nchoose the valid package and radio features, rather than the application silently selecting a valid configuration.\nWhen there are no dependent choices, it is a relatively simple process to transform the target matrix into the conflict resolution response.  However, the resolution object is more complicated when one family's choice is dependent on another\nfamily.\nThe configuration engine 106 makes a series of prompts or inquiries to the user when the guided choices are dependent on a prior choice.  However, each prompt can include more than one independent choice.  When there is a nested or dependent\nchoice, the configuration engine 106 lists the divergent branch as the last feature group in the list.\nIn branched conflict resolution, the minimum edit space may include some partial matches, where a choice is present in some, but not all of the target configurations.  Partial matches in the configuration space can cause the target space to be\ntoo large, and it can lead to awkward user prompts.  In one or more embodiments, the configuration engine 106 trims the minimum edit space to remove partial matches.\nWith reference to FIG. 47, at step S610, the configuration engine 106 determines if removing partial matches functionality is enabled.  If the determination at S610 is positive, the configuration engine 106 proceeds to S612.  The algorithm for\nremoving partial matches S612 is shown in the flowchart of FIG. 58.\nWith reference to FIG. 58, at step S614 the configuration engine 106 creates a weight object, with positive weights for features that are contained within the configuration, and zero weight for features that are not contained within the\nconfiguration.\nAt step S616, the configuration engine 106 creates cache objects.  The configuration engine 106 returns data from cache for node (Y) for weightFeature and for weightNode, if it already exists.  WeightFeature refers to the weight from the node to\nthe bottom of the MDD (i.e., the true node)--for a specified feature.  WeightNode is a Node-based lookup instead of feature based lookup.  Thus, for each node, the configuration engine 106 determines the maximum weight path feature for a given node,\nstores the weight for each feature.  Once the configuration engine 106 knows the maximum feature weight for a node and trims its edges, then it stores the maximum node weight.  The maximum node weight is used as a cache for when the configuration engine\n106 analyzes subsequent nodes.  It can use the previously calculated maximum weight for that node and trim the outgoing edges from the node to only those edges with the maximum weight.\nAt step S618, the configuration engine 106 performs the maximum weight quick-restrict operation.  The maximum weight quick-restrict operation of S618 is the same as the maximum weight quick-restrict subroutine S560 described above with reference\nto FIG. 50.  After the quick restrict operation has removed partial matches, the configuration engine 106 proceeds to S620 (FIG. 47) to derive a resolution object.\nReferring back to FIG. 47, if the configuration engine 106 determines that removing partial matches functionality is not enabled at S610, it proceeds to S620 to derive a resolution object.  The algorithm for deriving a resolution object S620 is\nshown in the flowcharts of FIGS. 59-63.\nReferring to FIG. 59, the configuration engine 106 identifies families to change at step S622.  The algorithm for identifying families to change S622 is shown in the flowchart of FIG. 60.  Referring to FIG. 60, the configuration engine creates a\nbitset of the invalid configuration at step S624.  Next, the configuration engine calculates the domain bitset of the minimum edit space at step S626.  Then at step S628, the configuration engine ANDS the configuration bitset and the domain bitset.\nFIGS. 64-74 are examples illustrating the impact of various steps of the derive resolution object subroutine S620 of the branched conflict resolution method.  Referring to FIG. 64, in one example, a configuration of Default (400, Std, White,\nStone, Less) is modified when the user selects the 401 package.  The configuration engine 106 determines the new invalid configuration to be (401, Std, White, Stone, Less) with a minimum edit space depicted by MDD 6400.\nFIG. 65 is a table 6500 listing the invalid configuration (401, Std, White, Stone, Less) as a bitset (010 100 100 100 10).  FIG. 66 is a table 6600 that depicts the minimum edit space of the configuration converted to a matrix, as determined in\nstep S626 (FIG. 60).\nReferring back to FIG. 60, the configuration engine 106 starts analyzing the nodes included in family level zero (x) of the MDD at step S630.  At step S632, the configuration engine 106 determines if the family level (x) is less than the total\nnumber of families included in the MDD.  If so, the configuration engine 106 proceeds to step S634.\nAt S634, the configuration engine 106 evaluates the number of active features in the intersection, or bitwise conjunction, or \"ANDed\" bitset for family (x).  If there is at least one active feature in the ANDed bitset for family(x), the\nconfiguration engine 106 proceeds to step S636 and increments the family level (x) by one.  However, if there are no active features in the ANDed bitset for family(x), the configuration engine 106 proceeds to step S638 and adds family(x) to the list of\nfamilies to change, and then proceeds to step S636.\nFIG. 67 is a table 6700 illustrating the bitwise conjunction (AND) of the domain of the edit space in the example from table 6600 with the invalid configuration from table 6500.  The configuration engine 106 identifies any family with no active\nbits (i.e., only \"0\"s) in the sum, as referenced by numeral 6702, as a family to change to transform the invalid configuration into a valid one.  Thus, the configuration engine 106 determines that the radio, paint and trim families are families to\nchange.\nWith reference to FIG. 60, once the configuration engine 106 has analyzed all families, it will make a negative determination at step S632, i.e., the level (x) will not be less than the number of families.  Then the configuration engine 106\nproceeds to step S640 and returns to the routine of FIG. 59.\nReferring to FIG. 59, at step S642 the configuration engine 106 trims the edit space to the families identified in S622.  Then at step S644, the configuration engine 106 converts the trimmed space to a matrix, which is represented by table 6600\n(FIG. 66).\nFIG. 68 is a table 6800 that illustrates the minimum edit space from table 6600 after it is trimmed to the families to change (i.e., radio, paint and trim) from table 6700.\nAt step S646 (FIG. 59), the configuration engine 106 creates a resolution object that describes the actions to change the invalid configuration to a valid configuration.  The algorithm for creating a resolution object S646 is shown in the\nflowchart of FIG. 61.\nIn creating a resolution object S646, the configuration engine takes as input the invalid configuration, a target matrix (i.e., the edit space), the list of families to change and the list of families that have been processed so far.  The list\nof families to change is sorted in priority order, according to one or more embodiments.  This sort can be provided by an alternate sequence, or default to the minimum edit space family structure shown in FIG. 68.\nThe configuration engine 106 divides the families to change into No-Branch and Branch lists.  The configuration engine 106 identifies any family that is not identical in all rows of the target matrix as a Branch family.  Each resolution contains\na list of actions for any number of No-Branch families and a single Branch family.\nAn action specifies the family to change, its prior choice, and its possible choice(s).  To simplify parsing of a resolution, the configuration engine 106 organizes the Branch action to be the last action.  The Branch items lead to a divergent\nchoice and the choices for the remaining families are unknown until the Branch family choice is made.  Each choice of the Branch family will have an associated nested resolution object defined in a feature choice that results in resolution mapping.  The\nnested resolution objects are derived by with a new target matrix that is restricted to the feature choice of the branching family, the original families list, and the updated processed families list.\nReferring to FIG. 61, step S648 is a recursive call in which the configuration engine 106 sets the families to consider changing (Families to Consider) equal to the families list minus the families that were already processed (Families\nProcessed).\nAt step S650, the configuration engine 106 divides the families to consider changing (Families to Consider) into Branch and No-Branch lists.  A Branch family is a family whose bit pattern is not identical in all rows of the target matrix,\nwhereas a No-Branch family's bit pattern is identical in all rows.  The algorithm for dividing families into Branch and No-Branch S650 is shown in the flowchart of FIG. 62.\nWith reference to FIG. 62, the configuration engine 106 derives a unique bit pattern for each family based on the target matrix at S652.  The configuration engine 106 starts analyzing the nodes included in family level zero of the MDD at step\nS654.  At step S655, the configuration engine 106 determines if the family level (x) is less than the total number of families to consider changing in the MDD.  If so, the configuration engine 106 proceeds to step S656.\nAt step S656 the configuration engine 106 evaluates the number of unique patterns for family (x).  If there is more than one unique pattern, the configuration engine 106 proceeds to step S658 and adds the family to the Branch category.  If there\nis only one unique pattern, the configuration engine 106 proceeds to step S660 and adds family level (x) to the No-Branch list.  After steps S658 and S660, the configuration engine 106 increments the family level (x) by one and then returns to S655. \nOnce the configuration engine 106 has organized all families into the Branch and No-Branch lists, it makes a negative determination at S655, and then sorts the families within each list by priority at step S662, with the highest priority family listed\nfirst.  The priority of each family is based on its family weight and is determined by a separate system, according to one or more embodiments.  After S662, the configuration engine 106 returns to the create resolution object subroutine S646 of FIG. 61.\nReferring back to FIG. 68, the first call to derive the resolution method object S620 will use the invalid configuration from FIG. 65, the target matrix from FIG. 68, and will pass an empty list for the processed families list--deriveResolution\n(Cfg65, Matrix68, [Radio, Paint, Trim], [ ]).  As shown in table 6800, the bit pattern for radio (i.e., \"011\") is the same in both rows, but is different for both paint and trim.  Therefore the configuration engine 106 identifies radio as a No-Branch\nfamily at S656 and S660, because it only has one unique pattern.  And the configuration engine 106 identifies paint and trim as Branch families at S656 and S658, because they each have more than one unique pattern.\nReferring back to FIG. 61, the configuration engine 106 initializes a resolution object at S664 by creating an empty object.  The configuration engine 106 starts analyzing the first No-Branch family (b=0) at step S666.  At step S668, the\nconfiguration engine 106 determines if the No-Branch family index (b) is less than the total number of No-Branch families.  If so, the configuration engine 106 proceeds to S670.  At step S670, the configuration engine 106 creates an action for No-Branch\nfamily index (b) and adds the action to the Resolution Object.  The algorithm for S670 is shown in the flowchart of FIG. 63.\nWith reference to FIG. 63, the configuration engine 106 initializes an empty Action object at step S672.  Next the configuration engine 106 sets a current feature (z) equal to the family feature (Family) in the invalid configuration at step\nS674.\nAt step S676, the configuration engine 106 sets the group of valid features for the user to choose from (Choices) equal to the active features for the No-Branch family index (b) in the target matrix domain.  Then at step S678, the configuration\nengine 106 returns the Action object to the subroutine S646 of FIG. 61.  With reference to FIG. 61, the configuration engine 106 adds the No-Branch family index (b) to the families processed list at step S679, then it increments the No-Branch family\nindex (b) by one and then returns to step S668.\nReferring to FIGS. 65-71, the configuration engine 106 initializes an empty resolution and adds an action for all No-Branch families, which in this case is radio--the only No-Branch family identified from table 6800.  As shown in table 6500, the\ninvalid configuration includes the Standard radio (i.e., \"100\") and the trimmed minimum edit space of table 6800 shows the possible valid choices for radio include Deluxe and Navigation (i.e., \"011\").  The Action for radio in this example specifies the\nfamily to change (i.e., radio), its prior choice (Standard), and its possible choices (Deluxe and Navigation), which may be represented by: Action {Radio, [Std], [Dlx, Nav]} as shown in FIG. 71.\nReferring back to FIG. 61, once the configuration engine 106 has analyzed all of the No-Branch families, it will make a negative determination at step S668 (i.e., the No-Branch family index (b) is greater than or equal to the number of No-Branch\nfamilies) and then proceed to step S680.  At S680 the configuration engine 106 evaluates the number of Branch families.  If there are zero Branch families, the configuration engine 106 returns to the derive resolution subroutine S620 of FIG. 59.  If\nthere are Branch families (i.e., Branch families&gt;0), the configuration engine 106 proceeds to step S682.\nAt S682 the configuration engine 106 sets Family equal to the first family (i.e., the highest priority family) in the Branch list.  At step S684 the configuration engine 106 creates Action for the Family.  The configuration engine 106\ninitializes an empty Action Object and sets the current feature equal to the Family configuration feature.  Next the configuration engine updates the Action to set Choices equal to the active features for Family in the target matrix domain.  At S688, the\nconfiguration engine 106 creates a new Families Processed list by appending Family to the Families Processed list.\nAt step S690, the configuration engine 106 starts analyzing Choice (c=0).  At step S692, the configuration engine 106 compares Choice (c) to the number of choices.  If Choice (c) is less than the number of choices, then the configuration engine\n106 proceeds to step S694 and creates a new target matrix that is restricted to Choice (c).\nAt step S696, the configuration engine 106 creates a Resolution Object for Choice (c) using the new target matrix and the new Families Processed list by the result of recursive invocation.  At step S698, the configuration engine 106 updates the\nAction to set Branch for Choice (c) equal to the nested Resolution Object.  At step S700, the configuration engine 106 increments Choice (c) by one and returns to step S692.  Once the configuration engine 106 has analyzed all Choices, it determines that\nChoice (c) is equal to the total number of choices at S692 (i.e., C is not less than # Choices).  In response to a negative determination at S692, the configuration engine 106 proceeds to step S702 and adds the Action object to the Resolution.  Then it\nreturns to subroutine S620 (FIG. 59) and then back to the main conflict resolution routine S500 of FIG. 47.\nWith reference to FIGS. 65-71, the configuration engine 106 generates the Action for the highest priority Branch family, which in this case is the Paint family because it defaulted to using MDD/Matrix structure/family ordering where the right to\nleft ordering defines priority values.  As shown in table 6700, paint oriented to the left of trim, so paint is higher priority.  For each paint Choice, the configuration engine derives a nested resolution by first creating a new target matrix by\nrestricting to the paint choice, and making a call to derive resolution.\nAs shown in the trimmed minimum edit space of table 6800, there are two possible Choices for the paint family--Red (i.e., \"010\") and Blue (\"001\").  There will be two additional calls to derive resolution: one for Red\npaint--deriveResolution(Cfg65, Matrix.Red, [Radio, Paint, Trim], [Radio, Paint]); and one for Blue paint--deriveResolution(Cfg65, Matrix.Blue, [Radio, Paint, Trim], [Radio, Paint]).  As shown in FIG. 71, the Action for paint in this example specifies the\nfamily to change (i.e., paint), its prior choice (White, i.e., \"100\" in table 6500), and its possible choices (Red and Blue), which may be represented by: Action {Paint, [White], [Red, Blue]}.\nIn both cases (Red paint and Blue paint), the configuration engine 106 uses a trimmed target matrix and the families list contains only one family (trim) because there is only one other Branch family in this example.  FIG. 69 is a target matrix\n6900 for the Red paint choice.  The target matrix 6900 shows that there is just one choice for trim (i.e., Ruby, \"001\").  FIG. 70 is a target matrix 7000 for the Blue paint choice.  The target matrix 7000 shows that there are two choices for trim (i.e.,\nCharcoal and Ruby, \"011\").  The configuration engine 106 determines the resulting resolution of each target matrix 6900 and 7000 and adds the nested resolutions for paint to its action to determine a final resolution object 7100 (FIG. 71).\nAs shown in FIG. 71, the Action for the nested resolution for Red paint in this example specifies the family to change (i.e., trim), its prior choice (Stone, i.e., \"100\" in table 6500), and its possible choice (Ruby), which is represented by:\nAction {Trim, [Stone], [Ruby]}.  The Action for the nested resolution for Blue paint in this example specifies the family to change (i.e., trim), its prior choice (Stone, i.e., \"100\" in table 6500), and its possible choices (Charcoal and Ruby), which is\nrepresented by: Action {Trim, [Stone], [Charcoal, Ruby]}.\nReferring back to FIG. 47, at S704, the configuration engine 106 restores the original set of node edges to the memory 108 (shown in FIG. 2).  S704 is similar to subroutine S146 of FIG. 28.  The configuration engine identifies each node (y),\ncopies each outgoing edge of each node.  Then, the configuration engine 106 sets the MDD to the identity of the root node.  At step S706, the configuration engine 106 returns a response by providing the resolution object 7100 to the author decorator 154;\nwho in turn transforms the resolution object 7100 into a SOAP xml response (FIG. 2) which is presented to the user in a series of windows, as shown in FIGS. 72-74.\nAs described above with reference to resolution object 7100 (FIG. 71), the configuration engine 106 determined a guided resolution that includes a nested choice for trim.  The Available choices for trim depend on the user's selection for paint. \nFIG. 72 depicts a window 7200 with a first prompt that is displayed to the user.  FIG. 73 and FIG. 74 show the next prompt displayed as determined by the choice of Red or Blue paint.\nIf the user selects Red paint in response to the prompt shown in window 7200, the configuration engine 106 will guide them along partial path 8-9-10 (FIG. 64) and then display window 7300 to instruct them to change the trim from Stone to Ruby.\nHowever, if the user selects Blue paint in response to the prompt shown in window 7200, the configuration engine 106 will guide them along partial path 8-11-12 (FIG. 64) and then display window 7400 to instruct them to change the trim from Stone\nto one of Charcoal and Ruby.\nAs described above with reference to FIG. 58, in branched conflict resolution the minimum edit space may include some partial matches, where a choice is present in some, but not all of the target configurations.  Partial matches in the\nconfiguration space can cause the target space to be too large, and it can lead to awkward user prompts.  The configuration engine 106 may trim the minimum edit space using the removing partial matches subroutine S612.  This is done using the maximum\nweight quick-restrict operation, according to one or more embodiments.  However, only the partial match features are provided with relative non-zero weights; all other features are given an equal weight of zero at S614.\nFIGS. 75-76 are examples illustrating the impact of various steps of the remove partial matches subroutine S612.  In the illustrated embodiment, a selection of D2 leads to the invalid configuration (A1, B2, C3, D2, E3, F1) with the minimum edit\nspace shown in MDD 7500 of FIG. 75.  There are two partial matches--B2 (i.e., the outgoing edge \"010\" from node 12) and E3 (i.e., the outgoing edge \"001\" from node 11)--where a user selection could remain the same or be changed.  If B2 remains unchanged,\nthen E3 must change to E2, because E3 is not located along the same path as B2 (i.e., partial path 11-12-13-14).  But, E3 can remain unchanged if B2 changes to B3, because E3 is located on the same path as B3 (i.e., partial path 11-15-16-14).\nWith an alternate sequence {A1 A2 B1 B2 B3 D1 D2 C1 C2 C3 C4 E1 E2 E3 F1 F2}, and an invalid configuration of {D2 A1 E3 B2 C3 F1}, the structure used for path weights is {A1 B2 C3 D2 E3 F1}.  The maximum weight operation will ignore any edges\nwith negative weights (A2 B1 C1 C2 C4 D1 E1 E2 F2).  The weights for the two paths in the minimum edit space are shown in Table 7600 of FIG. 76.  The first row shows path 2-10-11-12-13-14-1.  This path defines the configuration of {D2 A1 E2 B2 C2 F2} and\na path weight bit set of 010100.  There are two active bits in the path weight which correspond to the features B2 and D2--the two features on this path with non-negative weights.  There are no active bits for the other features (A1, C2, E2, F2) because\nthey have negative weights and are ignored.  The second row shows path 2-10-11-15-16-13-1.  This path defines the configuration of {D2 A1 E3 B3 C2 F2} and a path weight bit set of 000110.  There are two active bits in the path weight which correspond to\nthe features D2 and E3.  Based on these weights, the configuration engine 106 trims the space to a single path of 2-10-11-12-13-14-T. The higher priority family B will remain unchanged, and the resolution will include a change for family E.\nWhen an update request is made, the configuration engine 106 modifies the prior configuration by adding the newly Selected feature (while also removing the prior choice for the feature's family).  As described above with reference to FIGS. 47\nand 48, if the updated configuration is invalid, conflict resolution is triggered and the configuration engine 106 calculates the minimum edit space at S504.  The service API 134 does not dictate how the minimum edit space is calculated.  The\nconfiguration engine 106 determines the level of precedence to be given to prior Selected features.\nIn one embodiment, the configuration engine 106 treats all features in the invalid configuration equally, regardless of feature state.  In this instance the minimum edit calculation S504 is performed using the full invalid configuration.\nIn another embodiment, the configuration engine 106 gives precedence to keeping the maximum number of previously selected features.  The configuration engine 106 performs this strategy by performing the minimum edit calculation S504 using a\npartial configuration that ignores any feature whose prior state is Included or Default.  Only the new and previous Selected features are kept when making the minimum edit space calculation.  In one embodiment the configuration engine 106 performs the\nminimum edit calculation S504 after determining whether or not the resolution is guided at S558.  If the resolution is not guided, the configuration engine 106 performs the minimum edit space calculation S504 using only the Selected features.  However,\nif the resolution is guided, the configuration engine 106 performs the minimum edit space calculation S504 using the full invalid configuration.\nFIGS. 77-81 are examples illustrating the impact of various steps of the minimum edit space calculation S504 using a full configuration and using a partial configuration.  In the illustrated embodiments, the configuration engine 106 analyzes the\nfull buildable space shown in Table 7700 of FIG. 77, where the features are numerically named--e.g. Family E has two features E1 and E2.  If the previous configuration is Selected (F1, E2) and Included (A2, T1, R1) and Default (S5, P1, Y3) and an update\nrequest is received to select T2.  The configuration engine 106 determines that the updated configuration is invalid because (F1, E2, T2) is not a valid combination.  As shown in Table 7700, row 1 is the only configuration that includes both F1 and E2,\nbut it includes T1 not T2.\nThe two possible minimum edit spaces are shown in Table 7800 of FIG. 78 and Table 7900 of FIG. 79.  The first minimum edit space (7800) considers the partial configuration where only the new set of selected features is used in the minimum edit\nspace calculation (F1, E2, T2) and the second minimum edit space (7900) considers the full configuration where the complete invalid configuration is used in the minimum edit space calculation (F1, E2, A2, T2, R1, S5, P1, Y3).\nUsing the matrix structure as the priority sequence, the configuration engine 106 identifies a single target configuration from each minimum edit space.  The priority sequence is based on the matrix as is with left most bit being highest\npriority.  So in this case, the configuration engine 106 selects a configuration by choosing features for each family in a left-to right fashion, and choosing the left-most available feature for each family.  With reference to FIG. 78, since the E and F\nfamilies are the same for all configurations; and the configuration in the bottom row has the highest priority feature for family Y, the first space will result in a target of E1, F2, Y1, T2, R3, P1, S1, A2 which corresponds to the bottom row of Table\n7800.  The second space will result in a target of E1, F2, Y3, T2, R1, P1, S5, A2.  The decision on how to calculate the minimum edit space will affect the target configuration, and thus affects the number of feature edits required.\nTable 8000 of FIG. 80 shows the changes required (i.e., the shaded features in target 1) when the configuration engine 106 makes the minimum edit space calculation with only the selected features, based on the minimum edit space in Table 7800. \nAs shown in Table 8000, the features to change are: E1, F2, Y1, R3 and S1.\nTable 8100 of FIG. 81 shows the changes required (i.e., the shaded features in target 2) when the minimum edit space calculation is made with the full invalid configuration, based on the minimum edit space in Table 7900.  As shown in Table 8000,\nthe features to change are: E1 and F2.  In both cases the changes to families E and F are the same because T2 is only available with E1 and F2.  But, if the minimum edit space calculation considers only the Selected features, there are three other\nrequired changes (i.e., Y1, R3 and S1, as shown in Table 8000).\nWhen the configuration engine 106 performs the calculation with the full configuration, it minimizes the total edits, as shown in Table 8100.  It gives no special precedence to previous Selected features.\nWhen the configuration engine 106 performs the calculation with only the new selected set, it is attempting to minimize the changes to prior selections by giving precedence to Selected features.  The side effect is that this increases the total\nnumber of edits required, as shown in Table 8000.\nThe other motivation to perform the minimum edit space calculation on only Selected features is to ensure that the maximally standard default is always driven by the Selected set.\nThe configuration engine 106 results include a Boolean flag to indicate if there is a conflict.  When there is a conflict, the configuration engine 106 determines either a single conflict resolution object or a branched conflict resolution\nobject, depending on the guided resolution flag.\nBecause the services API 134 dictates that a conflict resolution is returned only if there are changes required to the previous selected features, it is possible that the same configuration request will return conflict=true when guided=true, but\nwill return conflict=false when guided=false.\nUsing the product definition from FIG. 10, in one example the configuration engine 106 considers a configuration where the user has selected Red paint, and autocomplete is true.  One such configuration is Selected (Red) and Default (400, Std,\nStone, Less).  If the user updates the configuration by selecting the navigation (Nav) radio, the new configuration (Nav, Red, 400, Stone, Less) is invalid.\nWhen guided resolution is true, the configuration engine 106 returns a conflict of false and a returns resolution such as {Actions [Action {Pkg, [400], [401,402]}, Action {Trim, [Stone], [Ruby]}]}.\nHowever, when guided resolution is false, the API dictates that there is no conflict because the new Selected features (Nav, Red) are compatible.  Even though changes are required for Pkg and Trim, because these were default choices, no conflict\nis reported.  The configuration engine 106 will return conflict of false even though the new configuration and associated feature states show that there is a necessary change to prior default choices for the 400 package, and Stone trim--{Std=AVAILABLE,\nNav=SELECTED, Stone=EXCLUDED, White=EXCLUDED, Charcoal=EXCLUDED, Vista=AVAILABLE, Dlx=AVAILABLE, Red=SELECTED, 400=EXCLUDED, 401=DEFAULT, 402=AVAILABLE, Less=DEFAULT, Blue=AVAILABLE, Ruby=INCLUDED}.\nThe service API 134 specifies that a request can select or unselect a feature.  Selecting a feature adds it to the configuration.  When a feature is unselected, the API dictates only that the feature state is no longer Selected.  It does not\nrequire that the feature be removed from the configuration.\nThere are at least two embodiments.  In a first embodiment, the configuration engine 106 removes the unselected feature from the Selected set and proceeds normally.  In a second embodiment, the configuration engine 106 removes the unselected\nfeature from the configuration entirely.\nRemoving the unselected feature from the Selected set follows the API specification that the feature is no longer Selected.  However, the feature may not actually be removed from the configuration.  In a configurator application, this could mean\nthat the user unchecks the box to remove the feature only to have the checkbox checked again because it is not removed from the configuration.  This behavior can be difficult because no matter what the user does to try and remove the feature, the feature\nkeeps getting added back.\nIn this first embodiment, if a Default or Included feature is unselected, there will be no change in the configuration or feature states.  The Selected set does not change because the feature being unselected wasn't in the Selected set.  As\nsuch, an Included feature will remain Included and a default will remain default.  Included state depends on the Selected set which did not change and auto completion is designed to give repeatable results for the same minimally complete configuration\nwhich did not change.\nIf a Selected feature is unselected, the feature state may change to Included or Default.  If the feature is Included by the remaining Selected features, its state will change from Selected to Included.  Otherwise, it is possible that the\nremoved feature is added back during auto completion.\nDepending on the front-end application 132, the user is most likely unaware of the feature states of Selected, Included and Default.  If the user is unaware of feature states, it can be quite perplexing to unselect a feature only to have it\nremain in the configuration.\nTo avoid this confusion, in the second embodiment, the configuration engine 106 removes the feature from the configuration regardless of its state.  This implementation will trigger conflict resolution when a feature from the configuration is\nunselected.  To ensure the unselected feature remains absent from the new configuration, the configuration engine 106 restricts the buildable space to only those configurations that do not contain the unselected feature prior to the minimum edit\ncalculation.  This approach ensures that the unselected feature is removed from the configuration.\nWhen auto completion is enabled, the configuration engine 106 makes Default choices until the configuration is complete with respect to displayable families.  This is done by making determinations for each incomplete family that is consistent\nwith prior Selected and Included feature states.\nIn one embodiment, the configuration engine 106 makes Default feature state determinations based on a priority sequence for each family and feature.  Incomplete families are processed in priority order, and where more than one feature is valid\nwith prior Selected, Included and Default feature states, the feature priority is used to make the Default determination.\nWith reference to FIG. 82, a method for automatically completing a configuration using a sequence-based approach is illustrated in accordance with one or more embodiments and generally referenced by S750.  The method S750 is implemented as an\nalgorithm within the configuration engine 106 using software code contained within the server 102, according to one or more embodiments.  In other embodiments the software code is shared between the server 102 and the user devices 112, 114.  The method\nS750 uses quick-restrict and domain to make default selections.\nAt S752, the configuration engine 106 starts with an MDD restricted to Selected features, and a configuration defined by the Selected and Included features.  At S754, the configuration engine 106 sorts families by priority.  Then, at S756, for\neach family without Selected or Included features, that are sorted by priority, the configuration engine 106 calculates the domain of the current restricted space.  At S758, the configuration engine determines the highest priority feature for the family,\nmarks it as a Default feature, and further restricts the restricted space to this feature.\nAlternatively, in another embodiment, after S752, the configuration engine 106 proceeds to S760 and uses sequences to determine the maximally weighted path in the MDD that contains the Selected and Included features, which identifies default\nchoices for families to complete.\nPath weight can be represented by a feature Bitset, where the families are ordered left to right according to priority (with the leftmost family being the highest priority), and features are also ordered left to right according to priority\nwithin each family (with the feature corresponding to the leftmost bit being the highest priority).  This is analogous to sorting the features in descending priority and assigning weights by powers of 2, -1 2 4 8 16 .  . . , and ensures that each path\nwill be uniquely weighted, and that there will be exactly one maximally weighted path when each family and feature is assigned a sequence.  To compare two paths, the Bitsets are sorted in descending bit order.\nInitially the path weight is 0, and as an edge is added during MDD traversal, edge weight is added to the path by simply setting a corresponding bit associated with the feature on that edge.\nIdeally, the MDD structure would reflect the priority sequence for features and families.  However, compression of the MDD requires the family ordering to be determined by the compression algorithm, and the feature order is arbitrarily\ndetermined by feature conditions of the MDD algorithm.  While the MDD structure can't be used to store priority sequence, a secondary structure can be created to store this sequencing.  The MDD structure is used to determine the feature for each edge,\nand the alternate/secondary structure is used to set the feature's bits in the path weight Bitset.\nFIG. 83 shows an MDD 8300 that defines the same buildable space as MDD 1300 (FIG. 13), except that the features within each family are sorted alphabetically and the family order is based on MDD compression.  For example, the radio features are\nsorted as STD, DLX and NAV in MDD 1300 and as DLX, NAV and STD in MDD 8300.  FIG. 84 is a table 8400 that defines the alternate sequence structure defining path weights, which is the same as the structure of MDD 1300.\nReferring back to FIG. 82, the configuration engine 106 begins the weighted operation with a minimally completed configuration, and starts with a quick-restrict operation (S752).  In another embodiment, the configuration engine 106 combines the\nquick-restrict operation with the weighted operation (S760), as is done in Minimum Edit Distance subroutine described with reference to FIG. 48 regarding resolving configuration conflicts.  On the downward traversal, no additional action is taken.  On\nthe upward traversal, the configuration engine 106 calculates the path weight with the aid of the alternate sequence structure 8400.  Where a node has more than one outgoing edge, the weight is calculated separately for each feature that has a valid\noutgoing edge.  When a new maximally weighted path is found, lesser weighted paths are trimmed from the MDD.\nFIG. 85 illustrates an MDD 8500 after the configuration engine 106 restricts the MDD 8300 (FIG. 83) to a selection of Blue paint and no Included or Default features, i.e., a minimally complete configuration: Selected{Blue}+Included{ }+Default{\n}, as described with reference to S752.  Then configuration engine 106 starts the weighted operation, i.e., S760, with the quick-restricted space shown in MDD 8500.  Using depth-first search and traversing child edges in descending bit order, the first\npath traversed is 2-8-9-10-6-T.\nThe configuration engine 106 calculates path weight on the upward traversal beginning with partial path T-6-10-9.  This path weight, along with the weight of its partial paths, is shown in Table 8600 of FIG. 86.\nThe configuration engine 106 continues the downward traversal from Node 9 with the 401 package (Pkg.401).  There are two partial paths to consider: 9-5-7-T and 9-5-6-T. The two partial paths from Node 5 to the truth node are compared to find the\nmaximum weight between Ruby and Charcoal Trim, as shown in Table 8700 (FIG. 87).  The configuration engine 106 determines that Charcoal Trim (path 9-5-6-T) is the maximum, because 000 000 001 010 00 is greater than 000 000 001 001 00, as referenced by\nnumeral 8702, and the edge 5-7 (Ruby Trim) is removed (shown in FIG. 89).\nNext, the configuration engine 106 compares the paths from Node 9 to the Truth node, as shown in Table 8800 (FIG. 88).  The configuration engine 106 determines that the partial path for the 401 Package is the maximum because the corresponding\nbits (010) are greater than the corresponding bits of the 402 package (i.e., 001), as referenced by numeral 8802; and trims edge 9-10 from the MDD 8500.  At this point the MDD will look like MDD 8900, as shown in FIG. 89.\nThe maximum weight path for edge 8-9 is MoonRf.Less, because the corresponding bits for Less (10) are greater than the corresponding bits for Vista (01).  The configuration engine 106 determines that the configuration\n{Dlx,Less,401,Charcoal,Blue} is the maximum weight for path 2-8- .  . . -T and that the maximum weight configuration for path 2-3- .  . . -T is {Std,Less,401,Charcoal,Blue}.  The edge weights for these paths are shown in Table 9000 in FIG. 90, and the\nmaximum weight outgoing edge from node 2 is Dlx, because 010 is greater than 001 (Nav), as referenced by numeral 9002.\nThe configuration engine 106 trims edges 2-8-9-5, 10-6 and 7-T as shown in MDD 8900 (FIG. 89).  This leaves the maximum weight path as 2-3-4-5-6-T, and the configuration engine 106 marks Radio.Dlx, MoonRf.Less, Pkg.401 and Trim.Charcoal as\nDefault features at S760 to generate an autocompleted configuration of: Selected {Blue}+Included{ }+Default {Dlx,Less,401,Charcoal}.\nA problem with sequence based auto completion is that it requires additional data to define the priority sequence.  This requires manual setup for every vehicle in the catalog.  Furthermore, it is not guaranteed to provide the maximally standard\nconfiguration.\nSequence-based auto completion is attempting to supplement the MDD with data that will allow the autocompleted configuration to be maximally standard.  A \"maximally standard\" configuration is one where a configuration contains the most possibly\nstandard content, where standard content is determined by the product definition.  A standard feature is generally a feature that is included in the base price for a product, such as a vehicle.  Whereas an optional feature is typically an upgrade and\nwill increase the price of the product.\nFor simpler product definition, it is may be possible to ensure maximally standard configurations using the alternate sequence approach.  However, for more complex product definition, this approach will not work.\nThe product definition defines a set of feature conditions that determine when a feature is available.  There are three types of availability--as a standard feature, as an included feature, and as an optional feature.  A feature could have\ndifferent availability depending on the current configuration.  A standard feature is a feature that is included in the base product (vehicle) configuration and an optional feature is a feature that is not included in the base product.  An optional\nfeature is typically an upgrade that will add cost to the base price, but this is not always the case as a feature could be a zero-cost option or even a less expensive option than the standard feature.  An included feature is generally a feature that is\nassociated with another feature (e.g., a package) and was added to the product by selecting the other feature.  For example, leather seats and fuzzy dice may be included in the 401 package.  When the user selects the 401 package, they see one change in\nprice for the package, but the change includes both features (i.e., leather seats and fuzzy dice).\nThe configuration engine 106 uses the maximally standard algorithm to distinguish feature availability based on standard or optional feature conditions.  A feature included in a package is a special case of a standard feature.  In addition to\nthe valid buildable space, the product definition also defines the standard feature conditions for each family.  When the configuration engine 106 selects Default features using the maximally standard algorithm, it is configured to select as many\nstandard features as possible to avoid or limit adding optional content and potentially increasing the price when the user has not explicitly selected the feature.\nFIG. 91 is a Table 9100 that shows a matrix that defines the same buildable space as MDD 1700 (FIG. 17).  FIG. 92 is a Table 9200 that shows the standard feature conditions for the product definition defining the buildable space.\nFor the package (Pkg) family, there is a single feature condition defining Pkg.400 as the standard package, as referenced by numeral 9202.  For the Radio family, there are two standard feature conditions, as referenced by numeral 9204.  The\nfirst (upper row) defines Radio.  Std as the standard Radio for Pkg.400.  The second (lower row) defines Radio.Dlx as the standard Radio for Pkg.401 and Pkg.402.  The buildable space shows that Radio.Nav is also available.  Because this feature condition\nis not included in the Standard feature conditions (i.e., Radio.Nav is not active (1) in condition 9204), the navigation radio (Nav) is defined as an optional choice that can be added in place of the deluxe radio (Dlx) for the 401 or 402 package.  There\nis a single feature condition for the moonroof family defining no moonroof (Less) as the standard package, as referenced by numeral 9206.  There are two standard feature conditions for the dice family, as referenced by numeral 9208; the first defines no\ndice as the standard feature for white paint; and the second defines fuzzy dice as the standard feature for red and blue paint.  There are three standard features for the seat temperature (Temp) family, as referenced by numeral 9210; the first defines no\nseat temperature feature (LessTemp) as the standard feature for the 400 package; the second defines heated seat control (Heat) as the standard feature for the 401 package; and the third defines heated and cooled seat control (HeatCool) as the standard\nfeature for the 402 package.\nWith reference to FIG. 93, a method for automatically completing a configuration using a maximally standard algorithm is illustrated as software code in accordance with one or more embodiments and generally referenced by 9300.\nTo automatically complete the configuration using standard feature conditions, the configuration engine 106 first restricts the buildable space to the minimally complete configuration at operation 9301.  Families absent from the configuration\nare processed in priority order, and the space is restricted for each successive choice.  To make the default choice for a family, its standard feature conditions are inspected to see what standard choice(s) are still possible at operation 9304.  If no\nstandard choices are possible, the domain of the restricted space will define possible optional choices at operation 9306.  Where more than one possible choice exists for a family, alternate sequencing is used to choose the highest priority feature as\nthe default at operation 9308.\nIt is uncommon, but valid, for a family to have to no standard feature conditions.  This is handled as if no standard features are available, and the choice will be made from the optional content.\nIt is also valid for the standard feature conditions to define more than one standard feature for the same partial configuration.  Where more than one standard feature is available, the highest priority feature will be chosen.\nWhere all feature conditions for a family are stored in a single MDD, the standard features that are still allowed with prior choices can be identified by an AND operation of this MDD with the current restricted buildable space.  An AND\noperation generates a new MDD for each inspection of a feature condition MDD.  As discussed in the Quick-Restrict section, this will incur performance problems from garbage collection.  The alternate approach, as shown in FIG. 93, is to divide the\nstandard feature conditions by feature (and not just family) and use the containsAny operation.  The containsAny operation is the same logic as an AND operation, however the new space is not created.\nWith reference to FIG. 94, in one embodiment, the configuration engine 106 considers a scenario where a user has selected the Vista moonroof and Ruby trim.  With these two selections, Fuzy Dice is included.  Given a priority order of [Pkg,\nRadio, Moonrf, Temp, Paint, Dice, Trim], the families to autocomplete, in order are [Pkg, Radio, Temp, Paint].  The configuration engine 106 does not auto-complete the Dice, Trim and Moonroof families because they are already \"complete\", i.e., they have\nfeatures with Selected or Included feature states.\nThe configuration engine 106 restricts the MDD to the minimally complete configuration Vista, Ruby, and Fuzzy Dice as shown by MDD 9400 in FIG. 94.\nFirst, the configuration engine 106 processes the package family (Pkg) because it has the highest priority.  As described with reference to FIG. 92, there is one standard feature condition for the package family (i.e., Pkg 400, 9202).  Because\nthe 400 package (i.e., the left-most feature of Pkg) is not contained in the restricted space illustrated by MDD 9400, the standard feature is not available.  MDD 9400 shows that the domain of the package family is 011 showing that both the 401 and 402\npackages are available in the restricted space.  The configuration engine 106 chooses the 401 package based on priority and the space is further restricted to package 401 (i.e., nodes 9 and 10 are removed) as shown by MDD 9402.  The restricted space now\ncontains a single superconfiguration.\nNext, the configuration engine processes the radio family.  As described with reference to FIG. 92, there are two standard feature conditions for the radio family: one for Radio.  Std and one for Radio.Dlx (9204, FIG. 92).  At this point the\ndeluxe (Dlx) radio and the navigation (Nav) radio are available in the restricted space illustrated by MDD 9402.  The configuration engine 106 selects Dlx as a Default feature, because it is the only standard feature remaining in the restricted space,\nand further restricts the buildable space to Dlx, as indicated by the modified edge label from 011 to 010 and reference by numeral 9404.  However, this restriction will not change availability for other families since the space is already a single\nsuperconfiguration.\nNext, the configuration engine 106 processes the seat temperature (Temp) family.  There are three standard feature conditions for Temp (9210, FIG. 92).  But, since Pkg 401 has already been selected, only Temp.Heat will be available, as indicated\nby edge label 010 in MDD 9402.  Therefore the configuration engine 106 adds heated seats (Heat) to the configuration as a Default feature.\nNext, the configuration engine 106 processes the paint family.  There are no standard feature conditions for paint (Table 9200, FIG. 92).  The domain of the restricted space has two choices--Red and Blue, as indicated by edge label 011 in MDD\n9402.  The configuration engine 106 adds Red as the Default choice, and further restricts the MDD 9402 to Red (010) as referenced by numeral 9406, because Red (010) has more weight than Blue (001).\nFinally, the configuration engine 106 processes the dice family.  There are two feature conditions for Dice (9208, FIG. 92).  Because Red paint has been added to the configuration, only Fuzzy Dice is available, and fuzzy dice is already an\nIncluded feature.  Therefore the configuration engine 106 does not change its feature state.\nWith reference to FIGS. 95-99, another method for automatically completing a configuration using a maximally standard algorithm is illustrated in accordance with one or more embodiments and generally referenced by S800.  The maximally standard\nauto-completion method S800 is implemented as an algorithm within the configuration engine 106 using software code contained within the server 102, according to one or more embodiments.  In other embodiments the software code is shared between the server\n102 and the user devices 112, 114.\nAt S802, the configuration engine 106 generates a maximally standard data space (MsDataSpace) based on a total or global buildable space and a relationships work object (relWork).  The total buildable space includes a main space that defines all\npossible configurations of non-deterministic features and relationships spaces that define the availability of deterministic features in terms of non-deterministic features.  The intersection of the main space and the relationships spaces define all\npossible configurations.  The main space and relationship spaces are specified by MDDs, according to one or more embodiments.  The total buildable space includes the main MDD and a relationships MDD, and is quick-restricted to any Selected and Included\nfeatures.  RelWork is a temporary object that is used to process a specific condition that may occur based on the order families are processed.  As discussed below, relWork is nontrivial if after selecting a Default feature from a deterministic family,\nthere is more than one defining feature condition such that the configuration engine 106 cannot quick restrict the main MDD.  Then at S804, the configuration engine 106 identifies any family without any Selected or Included features as a family to\ncomplete.\nWith reference to steps S806-811, the configuration engine 106 analyzes each family of the MDD in priority order.  The configuration engine 106 starts analyzing the first family in the sorted families to complete list at step S806.  At step\nS808, the configuration engine 106 determines if the index (x) is less than the total number of families included in the families to complete list.  If not, the configuration engine 106 proceeds to S810 (Done).  If so, the configuration engine 106\nproceeds to step S812 to determine the possible available standard features for family (x) within the restricted buildable space (MsDataSpace).  Once the configuration engine 106 has completed its analysis of family (x), it returns to S811 and starts\nanalyzing the next family by incrementing x by 1.  The subroutine of S812 is shown in the flowchart of FIG. 96.\nWith reference to FIG. 96, at S814 the configuration engine 106 initializes the list of possible standard features by setting it to empty.  With reference to steps S816, S818 and S842, the configuration engine 106 analyzes each feature of\nfamily(x).  The configuration engine 106 starts analyzing feature zero (z=0) at S816.  At step S818 the configuration engine 106 compares feature (z) to the number of features at the current family (x) to determine if z&lt;the number of features in\nfamily (x).  If the determination is positive, the configuration engine 106 proceeds to S820 to determine the essential sets for feature availability.  Once the configuration engine 106 has completed its analysis of feature (z) of family (x), it returns\nto S842 and starts analyzing the next feature of family (x) by incrementing z by 1.  The subroutine of S820 is shown in the flowchart of FIG. 97.\nReferring to FIG. 97, the configuration engine 106 determines a setlist of \"essential sets\" for the availability of feature (z) at S820-S848.  At S824 the configuration engine 106 initializes the setlist by adding the main MDD of the current\nbuildable space (buildableSpace).  Then at S826, the configuration engine 106 evaluates relWork to determine if it is not trivial (i.e., not all 1).  If relWork is not all trivial, (i.e., a previous Default selection was made from a deterministic family\nsuch that the relationship defined more than one determinant condition) then the configuration engine 106 proceeds to S828 and adds relWork to the setlist.  After S828, or in response to a negative determination at S826, the configuration engine 106\nproceeds to S830 to determine if there are not any standard feature conditions defined for this feature.  If there are no standard feature conditions defined for feature (z), then its standard space is null.  If there are standard feature conditions\ndefined for feature (z), then a negative determination is made at S830, and the configuration engine 106 proceeds to S832 and adds the standard space to the setlist.  After S832, or in response to a positive determination at S830, the configuration\nengine 106 proceeds to S834 to determine if the family of feature (z) is deterministic.  If family (x) is deterministic, the configuration engine 106 adds the relationship space for family (x) to the setlist at S836.  After S836, or in response to a\nnegative determination at S834, the configuration engine 106 proceeds to S838 and returns the setlist to the subroutine of FIG. 96.\nReferring to FIG. 96, at S840 the configuration engine 106 determines if the intersection of all spaces in the setlist for feature (z) is empty (i.e., if feature (z) is not a standard feature or it is a standard feature that is not available\nwith the current configuration).  If the determination at S840 is negative, the configuration engine 106 proceeds to S844 and adds feature (z) to the list of possible available standard features (POSSIBLE).  After S844, or after a positive determination\nat S840, the configuration engine 106 proceeds to S842 to analyze the next feature (z) of family (x).  Once the configuration engine 106 has analyzed all features of family (x), it makes a negative determination at S818 and proceeds to S846 to return the\npossible available standard features for family (x) to the main maximally standard routine of FIG. 95.\nWith reference to FIG. 95, at S848 the configuration engine determines if there are any standard features for family (x).  If there are no standard features, i.e., if POSSIBLE is empty, then the configuration engine 106 proceeds to S850 to find\nthe domain of family (x) in the maximally standard data space (MsDataSpace).  The subroutine of S850 is shown in the flowchart of FIG. 98.\nWith reference to FIG. 98, the configuration engine 106 determines the domain of family (x) at S850-S858.  At S852, the configuration engine 106 calculates the domain space of family (x) as the intersection of the main space and the relWork.  If\nthe configuration engine 106 determines that family (x) is deterministic at S854 based on the product definition, then it proceeds to S856.  At S856 the configuration engine 106 sets the domain space equal to the intersection of the domain space and\nrelationship space for that family.  After S856, or in response to a determination that family (x) is not deterministic at S854, the configuration engine 106 proceeds to S858 and sets the Domain to the domain of the domain space, adds any feature from\nfamily (x) that is present to the Domain to the list of possible features and returns to the main maximally standard routine of FIG. 95.\nReferring to FIG. 95, after determining the domain of family (x) at S850, or in response to a negative determination at S848, the configuration engine 106 proceeds to S860 and sorts POSSIBLE by an alternate sequence that defines the priority of\nthe features.  At S862 the configuration engine 106 selects the first feature in the sorted list as the Default feature for Family (x).  Then the configuration engine 106 proceeds to S864 to restrict the maximally standard data space to the new Default\nfeature.  The subroutine of S864 is shown in the flowchart of FIG. 99.\nWith reference to FIG. 99, at S864-S880, the configuration engine 106 further restricts the maximally standard data space to the new Default feature.  At S866 the configuration engine 106 restricts the main space to the new Default feature. \nThen if family (x) is deterministic, the configuration engine 106 proceeds to S870 and defines a temporary relationship (relTemp) by restricting the family relationship space to the new Default feature choice.  Then at S872, the configuration engine 106\nsets relWork to the intersection of relWork and relTemp.  At S874, the configuration engine 106 evaluates relWork to determine if it has a single path, i.e., a \"singleton.\" If the standard features (relWork) is a singleton, the configuration engine 106\nproceeds to S876 and uses quick restrict to restrict the main space using the single bitmask from relWork; and then resets relWork to be trivial (all 1s) at S878.  After S878, or in response to a negative determination at S868 or S874, the configuration\nengine 106 proceeds to S880 and returns to the main maximally standard routine of FIG. 95.\nWith reference to FIGS. 100-101, deterministic relationships are used to enable efficient creation and storage of the full buildable space.  As described previously, the global buildable space can be stored in a Global MDD that has a main space\n(e.g., an MDD) and a set of relationship spaces (e.g., MDDs).  Maximally standard auto completion requires standard feature conditions.  The buildable space (FIG. 100) and Standard Feature Conditions (FIG. 101) are shown as Tables 10000 and 10100,\nrespectfully, and combined in a single Buildable object.\nThere is no concept of displayable and non-displayable families during MDD generation.  Displayable families refer to content this is displayed to the user, for example paint color is displayed to a user in a build and price application. \nWhereas non-displayable families refer to content that is not displayed to the user, such as an electrical harness in a build and price application.  A Superconfiguration Generator (SCG) library (not shown) is a component of the ETL 128 (FIG. 2).  The\nSCG library simply finds all relationships in order to generate the smallest possible main space.\nSome algorithms that target displayable content (e.g., validation and feature state mapper) have been optimized to work on a single MDD, and others require all displayable content to be in a single MDD (e.g., minimum edit).  Valid input for the\nconfigurator is a global space where no displayable families have been pulled to an external relationship, even if it is deterministic.\nOne possible way to build a global space that conforms to the configurator input is to control which families can be deterministic.  The SCG algorithm includes an argument called relignore which can be used to specify which families are not\nallowed to be deterministic.  This argument can be used to specify that displayable families are not allowed to be deterministic.\nAnother approach is to allow SCG to build the MDD by pulling out whatever relationships it finds.  Then, an extra step is used before the space can be used by the configurator.  Any relationship that defines a display family dependence on the\nmain MDD is flattened back into the main MDD.  To do this efficiently, the MDD is recompressed as the relationships are flattened.\nGenerally both approaches will take the same amount of processing time.  In the second approach, the MDD may be generated much faster, but that any time savings is used in the extra flattening step.\nThe configuration engine 106 will be validating two types of configurations--a configuration of displayable features only or an expanded configuration of displayable and no display features.\nTo validate a configuration of displayable features the relationships can be ignored because the configuration engine 106 does not allow any displayable family to be deterministic.  This means that the main MDD contains all of the information\nnecessary to define feature combinations from the displayable families.  There is no information in the relationships that will shrink the space of displayable families that is defined in the main MDD.  Thus, only the main MDD is used to validate a\nconfiguration of display family features.  To validate a configuration of displayable families, simply call contains operation on the main MDD.\nTo validate a configuration that contains displayable and no-display features, both the main MDD and the relationships are inspected.  Just as the MDD containsAny operation is used to validate a configuration against an MDD, the Global MDD also\nhas a containsAny operation that can validate a configuration against a Global MDD.  The Global MDD operation utilizes the MDD containsAnyParallel operation, to validate a fully expanded configuration, the parallel operation will turn the mask into its\nown MDD and inspect that space along with the main space and all relationship MDDs.  To validate a partial configuration of both display and no display features, the parallel operation inspects the mask MDD, the main MDD and the relationships associated\nwith each deterministic feature in the configuration.  When processing a partial configuration, relationships for families that have no feature in the configuration can be ignored.\nFIG. 102 is a table 10200 that shows several example configurations, the relevant MDDs, and the containsAny call that the configuration engine 106 uses to validate the configuration.\nConflict resolution is also limited to displayable content.  As with the \"contains\" operation, when dealing with configurations that do not contain deterministic features, the main MDD contains sufficient information for the conflict resolution\nwithout including the relationships.\nAs described with reference to FIG. 47, conflict resolution begins with a minimum edit distance calculation that is performed on the main MDD.\nFor Single Conflict Resolution, the target configuration is identified by performing auto completion in the minimum edit space.  Because the main MDD includes no display content, the target configuration will also include no display content. \nThe no-display content is stripped from the configuration engine response.  Alternatively, the author decorators can be modified to ignore no-display features when adding conflict resolution to the xml response.\nFor Branched Conflict Resolution, the entire minimum edit space is used to build the response.  The minimum edit space is projected to displayable content before building the response.\nThere is no concept of displayable and non-displayable families during the first stage of authoring or determining the feature conditions.  As such, the feature conditions for displayable families may be determined with a dependency on\nno-display families.  This means that when the maximally standard auto completion algorithm uses the full configuration space; it accounts for the external relationship MDDs in addition to the main MDD.\nWhen using a Global Space (main space+relationships spaces) for maximally standard auto completion, the basic logic is the same as using an MDD.  Instead of checking a single MDD, the algorithm checks the global space--both the main MDD and the\nrelationship MDDs.  The basic operations of restrict, containsAny and domain accounts for both the main space and external relationships.\nDuring auto completion, the configuration engine 106 restricts the main space for each feature choice (S864).  When the choice is deterministic, the external relationship defines the determinant conditions for each feature.  The deterministic\nrelationship space is restricted to the feature choice to determine the determinant conditions and then the main space is restricted to the corresponding determinant conditions.\nWhen a deterministic feature has a single determinant condition, the configuration engine 106 quick-restricts the main space using the determinant condition, according to one or more embodiments (S874-S876).  The buildable space as shown in\nTable 10000 (FIG. 100) includes a main space 10002 and a relationships space 10004.  The relationships space 10004 shows that features Y2, Y5 and Y6 map to B1 as referenced by numeral 10006, and that features Y1, Y3, and Y4 map to B2 as referenced by\nnumeral 10008.  Table 10300 of FIG. 103 shows only one row remains after the relationship is restricted to the choice B1 (S870).  The configuration engine 106 quick-restricts the main space using this single superconfiguration as the bitmask.  After B1\nis chosen, the main space is restricted to B1 (S866) and is also restricted to Y2, Y5, and Y6 (S876), as shown in Table 10400 of FIG. 104, and referenced by numeral 10402.\nThe quick-restrict operation accepts a single bit mask.  This means that the main space cannot be quick-restricted to reflect a deterministic choice whenever a deterministic feature has multiple determinant conditions.  Table 10000 (FIG. 100)\nshows that family K is determined by two families [A,S] as referenced by numeral 10010.  Table 10500 of FIG. 105 shows the two rows defining the determinant conditions for feature K2.  The first row of Table 10500 shows that A2,S3; A2,S5; A2,S6 all map\nto K2 and the second row shows that A1,S3 also maps to K2.  When K2 is chosen, the main space is restricted to K2, but the configuration engine 106 cannot quick-restrict it with the K2 determinants because the restricted relationship space defines two\nsuperconfigurations.  Instead, the configuration engine 106 adds a special relWork space, as referenced by numeral 10602, to store the determinant conditions as shown FIG. 106.  After restricting to K2, relWork contains the two determinant conditions for\nK2.\nJust as the global space requires both the main MDD and all its relationships to fully define the space, relWork is necessary to fully define the restricted space.  However, if relWork is trivial (i.e., all 1s) then the configuration engine 106\ncan ignore it because it isn't further restricting the space.\nThe configuration engine 106 initializes the relWork space as a trivial space, with a single superconfiguration of all 1s, according to one or more embodiments.  When a deterministic choice is made that has multiple determinant conditions,\nrelWork is AND'ed with the restricted relationship space (S872).  If the result of the AND operation is a single superconfiguration (S874), the main space is restricted with that superconfiguration (S876) and relWork is trivialized (S878).\nReferring to FIG. 107, if the configuration engine 106 further restricts the space to M2, then there is just one row remaining in relationship M as shown in Table 10700.  When this restricted relationship space is ANDed with relWork (from FIG.\n106), just one row remains as shown in Table 10800 of FIG. 108.  This is used to restrict the main space, and then relWork is reset, with the final result shown in Table 10900 of FIG. 109.\nThe configuration engine 106 uses the containsAny operation of the maximally standard auto completion algorithm to determine if a Standard feature condition space is still valid in the restricted space, according to one or more embodiments.\nFor two MDDs, the operation mdd1.containsAny(mdd2) is equivalent to not(isEmpty(mdd1.and(mdd2)).  The ContainsAny operation can be extended to operate on two or more MDDs and is called containsAnyParallel.  For three MDDs, the operation\nmdd1.containsAnyParallel([mdd2,mdd3]) is equivalent to not(isEmpty(mdd1.and(mdd2).and(mdd3)).\nWhen dealing with deterministic relationships, this contains any operation may need to include the relWork MDD.\nIn order for the configuration engine 106 to determine if a standard feature is available in the restricted space (S812), the containsAny operation must always operate on the standard space and the main space and may need to account for the\nrelWork space and an external relationship space.  When the family is deterministic and relWork is not trivial the operation will be standardSpace.containsAny(mainSpace, rel, relWork).  The operation can skip relWork if it is trivial and will only\ninclude a relationship if the feature is deterministic (S822).\nThe configuration engine 106 determines if any standard features for A are still valid in the space from FIG. 103, by accounting for the A standard space and the main space in the containsAny operation.  There is no relationship space because A\nis not deterministic and the relWork is ignored because it is trivial (i.e., A is all is in Table 10300).\nIn order for the configuration engine 106 to determine if any standard features for B are still valid in the space from FIG. 103, the containsAny operation must account for the B standard space, the main space and relationship B space.  The\nconfiguration engine 106 ignores relWork because it is trivial.\nThe configuration engine 106 determines if any standard features for M are still valid in the space from FIG. 106, by accounting for the M standard Space, main Space, Relationship M space, and relWork in the containsAny operation.\nThe maximally standard auto completion algorithm uses domain calculation when the standard feature conditions do not identify a possible choice.  Because only the domain of a single family is needed, not all of the relationships must be\nincluded.  The domain calculation must consider the main space, the relWork space, and, if the family is deterministic, the external relationship space.  This is done by first ANDing the spaces, and then calculating the domain on the resulting space\n(S850).\nThe algorithm for maximally standard auto completion without deterministic relationships was shown previously in FIG. 93.\nThe modifications to account for deterministic relationships are: 1) Change mdd.quickRestrict to SPACE.RESTRICT; 2) Change mdd.containsAny with SPACE.containsAny, where space defines the main MDD, the relationship MDDs, and the relWork MDD\ndiscussed above in the Restrict Global Space section; and 3) Change mdd.findDomain.toListActive(Fa) to SPACE.findDomain(Fa).  The new algorithm is shown as flowcharts in FIGS. 95-99 and as software code in FIG. 110.\nThe following example illustrates the modified algorithm and references steps in the flow charts and operations in the software code where applicable.  This example will use the global space and standard feature conditions defined previously in\nTable 10000 (FIG. 100) and Table 10100 (FIG. 101).  Table 10100 also lists the family priority order, as generally referenced by numeral 10102.\nWith reference to FIG. 111, the configuration engine 106 restricts the space starting with a minimally complete configuration of Selected {Y3,E1,P1}+Included {F2} (11001, FIG. 110; S802, FIG. 95).  The configuration engine 106 makes Default\nchoices for the remaining families in priority order as defined in Table 10100 (FIG. 101), i.e.: V, R, K, B, A, M, T, I, S (S804, FIG. 95).\nReferring to FIG. 112, the configuration engine 106 determines that Family V is deterministic and includes a single standard feature condition.  To determine if standard feature V3 is available, the configuration engine 106 checks the main\nspace, standard space and deterministic relationship (S820, FIG. 97).  Operation 11004 (FIG. 110) stdV3.containsAnyParallel(mainSpace, relV) returns false because V3 is not available with the current choice Y3 (see also S840, FIG. 96).  The domain of V,\nfrom operation 1106 (FIG. 110) AND(relV,mainSpace), will identify only one possible choice (see also S852-S858, FIG. 98).  V2 is added and the newly restricted space, as determined at S864, FIG. 96 and operation 11008, FIG. 110, is shown in Table 11200\nof FIG. 112 and referenced by numeral 11202.\nWith reference to FIGS. 112-113, the configuration engine 106 determines that Family R has no standard feature conditions (S830-S836, FIG. 97; operation 11004, FIG. 110).  The domain of the restricted space identifies two possible choices--R1,\nR4 as referenced by numeral 11204 (S852-S858, FIG. 98; operation 1106, FIG. 110).  Without alternate sequencing, R1 is picked as the Default choice and the space is further restricted (S864, FIG. 99; operation 11008, FIG. 110) as shown in Table 11300 of\nFIG. 113, and referenced by numeral 11302.\nReferring back to FIG. 101, the configuration engine 106 determines that Family K has two standard feature conditions (S830-S836, FIG. 97; operation 11004, FIG. 110).  StdK1 defines K1 as standard for V1 and StdK2 defines K2 as standard for V2\nor V3.  Because V2 has been previously chosen, K2 is the only available standard choice and is added to the configuration.  The configuration engine 106 further restricts the space to reflect this choice (S864, FIG. 99; operation 11008, FIG. 110). \nFamily K is deterministic.  When RelK is restricted to K2, there are two rows remaining.  The main space cannot be quick-restricted and relWork is updated as shown in Table 11400 of FIG. 114.\nWith reference to FIG. 115, the configuration engine 106 adds B2 based on its Standard space and chooses A2 because it is standard with {R1, V2}.  The restricted space after these choices is shown in Table 11500 of FIG. 115.  Table 11500 shows\nthat the configuration engine 106 could restrict relWork to A2, minimize it to one row, use it to restrict the main space and then trivialize it; however, the containsAny optimizations (operation 11004, FIG. 110) dictate that it is actually better to\nwait until relWork is minimized by another deterministic feature.  It is actually counterproductive to restrict relWork for every choice.\nReferring to FIG. 116, the configuration engine 106 determines that Family M has standard feature conditions (S830-S836, FIG. 97; operation 11004, FIG. 110).  M1 is the only standard feature that is still available in the restricted space. \nAfter relWork is updated for M1, only one row remains, i.e., the second row of Table 11500 of FIG. 115.  This row is used to restrict the main space and relWork is trivialized, as shown by Table 11600 of FIG. 116 (S864, FIG. 99; operation 11008, FIG.\n110).  The restricted space after processing family M is shown in Table 11600.\nWith reference to FIG. 117, the configuration engine 106 adds T1 as the Default choice from its Standard Feature Condition and I1 is chosen as the Default from the possible choices I1 and I2 (S830-S836, FIG. 97; operation 11004, FIG. 110).  The\ndeterministic relationship for I shows that I1 maps to S1 or S5.  After T1 and I1 are chosen, S5 remains the only choice for family S, as shown in Table 11700 of FIG. 117.\nThe configuration engine's use of relWork to account for deterministic relationships when quick-restricting the main space, along with the containsAnyParallel operation, allows for a very efficient maximally standard auto completion algorithm. \nThis allows the configuration engine 106 to support maximally standard configurations without requiring feature condition authoring to be modified in order to account for display and no display families.\nComputing devices described herein, generally include computer-executable instructions where the instructions may be executable by one or more computing devices such as those listed above.  Computer-executable instructions may be compiled or\ninterpreted from computer programs created using a variety of programming languages and/or technologies, including, without limitation, and either alone or in combination, Java.TM., C, C++, C#, Visual Basic, Java Script, Perl, etc. In general, a\nprocessor (e.g., a microprocessor) receives instructions, e.g., from a memory, a computer-readable medium, etc., and executes these instructions, thereby performing one or more processes, including one or more of the processes described herein.  Such\ninstructions and other data may be stored and transmitted using a variety of computer-readable media.\nWhile exemplary embodiments are described above, it is not intended that these embodiments describe all possible forms of the invention.  Rather, the words used in the specification are words of description rather than limitation, and it is\nunderstood that various changes may be made without departing from the spirit and scope of the invention.  Additionally, the features of various implementing embodiments may be combined to form further embodiments of the invention.\n<BR><BR><CENTER><b>* * * * *</b></CENTER>\n<HR>\n   <CENTER>\n   <a href=http://pdfpiw.uspto.gov/.piw?Docid=10318702&homeurl=http%3A%2F%2Fpatft.uspto.gov%2Fnetacgi%2Fnph-Parser%3FSect1%3DPTO2%2526Sect2%3DHITOFF%2526p%3D1%2526u%3D%25252Fnetahtml%25252FPTO%25252Fsearch-bool.html%2526r%3D1%2526f%3DG%2526l%3D50%2526co1%3DAND%2526d%3DPTXT%2526s1%3D20170206577%2526OS%3D%2526RS%3D&PageNum=&Rtype=&SectionNum=&idkey=NONE&Input=View+first+page><img src=\"/netaicon/PTO/image.gif\" alt=\"[Image]\" border=\"0\" valign=\"middle\"></A>\n   <TABLE>\n   <TR><TD align=\"center\"><A href=\"https://certifiedcopycenter.uspto.gov/other/patft/view.html?backUrl1=http%3A//patft.uspto.gov/netacgi/nph-Parser?Sect1%3DPTO2%26Sect2%3DHITOFF%26p%3D1%26u%3D%25252Fnetahtml%25252FPTO%25252Fsearch-bool.html%26r%3D1%26f%3DG%26l%3D50%26co1%3DAND%26d%3DPTXT%26s1%3D20170206577%26OS%3D&backLabel1=Back%20to%20Document%3A%2010318702\"><IMG border=\"0\" src=\"/netaicon/PTO/cart.gif\" border=\"0\" valign=\"m\niddle\" alt=\"[View Shopping Cart]\"></A>\n   <A href=\"https://certifiedcopycenter.uspto.gov/other/patft/order.html?docNumber=10318702&backUrl1=http%3A//patft.uspto.gov/netacgi/nph-Parser?Sect1%3DPTO2%26Sect2%3DHITOFF%26p%3D1%26u%3D%25252Fnetahtml%25252FPTO%25252Fsearch-bool.html%26r%3D1%26f%3DG%26l%3D50%26co1%3DAND%26d%3DPTXT%26s1%3D20170206577%26OS%3D&backLabel1=Back%20to%20Document%3A%2010318702\">\n   <IMG border=\"0\" src=\"/netaicon/PTO/order.gif\" valign=\"middle\" alt=\"[Add to Shopping Cart]\"></A>\n   </TD></TR>\n   <TR><TD align=\"center\">\n   <A href=\"#top\"><IMG valign=\"middle\" src=\"/netaicon/PTO/top.gif\" border=\"0\" alt=\"[Top]\"></A>\n   </TD></TR>\n   </TABLE>\n   <A name=\"bottom\"></A>\n   <A href=\"/netahtml/PTO/index.html\"><IMG src=\"/netaicon/PTO/home.gif\" alt=\"[Home]\" border=\"0\" valign=\"middle\"></A>\n   <A href=\"/netahtml/PTO/search-bool.html\"><IMG src=\"/netaicon/PTO/boolean.gif\" alt=\"[Boolean Search]\" border=\"0\" valign=\"middle\"></A>\n   <A href=\"/netahtml/PTO/search-adv.htm\"><IMG border=\"0\" src=\"/netaicon/PTO/manual.gif\" alt=\"[Manual Search]\" valign=\"middle\"></A>\n   <A href=\"/netahtml/PTO/srchnum.htm\"><IMG src=\"/netaicon/PTO/number.gif\" alt=\"[Number Search]\" border=\"0\" valign=\"middle\"></A>\n   <A href=\"/netahtml/PTO/help/help.htm\"><IMG border=\"0\" src=\"/netaicon/PTO/help.gif\" alt=\"[Help]\" valign=\"middle\"></A>\n   </CENTER>\n</BODY>\n</HTML", "application_number": "15294330", "abstract": " A system is provided with a memory and a processor. The memory is\n     configured to store a cached copy of data representative of a\n     multi-valued decision diagram (MDD). The MDD indicates a Boolean function\n     specifying a buildable space of all possible configurations of features\n     of a vehicle. The processor is in communication with the memory, and\n     programmed to generate a working copy of the data from the cache. The\n     processor is further programmed to generate a restricted buildable space\n     in the working copy of the data while traversing the MDD, including to\n     remove available features from the labels of the outgoing edges deemed\n     invalid according to a feature selection, disconnect outgoing edges\n     having no remaining available features, and replace nodes that have no\n     outgoing edges with the false node.\n", "citations": ["4479197", "4591983", "4827423", "4873643", "4875162", "5119307", "5165015", "5225987", "5233513", "5255356", "5257387", "5260866", "5283865", "5293479", "5295067", "5295242", "5307261", "5311424", "5311437", "5353432", "5367622", "5367627", "5369566", "5394522", "5428791", "5434791", "5487135", "5499357", "5500802", "5515269", "5515524", "5546575", "5552995", "5579529", "5586039", "5590319", "5594651", "5621905", "5630025", "5675748", "5740425", "5745765", "5761063", "5777877", "5781906", "5815395", "5825651", "5844554", "5850539", "5864660", "5877966", "5963953", "5987473", "5991826", "6002854", "6035305", "6055529", "6115547", "6122560", "6125408", "6137499", "6151697", "6167380", "6167383", "6177942", "6192355", "6205446", "6208987", "6223094", "6223170", "6247128", "6259451", "6272390", "6278982", "6282537", "6300948", "6324534", "6349274", "6366922", "6377956", "6405308", "6407761", "6412012", "6430730", "6519588", "6523040", "6536014", "6549908", "6556991", "6557002", "6581068", "6615220", "6633788", "6647305", "6678882", "6687705", "6757678", "6810401", "6836766", "6839711", "6850895", "6850921", "6853996", "6898472", "6918124", "6937966", "6938038", "6965887", "6986104", "6988014", "7003360", "7039602", "7043309", "7050956", "7062478", "7065499", "7069537", "7076507", "7076521", "7082426", "7093010", "7096350", "7096465", "7107297", "7127424", "7188333", "7188335", "7200582", "7225038", "7225197", "7233885", "7237187", "7246087", "7328177", "7337174", "7337179", "7343212", "7343584", "7386562", "7424444", "7461049", "7464064", "7487072", "7509326", "7516103", "7567922", "7580871", "7584079", "7650296", "7698170", "7760746", "7797177", "7809758", "7860690", "7869981", "7873503", "7882057", "7930149", "7953639", "7953767", "7953779", "7992145", "7996329", "8078489", "8249885", "8280700", "8306795", "8463682", "8665731", "8805825", "8918750", "9020880", "9098854", "20020013775", "20020035463", "20020052803", "20020095348", "20020107861", "20020116417", "20020124005", "20020143653", "20020161668", "20020165701", "20020177911", "20020184308", "20030041088", "20030046047", "20030055751", "20030061238", "20030069737", "20030130749", "20030177412", "20030195806", "20030216951", "20040064441", "20040068485", "20040073436", "20040073448", "20040102995", "20040162835", "20040167906", "20050071146", "20050080648", "20050114158", "20050163143", "20050268255", "20060064685", "20060095711", "20060100829", "20070094204", "20090323539", "20110082675", "20120253754", "20140019739", "20150120490", "20150331974", "20150379442"], "related": ["62280609", "62352463"]}, {"id": "20170223092", "patent_code": "10268689", "patent_name": "Providing media content based on user state detection", "year": "2019", "inventor_and_country_data": " Inventors: \nSubramanian; Prakash (Littleton, CO), Newell; Nicholas Brandon (Centennial, CO)  ", "description": "<BR><BR>BACKGROUND\nUsers of media content lack mechanisms for selecting appropriate items of media content, e.g., programming that may include movies, sports, live events, etc. For example, present media content delivery devices (e.g., set-top boxes and the like,\nare lacking in the ability to detect various user attributes, e.g., to interpret data indicating a user's mental state and events. <BR><BR>DRAWINGS\nFIG. 1 is a diagram of an exemplary media system for providing media content based on user state detection.\nFIG. 2 is a diagram of an exemplary user device for the media system of FIG. 1.\nFIG. 3 is a diagram of an exemplary media device for the media system of FIG. 1.\nFIGS. 4A and 4B are a diagram of an exemplary process for providing media content based on a user state.\n<BR><BR>DETAILED DESCRIPTION\nExemplary System\nA user device computer, with authorization from the user, collects data that can be used to predict a user's mental state.  For example, collected data may indicate a user's mental state by providing values for attributes such as a user's\nphysical condition, recent events affecting a user (sometimes referred to as a user's \"personal circumstances\" or \"situation\"), events possibly affecting a user's mental state, etc. Physical condition data that can be used to determine a mental state can\ninclude, for example voice samples, facial expressions, biometric data (respiration, heartrate, body temperature, etc.), etc. Situation data may be collected related to events (received promotion, had a child, bought a new home, etc.), locations (at\nwork, in Hawaii, in a bar, in the living room, etc.), demographic characteristics (age, gender, religion, marital status, financial circumstances, etc.), company (people user is with, their gender, age, relationship, etc.) time (date, day of the week,\ntime of day, user's birthday, holiday) and any other information that may be used to understand the current situation of the user.  Sources for collected data indicating a user's mental state may include communications (emails, texts, conversations,\netc.), documents (tax returns, income statements, etc.), global positioning (GPS) data, calendar data (past, present and future events), internet browsing history, mobile purchases, input provided by the user, etc.\nThe user device computer is typically is programmed to provide the collected data to a server of a media content provider.  The media server can store and maintain the data about the user.  Based on the stored collected data, the media content\nprovider computer is programmed to assign one or more predetermined keywords describing the user's situation and one or more predetermined keywords describing the user's mood.  Predetermined keywords to describe a user's situation may include, e.g.,\n\"inspirational,\" \"comedy,\" \"jimcarrey,\" \"family vacation,\" \"goofy,\" \"grief,\" etc. Predetermined keywords to describe a user's mood may include, e.g., \"happy,\" \"sad,\" \"excited,\" \"bored,\" \"frustrated,\" \"relaxed,\" etc.\nThe media server is programmed to generate and provide to the user a set of the assigned keywords.  For example, the set of assigned keywords may include two predetermined keywords selected according to a user situation or situations and one\npredetermined keyword selected according to one or more detected user physical conditions.  The media provider computer may provide the set of assigned keywords, e.g., in response to a request from the user, or for example, on a regular basis (e.g., once\nper hour), or for example, based on the location of the user (when the user arrives at home, arrives in the living room, etc.).\nAs described in additional detail below, the user may identify, and request a media content item which is provided by the media provider for selection according to a current predicted user mental state, e.g., based on a user's situation,\nphysical condition(s), etc., based on the set of assigned keywords.  The user may send the request to the media content provider computer, either via the user device or via a media device available to the user.  The media content provider may then\nprovide the requested media content to the user via, e.g., the user device or the media device.\nAs shown in FIG. 1, an exemplary media system 10 includes one or more user devices 12, one or more media devices 13, a network 14, and a media server 16.  The media device 13 may be communicatively coupled to a display device 22.  The user\ndevice 12, media device 13 and display device 22 may be included in a customer premises 11.\nA user may be a consumer of media content who provides access to various user data by the media system 10.  Generally, the user operates a user device 12 which collects some or all of the data related to the user, and provides the data to the\nmedia server 16.  The server 16 may be provided by a media content provider such as are known, e.g., a cable or satellite media provider, an internet site, etc.\nAs described in additional detail below, the user device 12, data collectors associated with the user device 12, and/or other data collectors communicatively coupled to the user device 12, media device 13 or media server 16, may collect data\nregarding the user and provide the collected data to the media server 16.  Based on the collected data, a media server 16 may assign to the user one or more keywords describing a user mental state, e.g., based on a mood of the user indicated by collected\ndata concerning physical attributes of the user, and/or one or more keywords describing a situation of the user indicated by data collected from documentation concerning the user, e.g., from an audio conversation, e-mail, text messages, calendar entries,\netc. Further, based on the keywords associated with the user, the media server 16 may recommend or provide one or more items of media content to the user via, e.g., the media device 13.\nThe user device 12 may be a known device such as a mobile telephone, tablet, smart wearable (smart watch, fitness band, etc.), other portable computing device, etc. As described in additional detail below, the user device 12 may include one or\nmore applications such as email, a calendar, web browser, social media interfaces, etc., and one or more data collectors such as a video camera, biometric sensors, a global positioning system, etc. The user device 12 may additionally include an\napplication for collecting data related to the user from the one or more applications and one or more data collectors, and providing the collected data to the media server 16 computer or to another computing device.\nThe media device 13 receives and displays media content, and is typically a known device such as a set-top box, a laptop, desktop, tablet computer, game box, etc. The term \"media content\" as used herein, refers to digital audio and/or video data\nreceived in the user device 12 computer and/or in the media device 13.  The media content may be received, for example, from the media server 16 via the network 14.\nThe media device 13 is connected to or could include a display device 22.  The display device 22 may be, for example, a television receiver, a monitor, a desktop computer, a laptop computer, a tablet, a mobile telephone, etc. The display device\n22 may include one or more displays and one or more speakers for outputting respectively the video and audio portions of media content and advertisement content received from the media device 13.\nThe network 14 represents one or more mechanisms for providing communications, including the transfer of media content items, between the user device 12, media device 13, and the media server 16.  Accordingly, the network 14 may be one or more\nof various wired or wireless communication mechanisms, including any desired combination of wired (e.g., cable and fiber) and/or wireless (e.g., cellular, wireless, satellite, microwave, and radio frequency) communication mechanisms and any desired\nnetwork topology (or topologies when multiple communication mechanisms are utilized).  Exemplary communication networks include wireless communication networks, local area networks (LAN) and/or wide area networks (WAN), including the Internet, etc.\nThe media server 16 may be, for example, a known computing device included in one or more of a cable or satellite television headend, a video streaming service such as generally includes a multimedia web server (or some other computing device),\netc. The media server 16 may provide media content, e.g., a movie, live event, audio, to the user device 12 and/or media device 13.\nThe media content is typically delivered as compressed audio and/or video data.  For example, the data may be formatted according to known standards such as MPEG or H.264.  MPEG refers to a set of standards generally promulgated by the\nInternational Standards Organization/International Electrical Commission Moving Picture Experts Group (MPEG).  H.264 refers to a standard promulgated by the International Telecommunications Union (ITU).  Accordingly, by way of example and not limitation,\nmedia content may be provided to a media device 13 in a format such as the MPEG-1, MPEG-2 or the H.264/MPEG-4 Advanced Video Coating standards (AVC) (H.264 and MPEG-4 at present being consistent) and HEVC/H.265.  As is known, MPEG and H.264 data include\nmetadata, audio, and video components.  Further, media content and advertisement content in the media system 10 could alternatively or additionally be provided according to some other standard or standards.  For example, media content and advertisement\ncontent could be audio data formatted according to standards such as MPEG-2 Audio Layer III (MP3), Advanced Audio Coding (AAC), etc.\nAs shown in FIG. 2, the user device 12 includes a computer 32, a communications element 34 and a user interface 36.  Additionally, the user device 12 may include and/or be communicatively coupled, e.g., in a known manner, with one or more data\ncollectors 30.\nThe data collectors 30 may include, for example cameras, microphones, biometric sensors, accelerometers, gyroscopes, a global positioning system and other types of sensors for collecting data regarding the respective user of the user device 12. \nThe data collectors 30 are communicatively coupled to the computer 32, and may be included in or remote to the user device 12.\nThe data collectors 30 may be used to collect data related to the user and other people and objects proximate to the user device 12.  Proximate to the user device 12 may be defined, for example, to be within a detection range of a respective\nsensor, within a same room as the user device 12, or within a fixed distance, for example 20 meters, of the user device 12.  As discussed below, the computer 32 may be authorized to collect data via the data collectors 30 at any time, or based on\nconditions established, for example, by the user of the user device 12.\nFor example, a microphone in the user device 12 may listen, on a substantially continuous basis, to the surroundings, and record conversations and other received sounds and provide audio data to the computer 32.  The computer 32 may determine\nwhether the received data may be useful in determining a situation and/or mood of the user.  The computer 32 may store data determined to be useful in determining a situation and/or mood of the user and discard data which is determined not to be useful\nin determining a situation and/or mood of the user.  For example, the content of a conversation that includes only an exchange of greetings and small talk may be discarded, whereas the tone quality of the same conversation may be determined to be\nindicative of mood, and may be stored.\nThe data collectors 30 may further be used to collect biometric data related to the user.  For example, the data collectors 30 may measure the user's blood pressure, heartrate, body temperature, etc.\nThe communications element 34 may include hardware, software, firmware, etc., such as are known, and may be configured for one or more types of wireless communications.  The hardware may include, e.g., one or more transceivers, one or more\nreceivers, one or more transmitters, one or more antennas, one or more microcontrollers, one or more memories, one or more electronic components etc. The software may be stored on a memory, and may include, e.g., one or more encoders, one or more\ndecoders, etc. for converting messages from one protocol to another protocol.  Some functions, e.g., encoding functions, may be realized via firmware.\nThe types of wireless communications may include cellular communications, WiFi communications, two-way satellite communications (e.g., emergency services), one way satellite communications (e.g., receiving digital audio radio broadcasts), AM/FM\nradio, etc.\nThe user interface 36 may include one or more input elements such as buttons, a key board, a touchscreen, a microphone, a touchpad etc. for receiving input from a user.  The user interface 36 may further include one or more display elements such\nas an LCD display, speaker, light emitting diodes, buzzers, etc. for outputting data to the user.\nThe computer 32 includes a memory, and one or more processors, the memory storing program code, i.e., computer-executable instructions, executable by the processor.  The computer 32 is operable to receive input from a user and transmit the input\nto another computing device such as the media device 13 or the media server 16.  The computer 32 further may include one or more applications such as are known for email, a calendar, texting, social media interfaces, web browsers, etc., and may send data\nto and receive data from remote computers, including without limitation the media server 16, for such applications.\nAdditionally, the computer 32 is programmed to collect data related to the user and provide the collected data to another computing device such as the media server 16.  The data may be collected from other applications installed on the computer\n32, or from the data collectors 30.  The collected data may include, e.g., data which may be useful for determining the mood and the situation of the user.  For example, the collected data may include words or phrases parsed from documents or files,\ne.g., from monitoring or recording voice communications, parsing e-mails, text messages, calendar entries, etc. Alternatively or additionally, the collected data could include data concerning current physical attributes of a user, e.g., heartrate,\nrespiration, skin color, body temperature, etc.\nAs shown in FIG. 3, the media device 13 includes a computer 42, a communications element 44, and a user interface 46.  The media device 13 may further include one or more data collectors 40.  The computer 42 is communicatively coupled with each\nof the data collectors 40, communications element 44 and user interface 46.\nThe data collectors 40 may include, for example cameras, microphones, motion detectors, infrared sensors, ultrasonic sensors, and other types of sensors for collecting data regarding users proximate to the media device 13.  Proximate to the\nmedia device 13 may be defined, e.g., as within a range to be detected by the data collectors 40.  As other examples, proximate to the media device 13 may be defined to be within a fixed distance, e.g., 20 meters, of the media device 13, within a range\nto view a display device 22 included in the media device 13, within a room including the media device 13, etc.\nThe data collectors 40 are communicatively coupled to the computer 42, and may be included in or remote to the media device 13.  The data collectors 40 may be used to collect visual data, audio data, motion data, biometric data, etc. related to\none or more users proximate to (e.g., in a room with and/or within a predetermined distance of) the media device 13.\nThe communications element 44 may include hardware, software, firmware, etc., such as are known, and may be configured for one or more types of wireless communications.  The hardware may include, e.g., one or more transceivers, one or more\nreceivers, one or more transmitters, one or more antennas, one or more microcontrollers, one or more memories, one or more electronic components etc. The software may be stored on a memory, and may include, e.g., one or more encoders, one or more\ndecoders, etc. for converting messages from one protocol to another protocol.  Some functions, e.g., encoding functions, may be realized via firmware.\nThe types of wireless communications may include cellular communications, WiFi communications, two-way satellite communications (e.g., emergency services), one way satellite communications (e.g., receiving digital audio radio broadcasts), AM/FM\nradio, etc.\nThe user interface 46 may include one or more input elements such as buttons, a key board, a touchscreen, a roller ball, a touchscreen, a mouse, a microphone, switches, etc. for receiving input from a user.  The user interface 46 may further\ninclude one or more display elements such as an LCD display, plasma display, speaker, lamps, light emitting diodes, buzzers, etc. for outputting data to the one or more users.\nThe computer 42 includes a memory, and one or more processors, the memory storing program code, i.e., computer-executable instructions, executable by the processor.  The computer 42 is operable to receive media content from the media server 16\nand display received media content on the display device 22.\nAdditionally, the computer 42 is may be programmed to collect data regarding the users proximate to the media device 13.  The data may be collected, via, e.g., the data collectors 40.  The collected data may include, e.g., data which may be\nuseful for determining the mood and the situation of the user.\nThe media server 16 may provide media content to the user device 12 and/or media device 13.  The media server 16 may include one or more processors and memories as is known, as well as known mechanisms for communicating via the network 14.\nThe memory of the server 16 can store program code, i.e., computer-executable instructions, executable by the processor.  The server 16 is programmed to provide media content to the user device 12 and/or media device 13, via the network 14.\nAdditionally, the server 16 may be programmed to receive data related to the situation and mood of the user.  Based on the data, and as described in additional detail below, the server 16 may be programmed to assign one or more predetermined\nkeywords describing the user's situation and/or one or more predetermined keywords describing the user's mood to the user.  The server 16 may further be programmed to provide the keywords to the user.  The server 16 may yet further be programmed to\nprovide one or more media content items to the user based on the assigned keywords.  In some cases the server 16 may recommend one or more media content items to the user based on the assigned keywords to the user, e.g., via the user device 12.  The\nserver 16 may then receive a request for a media content item selected by the user from the one or more recommended media content items, and provide the media content to the user based on the request.\nThe communications element 54 may include hardware, software, firmware, etc., such as are known, and may be configured for one or more types of wireless communications.  The hardware may include, e.g., one or more transceivers, one or more\nreceivers, one or more transmitters, one or more antennas, one or more microcontrollers, one or more memories, one or more electronic components etc. The software may be stored on a memory, and may include, e.g., one or more encoders, one or more\ndecoders, etc. for converting messages from one protocol to another protocol.  Some functions, e.g., encoding functions, may be realized via firmware.\nThe communications element may be programmed to transmit and receive media content, e.g., via satellite and/or wired (cable) communications.  Additionally, the communications element may be programmed for wireless communications such as cellular\ncommunications and WiFi communications.\nProcesses\nCollecting User Data\nAs described above, the device 12 computer 32 may collect various types of data related to the user.  The collected data may be categorized, e.g., as mood data and situation data.\nMood data may include, e.g., audio data and body data.  The audio data may include, e.g., voice samples from the user.  The body data may include visual data of the user, e.g., (facial expression, posture, etc.) and biometric data (heart rate,\nblood pressure, body temperature, pupil dilation, etc.)\nSituation data may be collected related to events (received a promotion, bought a new home, birth of a child, etc.), locations (at work, in Hawaii, in a bar, in the living room, etc.), circumstances (age, gender, religion, marital status,\nfinancial circumstances, etc.), company (people user is with, their gender, age, relationship, etc.) time (date, day of the week, time of day, user's birthday, holiday) and other information that may be used to understand the situation of the user.\nThe computer 32 may collect the data via data collectors 30 included in or communicatively coupled to the computer 32.  For example, the computer 32 may receive audio data.  The computer 32 may detect, for example, when the user is speaking with\nanother person, and record the speech.  Additionally or alternatively, the computer 32 may, for example, when the user indicates that the user would like to select a media content item, engage the user in conversation.  For example, the computer 32 may\nask the user \"What is your current mood?\" or \"How are you feeling today?\" The computer 32 may collect samples of speech for use to analyze the mood and/or situation of the user.\nThe computer 32 may further collect visual data from the data collectors 30.  The data collectors 30 may include one or more cameras included in or communicatively coupled to the computer 32.  The cameras may collect visual data related to the\nuser facial expressions, related to the user's posture, etc. The cameras may further collect data indicating, for example, a degree of dilation of the user's pupils, a degree of coloration of the skin (for example, blushing), etc.\nStill further, the data collectors 30 may include sensors for measuring blood pressure, pulse, body temperature, etc. of the user.\nThe data collectors 30 may still further be used to collect situational data related to the user.  For example, an audio data collector (microphone) 30 may detect the voices of other people in conversation with or otherwise proximate to the\nuser.  A camera 30 may receive images of people proximate to the user, or of the environment of the user.\nIn addition to collecting data via the data collectors 30, the computer 32 may collect data related to the user from other sources.  The data sources may include communications (emails, texts, conversations, etc.), documents (tax returns, income\nstatements, etc.), global positioning data (GPS), calendar or other scheduling application (past, present and future appointments, events, etc.), internet browsing history, mobile purchases, input provided by the user, etc.\nA time stamp may be associated with some or all of the data.  For example, when collecting a voice sample, the computer 32 may note the time that the voice sample was collected, and store the time along with the voice sample.  In this way, data\nsuch as voice data may by correlated in time to other data such as biometric data or visual data related to the user.\nSimilarly, a date and time that a communication was sent may be extracted from the communication and stored with the data extracted from a text of the email.  In this manner, a time can be associated with a text of the communication.  For\nexample, an email from a user complaining about a decision by a colleague may be associated with a time of the communication.\nIn addition to monitoring the user, the user's surroundings, the user's communications, etc., the computer 32 may collect data from the user interactively.  For example, the computer 32 may (e.g., via a speech program) ask the user how the user\nis feeling today, or how the user's day is going.  The computer 32 may record the user's response and use the recorded response as a voice sample.\nThe computer 32 may provide the data to, for example, the media provider 16 server 16, which may use the data to determine the user's mood and situation.  Based on the determined mood and situation of the user, the media provider 16 server 16\n(or other computing device) may assign one or more keywords to the user, indicating the mood and situation of the user.\nEvaluating User Data\nThe media provide 16 server 16 may, as indicated above, determine the user's mood based on the collected data.  For example, the server 16 may evaluate voice data and body data related to the user.\nVoice Data:\nThe user device 12 computer 32 may collect voice samples related to the user.  For example, as described above, a microphone 30 may be activated while the user is conducting conversations with other people, and the computer 32 may collect one or\nmore samples of the user's voice.  As another example, when, for example, the user indicates that the user would like to select an item of media content for viewing, the computer 32 may engage the user in conversation.  The computer 32 may ask questions\nof the user such as \"What is your mood at the moment?\" or \"How has your day gone?\" The computer 32 may collect the responses as current samples of the user's voice.  The computer 32 may provide the collected data to, e.g., the media provider 16 server\n16, which may analyze the voice samples to determine the user's mood.\nThe server 16 may, e.g., analyze the voice samples for qualities such as tone, volume, voice inflection, pitch, speed, contrast, etc. The server 16 may compare the data to data for the general population, or for a demographic segment thereof,\ne.g., according to age, gender, etc., of the user.  Such comparison, using the general population data as a baseline, can be used to evaluate a user mental state, e.g., a user may have a positive or negative mental state that could be quantified as a\npercentage worse or better than the general population.  For example, speech at a speed within a particular range may indicate that the user is excited or agitated.  Speech at a speed below a speed threshold may indicate that the user is relaxed.  Speech\nin a monotone voice may indicate that the user is bored.\nAdditionally or alternatively, the server 16 may analyze the voice samples in comparison to one or more baseline samples of the user.  For example, the server 16 may request a baseline voice sample from the user when the user is happy and\nanother baseline sample when the user is angry, etc. The server 16 may analyze the current voice samples by comparing the samples to the one or more baseline samples.\nStill further, the server 16 could, upon receiving a voice sample, ask the user to describe the user's mood.  In this manner the server 16 could build a table of voice samples reflecting different user moods.\nBody Data:\nThe user device 12 computer 32 may collect data related to the facial expressions, biometrics, body language, etc. related to the user.  For example, the computer 32 may collect via a camera 30 or video recorder 30 included in or communicatively\ncoupled with the user device 12, facial expressions of the user and body language of the user.  The computer 32 may further collect, via, e.g., biometric sensors 30 as are known, biometric data such as heart rate, blood pressure, body temperature, pupil\ndilation, etc. related to the user.  The computer 32 may collect the data on an on-going basis as the data is available.  Additionally or alternatively, the computer 32 may for example, collect biometric data, visual data, etc. at a time when the user\nindicates that the user would like to select an item of media content.  The computer 32 may provide the collected data, e.g., to the media server 16.  The server 16 may analyze the data, and determine whether the body data indicates a particular mental\nstate (e.g., mood), e.g., that the user is sad, angry, agitated, calm, sleepy, etc.\nFor example, using facial recognition techniques as are known, the server 16, may recognize that the user is smiling, or frowning, and determine respectively that the user is happy or sad.  The server 16 may recognize that the user's eyes are\nopened widely, and determine that the user is surprised.  The server 16 may determine, based on skin temperature, or skin color that the user is flushed, and further determine that the user is embarrassed.\nThe server 16 may further combine voice data, visual data and/or biometric data to more precisely identify the mood of the user.  As discussed above, the voice data, visual data, biometric data, etc. may be collected and stored together with\ntime stamps when the data was received (or generated).  Data from a same or similar time period may be combined to identify a mood (or situation) of the user.\nFor example, high paced speech may indicate either that the user is angry or that the user is excited.  Combining this data with facial data indicating that the user is smiling at a same time that the high paced speech is observed may assist the\nserver 16 in accurately identifying that the user is excited.  As another example, elevated blood pressure together with high pitched speech may be an indication that the user is frightened.\nAs described above, the computer 32 may collect what is sometimes referred to as document data, e.g., text files, audio files, video files, etc., related to the user's situation via the data collectors 30.  For example, the computer 32 may\ndetermine a user's identity and/or location, etc., based on data from a camera and/or microphone 30.\nAdditionally, data from other sources may be used to determine the situation of the user.  The data sources may include communications (emails, texts, conversations, etc.), documents (tax returns, income statements, etc.), global positioning\n(GPS) data, calendar or other scheduling application (past, present and future appointments, events, etc.), Internet browsing history, mobile purchases, input provided by the user, etc.\nThe server 16 may analyze the user's current situation based on events in the user's life (just completed a stressful meeting, planning to meet an old friend, a relative recently died, just received a raise, etc.), the user's company (people\nwith the user), the user's location (the user's living room, in a hotel, etc.), the user's circumstances (financial status, age, religion, politics, etc.), and the day and time (year, month, week, weekday, weekend, holiday, user's birthday, birthday of\nthe user's spouse, anniversary, morning, evening, etc.).  The computer 32 may collect situation data related to the user, and determine the situation of the user based on the data.\nEvents:\nThe server 16 may identify past, present and future events related to the user.  For example, based on data entered in, e.g., a calendar, the server 16 may determine that the user has a business trip scheduled for the following week.  Based on\nemail exchanges, the server 16 may determine that the business trip will require extensive preparation, and that the user will be travelling with his boss.\nAs another example, based on text messages, emails, and conversations, etc., the server 16 may determine that a relative of the user recently died.\nCompany:\nThe server 16 may determine, based on collected data other people who are with the user at a current time.  For example, calendar data (email exchanges, text message exchanges, etc.) may indicate that the user is scheduled to meet with friends\nto watch a sporting event at the current time, or to meet with colleagues to discuss a business issue.  Visual and audio data, collected by cameras 30 and microphones 30 may be used to identify people proximate to the user 30, using image recognition and\naudio recognition techniques, as are known.  The server 16 may determine general demographic information about the people with the user such as their gender, approximate age, etc. Additionally or alternatively, the server 16 may identify specific people,\nand associate the specific people with stored data about the people.  The stored data may indicate, for example, the situation of the people.\nLocation:\nThe server 16 may determine, based on collected data, a past, present or future location of the user.  For example, the server 16 may, based on global positioning data, visual data, audio data, calendar data, etc., that the user is in the user's\nliving room, in the user's office, in Hawaii, etc.\nCircumstances:\nThe server 16 may determine, based on collected data, both long and short term circumstances related to the user.  Circumstances may include age, gender, employment status, marital status, political views, religion, financial status, health\nstatus, place of residence, etc. For example, the server 16 may determine data related to financial status for documents such as electronic tax returns or W2 forms, or from communications such as emails, texts and conversations.  Data related to internet\nbrowsing history may, e.g., provide an indication of political views or health status.\nDay and Time:\nThe computer 32 may collect and provide, e.g., to the server 16, day and time data related to the user.  For example, the computer 32 may determine, based on documents, communications, etc. important dates to the user such as the user's\nbirthday, the birthday of the user's spouse, the user's anniversary, etc. The computer 32 may further determine, and provide to the server 16, routines of the user such as work schedule, times when the user is at home, days and times when the user\nattends a fitness center, etc. The server 16 may, based on this data, determine what a user is mostly likely doing at a particular time on a particular day of the week, date of the month, etc. Additionally, the server 16 may, for example, take into\nconsideration that a religious holiday important to the user, or the birthday of the user will soon occur.\nThe server 16 may accumulate situation data related to the user on an on-going basis.  The accumulated data 52 may be considered together with current data for determining the situation of the user.\nAssigning Keywords to the User According to a Determined Mental State\nThe server 16 may assign or update keywords related to a user in response to a trigger event.  For example, the server 16 may be programmed to assign or update keywords related to the user every evening at a particular time, such as 7 pm.  The\ntime may be selected, for example, to correspond to a time when the user generally watches television.  The user may select the time via input to the server 16, or the server 16 may determine the time based on routines of the user.\nAs another example, the server 16 may receive a request from the user for updated situation keywords.  For example, the user may input a request via the user device 12 for updated keywords, in preparation for selecting a movie to watch.\nAs yet another example, the server 16 may receive an indication, for example, from the media device 13, that the user has turned the media device 13 on, and is (apparently) planning to watch television.\nUpon identifying a trigger event, server 16 may assign or update one or more keywords to the user.  The keywords may be related to the user's mental state at a current time.  The current time may be, for example, the time the trigger event is\nreceived, or within an hour before the trigger was received, etc.\nThe server 16 may assign, based on data related to the user, one or more keywords to a user selected from a list of predetermined keywords.  The predetermined keywords may be single words such as \"home\", \"travelling\", \"Republican\", \"married\",\netc., and/or phrases such as \"preparing for a difficult task\", or \"going out with friends\", \"planning a trip\", \"relative died\", etc. A set of predetermined keywords may be available to the server 16, which allow the server 16 to characterize a wide range\nof situations which may occur in the life of the user.\nBased on the data collected, as described above, the server 16 may identify one or more keywords which describe a current situation of the user.  For example, based on global positioning data, the server 16 may identify that the user is home. \nBased on data extracted from a calendar, the server 16 may know that the user just completed entertaining a client for two days.  Based on the available data, the server 16 may assign a first keyword \"home\" and a second keyword \"completed demanding task\"\nto the user.\nThe server 16 may assign keywords to the user based on sets of sub-keywords or watchwords associated with each keyword.  The watchwords may be single words or phrases.  For example, the server 16 may associate a set of watchwords with each\nkeyword.  The set of watchwords for a particular keyword may contain any number of watchwords from just one or two watchwords to hundreds or even thousands of watchwords.\nFurther, while analyzing user mental state data, the server 16 may create a list of watchwords associated with the user.  The watchwords may be, e.g., extracted from user communications, determined based on user physical conditions, or\nassociated with the user based on the user location, people together with the user, demographics of the user, etc.\nAt a time, e.g., when the server 16 is triggered to assign keywords to the user, the server 16 may match the watchwords assigned to the user with the watchwords assigned to each keyword.  The server 16 may then, assign the two keywords to the\nuser with the highest number of matches between the watchwords assigned to the user and the watchwords assigned to the keyword.\nFor example, based on a sensor data, the server 16 may associate watchwords \"flushed face\", \"clenched teeth\" and \"red face\" with the user.  The watchword \"flushed face\" may be included in the set of watchwords for both of the keywords\n\"embarrassed\" and \"angry\".  The watchwords \"clenched teeth\" and \"red face\" may however, only be included in the set of watchwords for the keyword \"angry\".  Because more watchwords are matched for \"angry\" than for \"embarrassed\", the server 16 may assign\nthe keyword \"angry\" to the user.  In some cases, for example, when there are an equal number of matches for two different keywords, the server 16 may ask the user to select a keyword.  The question may ask the user to choose between two different\nkeywords.  For example, the server 16 may ask \"Would you say that angry or embarrassed better describes your mental state at this time?\"\nPriorities may be assigned to different types of data when determining keywords.  The data may be, for example, assigned a priority value in a range of from 1 to 100, with 100 being the highest priority.  A death in the immediate family or being\ndiagnosed with a serious illness may be assigned a value of 100.  A change in employment situation or recently moving may be assigned a value of 75.  A planned, routine business trip may be assigned a value of 54.\nFurther, the priority values may be determined based on when the event occurred (or is scheduled to occur) relative to the current time.  For example, a death in the family that occurred within the last three months may have a priority value of\n100.  The priority value may be reduced slowly as time passes following the initial three months.  With regard to a planned event, the priority value may increase as the event comes closer.\nOther types of time-based algorithms may be used.  For example, following the death of an immediate family member, this event may receive an increased priority value during holidays, and on the anniversary date of the event.\nThe user's company, i.e., the people with the user, may be given a high priority value.  For example, when the user is together with the user's spouse, this may outweigh events related to the user, and be given a high priority value.\nThe server 16, based, e.g., on assigned priorities, determines data that may be most relevant to the current situation of the user.  The server 16 then selects one or more situation keywords which may best describe the user.  The server 16 may\nselect the keywords by selecting the data (event, company, location, circumstances, time, etc.) with the highest priority values as described above, and selecting the predetermined keywords which best match the selected data.  In some cases, the\npredetermined keyword may be a direct match with the data.  For example, a set of predetermined keywords may include \"death in the immediate family\" which may directly match to high priority data related to the user.\nIn other cases, the server 16 may need to identify a keyword which best correlates to data related to the user.  For example, several different types of situations, such as changing a job, moving to a new location, graduating from a school, etc.\nmay all be associated with a situation keyword \"major transition\".  In order to establish this correlation, the server 16 may, for example, be provided with a list of examples of events that qualify as a \"major transition\", and the server 16 may search\nfor the event in the list.  Additionally or alternatively, the server 16 may analyze the received data and determine a meaning as is known, and compare the meaning to a meaning of the situation keyword.\nAs stated above, the server 16 may assign, based on data collected concerning a user's physical state, one or more keywords to a user.  Such predetermined keywords may indicate a user's mood, and may be words or expressions such as \"joyful,\"\n\"relieved,\" \"sad,\" \"excited,\" \"overwhelmed,\" \"at peace,\" \"happily surprised,\" etc. A set of predetermined keywords may be available to the server 16, which allow the server 16 based on various possible detected physical attributes of a user.\nFor example, based on a recorded voice sample, the server 16 may measure the voice parameters such as rate of speech, pitch, contrast, volume, tone, etc. Speech at a high rate of speed, e.g., may indicate that the user is excited.  Speech with a\nlow contrast, i.e., in a monotone voice, may indicate that the user is bored.  Sentences with an upward inflection at the end may indicate that user is feeling insecure.\nThe server 16 may further analyze data related to body language of the user.  For example, visual data may indicate that the user is standing erectly with the head facing forward and determine that the user is feeling confident.  The server 16\nmay analyze the user's face, detect tightness and determine that the user is feeling tense.\nStill further, the server 16 may analyze biometric data such as the heart rate of the user or blood pressure of the user.  A high pulse rate may indicate that the user is frightened or excited.  A low pulse rate may indicate that the user is\nrelaxed.\nAs discussed above, the server 16 may consider a combination of voice data, visual data and biometric data to determine a user's mental state.  For example, a high pitched voice, combined with a high pulse rate and a smile detected on the user's\nface may indicate that the user is \"happily surprised.\" Also as discussed above, the server 16 may use time stamps associated with the voice, visual and biometric data in order to combine data associated with a particular time.\nDifferent types of data may be given higher priority than other types of data.  For example, facial expressions, such as a smile or frown may be strong indications of a particular mood, whereas voice data or biometric data may be associated with\nmultiple moods.  In such cases, a facial expression which is a strong indicator of a particular mood may be given priority over the voice and biometric data.  In other cases, for example, a particular facial expression may be indicative of two or more\npossible moods.  Voice and biometric data may be used in order to select between the possible moods.\nCurrent data, for example, voice samples or visual data from the previous five minutes, may be given priority over data which is older.\nBased on the visual data, voice data and biometric data related to the user, the server 16 may assign one or more mood keywords to the user which may best characterize the mood of the user at the current time.\nAssigning a Complementary Keywords to the User\nAs described above, the server 16 may assign one or more keywords to the user at a current time.  In some cases, however, the server 16 may wish to exchange an assigned keyword with a complementary keyword prior to using the keywords for\nselecting a media content item.  This may particularly be the case when the keyword indicates a strong mental state, e.g., very sad, very happy, highly valued, etc.\nFor example, when a user is experiencing a negative mental state such as depression, loneliness, anger, fear, etc., the user may wish to view media content which is uplifting and cheerful.  Accordingly, the server 16, when it determines that the\nuser may be experiencing a negative mental state, may assign a mood keyword describing a type of media content which will encourage the user.  Similarly, when the user is feeling a positive mental state such as joy, happiness, gratitude, encouraged,\nvalued, loved, capable, etc., the user may wish to engage in more challenging entertainment, and watch a serious movie about social injustice.  Accordingly, the server 16, when it determines that the user may be experiencing a positive mental state, may\nassign a mood keyword describing a type of media content which will challenge the user.\nSelecting a Media Content Item Based on Assigned Keywords\nBased on the one or more situation keywords and one or more mood keywords assigned to the user, the server 16 may further select one or more media content items to recommend and/or provide to the user.\nAs one example algorithm, the server 16 may compare keywords assigned to the user with keywords assigned to the media content item, e.g., a media content item may include metadata specifying one or more keywords.  The server 16 may prepare a\nlist of media content items to recommend to the user based on a number of matches found between the user keywords and the media content item keywords.\nFor example, the server 16 may assign one mood keyword and two situation keywords to the user.  The server 16 may give a highest ranking to media content items which have keywords matching all three of the keywords assigned to the user.  The\nserver 16 may give a second highest ranking to media content items which have a matching mood keyword, and one matching situation keyword.  The server 16 may give a third highest ranking to a media content item having two matching situation keywords, and\nnot having a matching mood keyword, etc.\nAs another example, the server 16 may rank media content items based on the ratings the media content items received from other users which had been assigned the same set of keywords.  As described below, the server 16 may receive a rating from\nusers following the viewing of a media content item.  The server 16 may store the rating, along with keywords assigned to the user, and the media content item which was viewed by the user.  In this way, the server 16 can recommend media content items\nwhich received high ratings from other users when they were assigned the same set of keywords.\nAdditional or alternative criteria may be used, together with the keyword data, to select media content to recommend or provide to the user.  For example, when applying ratings to combinations of keywords and media content, the server 16 may\nonly consider other users identified as friends of the user, or may only consider other users that viewed the media content item within a predetermined period of time of the current time, etc.\nUpon determining a ranking of media content items to recommend or provide to the user, the server 16 may present a list of the media content items to the user.  The media content items with the highest ranking may appear at the top of the list,\nand media content items with lower rankings may appear lower in the list.  The server 16 may transmit the list to the user via, e.g., the user device 12 or the media device 13.  The user may select a media content item for view, and send a request for\nthe media content item to the server 16.  The server 16 may, e.g., stream the media content item to the media device 13.\nThe server 16 may further present a list of media content viewed by friends while having been assigned the same set of keywords, or, e.g., at least one of the same keywords.  The list may be arranged in chronological order, and indicate the\nmedia content viewed by the friend, together with the name of the friend, and if available, the rating provided the friend.\nAlternatively, the server 16 may select a media content item, for example the media content item at the top of the list, and present the media content item to the user via a computing device such as the user device 12 or the media device 13.\nIn addition to recommending and/or providing media content based on the keywords assigned to the user, the server 16 may also identify other users that currently or recently (e.g., within the last week), have been assigned the same set of\nkeywords.  The server 16 may, e.g., prioritize friends of the user.  In this manner, the user may contact the other user with the same set of keywords, and ask, e.g., for a recommendation for media content, or otherwise strike up a conversation.\nRanking a Media Content Item\nAs described above, during, or after providing the media content item to the user, the server 16 may receive a rating of the media content item from the user.  For example, the server 16 may send a request, via the user device 12, or via the\nmedia device 13, for the user to rate the media content item.  The rating may be, for example, a numerical value between zero and five, with five being the highest rating and zero being the lowest rating.  Based on the request, the user may provide the\nrating, using for example, the user interface 36 on the user device 12, or the user interface 46 on the media device 13.\nThe server 16 may store the rating received from the user, along with the identity of the media content item, and the keywords assigned to the user at the time the media content item was provided.  In this manner, the server 16 can develop\nstatistical data indicating the responses of users with a particular set of keywords, to a particular media content item.\nAdditionally, the user may create new keywords and associate the new keywords with the media content item.  For example, the user, in addition to assigning a rating of five out of five to a media content item, the user may describe the media\ncontent with the keywords \"life-changing\", \"drama\", \"thriller\" and \"cerebral\".  In the case that the keyword \"life-changing\" had not already been assigned to the media content item, the server 16 may add this keyword.  The server 16 may further associate\nthe watchwords associated with the user, e.g., at the time of the rating, to the keyword \"life-changing\".  The list of watchwords associated with the keyword \"life-changing\" will grow by association, as other users are then, assigned the keyword\n\"life-changing\", or otherwise participate in the conversation around the media content item.\nExample Process\nFIGS. 4A and 4B are a diagram of an exemplary process 400 for providing media content to a user based on a user mental state.  The process 400 begins in a block 405.\nIn the block 405, a computer 32 in the user device 12 determines if the computer 32 is authorized to collect data related to the user.  For example, the computer 32 may have previously received and stored authorization from the user.  The user\nmay have, e.g., authorized the computer 32 to collect all available data.  Alternatively, the user may have restricted the types of data which may be collected (only email data, only voice data, all types of data except voice data, etc.), or the times\nand/or situations when data may be collected (at particular times of the day, when the user is watching media content, when the user is at home, etc.).  The authorization may have been input by the user and stored by the user device 12.\nThe user device 12 may query the stored data from time-to-time to determine authorization.  In the case that the user device 12 is not authorized to collect data, the process continues in the block 405.  In the case that the user device 12 has\nreceived authorization from the user, the process 400 continues in a block 410.\nIn the block 410, as described above, the computer 32 of user device 12 collects data related to the user.  The computer 32 may collect data such as audio data, visual data and biometric data from data collectors 30.  Additionally, the computer\n32 may collect data related to the user from other sources.  The data sources may include, e.g., communications (emails, texts, conversations, etc.), documents (tax returns, income statements, etc.), global positioning data (GPS), calendar or other\nscheduling application (past, present and future appointments, events, etc.), internet browsing history, mobile purchases, input provided by the user, etc.\nThe computer 32 may provide the collected data to another computing device such as the media server 16.\nAdditionally, other computing devices, such as the media device 13 may collect data.  For example, the computer 42 of the media device 13 may collect data related to the user, via data collectors 40.  The computer 42 may provide the collected\ndata, e.g., to the server 16 of media server 16.\nUpon receipt of the data by the server 16, the process 400 continues in a block 415.\nIn the block 415, the server 16 (or a computer communicatively coupled to the server 16 such as the computer 32) may sort the data as short term data and long term data.  Short term data may be data that is determined not to have a long term\nimpact on the mood or situation of the user.  For example, data indicating that the user followed a regular routine and met a colleague for lunch may be considered as short term data which does not have long term significance.  Data indicating that the\nuser is expecting a child may be considered to be data that has long term significance.  The short term data may be stored for a short period of time, e.g., 24 hours.  The long term data may be added to long term data storage, where it is stored, for\nexample, indefinitely.\nAdditionally or alternatively, as described above, a time stamp may be associated with some or all of the stored data.  Based on the type of data, the weighting of the data when determining the mood and the situation of the user may be adjusted\nas time passes.  After storing the data, the process 400 continues in a block 420.\nIn the block 420, the server 16 determines if a trigger event has occurred to provide keywords to the user.  As described above, the server 16 may be programmed to assign or update keywords related to the user every evening at a particular time,\nsuch as 7 pm.\nAdditionally or alternatively, the server 16 may receive a request from the user for updated keywords.  For example, the user may input a request via the user device 12 for updated keywords, in preparation for selecting, e.g., a movie to watch.\nAs another example, the server 16 may receive an indication, for example, from the media device 13, that the user has turned the media device 13 on, and infer that the user is planning to watch television.  The server 16 may recognize the\nturning on of the media device 13 as a trigger to provide keywords to the user.\nIn the case that the server 16 recognizes a trigger event, the process 400 continues in a block 425.  In the case that the server 16 does not recognize a trigger event, the process 400 continues in the block 405.\nIn the block 425, the server 16 assigns, as described above, one or more situation and/or mood keywords to the user.  The server 16 may select situation and mood keywords from sets of predetermined situation and mood keywords, based on data\nrelated to the user.  In some cases, as described above, when for example the selected keywords associated with the user indicate strong feelings, complementary mood keywords may be exchanged for the originally selected keywords.  The process 400\ncontinues in a block 430.\nIn the block 430, the server 16 may provide the assigned keywords to the user.  For example, the server 16 may transmit the keywords to the user device 12 computer 32, and instruct the computer 32 to display the keywords on the user interface\n36.  As another example, the server 16 may transmit the keywords to the media device 13 computer 42 and instruct the computer 42 to display the keywords on the user interface 46.  The process 400 continues in a block 435.\nIn the block 435, the server 16 determines whether the user has requested a recommended list of media content.  For example, the user may, in response to receiving the assigned keywords, request, via the user device 12 computer 32 to the media\nprovider 16 server 16, a list of recommended content based on the keywords assigned to the user.  Alternatively, the server 16 may receive, for example, a request for an electronic programming guide (EPG) from the media device 13.  In the case that the\nserver 16 receives (or otherwise identifies) a request for a recommended list of media content, the process 400 continues in a block 440.  Otherwise, the process 400 continues in the block 405.\nIn the block 440, the server 16 provides a list of recommended media content to the user via, e.g., the user device 12 computer 32, or the media device 13 computer 42.  The media content may be ranked based on the keywords assigned to the user\nand the keywords assigned to each media content item, as described above.  The process 400 continues in a block 445.\nIn the block 445, the server 16 receives a selection for a media content item from the user.  The selection may be received, for example, via the user interface 36 of the user device 12, or the user interface 46 of the media device 13.  The\nprocess 400 continues in a block 450.\nIn the block 450, the server 16 provides the media content to the user.  For example, the server 16 may stream the media content to the media device 13 computer 42.  The process 400 continues in a block 455.\nIn the block 455, the server 16 may request feedback from the user regarding the media content.  For example, during, or upon finishing the streaming of the media content item, the server 16 may send a request to the user, via the user device 12\ncomputer 32, requesting that the user rate the media content item.  The process 400 continues in a block 460.\nIn the block 460, the server 16 determines whether the server 16 has received feedback from the user.  In the case that the server 16 has received feedback, the process 400 continues in a block 465.  In the case, for example, that after waiting\na predetermined time from the request for data, the server 16 does not receive feedback, the process 400 continues in a block 405.  The predetermined time may be, e.g., 10 minutes.\nIn the block 465, the server 16 updates metadata related to the media content item.  For example, the metadata may include a rating of the media content item based on other users that had the same assigned keywords when viewing the media content\nitem.  The server 16 may update the keyword specific rating to take into account the rating from the user that provided the feedback.  As another example, the metadata may include a rating of the media content item based on other users that had the same\nmood keyword as the user and are indicated to be friends of the user.\nUpon updating the metadata associated with the media content item, the process 400 continues in a block 470.\nIn the block 470, the server 16 determines whether the process 400 should continue.  For example, the server 16 may be programmed to continue to receive data related to the user from the user device 12 on an on-going basis.  In this case, the\nprocess 400 may continue in the block 405.  Additionally or alternatively, the server 16 may ask the user, e.g., via the user device 12, to confirm that the process 400 should continue.  In the case that the server 16 receives confirmation, the process\n400 may continue in the block 405.  Otherwise, the process 400 may end.  The server 16 may, for example, send an instruction to the user device 12 computer 32, to discontinue collecting data, or, may discontinue receiving data from the user device 12. \nIn this case, the process 400 ends.\nThe descriptions of operations performed by the one or more user devices 12, one or more media devices 13, and the media server 16 are exemplary and non-limiting.  The one or more user devices 12, one or more media devices 13, and media server\n16 are communicatively coupled computing devices.  Accordingly, computing operations may be distributed between them.  Operations such as collecting data, selecting data to be stored, assigning keywords to a user, comparing user keywords to media content\nkeywords, may be performed in any one of the computing devices, or distributed over any combination of the computing devices.\n<BR><BR>CONCLUSION\nAs used herein, the adverb \"substantially\" means that a shape, structure, measurement, quantity, time, etc. may deviate from an exact described geometry, distance, measurement, quantity, time, etc., because of imperfections in materials,\nmachining, manufacturing, etc.\nThe term \"exemplary\" is used herein in the sense of signifying an example, e.g., a reference to an \"exemplary widget\" should be read as simply referring to an example of a widget.\nNetworked devices such as those discussed herein generally each include instructions executable by one or more networked devices such as those identified above, and for carrying out blocks or steps of processes described above.  For example,\nprocess blocks discussed above may be embodied as computer-executable instructions.\nComputer-executable instructions may be compiled or interpreted from computer programs created using a variety of programming languages and/or technologies, including, without limitation, and either alone or in combination, Java.TM., C, C++,\nVisual Basic, Java Script, Perl, HTML, etc. In general, a processor (e.g., a microprocessor) receives instructions, e.g., from a memory, a computer-readable medium, etc., and executes these instructions, thereby performing one or more processes,\nincluding one or more of the processes described herein.  Such instructions and other data may be stored and transmitted using a variety of computer-readable media.  A file in a networked device is generally a collection of data stored on a computer\nreadable medium, such as a storage medium, a random access memory, etc.\nA computer-readable medium includes any medium that participates in providing data (e.g., instructions), which may be read by a computer.  Such a medium may take many forms, including, but not limited to, non-volatile media, volatile media, etc.\nNon-volatile media include, for example, optical or magnetic disks and other persistent memory.  Volatile media include dynamic random access memory (DRAM), which typically constitutes a main memory.  Common forms of computer-readable media include, for\nexample, a floppy disk, a flexible disk, hard disk, magnetic tape, any other magnetic medium, a CD-ROM, DVD, any other optical medium, punch cards, paper tape, any other physical medium with patterns of holes, a RAM, a PROM, an EPROM, a FLASH-EEPROM, any\nother memory chip or cartridge, or any other medium from which a computer can read.\nIn the drawings, the same reference numbers indicate the same elements.  Further, some or all of these elements could be changed.  With regard to the media, processes, systems, methods, etc. described herein, it should be understood that,\nalthough the steps of such processes, etc. have been described as occurring according to a certain ordered sequence, such processes could be practiced with the described steps performed in an order other than the order described herein.  It further\nshould be understood that certain steps could be performed simultaneously, that other steps could be added, or that certain steps described herein could be omitted.  In other words, the descriptions of processes herein are provided for the purpose of\nillustrating certain embodiments, and should in no way be construed so as to limit the claimed invention.\nAccordingly, it is to be understood that the above description is intended to be illustrative and not restrictive.  Many embodiments and applications other than the examples provided would be apparent to those of skill in the art upon reading\nthe above description.  The scope of the invention should be determined, not with reference to the above description, but should instead be determined with reference to the appended claims, along with the full scope of equivalents to which such claims\nare entitled.  It is anticipated and intended that future developments will occur in the arts discussed herein, and that the disclosed systems and methods will be incorporated into such future embodiments.  In sum, it should be understood that the\ninvention is capable of modification and variation and is limited only by the following claims.\nAll terms used in the claims are intended to be given their plain and ordinary meanings as understood by those skilled in the art unless an explicit indication to the contrary in made herein.  In particular, use of the singular articles such as\n\"a,\" \"the,\" \"said,\" etc. should be read to recite one or more of the indicated elements unless a claim recites an explicit limitation to the contrary.", "application_number": "15008543", "abstract": " A system includes a computing device including a processor programmed to\n     receive data identifying a mental state of a user, the data including at\n     least one of a user physical condition and a user communication. Based on\n     the mental state data, the processor is programmed to assign one or more\n     stored keywords to the user, and provide media content to the user based\n     on the keywords assigned to the user based on the mental state data.\n", "citations": ["4870579", "6321221", "6774926", "6978470", "7958525", "8180804", "8195460", "8327395", "8332883", "8561095", "8589968", "8654952", "8682666", "8768744", "8782681", "8849199", "8849649", "8973022", "9009024", "9026476", "9306989", "9338493", "9454519", "9679570", "9712587", "9832619", "20030063222", "20040001616", "20050132401", "20050144064", "20060159109", "20070288987", "20080046917", "20090030792", "20090144075", "20090234727", "20100114937", "20100138416", "20100324992", "20110238495", "20110282947", "20110320471", "20120005224", "20120266191", "20120311618", "20130145385", "20130297638", "20140036022", "20140067953", "20140088952", "20140089801", "20140108142", "20140173653", "20140188997", "20140195328", "20140201125", "20140244636", "20140279751", "20140337427", "20140344039", "20140365349", "20150020086", "20150026706", "20150039549", "20150112918", "20150294221", "20160034970", "20160147767", "20160239547", "20160259797", "20160277787", "20170048184", "20170134803", "20170169726", "20170322947", "20170339467", "20170366861", "20180040019"], "related": []}, {"id": "20170310643", "patent_code": "10320752", "patent_name": "Gradients over distributed datasets", "year": "2019", "inventor_and_country_data": " Inventors: \nHardy; Stephen (Eveleigh, AU), Lawrence; Felix (Eveleigh, AU), Visentin; Daniel (Eveleigh, AU)  ", "description": "<BR><BR>CROSS-REFERENCE TO RELATED APPLICATIONS\nThe present application claims priority from Australian Provisional Patent Application No 2014904260 filed on 24 Oct.  2014, the content of which is incorporated herein by reference.\n<BR><BR>TECHNICAL FIELD\nThis disclosure relates to characterising data sets that are distributed as multiple data subsets over multiple computer systems.\n<BR><BR>BACKGROUND ART\nCompanies that provide services or products over the Internet often collect a wide range of data from their customers and process this data to obtain aggregated insights into their client's behaviour.\nFIG. 1 illustrates a prior art corporate-centric computer network 100 with three participating customers or users 102, 104 and 106 operating three respective Internet enabled communication devices, such as smartphones, 108, 110 and 112.  The\nusers 102, 104 and 106 are registered with social media provider 114 and interact with each other by providing indications of their preferences, posting comments or uploading and tagging photos.  In essence, these activities involve storing the personal\ndata related to the three users 102, 104 and 106 on a database 116 operated by the social media provider 114.\nConnected to the database 116 is a server 118 that analyses the user data stored on database 116 to derive aggregated information.  The result may then be sold to a third party, such as an advertising company 120.  However, users 102, 104 and\n106 are reluctant to share private or sensitive information.  Therefore, it is difficult to derive aggregated insights based on private or confidential data related to the users 102, 104 and 106.\nAny discussion of documents, acts, materials, devices, articles or the like which has been included in the present specification is not to be taken as an admission that any or all of these matters form part of the prior art base or were common\ngeneral knowledge in the field relevant to the present disclosure as it existed before the priority date of each claim of this application.\nThroughout this specification the word \"comprise\", or variations such as \"comprises\" or \"comprising\", will be understood to imply the inclusion of a stated element, integer or step, or group of elements, integers or steps, but not the exclusion\nof any other element, integer or step, or group of elements, integers or steps.\n<BR><BR>DISCLOSURE OF INVENTION\nThere is provided a method for determining a gradient of an objective function to iteratively characterise a data set that is distributed as multiple data subsets over multiple computer systems.  The method comprises: determining by the a first\ncomputer system a partial gradient of the objective function over a first data subset stored on the first computer system; determining by the first computer system random data; determining by the first computer system an altered gradient by modifying the\npartial gradient based on the random data; encrypting by the first computer system the altered gradient to determine a first encrypted gradient such that one or more operations on the altered gradient can be performed based on the first encrypted\ngradient; determining by the first computer system an output gradient based on the first encrypted gradient; sending by the first computer system the output gradient to a receiving computer system.\nSince the partial gradient is altered based on random data and encrypted it is difficult, if not impossible, for the second computer system to calculate the data that is stored on the first computer system.  This is an advantage as it allows to\npreserve the privacy of the data stored on the first computer system while still allowing to characterise the data set.\nThe method may further comprise: receiving by the first computer system a second encrypted gradient of the objective function over a second data subset, the second data subset being stored on one or more second computer systems different to the\nfirst computer system; wherein determining the output gradient comprises performing the one or more operations to combine the first encrypted gradient with the second encrypted gradient.\nSince the first and second encrypted gradients are combined, many different computer systems can operate in a chain structure where the partial gradient is refined while it is passed through the chain and combined with the current local gradient\nat each computer system.  Using the one or more operations allows the combination of the gradients without having to decrypt them.  As a result, the partial gradients and the data remain confidential.\nPerforming the one or more operations to combine the first encrypted gradient with the second encrypted gradient may comprise adding the first encrypted gradient to the second encrypted gradient.\nDetermining random data may comprise determining a random number and determining the altered gradient may comprise multiplying the random number with the partial gradient or adding the random number to the partial gradient.\nThe method may further comprise: encrypting the random data to determine first encrypted random data; determining output random data based on the first encrypted random data; and sending the output random data to the receiving computer system.\nThe method may further comprise: receiving by the first computer system second encrypted random data;\nwherein determining the output random data comprises performing the one or more operations to combine the first encrypted random data with the second random data.\nDetermining the partial gradient may be based on a regression model.\nThe first data subset may comprise training data for training a classifier and the training data may comprise one or more samples and a label for each of the one or more samples.  The one or more samples may comprise DNA related data.\nDetermining the partial gradient may comprise determining the partial gradient to extract principle components of the data set.  The first data subset may comprise multiple images.\nThe first data subset may comprise training data of a recommender system and determining the partial gradient may comprise determining the partial gradient of the recommender system.\nThe data set may comprise data from which an anomaly or outlier is to be detected and determining the partial gradient may comprise determining the partial gradient of an anomaly or outlier detection system.\nThe first data subset or the second data subset or both may consist of a single data record.\nEncrypting the altered gradient may comprise using Paiflier encryption.\nSoftware, when installed on a computer, causes the computer to perform the above method.\nThere is provided a computer system for determining a gradient of an objective function to iteratively characterise a data set that is distributed as multiple data subsets over multiple computer systems.  The computer system comprises: a\ndatastore to store a first data subset; a processor to determine a partial gradient of the objective function over the first data subset, determine random data, determine an altered gradient by modifying the partial gradient based on the random data,\nencrypt the altered gradient to determine a first encrypted gradient such that one or more operations on the altered gradient can be performed based on the first encrypted gradient, and determine an output gradient based on the first encrypted gradient;\nand an output port to send the output gradient to a receiving computer system.\nThere is provided a method for updating a characterisation of a data set that is distributed as multiple data subsets over multiple computer systems.  The method comprises: sending an initial characterisation of the data set to the multiple\ncomputer systems; receiving an encrypted gradient of an objective function over the data set; receiving encrypted random data; decrypting the encrypted gradient to determine a decrypted gradient; decrypting the encrypted random data to determine\ndecrypted random data; and determining an updated characterisation of the data set based on the decrypted gradient and the decrypted random data.\nDetermining the updated characterisation may comprise partially reverting an alteration of the gradient based on the random data.\nThe characterisation may comprise one or more coefficients of a linear model.\nDetermining an updated characterisation may comprise adding the initial weights of the linear model to a fraction of the decrypted gradient over the decrypted random data multiplied by a learning factor.\nSoftware, when installed on a computer, causes the computer to perform the above method for updating a characterisation of a data set.\nThere is provided a computer system for updating a characterisation of a data set that is distributed as multiple data subsets over multiple computer systems.  The computer system comprises: a communication port to send an initial\ncharacterisation of the data set to the multiple computer systems, receive an encrypted gradient of an objective function over the data set, and receive encrypted random data; and a processor to decrypt the encrypted gradient to determine a decrypted\ngradient, decrypt the encrypted random data to determine decrypted random data, and determine an updated characterisation of the data set based on the decrypted gradient and the decrypted random data.\nOptional features described of any aspect of method, computer readable medium or computer system, where appropriate, similarly apply to the other aspects also described here. <BR><BR>BRIEF DESCRIPTION OF DRAWINGS\nFIG. 1 illustrates a prior art corporate-centric computer network with a social media provider.\nAn example will be described with reference to\nFIG. 2 illustrates a user-centric computer network with three service providers.\nFIGS. 3a and 3b illustrate screenshots of a mobile app to calculate a dosage of a drug.\nFIG. 4 illustrates a computer system for determining a gradient of an objective function.\nFIG. 5 illustrates a method for determining a gradient of an objective function.\nFIGS. 6a and 6b illustrate examples of computer networks with a distributed data set.\nFIG. 7 illustrates a method for updating a characterisation of a data set.\nFIG. 8 illustrates an example of a network comprising multiple aggregators.\nFIG. 9 illustrates another example of a network comprising multiple aggregators.\n<BR><BR>BEST MODE FOR CARRYING OUT THE INVENTION\nFIG. 2 illustrates a person-centric computer network 200 comprising user 202 operating a communication device, such as a smartphone or tablet computer, 204.  User 202 receives products or services from providers 206, 208 and 210.  The service\nproviders 206, 208 and 210 collect data that is related to that user 202 arid provide that data back to the user 202 to be stored on communication device 204.  As a result, communication device 204 holds a rich collection of personal data related to user\n202.  Of course, this data may comprise data that is generated by user 202, such as by the user 202 providing preferences, taking photos, answering questions or providing comments.  It is also possible that the data is stored on a cloud service and the\nphone provides a key, such as through a user interface, to grant the right to run some computation over that data stored in the cloud.\nUser device 204 and multiple further user devices (not shown) are connected 212 to an aggregating system 214.  Although the aggregating system 214 is shown as a single computer, the aggregating system can comprise multiple nodes, some of which\nmay include those holding data (such as the user's smartphone 204).  The connection 212, that is the communication, between the user device 204 and the aggregating system 214 is such that the aggregating system 214 can determine or learn aggregated data,\nbut the used data stored on user device 204 is not shared with aggregating system 214.\nAs a result, an individual 202 gathers and aggregates data from all the companies 206, 208 and 210 with whom they engage, enabling deep insights from all their engagements and consequently a much more personal understanding of individual needs,\nwants and behaviour.\nThis architecture 200 has a number of consequences.  Most important, individuals now aggregate their own data and can provide informed consent as to its use.  First, this means that privacy becomes a local people-centric issue and not a matter\nof how companies or organisations share their data.  This turns the whole privacy debate on its head.  Second, enormously rich data about individual behaviour becomes available at a single location.  Such rich data can be aggregated by the individual as\norganisations themselves will not and often cannot share this deep information.  Such rich data enables much deeper insights into individual behaviour and drives a new personalised analytics paradigm.\nOne important application of this technology is in management of personal health.  Individuals can own their own personal health information and individuals can aggregate this information locally on their devices to provide the best possible\nhealth predictions and management solutions.\nThe health information may include the individual (differential) genomic sequence, the personal phenotype, information ingested during visits to the doctors or hospital, and personal (food and activity) life-style information collected from the\ndevice itself or ingested from the now popular activity measurement devices such as FuelBand.\nThere are three example use-cases for health-related applications: A visit to the doctors and the consequent prescription of a specific drug; a medical researcher seeking to run cohort studies across a population; and an individual who wants to\nreceive the best advice, targeted at their personal needs, sourced from the world-best medical practitioners.\nFIGS. 3a and 3b illustrate two screen shots from a Warfarin dose smartphone application.  FIG. 3a shows the individual's genome and phenotype information while FIG. 3b shows the results of the secure computation of Warfarin dose.\nIn this scenario, an individual's genome and phenotype are held securely and privately on a mobile phone.  The doctor wishes to determine the appropriate dosage of Warfarin (a blood thinning agent whose optimal dosage depends on both genetic and\nphenotype information).  A dosage is computed and returned to the doctor.  While private personal data is used to compute the correct dosage, this information is kept secure by the individual and not provided to either the doctor or the drug company.\nAnother health related scenario is to provide a tool for cancer researchers to query individually held genomic information.  Population genetics has the potential to have a major impact on understanding cancer and the development of cancer\ntherapies--and will become increasingly important as the cost of whole genome sequencing drops to below $1,000.  However, access to genomic databases has proved to be enormously difficult as different institutions have access to different data and as\nethical and institutional constraints prevent this data being shared, particularly across international borders.  This has become a huge impediment to cancer research.\nIn one scenario, all individuals own their own genetic information maintained on a personal device or on a personal cloud.  Individuals then volunteer to participate with their devices while being confident that the computation is kept secure\nand that the data is kept private and the results anonymous.\nIn health-related applications, it is possible for researchers to ask questions, such as how many people have this combination of SNPs, are between these weights, have taken this medication in the past six months and exercise more than twice a\nweek? Provided is a solution to the problem of ethics and data privacy, while simultaneously providing richer and more personal information for researchers.\nMany of the privacy, security and data richness issues that abound in health are equally important in banking and personal finance applications.  Decisions about spending and investment, risk and insurance, short versus long term behaviour are\nimportant both to the individual and the financial institution concerned.  A solution is provided to both the data aggregation and data privacy issues while enabling rich new capabilities with analytics applied to individual customers.\nIn a first example, individuals aggregate data and financial institutions want to better target, predict and personalise financial products and advice.  In a second example businesses and even business divisions want to undertake analytics or\nshare information across a number of different databases while making guarantees about the security and privacy of each individual database.\nIndividuals have access not only to their personal financial information, but also direct access to their life style, family circumstance, social behaviour, spending and investment profiles with third parties.  The proposed solution allows\naggregation of this personal data to create a rich source of information at a single location, while still allowing insights to be generated from the data.  Further, a financial institution can use this information to provide far more directed financial\nadvice and personal product direction.  This ensures the privacy and security of information for the individual while enabling directed individual and personalised analyses.\nIt is also possible to envisage a wide range of potential commercial applications, allowing individuals to monetise their data by selling deeper individual insights to third party organisations (media, marketing, sales and others).\nFIG. 4 illustrates a computer system 400 for determining a gradient of an objective function.  The computer system 400 may be a mobile phone and comprises a processor 402 connected to a program memory 404, a data memory 406, a communication port\n408 and a user port 410.  The program memory 404 is a non-transitory computer readable medium, such as a hard drive, a solid state disk or CD-ROM.  Software, that is, an executable program stored on program memory 404 causes the processor 402 to perform\nthe method in FIG. 5, that is, processor 402 determines a partial gradient of the local data, randomizes and encrypts the gradient before sending the output gradient to a receiving computer system.\nSince this disclosure describes multiple computer systems with similar elements to computer system 400, computer system 400 is described and illustrated only once.  Where the following description states that a particular device, such as a\nsmartphone or server performs a particular step, it is to be understood that this step is performed by processor 402 of that particular smartphone or server.\nThe term \"determining a partial gradient\" refers to calculating a value that is indicative of the partial gradient.  This also applies to related terms.  The objective function may be a cost function, such as an error function between a linear\nregression model and the dataset, an error function between a set of principle components and the dataset or any other cost function that expresses how well the dataset is characterised.  Principle components are used in principle component analysis\n(PCA).  The principle components are the most significant basis vectors in the dataset, which means that a linear combination of the principle components approximates the dataset.  For example, a principle component of 1000 face images with 200.times.300\npixels is also a 200.times.300 pixel image and represents the most common face features.\nIt is noted that the gradient of the objective function can be determined without explicitly referring to the objective function itself.  Examples below show how a closed form expression can be used to determine the gradient of the objective\nfunction directly from predictions and the values of the data set without calculating the objective function for the values of the data set.\nThe processor 402 may then store the output gradient on data store 406, such as on RAM or a processor register.  Processor 402 may also send the determined randomised and encrypted output gradient via communication port 408 to another computer\nsystem, such as another mobile phone.\nThe processor 402 may receive data, such as data of a data set to be characterised, from data memory 406 as well as from the communications port 408 and the user port 410, which is connected to a display 412 that shows a visual representation\n414 of the data set or characterisation of the data set to a user 416.  In one example, the processor 402 receives the data set from a storage device via communications port 408, such as by using a Wi-Fi network according to IEEE 802.11.  The Wi-Fi\nnetwork may be a decentralised ad-hoc network, such that no dedicated management infrastructure, such as a router, is required or a centralised network with a router or access point managing the network.\nIn one example, the processor 402 receives and processes the data set in real time.  This means that the processor 402 determines the output gradient every time new data of the data set is received and completes this calculation before the next\ndata update is provided.\nFor example, the aim may be to determine the principle components of a data set comprised of photographs of faces and to characterise the data set in terms of those principal components, also called eigenfaces, to compress the face images. \nProcessor 402 determines a partial gradient based on the face images that are stored locally.  An aggregating computer system then determines based on output gradients from multiple computer systems a final gradient and optimises a cost function to\ndetermine the principle components of the data set.  The aggregating computer then sends these principal components back to the computer systems, which in turn, use the principal components to store linear combination of principal components instead of\nthe image files.\nAlthough communications port 408 and user port 410 are shown as distinct entities, it is to be understood that any kind of data port may be used to receive data, such as a network connection, a memory interface, a pin of the chip package of\nprocessor 402, or logical ports, such as IP sockets or parameters of functions stored on program memory 404 and executed by processor 402.  These parameters may be stored on data memory 406 and may be handled by-value or by-reference, that is, as a\npointer, in the source code.\nThe processor 402 may receive data through all these interfaces, which includes memory access of volatile memory, such as cache or RAM, or non-volatile memory, such as an optical disk drive, hard disk drive, storage server or cloud storage.  The\ncomputer system 400 may further be implemented within a cloud computing environment, such as a managed group of interconnected servers hosting a dynamic number of virtual machines.\nIt is to be understood that any receiving step may be preceded by the processor 402 determining or computing the data that is later received.  For example, the processor 402 determines the partial gradient and stores the partial gradient in data\nmemory 406, such as RAM or a processor register.  The processor 402 then requests the data from the data memory 406, such as by providing a read signal together with a memory address.  The data memory 406 provides the data as a voltage signal on a\nphysical bit line and the processor 402 receives the partial gradient via a memory interface.\nFIG. 5 illustrates a method 500 as performed by processor 402 for determining a gradient of a objective function to iteratively characterise a data set.  that is distributed as multiple data subsets over multiple computer systems.\nFIG. 6a illustrates a computer network 600 comprising multiple computer systems.  In particular, FIG. 6a shows a first computer system 602, a second computer system 604, a third computer system 606 and a central learning server 608.  Each of the\nthree computer systems 602, 604 and 606 and the central learning server 608 comprise the elements described with reference to FIG. 4.\nIn one example, the aim is to learn a predictive model--such as logistic regression with a regulariser.  This involves finding the parameter vector .theta.* that minimises the objective function\nL(.theta.)=.SIGMA..sub.i=1.sup.N.SIGMA..sub.j=1.sup.N.sup.i log(1+exp(-y.sub.ij.theta..sup.Tx.sub.ij))+.lamda..theta..sup.T.theta..SI- GMA..sub.i=1.sup.NN.sub.i where N is the number of data providers, N.sub.i is the number of examples held by data\nprovider i, x.sub.ij is the jth feature vector held by data provider i, y.sub.ij is a binary label corresponding to the feature vector x.sub.ij, and .lamda.  is the regularisation parameter.  We aim to find .theta.*, or a nearby parameter vector, while\nmaintaining the privacy of the training examples (x.sub.ij, y.sub.ij).  It is noted that training examples may equally be denoted as (d.sub.i, t.sub.i) in other examples below.\nOne procedure for finding the optimal parameter vector involves iteratively improving an initial guess .theta..sub.1 using a gradient descent algorithm.  Each iteration begins with the data providers calculating the gradient for their portion of\nthe objective function.  These gradients are sent to a central learner who sums the local gradients and the gradient of the regulariser .lamda..theta..sup.T.theta..SIGMA..sub.i N.sub.i to obtain the global gradient.  The learner subsequently updates the\nparameters according to the gradient and a step size.  Finally, the updated parameters are communicated to each of the nodes.\nProcedures of this type are not privacy preserving due to the transmission of the local gradients directly to the learner.  By manipulating the parameter vector the learner can use these gradients to obtain information about the data sets.  This\nis particularly problematic when the size of the data sets held by a data provider is small.\nTo account for these failings, the proposed solution augments a gradient descent algorithm with a procedure involving random sampling, partial homomorphic encryption, and aggregation so as to obscure the local gradients from the learner and thus\nensure the privacy of the data.  Before the gradient descent begins, the learner provisions several aggregating nodes.  These nodes may also be data providers.  The learner also generates a public/private key pair for an additively homomorphic\ncryptosystem, such as the Paillier cryptosystem, and sends the public key to each of the data providers.\nIn this example, the task is to determine a logistic regression classifier based on a simple questionnaire.  The questionnaire comprises three questions.  Two questions are related to features while the third question is related to a label.  The\nfirst question is whether a person is a smoker, while the second question is whether the person is a vegan.  The third question is whether the person has cancer, that is, the label for each samples is whether the person has `cancer`.\nThe task is to construct a classifier that can predict whether a person has cancer based on whether they are a smoker or a vegan.  However, having cancer is information that most users would not want to share openly and therefore, it is\nimportant for the questionnaire to be successful that the privacy is preserved, which means that the information whether a particular user has cancer is not disclosed to any party or device other than computer system 602 for the first user.\nIn this example, the three computer system 602, 604 and 606 are smartphones and the questionnaire questions are displayed on the respective screens.  A user of the first smartphone 602 has answered `Yes` to being a smoker, `No` to being a vegan\nand `Yes` to having cancer.  The answers are stored as a first data subset 610 stored on the data memory (referred to as 406 in FIG. 4) of first computer system 602.  The first row relates to feature `1`, which is `smoker`, the second row relates to\nfeature `2`, which is `vegan` and the third row relates to the label `L`, which is `cancer`.  In this example, the second column stores the feature value of the respective feature where `1` represents a `yes` answer and `-1` represents a `no` answer.\nBased on the results provided to the first smartphone 602, it appears that smoking and not being a vegan leads to having cancer.  However, this conclusion is based on a single sample and is therefore statistically not significant.  Incorporating\nmore participants would make the result more significant.\nIn a similar way, a user of the second smartphone 604 has indicated that he is not a smoker, is not a vegan and has no cancer, which is stored as second data subset 612 on second computer system 604.  A user of the third smartphone 606 has\nindicated that she is a smoker, a vegan and has cancer, which is stored as third data subset 614 on third computer system 606.\nIn other examples, the training data, that is, the data subsets 610, 612 and 614 may store other types of data, such as face images as described above or a genome and a particular disease.  For example, the data subsets 610, 612 and 614 may\ninclude one feature for each of a large number of single-nucleotide polymorphism (SNPs), such that the subset stores a `1` if that person's DNA shows that SNP or a `-1` if it doesn't.  The label may again be a specific disease, such as diabetes.\nIn another example, the data subsets 610, 612 and 614 comprise features related to user data, such as age, gender, address, nationality, ethnicity and so on.  This user data should not be disclosed or shared with other parties.\nThe label may represent historical behaviour data of the respective users, such as purchased items, watched movies, read books or individual words of comments, website keywords or photographs that the users have indicated as their preference,\nsuch as by selecting a `like` or `love it` link.\nThe network 600 can then function as a recommender system where characterising the dataset means learning the relationship between the historical behaviour, preferences of the users and user data.  As a result, additional items, movies, books,\ncomments, websites photographs or the like can be recommended to the user according to the user data or preferences.\nAlthough the data subsets 610, 612 and 614 in the above examples only comprise a single sample, it is to be understood that each data subset may equally have more than one sample and each sample may have more than one label.  In the multi-label\nexample, the processes described herein are simply performed for each of the multiple labels separately.\nFIG. 6b illustrates another example of a computer network 650 where smartphones or any other personal computing devices act as access points to the data while the data is stored on three servers 602, 604 and 606.  The same reference numerals are\nused in FIG. 6a and FIG. 6b to denote that elements with the same reference numerals perform the same functions.  The three servers 602, 604 and 606 in FIG. 6b may be operated by three respective companies and they provide the encrypted gradient updates\nbased on their data as will be described below with reference to FIG. 6a.\nReferring back to FIG. 5, processor 402 of the first computer system 602 determines 502 a partial gradient g of the objective function over the first data subset 610 stored on the first computer system 602.  Determining the partial gradient may\nbe based on a regression model, which means the partial gradient is computed such that it points towards a reduction in the fitting error of the regression model.\nThe data subset may be written as {(d.sub.i,t.sub.i)}, where d.sub.i is a vector comprising the feature values, such as the first two rows of the second column of data subset 610 in FIG. 6a and t.sub.i is the label in the third row of the second\ncolumn of the data subset 610.  The partial gradient may be based on current model parameters .THETA.  which may be provided by the learning server 608.  In the first iteration when no model parameters are available from a previous iteration, all model\nparameters may be initialised to zero.\nThe number of model parameters may be identical to the number of feature values, that is, two in this example, such that processor 402 can calculate predictions y of the label t.sub.i (`cancer`) based on the feature values (`smoker` and `vegan`)\nd.sub.i by calculating y.sub.i=.sigma.(.THETA..sup.Td.sub.i)=1/(1+exp(-.THETA..sup.Td.sub.i)).  For the example of the first computing device and assuming zero model parameters, the predicted label y for the first data subset, that is feature values `1`\nand `-1` is y.sub.i=1/(1+exp(-(0.1+0(-1))))=1/(1+exp(0))=1/2, which means that the prediction is exactly in the middle between having cancer and not having cancer.\nThe error between a prediction y.sub.i and the actual label t.sub.i can then be expressed in terms of a loss function l(y.sub.i, t.sub.i)=t.sub.i ln y.sub.i+(1-t.sub.i) ln(1-y.sub.i).  For the single example described above, the result of the\nloss function is l(1/2, 1)=1ln 1/2+0ln 1/2=ln 1/2.  The partial gradient of the loss function applied to this example is given by\n.differential.  .function..differential..THETA..times..function.  ##EQU00001## It is noted that the shorthand .differential.l(y.sub.i, t.sub.i) is used below in place of .differential.l(y.sub.i, t.sub.i)/.differential..THETA..sub.1.\nThe objective function for the entire dataset is simply the sum of the loss functions applied to each example L(.THETA.)=.SIGMA..sub.il(y.sub.i,t.sub.i) where we note that each prediction y.sub.i is implicitly dependent on the parameters .THETA. as defined above.  Similarly, the partial gradient of the objective function with respect to the parameters is simply the sum of the partial gradients of the loss functions .differential.L(.THETA.)/.differential..THETA.=.SIGMA..sub.i.differential-\n.l(y.sub.i, t.sub.i).\nProcessor 402 can update the model parameters by .THETA..THETA.-.eta..differential.l(y.sub.i,t.sub.i) and in this case assuming .eta.=1:\n.THETA.  ##EQU00002## This shows that now the answer to `smoker` has a positive contribution to `cancer` and the answer to `vegan` has a negative influence on `cancer`, which corresponds to the intuitive result above.\nSince the updated model parameters are based on only a single sample, processor 402 of first smartphone 602 should send the partial gradient to the second smartphone 604 to allow the second smartphone 604 to update the partial gradient based on\nthe second data subset 612.  However, sending the partial gradient in plain text, that is,\n##EQU00003## would allow the second smartphone 604 to reconstruct the first data subset 610 or at least derive some information about the first data subset 610.\nTherefore, processor 402 determines 504 random data, such as a vector of random numbers with the same dimension as the number of features a.sub.i .di-elect cons.  (0,1).sup.n.  For example, the random data may be\n##EQU00004##\nProcessor 402 then determines 506 an altered gradient by modifying the partial gradient based on the random data, such as by computing a.sub.i.differential.l(y.sub.i, t.sub.i), where denotes element-wise multiplication.  In other examples, may\ndenote element-wise addition.  In the current example of element-wise multiplication, the result is\n##EQU00005##\nThe example above is given for illustrative purpose only.  Due to the small number of features, it may be preferred that first smartphone 602 does not send the output gradient to the second smartphone 604 but to a trusted aggregator, which\nperforms the Paillier addition.  This will be explained in more detail with reference to FIG. 8.\nIn another example, the data provider, that is one of the smartphones, samples a vector g.sub.i from the uniform distribution with maximal values according to .differential.l(y.sub.i, t.sub.i).  That is, the jth component of g.sub.i is uniformly\nsampled from the interval [0, .differential..sub.jl(y.sub.i, t.sub.i)] where .differential..sub.jl(y.sub.i, t.sub.i) denotes the jth component of the gradient .differential.l(y.sub.i, t.sub.i).  The data provider then calculates a normalisation factor\nr.sub.i, whose jth component is given by .differential..sub.jl(y.sub.i, t.sub.i)/g.sub.ij so that r.sub.ijg.sub.ij=.differential..sub.jl(y.sub.i, t.sub.i).  This normalisation factor will be used subsequently by the learner to diminish the detrimental\neffects of the randomly sampled gradient.  The randomised gradient and normalisation factor are then encrypted with the learner's public key and sent to an aggregating node.\nAfter that, processor 402 encrypts 508 the altered gradient to determine a first encrypted gradient by calculating E(a.sub.i .differential.l(y.sub.i,t.sub.i)), where E( ) is an encryption function.  The encryption function is such that one or\nmore operations on the altered gradient a.sub.i.differential.l(y.sub.i, t.sub.i) can be performed based on the encrypted gradient E(a.sub.i .differential.l(y.sub.i, t.sub.i)).  An example of such an encryption is Paillier encryption, which will be\ndescribed now.\nPaillier encryption is based on an asymmetric key pair generated by the following procedure.  Two large primes p, q are chosen randomly such that the greatest common divisor of pq and (p-1)(q-1) is 1.  Then, the integer n=pq and the least common\nmultiple .lamda.=lcm(p-1, q-1) of p-1 and q-1 are computed.  Subsequently, a random integer g .di-elect cons.  .sub.n.sub.2 is chosen from the multiplicative group of integers modulo n.sup.2 such that n divides the order of g. This divisibility can be\ndetermined by checking for the existence of the modular multiplicative inverse .mu.=(L(g.sup..lamda.mod n.sup.2)).sup.-1 where L(u)=(u-1)/n. The result of this procedure is a public key given by (n, g) and a private key given by (.lamda., .mu.).\nThe encryption of an integer message m .di-elect cons.  *.sub.n is described by the function E(m)=g.sup.mr.sup.nmod n.sup.2 where r .di-elect cons.  *.sub.n is the multiplicative group of integers modulo n and is chosen at random.  Decryption or\nan integer c .di-elect cons.  *.sub.n.sub.2 is performed by the function D(c)=.mu.L(c.sup..lamda.  mod n.sup.2) mod n. These functions satisfy the property that D(E(m))=m, which is to say that an encrypted message can be decrypted to obtain the original\nmessage.  The encryption function can be applied by any party who possesses the public key (n, g) while the decryption function can only be performed by a party who also knows the private key (.lamda., .mu.).\nIn order to securely communicate using the Paillier cryptosystem, a first party generates a public/private key pair and publishes its public key.  A second party can then obtain the public key of the first party and use it to encrypt a message\nbefore sending it to the first party.  The first party can use its private key to decrypt the message.  Provided that the first party keeps its private key a secret, any eavesdroppers will be unable to recover the original message.\nThe second important property of the Paillier cryptosystem is that one or more operations on the original data can be performed based on the encrypted data and in particular that multiplication of two encrypted messages is equivalent to the\naddition of the unencrypted messages modulo n. More formally, D(E(m.sub.1)E(m.sub.2) mod n.sup.2)=m.sub.1+m.sub.2 mod n for any two messages m.sub.1, m.sub.2 .di-elect cons.  *.sub.n encrypted with the same public key pair.  One consequence of this\nproperty is that exponentiation of an encrypted number by an unencrypted number is equivalent to the multiplication of the two unencrypted numbers modulo n. That is, D(E(m.sub.1).sup.m.sup.2 mod n.sup.2)=m.sub.1m.sub.2 mod n. These properties constitute\nan additive homomorphism and the Paillier cryptosystem is referred to as being additively homomorphic or partially homomorphic.  A fully homomorphic encryption scheme also allows multiplication of two encrypted values.\nIn one example, homomorphism is a synonym for the property that addition and multiplication are allowed.  In other examples, there may be other encryption methods which allow addition and multiplication and potentially other operations to be\nperformed on the secret data based on the encrypted data without being considered homomorphic in a mathematically strict sense.  For example, the operations based on the encrypted data may introduce some inaccuracy but that inaccuracy is acceptable as it\nintroduces only a small amount of error into the final characterisation of the data set.\nThe Paillier cryptosystem allows the addition of integers.  In order to sum floating point numbers they may be encoded as fixed point numbers.  For example: 0.01 could be encoded as 10 with the respect to the base 10.sup.-3.\nIn this example, after modifying the partial gradient as explained above based on the random data, the processor 402 encrypts with the learner's public key the product of the random data with the partial gradient.\nThen, processor 402 determines 510 an output gradient based on the encrypted gradient.  In the case of the first smartphone 602, the output gradient is identical to the encrypted gradient and the determining step 510 is performed simultaneously\nwith the previous step of encrypting the partial gradient.\nFinally, the processor 402 sends 512 the output gradient to the second smartphone 604 using communication port 408.  Since the output gradient is an encrypted randomised version of the partial gradient it is difficult, if not impossible for the\nsecond smartphone 604 to determine the first data subset 610 or derive any knowledge about the first data subset 610.\nThe second smartphone 604 also performs method 500 based on the second data subset 612.  However, at any time before the step of determining the output gradient 510 the second smartphone 604 receives from the first smartphone 602 the output\ngradient determined by the first smartphone 602, which is in essence the encrypted gradient determined in step 508 over the first data subset 610.  As shown in FIG. 6a, the first data set 610 is stored on smartphone 602 that is different to the\nsmartphone 604 which is now performing the method 600.\nIn case of second smartphone 604, determining the output gradient in step 510 comprises performing the one or more operations to combine the encrypted gradient determined by second smartphone 604 with the encrypted gradient determined by first\nsmartphone 604.  In the example of using Paillier encryption, performing the one or more operations comprises performing an addition.\nMore formally, first smartphone 602 determines partial gradient g.sup.l.sub.k , multiplies the partial gradient with random number a, encrypts the result to obtain E(ag.sup.l.sub.k) and sends E(ag.sup.l.sub.k) to the second smartphone 604 over\nthe internet using a 4G, LTE or Will connection, for example.\nThe second smartphone 604 receives the encrypted randomised partial gradient E(ag.sup.l.sub.k) and determines partial gradient g.sup.2.sub.k, multiplies the partial gradient with random number b and encrypts the result to obtain\nE(bg.sup.2.sub.k).  The second smartphone 604 then combines the two encrypted randomised partial gradients by adding them to determine the output gradient in step 510.  The encryption method allows the addition of the secret data based on the encrypted\ndata, which means that adding the encrypted values is equal to adding the unencrypted values and then encrypting the result: E(ag.sub.k.sup.1)+E(bg.sub.k.sup.2)=E(ag.sub.k.sup.1+bg.sub.k.sup.2).\nSecond smartphone 604 sends the result E(ag.sub.k.sup.1+bg.sub.k.sup.2) to third smartphone 606 which similarly computes a further partial gradient over the third data subset 614, multiplies the partial gradient with random number c, encrypts\nthe result, combines the encrypted gradient with the gradient received from second smartphone 604 and sends E(ag.sub.k.sup.1+bg.sub.k.sup.2+cg.sub.k.sup.3) to the central server 608.\nIn one example, each of the three smartphones 602, 604 and 606 further encrypt their random number a, b and c, respectively.  First smartphone 602 then sends the encrypted random number E(a) to second smartphone 604.  Second smartphone 604 again\nperforms the operations provided by the Paillier encryption to combine the received encrypted random number with the locally encrypted random number.  That is, second smartphone 606 adds its own encrypted random number to obtain E(a+b) and sends this\nresult to third smartphone 606 that similarly determines E(a+b+c) and sends this result to the server 608.\nIn the example above, the second smartphone 604 and the third smartphone 606 perform the homomorphic addition.  However, it is equally possible in other examples that additional aggregators are present in the network 600.\nFIG. 8 illustrates another example of a network 800 comprising multiple data providers, two of which are shown as data providers 802 and 804.  The data providers are connected to multiple aggregators, four of which are shown as aggregators 806,\n808, 810 and 812 and a learner 814.  The data providers can generate one or more randomised gradients and random numbers from the partial gradient and send these to the aggregators.  The aggregators then add them as described above and send the results\nto the server 608.\nFIG. 9 illustrates yet another example of a network 900 comprising 14 nodes 902 to 915.  Nodes 902, 904, 905, 909, 911, 912, 914 and 915 determine their respective encrypted gradients and send them together with the encrypted random numbers to a\nfirst aggregating node 911.  The remaining nodes 903, 906, 907, 908, 910 and 913 also determine their respective encrypted gradients and send them together with the encrypted random numbers to a second aggregating node 911.  The aggregating nodes 908 and\n911 perform the Paillier addition and send the result to a learner server (not shown in FIG. 9).\nIn this example, all encryptions E( ) are performed using a public key, which means that any computer including the three smartphones 602, 604 and 606 can perform the encryption.  However, only the central server 608 has the corresponding\nprivate key, which means that no computer other than the central server 608 can decrypt the encrypted data.  Even the smartphones 602, 604 and 606 cannot decrypt the data that they have encrypted themselves.\nCentral server 608 has similar components to the three smartphones 602, 604 and 606 and the description of computer system 400 with reference to FIG. 4 also applies to the central server 608.  Program memory 404 of server 608 has installed a\nsoftware program, that causes the processor 402 to perform the method of FIG. 7.\nFIG. 7 illustrates a method as performed by server 608 for updating a characterisation of a data set.  As explained above, the dataset is distributed as multiple data subsets over multiple computer systems, such as three data subsets 610, 612\nand 614 distributed over three smartphones 602, 604 and 606, respectively.\nIn order to initialise the smartphones 602, 604 and 606, server 608 uses communication port 408 of server 608 to send 702 an initial characterisation of the data set to the three smartphones 602, 604 and 606.  In one example, server 608 sends\nthe initial characterisation only to first smartphone 602 and the first smartphone 602 forwards the initial characterisation to the second smartphone 604 together with or separately from the encrypted gradient as described above.\nOnce the computation of partial gradients is completed as described above, server 608 receives 704 via the communication port 408 of server 608 the encrypted gradient E(ag.sub.k.sup.1+bg.sub.k.sup.2+cg.sub.k.sup.3) of the objective function over\nthe data set and receives 706 via the communication port 408 of server 608 the encrypted random data E(a+b+c).  Server 608 then decrypts 708 the encrypted gradient E(ag.sub.k.sup.1+bg.sub.k.sup.2+cg.sub.k.sup.3) to determine the decrypted gradient\nag.sub.k.sup.1+bg.sub.k.sup.2+cg.sub.k.sup.3 and decrypts 710 the encrypted random data E(a+b+c) to determine decrypted random data a+b+c.  Finally, server 608 determines 712 an updated characterisation .THETA..sub.k+1 of the data set based on the\ndecrypted gradient and the decrypted random data according to\n.THETA..THETA..eta..times.  ##EQU00006## where .eta.  is an appropriately chosen learning factor which may be decreased each iteration.  When performing gradient descent, processor 402 iteratively updates the parameters according to the\ngradient.  The learning factor .eta.  or \"step size\" is typically decreased from some initial value to zero.  This has the effect of allowing large changes initially (when the parameters are far from the optimal parameters) and reducing the size of the\nchanges as they get closer to the optimum.  The initial value and decay schedule are highly dependent on the data and objective function.  In one example, the initial value is `0.01` and the decay is proportional to the inverse of k squared, that is\n.eta..sub.k=0.01.times.k.sup.-2.\nAs can be seen from the equation above for .THETA..sub.k+1, dividing the decrypted sum of gradients by the sum of random numbers partially reverts the alteration of the gradient based on the random data, that is, the multiplication of the\npartial gradients by the random numbers.  This reversion is only partial and not perfect because in general terms\n.noteq.  ##EQU00007## However, me reversion is sufficient to allow the update of the model parameters.  In particular, if the random numbers a, b and c are uniformly distributed, their influence should even out and the direction of correction of\nthe model parameters remains close to the non-randomised result.  It is noted that in some examples, the performance may be sufficient without this normalisation by the sum of random numbers.\nThe process described above, that is, performing method 500 on the three smartphones 602, 604 and 606 and performing method 700 on the server is repeated and in each iteration the model parameters are updated.  This repetition can be stopped\nafter a stopping criterion has been attained such as a predetermined number of iterations, such as 1000, or a sufficiently small update value, such as 10E-6.\nAs mentioned above, the characterisation may comprise one or more coefficients of a model, such as a linear regression model or principle components or other basis vectors for data compression.\nIn one example, the data set comprises data from which an anomaly or outlier is to be detected.  In this example, each of the three smartphones 602, 604 and 606 determine the partial gradient of an anomaly or outlier detection system.  This may\nnot change the operation that is described above, which means that after the last iteration the final model parameters are available.  Each of the three smartphones 602, 604 and 606 can then determine how far the samples of the data subsets 610, 612 and\n614, respectively, are away from the regression model and can discard those samples if the distance to the regression model is above a predetermined threshold.  This way, anomalies and outliers are detected and can be excluded from further consideration.\nThe privacy preserving gradient descent procedure can be applied to a large class of optimisation problems.  The objective function is differentiable or sub-differentiable and takes the form of a sum of data provider dependent portions plus an\nadditional parameter dependent term.  The objective function does not necessarily have to be the same function for each iteration.\nThe procedure itself can also embody many variations.  Some of these are listed below: The number of data providers may change over time.  The data set held by each data provider may change over time.  Each data provider may provide data\nrelating to multiple entities or individuals--for instance, each data provider may be involved in a particular industry and hold information about different sets of customers of that industry.  The learner may use a random subset of data providers during\neach iteration.  The number of aggregators may change over time.  The aggregation process may involve an arbitrary number of aggregators, connected in different ways, and may change over time.  The data providers may perform different random\nperturbations of their local gradient.  They may sample multiple randomised gradient portions instead of one.  They may send each portion to a different aggregator.  They may omit the normalisation factors.  The key property is that the expected value of\nthe sum of the randomised gradient portions equals some multiple of the true gradient.  The data providers may take any subgradient of their local objective function when it is only subdifferentiable and not differentiable.  The procedure does not\nrequire the notion of feature vectors and labels in the objective function.  These are simply to motivate the notion of privacy preservation.  The gradient descent procedure can vary.  It can take account of all previous parameters, step sizes, and\ngradients to calculate an update.  The homomorphic cryptosystem can vary so long as it allows addition.  The procedure can perform maximisation instead of minimisation.\nA more general formulation of the procedure might be as follows.  Let .THETA.  be the parameter space.  Let t .di-elect cons.  {1, 2, 3, .  . . } be the index of the current iteration.  Let .theta..sub.t be the parameters during iteration t. Let\nN.sub.t be the set of data providers who participate in iteration t. Let L.sub.t,n:.THETA..fwdarw.  be the local objective function for data provider n .di-elect cons.  N.sub.t during iteration t. Let .OMEGA..sub.t: .THETA..fwdarw.  be the regulariser\nduring iteration t.\nLet t.sub.t(.theta.)=.SIGMA..sub.n.di-elect cons.N.sub.tL.sub.t,n(.theta.)+.OMEGA..sub.t(.theta.) be the global objective function during iteration t. Let g.sub.t,n .di-elect cons.  .differential.L.sub.t,n(.theta..sub.t) be a subgradient of\nL.sub.t,n with respect to the parameters .theta..sub.t.  Let P.sub.t,n={p.sub.t,n,1, .  . . , p.sub.t,n,M} be a set of probability distributions for data provider n during iteration t. Let G.sub.t,n={g.sub.t,n,1, .  . . , g.sub.t,n,M} be the set of\ngradients sampled from the distributions of P.sub.t,n where g.sub.t,n,m is distributed according to p.sub.t,n,m.\nThe probability distributions may be chosen such that the expected value of the sum of the sampled gradients E[.SIGMA..sub.g.di-elect cons.G.sub.t,ng] is in the set .differential.L.sub.t,n(.theta..sub.t).  The privacy preserving subgradient\nportions are encrypted with the learners public key and sent through an aggregation network.  Each aggregator sums the encrypted vectors using homomorphic addition and forwards them on to another aggregator or the learner.  The learner decrypts these and\ncalculates the global privacy preserving gradient g.sub.t=.SIGMA..sub.n.di-elect cons.N.sub.tg.sub.t,n+.differential..OMEGA.(.theta..sub.t) for iteration t. At the end of the iteration the learner perform a parameter update step of the form\n.theta..sub.t+1=.theta..sub.t-.alpha..sub.t(.theta..sub.1, .  . . , .theta..sub.t, g.sub.1, .  . . , g.sub.t) where .alpha..sub.t calculates the update step according to the previous parameters and privacy preserving gradients.\nIt will be appreciated by persons skilled in the art that numerous variations and/or modifications may be made to the specific embodiments without departing from the scope as defined in the claims.\nIt should be understood that the techniques of the present disclosure might be implemented using a variety of technologies.  For example, the methods described herein may be implemented by a series of computer executable instructions residing on\na suitable computer readable medium.  Suitable computer readable media may include volatile (e.g. RAM) and/or non-volatile (e.g. ROM, disk) memory, carrier waves and transmission media.  Exemplary carrier waves may take the form of electrical,\nelectromagnetic or optical signals conveying digital data steams along a local network or a publically accessible network such as the intemet.\nIt should also be understood that, unless specifically stated otherwise as apparent from the following discussion, it is appreciated that throughout the description, discussions utilizing terms such as \"estimating\" or \"processing\" or \"computing\"\nor \"calculating\", \"optimizing\" or \"determining\" or \"displaying\" or \"maximising\" or the like, refer to the action and processes of a computer system, or similar electronic computing device, that processes and transforms data represented as physical\n(electronic) quantities within the computer system's registers and memories into other data similarly represented as physical quantities within the computer system memories or registers or other such information storage, transmission or display devices.\nThe present embodiments are, therefore, to be considered in all respects as illustrative and not restrictive.", "application_number": "15521409", "abstract": " This disclosure relates to characterising data sets that are distributed\n     as multiple data subsets over multiple computers such as by determining a\n     gradient of an objective function. A computer determines a partial\n     gradient of the objective function over a data subset stored on the\n     computer and determines random data. The computer then determines an\n     altered gradient by modifying the partial gradient based on the random\n     data and encrypts the altered gradient such that one or more operations\n     on the altered gradient can be performed based on the encrypted gradient\n     and sends the encrypted gradient. Since the partial gradient is altered\n     based on random data and encrypted it is difficult for another computer\n     to calculate the data that is stored on the first computer. This is an\n     advantage as it allows to preserve the privacy of the data stored on the\n     first computer while still allowing to characterise the data set.\n", "citations": ["5341427", "8375030", "9166789", "20070118492", "20090150362", "20100030764", "20110029809", "20120237082", "20130282679", "20140234845", "20150262095", "20150288662", "20160099807"], "related": []}, {"id": "20170316319", "patent_code": "10354192", "patent_name": "Recommender system for exploratory data analysis", "year": "2019", "inventor_and_country_data": " Inventors: \nLivingston; Mark A. (Alexandria, VA), Russell; Stephen (Laurel, MD), Decker; Jonathan W. (Silver Spring, MD), Guleyupoglu; Suleyman (Springfield, VA), Gilliam; Antonio (Lorton, VA)  ", "description": "<BR><BR>FIELD OF THE DISCLOSURE\nThis disclosure relates to data analysis systems, including adaptive and predictive data analysis systems.\n<BR><BR>BACKGROUND\nIn many scientific fields, data analysts analyze raw data and process this raw data to glean useable information.  For example, a data analyst can use visual and textual representations of data with analytical operations to explore, understand,\nand generate hypotheses for evaluation based on this data.  As advances have been made in technology that allows data to be gathered in increasingly larger volume and complexity, processing data in an efficient and meaningful manner has become an\nimportant and difficult challenge.  As data sets become larger and more complex, an increasing amount of expertise may be needed to adequately analyze the raw data to discern useful conclusions.  Data analysis in many fields requires a data analyst to\nhave access to expert knowledge both in the domain of the underlying subject matter of the data and also in the techniques uses to process the raw data to derive conclusions.\nAdequately trained experts are not always easily available to interpret these increasingly large and complex data sets.  Thus, there is a need for assistance in data analysis.  Previous attempts to provide assistance for data analysis have not\nadequately captured the knowledge and experience that an expert data analyst would use when analyzing a large, complex set of data. <BR><BR>BRIEF DESCRIPTION OF THE DRAWINGS/FIGURES\nThe accompanying drawings, which are incorporated in and constitute part of the specification, illustrate embodiments of the disclosure and, together with the general description given above and the detailed descriptions of embodiments given\nbelow, serve to explain the principles of the present disclosure.  In the drawings:\nFIG. 1 is a block diagram of an exemplary recommender system in accordance with an embodiment of the present disclosure;\nFIG. 2 is a flowchart of an exemplary method for exploratory data analysis using a recommender system in accordance with an embodiment of the present disclosure;\nFIGS. 3-8 show exemplary output that can be displayed to a user based on output from a recommender system in accordance with embodiments of the present disclosure;\nFIG. 9 shows a block diagram of an exemplary agent-based environment for a recommender system in accordance with an embodiment of the present disclosure; and\nFIG. 10 shows a block diagram of an exemplary recommender system including a sensor in accordance with an embodiment of the present disclosure.\nFeatures and advantages of the present disclosure will become more apparent from the detailed description set forth below when taken in conjunction with the drawings, in which like reference characters identify corresponding elements throughout. In the drawings, like reference numbers generally indicate identical, functionally similar, and/or structurally similar elements.  The drawing in which an element first appears is indicated by the leftmost digit(s) in the corresponding reference number.\n<BR><BR>DETAILED DESCRIPTION\nIn the following description, numerous specific details are set forth to provide a thorough understanding of the disclosure.  However, it will be apparent to those skilled in the art that the disclosure, including structures, systems, and\nmethods, may be practiced without these specific details.  The description and representation herein are the common means used by those experienced or skilled in the art to most effectively convey the substance of their work to others skilled in the art. In other instances, well-known methods, procedures, components, and circuitry have not been described in detail to avoid unnecessarily obscuring aspects of the disclosure.\nReferences in the specification to \"one embodiment,\" \"an embodiment,\" \"an exemplary embodiment,\" etc., indicate that the embodiment described may include a particular feature, structure, or characteristic, but every embodiment may not\nnecessarily include the particular feature, structure, or characteristic.  Moreover, such phrases are not necessarily referring to the same embodiment.  Further, when a particular feature, structure, or characteristic is described in connection with an\nembodiment, it is submitted that it is within the knowledge of one skilled in the art to affect such feature, structure, or characteristic in connection with other embodiments whether or not explicitly described.\nFor purposes of this discussion, the term \"module\" shall be understood to include one of software, or firmware, or hardware (such as circuits, microchips, processors, or devices, or any combination thereof), or any combination thereof.  In\naddition, it will be understood that each module can include one, or more than one, component within an actual device, and each component that forms a part of the described module can function either cooperatively or independently of any other component\nforming a part of the module.  Conversely, multiple modules described herein can represent a single component within an actual device.  Further, components within a module can be in a single device or distributed among multiple devices in a wired or\nwireless manner.\n<BR><BR>1.  Overview\nEmbodiments of the present disclosure provide systems and methods for enhancing exploratory data analysis using a recommender system.  The recommender system can predict what data analysis a user (e.g., an analyst) would likely be interested in\nand can adapt to feedback received from the user and other users with similar interests and/or backgrounds.  In an embodiment, the recommender system can recommend operations and analytical results to examine to an analyst.  Based on observations about\nthe data (e.g., whether the data contains text and/or numerical data fields), the recommender system can infer steps the user may wish to take in exploring and analyzing the data.  As the user makes specific requests using the recommender system, his or\nher interests in explaining certain data or filtering the data in certain ways can lead to more precise analytical operations performed by the recommender system.\nBased on this feedback (and/or on feedback from other users), the recommender system can automatically infer the need for certain analytical operations to be performed.  These inferences can be used by the recommender system to infer analytical\noperations when the user (and/or other users) explore new data sets.  For example, the recommender system can be configured to recommend combinations of data that may be statistically interesting, operations that are relevant to the data in the EDA\nprocess, operations that are relevant to a methodology, and/or results that may engender creative decision making.\nBy analyzing all data to determine which operations and/or variables to recommend, embodiments of the present disclosure can advantageously lead to insights that a data analyst and/or domain expert might not reach.  For example, by thoroughly\nanalyzing data to determine which operations lead to statistically significant results, a recommender system in accordance with an embodiment of the present disclosure can recommend using an operation and/or variable that most data analysts and/or domain\nexperts might overlook.  For example, a particularly variable and/or operation might be relatively obscure or might not typically be relevant for analyzing a certain data set, but the recommender system might determine that, in this case, the results are\ninteresting (e.g., statistically significant).  This thorough analysis provided by embodiments of the present disclosure can enable a data analyst and/or domain expert to engage in \"outside of the box\" thinking by to reach new insights that they might\nnot otherwise reach.\nSuch recommendations codify expert and individual analytical approaches and preferences to support EDA to integrate domain expertise with analytical expertise.  Thus, using systems and methods according to embodiments of the present disclosure,\nthe recommender system can advantageously capture the expertise of a data analyst and a domain expert.  It can then use that expertise to lend expert guidance to non-experts, remind experts of potentially forgotten operations, and perhaps promote the\nadoption of methods of analysis that are novel for the data domain.\n<BR><BR>2.  Recommender Systems\nRecommender systems can be used in a variety of fields and applications.  A recommender system can use one or more techniques that seek to predict the rating or preference that a user would give an item.  For example, a movie recommender system\ncould recommend movies that a user might like based on the user's past history of selected films to rent, and an online shopping recommender system could use a user's past history of products purchased and/or browsed to recommend products to buy. \nFurther, a recommender system could be used for a news site to recommend news stories based on a user's browsing history.\nRecommender systems can use collaborative filtering and/or content filtering techniques when recommending an item to a user.  For example, collaborative filtering can use a user's behavior and the behavior of similar users when deciding an item\nto recommend.  Content filtering can utilize characteristics of items when making a recommendation.  Hybrid systems using both collaborative and content filtering techniques can also be used.\nEmbodiments of the present disclosure apply recommender systems to exploratory data analysis (EDA) to recommendations for specific operations, sequences of operations, analytical methods, analytical results, etc. to an analyst.  Because of the\ndegree of experience and expertise necessary in data analysis in many fields, recommender systems can be especially useful for providing recommendations to a relatively inexperienced data analyst.  For example, showing a certain visual representation of\nthe data to the analyst could spark insight on the part of the analyst and help generate hypotheses to test via traditional statistical analysis.\nBy automating the exploratory aspect of data analysis in accordance with embodiments of the present disclosure, the expertise and experience of an expert can be captured by the recommender system to aid other data analysts.  These\nrecommendations can help a novice analyst to develop expertise and can also assist domain experts to perform their own data analyses.  For example, a recommender system in accordance with an embodiment of the present disclosure can assist a data analyst\nwith learning and remembering typical sequences of operations, learning new methods that can be helpful in analyzing data, and in automating the analysis rather than requiring that the user specify each operator to apply.  The framework provided by\nembodiments of the present disclosure also helps to unify architectures for learning analytical operations with factors that are also important to EDA, such as layout and visual representations.\n<BR><BR>3.  Exemplary Recommender System\nFIG. 1 is a block diagram of an exemplary recommender system 102 in accordance with an embodiment of the present disclosure.  Recommender system 102 receives input data 104 and generates output data 106 based on input data 104.  For example,\ninput data 104 can be a raw data set input by a user.  The data set can be input manually by the user (e.g., using an input device), or the data set can be read from a file, such a text file, a Microsoft Excel file, a Portable Document Format (Adobe\nAcrobat) file, a special purpose file, etc. In an embodiment, recommender system 102 can gather input data 104 (e.g., via a sensor couple to and/or in communication with recommender system 102).  Such data gathering can be performed by recommender system\n102 automatically or in response to a command issued to recommender system 102 by a user.\nBased on input data 104, recommender system 102 generates output data 106.  Output data 106 can take a variety of formats.  For example, in accordance with embodiments of the present disclosure, output data 106 can be text data, image data, an\nexecutable program, a Microsoft Excel file, a Portable Document Format (PDF) file, a special purpose file, etc. In an embodiment, output data 106 includes data for a visual representation of processed input data 104.  For example, output data 106 can\ninclude charts, graphs, etc., that are generated based on input data 104 which can be used by a data analyst when analyzing input data 104.  In an embodiment, recommender system 102 can receive user feedback data 108, and output data 106 can be modified\nby recommender system 102 based on user feedback data 108.\nIn an embodiment, recommender system 102 includes data gatherer 110, data analyzer 112, results generator 114, and user feedback analyzer 116.  While each of data gatherer 110, data analyzer 112, results generator 114, and user feedback analyzer\n116 is shown separately in FIG. 1, it should be understood that the functionality of each of data gatherer 110, data analyzer 112, results generator 114, and user feedback analyzer 116 can be combined into a single block of code, module, device, etc., or\ncan be further divided into additional blocks of code, modules, devices, etc.\nIn an embodiment, recommender system 102 is implemented on host device 101.  For example, host device 101 can be a computer, such as a general purpose computer or a special purpose computer, or a combination of multiple general or special\npurpose computers.  In an embodiment, host device 101 includes processor 118 and memory 120.  However, it should be understood that, in accordance with embodiments of the present disclosure, recommender system 102 includes processor 118 and/or memory 120\nand is not part of host device 101.  For example, in an embodiment, recommender system 102 is implemented as a single stand-alone device instead of as part of another device (e.g., host device 101).\nIn an embodiment, host device 101 is a computer running code for recommender system 102, and recommender system 102 accesses processor 118 and/or memory 120 in host device 101.  Memory 120 can be any of a variety of memory types, including a\ncache, a register, etc. In an embodiment, processor 118 includes processor circuitry for a central processing unit (CPU) that is configured to perform operations for recommender system 102.  For example, in an embodiment, memory 120 stores code\nconfigured to for performing operations for data gatherer 110, data analyzer 112, results generator 114, and user feedback analyzer 117, and processor 118 includes processor circuitry configured to execute code for performing these operations.\n3.1 Data Gatherer\nIn an embodiment, data gather 110 receives input data 104.  Data gatherer 110 can receive input data 104 via direct user input (e.g., via a user input device such as a keyboard, microphone, camera, etc.) or via reading a data file from a disc, a\ndata bus (e.g., via a Universal Serial Bus or other data bus), or a memory (e.g., memory 120, another memory of a host computer (e.g., host device 101), or any other memory accessible by recommender system 102).  In an embodiment, data gatherer 110\nstores data (e.g., in memory 120).  In an embodiment, data gatherer 110 can also receive user feedback data 108, either directly from a user or from an intermediary module, such as user feedback analyzer 116.  Data gatherer can store user feedback data\n108 in memory (e.g., in memory 120) for further processing.\n3.2 Data Analyzer\nIn an embodiment, data analyzer 112 analyzes gathered data 105 gathered by data gatherer 110.  In an embodiment, gathered data 105 includes input data 104 and/or user feedback data 108.  In an embodiment, data gatherer 110 sends gathered data\n105 to data analyzer 112.  In another embodiment, data analyzer 112 reads gathered data 105 from data gatherer 110 (e.g., periodically or in response to determining that new input data 104 or user feedback data 108 has been received by data gatherer\n110).  In an embodiment, data analyzer 112 performs operations on gathered data 105 and sends the results to results generator 114.  For example, in an embodiment, data analyzer 112 can determine, based on analyzing gathered data 105, how output data 106\nshould be presented to the user.  For example, in an embodiment, data analyzer 112 can determine which charts, graphs, analytical operations, etc. should be performed on gathered data 105 so that output data 106 can be presented to a data analyst in a\nuseful way.\nIn an embodiment, data analyzer 112 can make an initial determination regarding how gathered data 105 should be processed based on stored information.  For example, this stored information can be information regarding domain expert\nrecommendations for data analysis corresponding to a type of gathered data 105 and previous recommendations by users of recommender system 102.  For example, this information regarding domain expert recommendations and/or previous recommendations by\nusers of recommender system 102 can be stored in a database and/or memory accessible by recommender system 102 (e.g., memory 120, another memory of a host computer (e.g., host device 101), or any other memory accessible by recommender system 102).\nIn an embodiment, data analyzer 112 can determine the type of gathered data 105 (e.g., based on a file type, user input, and/or information in gathered data 105).  Data analyzer can further alter and/or refine the initial determination regarding\nhow gathered data 105 should be processed based on user feedback data 108.  In an embodiment, data analyzer 112 ranks potential operations that can be performed on gathered data 105 (e.g., charts, graphs, analytical operations, etc., that can be\ngenerated based on gathered data 105).  In an embodiment, this ranking is performed by data analyzer 112 based on a determination regarding how useful respective operations are likely to be for a user.\nData analyzer 112 can perform this ranking of potential operations in a variety of ways in accordance with embodiments of the present disclosure.  For example, in an embodiment, data analyzer 112 can assign interest values for certain\noperations, variables, and/or operators for gathered data 112.  Recommender system 102 can change and/or update these interest values as new information (e.g., user feedback data 108) is received.  For example, an operation may be assigned a certain\ninterest value because a user selected that operation as something he or she wishes to explore further or because an operation is popular with similar users.  Additionally, for example, an operation can be assigned a greater than average interest value\nif recommender system 102 determines that the operation has statistical significance.  This interest value can be assigned based on prior user feedback data 108 received from the same or similar user or recently received user feedback data 108 from the\ncurrent user.  In an embodiment, the longer a user explores output data 106 corresponding to a particular operation, the more points can accumulate, until such time as the user indicates a desire to shift the focus.\nIn an embodiment, an operation, variable, and/or operator can also be assigned interest because an analytical operation involving it is determined to be of statistical significance (e.g., when the probability of obtaining at least as extreme\nresults given that the null hypothesis is true is less than the probability of rejecting the null hypothesis given that it is true) or because its distribution fits a pre-defined or user-defined pattern of interest.  For example, a bi-modal distribution\nmay be considered interesting because it might not fit the typical pattern (in contrast to a uniform or a normal distribution).  A user may also express a preference for one or more particular analytical operations (e.g., correlation), and this\npreference can be used to assign or modify one or more interest values corresponding to these one or more analytical operations.  This framework enables automatic specification of operations (e.g., those operations that have high interest values can be\ndesignated to be conducted if they are not already completed).  It also enables prioritization of a large menu of intermediate operations that a user can choose from for display (e.g., by indicating interest in one or more of these operations via user\nfeedback data 108).\nIn an embodiment, recommender system 102 can store a list of potential operations, ranked according to determined usefulness for a user, and recommender system 102 can change the ordering of the operations in this list (as well as add and/or\nsubtract operations from this list) as new information (e.g., user feedback data 108) is received.  Exemplary operations that can be performed on gathered data 105 by data analyzer 112 are discussed in more detail below.\n3.3 Results Generator\nOnce data analyzer determines potential operations to be performed on gathered data 105, data analyzer sends information regarding one or more of these potential operations to results generator 114.  This information can be, for example, an\nidentification of analytical (or other) operations to be performed on gathered data 105 and/or an identification of visual representations (such as charts, graphs, etc.) of gathered data 105 to be generated.  In an embodiment, results generator 114\ngenerates results, by for example, performing the operations selected by data analyzer 112.  In an embodiment, results generator 115 can also generate visual representations of gathered data 105 and/or operations performed on gathered data 105.  In an\nembodiment, results generator 114 or data analyzer 112 is configured to select a predetermined number of results to be generated based on, for example, input from a user.  Results generator outputs the generated results as output data 106, which is sent\nto a user (e.g., by displaying output data 106 on a screen or transmitting it to another output device, e.g., via a data port).\nIn an embodiment, results generator 114 also generates and/or modifies a user interface (UI) for a user.  For example, the user interface can be displayed on a screen and can be used to display output data 106.  In an embodiment, the UI can also\nenable a user to send user feedback data 108 back to recommender system 102.  User feedback data 108 can take a variety of forms including text data, voice data, camera data, etc. In an embodiment, the UI provides a text prompt to enable the user to send\nuser feedback data 108.  The UI can further include one or more buttons, such as \"like\" and/or \"dislike\" buttons to gather user feedback data 108 regarding one or more of the generated results in output data 106.  In an embodiment, the UI includes an\narea that enables the user to request operations, an area that lists pending operations, and an area that lists available results (e.g., sorted according to interest values).\n3.4 User Feedback Analyzer\nIn an embodiment, user feedback analyzer 116 receives user feedback data 108 from a user of recommender system 102.  User feedback data 108 can be received in a variety of ways.  For example, user feedback analyzer 116 can receive user feedback\ndata 108 via direct user input (e.g., via a user input device such as a keyboard, microphone, camera, etc.) or via reading a data file from a disc, a data bus (e.g., via a Universal Serial Bus or other data bus), or in a memory (e.g., memory 120, another\nmemory of a host computer (e.g., host device 101), or any other memory accessible by recommender system 102).  In an embodiment, user feedback data 108 can contain requests for additional and/or modified operations to be performed on input data 104. \nUser feedback data 108 can also include a user indication regarding whether a specific operation was useful (e.g., via a \"like\" or \"dislike\" button or a similar indicator).  User feedback data 108 can be gathered actively (e.g., data collected in\nresponse to specific actions by a user) or passively (e.g., data collected without specific actions by a user).\nIn an embodiment, user feedback analyzer 108 can collect and analyze user feedback data 108 for use when performing further operations.  For example, in an embodiment, user feedback analyzer 116 can use user feedback data 108 to modify stored\ninformation in a memory and/or database accessible by recommender system 102 (e.g., memory 120, another memory of a host computer (e.g., host device 101), or any other memory accessible by recommender system 102) regarding previous recommendations by\nusers of recommender system 102.  Based on this modification, recommender system 102 can take user feedback data 108 into account when performing future operations on similar input data 104 (e.g., input data from the same data domain, input data of a\nsimilar determined data type, input data by the same or similar data analyst, etc.) In an embodiment, user feedback analyzer 116 can send user feedback data 108 to data gatherer 110 (e.g., for storage or to refine output data 106 generated based on input\ndata 104.\nIn an embodiment, user feedback analyzer 116 can send information to data analyzer 112, e.g., to modify the operations to be performed by data analyzer 112.  For example, user feedback data 108 can include a user request for an additional\noperation to be performed on input data 104 or a user indication (e.g., a \"like\" or \"dislike\") regarding a performed operation.  In an embodiment, based on information received from user feedback analyzer 116, data analyzer 105 can modify interest values\nfor variables and operators assigned to gathered data 112.  In embodiment, data analyzer 105 can modify a list of potential operations to be performed on gathered data 105 based on information received from user feedback analyzer 116.  In an embodiment,\nuser feedback analyzer 116 can send user feedback data 108 to results generator 114.  For example, based on information from user feedback analyzer 116, results generator 114 can modify a generated result (e.g., by changing the visual representation of a\ngenerated result).  Results generator 114 can modify output data 106 based on user feedback data 108.\nIn an embodiment, user feedback analyzer 116 and/or data analyzer 112 uses user feedback data 108 to predict additional operations that may be useful to the user.  For example, in an embodiment, if a user indicates an interest in a particular\nvariable, user feedback analyzer 116 and/or data analyzer 112 can determine that the user might also be interested in additional operations for this variable.  In an embodiment, these determinations can be made based on stored information that indicates,\nfor example, how an expert would conduct further EDA on the particular indicated variable.  In this way, a user can use recommender system 102 to direct exploration of input data 104 along selected paths specified via user interest indications but can\nstill leverage domain expert knowledge for EDA of an indicated variable via stored expert information.\n3.5 Exemplary Method for Exploratory Data Analysis Using Recommender System\nFIG. 2 is a flowchart of an exemplary method for exploratory data analysis using a recommender system in accordance with an embodiment of the present disclosure.  In step 202, data to be analyzed is received.  For example, in an embodiment, data\ngatherer 110 receives input data 104.  In an embodiment, data gatherer 110 can also receive additional data generated by user feedback analyzer 116 based on user feedback data 108.  Based on this received data, data gatherer 110 can generate gathered\ndata 105.\nIn step 204, interest values for operations are determined.  For example, in an embodiment, one or more policies stored in memory (e.g., memory 120) determines a set of rules for data analysis for one or more users.  In an embodiment, data\nanalyzer 112 can determine one or more appropriate polic(ies) (or appropriate rules) to apply to gathered data 105.  This determination can be made, for example, based on an identity of the current user of recommender system 102 and/or based on a\nclassification of input data 104.  In an embodiment, the policy (or the rules) can determine interest values for the operations.\nIn step 206, operations to be performed on the data are determined based on the determined interest values.  For example, in an embodiment, data analyzer 112 determines a set of operations to be performed based on the determined policy (or the\nrules) and gathered data 105.  For example, in an embodiment, data analyzer 112 can select a predetermined number of operations to be performed on gathered data 105 based on the determined policy.  In an embodiment, data analyzer can also use received\nuser feedback data 108 to determine the set of operations to be performed.  In step 208, the selected operations are performed on the data.  In an embodiment, output is generated based on the performed operations by results generator 114, and output data\n106 is sent to a user.\nIn step 208, user feedback regarding the performed operations is received.  For example, in an embodiment, user feedback analyzer 116 receives and analyzes user feedback data 108.  Analyzed user feedback data 108 can be sent to data gatherer\n110, data analyzer 112, and/or results generator 114 for further analysis of input data 104 and to train recommender system 102 for future use.  For example, in an embodiment, the method proceeds back to step 204, and user feedback data 108 is used to\nmodify interest values for operations.  The method can then proceed again to steps 206 and 208 to determine and perform new operations based on user feedback data 108.  Additional user feedback data 108 can again be received in step 210 as the user\ncontinues providing feedback to recommender system 102 during the course of exploratory data analysis of input data 104.  In an embodiment, if no user feedback is received, the method of FIG. 2 can stop at step 208.  For example, after step 208, output\ndata 106 can be sent to a user, and the method of FIG. 2 can wait to see if any user feedback data is received.\nIn an embodiment, recommender system 102 runs using parallel processing techniques (e.g., when using an agent-based embodiment, as discussed below with reference to FIG. 9).  In an embodiment, multiple instances of the method described by FIG. 2\ncan be running simultaneously, and the results of the operations performed according to the method of FIG. 2 can be collated into a single list.  For example, in an embodiment, at step 206, recommender system 102 can determine a plurality of operations\nto be performed and can use a different agent to perform each operation at step 208 and/or to receive user feedback at step 210.  In an embodiment, the results of these parallel processes performed by these agents can be later combined after operations\nare performed (e.g., in step 208) and/or after user feedback is received (e.g., in step 210).  For example, in an embodiment, the combined results of these parallel processes can be used to modify interest values in step 204 and/or to determine further\noperations to be performed on gathered data 105 in step 206.\n3.6 Implementations\nRecommender system 102--including data gatherer 110, data analyzer 112, results generator 114, and user feedback analyzer 116--can be implemented using hardware, software, or a combination of hardware and software.  In an embodiment, recommender\nsystem 102 is implemented using computer code executing on one or more general purpose computers.  In another embodiment, recommender system 102 is implemented using computer code executing on one or more special purpose computers and/or devices.  In an\nembodiment, any combination of a plurality of general purpose computers, a plurality of special purpose computers, and/or a plurality of devices can operate together to perform the systems and/or methods described by embodiments of the present\ndisclosure.\nIn an embodiment, data gatherer 110, data analyzer 112, results generator 114, and user feedback analyzer 116 are implemented using one or more blocks of code, such as software modules, executing on a processor that is a part of recommender\nsystem 102 (e.g., processor 118) or is accessible by recommender system 102.  In another embodiment, recommender system 102 is implemented using hardware (e.g., using circuitry, hardware logic, and/or chips).  For example, in an embodiment, recommender\nsystem 102--including data gatherer 110, data analyzer 112, results generator 114, and user feedback analyzer 116--is implemented on a single chip as part of a device (e.g., a general purpose computer or a special purpose device).  It should further be\nunderstood that each of data gatherer 110, data analyzer 112, results generator 114, and user feedback analyzer 116 can be implemented using any number of chips in a device.  For example, in an embodiment, each of data gatherer 110, data analyzer 112,\nresults generator 114, and user feedback analyzer 116 can be implemented on a separate chip.  Additionally, in an embodiment, the functionality of data gatherer 110, data analyzer 112, results generator 114, and user feedback analyzer 116 can be\nimplemented by a single chip, device, module, and/or block of code in accordance with embodiments of the present disclosure.  Exemplary implementations of recommender system 102 are discussed in further detail below.\nIn an embodiment, recommender system 102 includes security functionality that enables recommender system 102 to securely receive input data 104 and user feedback data 107 and/or to generate output data 106.  For example, in an embodiment,\nrecommender system 102 is implemented as part of a secure processing system on a host computer (e.g., host device 101).  In an embodiment, recommender system 102 is configured to securely receive input data 104 and/or user feedback data 108 via a\nsecurity technique such as encryption, password verification, a security certificate, etc. In an embodiment, recommender system 102 is configured to encrypt output data 106 before output data 106 is transmitted from recommender system 102.\n<BR><BR>4.  Determining Operations to be Performed on Gathered Data\nAs discussed above, in an embodiment, data analyzer 112 can analyze gathered data 105, determine which operations to perform on gathered data 105, perform one or more of the determined operations on gathered data 105, and send the results to\nresults generator 114.  Data analyzer 112 can make an initial determination regarding how gathered data 105 should be processed based on stored information and can make further determinations regarding how gathered data 105 should be processed based on\nuser feedback data 108.  In an embodiment, to make these determinations, data analyzer 112 uses a set of rules to determine which operations data analyzer 112 should select for processing gathered data 105.  These rules can take a variety of formats. \nFor example, in an embodiment, these rules are part of the code of recommender system 102.  In an embodiment, these rules can be stored in a policy in memory (e.g., stored in memory 120 or any other memory accessible by recommender system 102.)\nWhen gathered data 105 is first received by data analyzer 112 (e.g., before user feedback data 108 has been received for the current data set), data analyzer 112 can access the rules to make an initial determination regarding how gathered data\n105 should be processed.  In an embodiment, data analyzer 112 can first classify input data 104 to determine a type of the data set before making the initial determination.  This type determination can be based on the file type corresponding to input\ndata 104, a user specification, information within input data 104 designating its type, etc. Data analyzer 112 can use the type determination and the rules to determine initial operations to be performed.  In an embodiment, the rules may further specify\none or more further operations to be performed based on one or more results from these initial operations.  For example, in an embodiment, one or more rules can specify that an F-test (e.g., a statistical test in which the test statistic has an\nF-distribution under the null hypothesis finds a significant difference for an independent variable with more than two levels) should be performed for certain types of experimental data.  If the F-test finds a significant difference for an independent\nvariable with more than two levels, the rules can specify that a post-hoc t-test (e.g., a statistical hypothesis test in which the test statistic follows a Student's t-distribution if the null hypothesis is supported) should be applied to the data.\nIn an embodiment, recommender system 102 can further determine which operations should be performed based on user feedback data 108.  In an embodiment, the rules can specify which operations data analyzer 112 should select based on received user\nfeedback data 108.  For example, once a set of experimental data is loaded into recommender system 102, recommender system 102 may initially determine that an F-test and a t-test should be performed.  Results generator 114 can generate the results of\nthese tests and present them to the user via a UI (e.g., via producing one or more charts, graphs, etc. corresponding to these tests).  Results generator 114 can also present (e.g., via the UI) the user with additional operations that can be performed,\nranked according to interest values.  If the user selects one of these additional operations, this selection can be passed back to recommender system 102 as user feedback data 108.  This user feedback data 108 can be analyzed by user feedback analyzer\n116.  Based on the rules, user feedback analyzer 116 (and/or data analyzer 112) can instruct data analyzer 112 to perform one or more operations corresponding to the user-selected operation identified in user feedback information 108.  Results generator\n114 can then present the results of this user-selected operation to the user as output data 106 via the UI (e.g., results generator 114 can generate new charts, graphs, etc. based on the user-selected operation).\nIn an embodiment, user feedback analyzer 116 can modify the rules based on user feedback data 108 (e.g., in an embodiment, user feedback analyzer 116 can raise the interest value of the user-selected operation so that it is ranked higher in the\nadditional operations presented to the user via the UI when the same or similar user uses recommender system 102.  In an embodiment, if the operation attains enough interest (e.g., an interest value above a predetermined threshold), the operation can\nbecome an initial operation that is performed on a data set that the same or similar user analyzes before recommender system 102 receives any user feedback data.\nIn an embodiment, recommender system 102 can access the rules to determine if a user is similar to a previous user.  For example, the rules may specify that a user is similar to a previous user if the user works in a related field to a previous\nuser, has worked on the same (or related) project as a previous user, works at the same (or related) location as a previous user, has a similar workflow as that of a previous user, has data of a similar structure to a previous user, etc. In an\nembodiment, recommender system 102 can store multiple sets of rules corresponding to multiple users and/or user types (e.g., users corresponding to a certain field).  In an embodiment, a user can instruct recommender system 102 to load a specific rule\nset corresponding to a certain user or a certain type of users.  Further, in an embodiment, recommender system 102 can enable a user to manually edit the rules corresponding to a user or a certain type of users.  In an embodiment, recommender system 102\nincludes security functionality that prevents unauthorized users from making such edits without permission.\nAs discussed above, recommender system 102 is configured to perform multiple operations using input data 104, and a user can provide user feedback data 108 to enable recommender system 102 to select different operations to be performed during\nthe course of data analysis.  In an embodiment, recommender system 102 can predict new operations that a user might be interested in by assigning potential operations and/or variables higher interest values when related analytical operations are\ndetermined to be of statistical significance.  For example, in an embodiment, recommender system 102 can determine that initially, summary statistics should be generated and recommended to analyze input data 104.  As a user explores the generated summary\nstatistics and provides user feedback data 108, recommender system 102 can use this feedback to recommend additional operations that have statistical significance and/or involve some of or all of the variables whose summary statistics were determined to\nbe of interest.\nFor example, recommender system 102 can determine the effects of an independent variable that the user indicated an interest in on dependent variables (or other independent variables).  If there is a statistically significant effect on one or\nmore dependent variables, recommender system 102 can assign interest to these dependent variables and/or operations involving these dependent variables and recommend them to the user.  Further, recommender system 102 can recommend performing operations\nusing variables where a user indicates interest (e.g., correlations).  In an embodiment, recommender system 102 can recommend using principle components analysis (PCA) techniques to plot variables in which a user indicates interest on a domain to\ndetermine dimensions where there is a difference among these variables.  Further, in an embodiment, recommender system 102 can suggest converting a variable from an independent variable to a dependent variable (e.g., if doing so would result in a\nstatistically significant result).\nIn an embodiment, the operations that recommender system 102 can perform include descriptive statistics (e.g., min, max, mean, var, frequency count, etc.) analysis of variance (ANOVA), principal components analysis (PCA), correlation, moving\naverage, function approximation, sampling, outlier tests, Fourier analysis, time-series analysis, and other operations used for statistical analysis.  For example, in an embodiment, recommender system 102 can include operations for statistical tests for\ndescriptive statistics (e.g., describing the data and its distribution), parametric statistics (e.g., to test for relationships or differences using correlation or more sophisticated forms of regression), and non-parametric statistics.  In an embodiment,\ngroup differences can be tested using ANOVA techniques both within subjects and between subjects' variables.\n<BR><BR>5.  Exemplary Use Cases\nAs discussed above, recommender system 102 can be used with a variety of data to perform and recommend operations based on data sets.  Two exemplary use cases for data analysis that can be performed using recommender system 102 in accordance\nwith embodiments of the present disclosure are discussed below.\n5.1 Use Case 1: Data Derived from Image Analysis of Stimuli for a User Study\nIn a first exemplary use case of recommender system 102, input data 104 includes metrics on images used in user studies of multivariate visualization techniques.  In this example, input data 104 includes approximately 600 measures, on 108\nstimuli studied for multivariate visualization.  EDA is performed on input data 104 using recommender system 102 to determine whether objective measures of image properties offer insight into user performance (e.g., error and response time).  In an\nexample, the objective properties include target/distraction differences in color or intensity distribution, edge strength or orientation, texture frequency, etc.\nInput data 104 is received by data gatherer 110 and analyzed by data analyzer 112 to determine and perform initial operations on input data set 104 based on a stored policy.  In this example, data analyzer 112 infers the type of variables in\ninput data 104 (e.g., string, integer, floating point) and the distribution type of the variables.  Based on a stored policy, data analyzer 112 determines that the initial operations to be performed on input data 104 should be summary statistics,\ncaptured in a plurality of histograms.  Output data 106 for histograms of the summary statistics is generated by results generator 114 and sent to the user.\nFIG. 3 shows exemplary output graphs generated based on output data 106 in accordance with this use case.  In this example, the recommender system recommends that the user examine summaries of variables according to a stored policy, and the user\nhas selected the variables \"mean error\" and \"response time.\" The recommender system 102 generates and displays the violin plots (e.g., histograms with box plots embedded to show mean and other summary statistics) shown in FIG. 3 for these variables in\nresponse to these user selections.  The user then indicates interest in the variables for \"mean error\" and \"response time\" (e.g., via a \"like\" button).  For example, the user might consider these variables interesting because their distributions do not\nfit any \"standard\" distribution patterns like uniform, Gaussian, etc. Additionally, for example, these variables might be interesting because of expert domain knowledge regarding them (e.g., an expert might want to explain these variables and their\ncorresponding values when conducting a user study).  The UI detects these user indications and transmits user feedback data 108 to recommender system 102 indicating that the user indicated interest in these two variables.  User feedback analyzer 116\nanalyzes these indications and sends information to data analyzer 112.  Based on user interest in the \"mean error\" and \"response time\" variables, data analyzer 112 accesses the policy (which stores information regarding domain expert recommendations for\nfurther EDA on these variables) to determine additional operations to be performed based on this indicated user interest.  Data analyzer 112 determines, based on the rules and/or policy, that the user may be interested in F-tests using these two\nvariables and a third variable, \"visualization technique,\" and sends information to results generator 114 to generate new output data 106.  For example, data analyzer 112 can determine to recommend two separate F-tests, each of which involves one of the\nvariables whose summaries were \"interesting\" (e.g., \"mean error\" and \"response time\") in addition to \"visualization technique.\"\nFIG. 4 shows exemplary output graphs generated based on output data 106 showing a result of an F-test for these variables.  The two graphs shown are the standard way to show the result of an F-test (difference of means).  Each group is shown as\none bar in a bar graph, with error bars for one unit of standard error.  The F-test shows that (some pair of) the means are statistically different.  A domain expert might recommend that a post-hoc test such as a I-test or Tukey's Honestly Significant\nDifference test would be applied to verify this statistical difference.  In accordance with the stored policy of recommender system 102, results that qualify as \"statistically significant\" (according to predetermined specifications in the policy) are\nassigned more interest value by recommender system 102 than results that do not qualify as \"statistically significant.\" The user then indicates interest in the F-test, which is passed back to recommender system 102 as user feedback data 108.\nRecommender system 102 then recommends, based on this user feedback data 108 (as well as prior user feedback data), an F-test that has statistical significance: an F-test using the variables \"visualization technique\" on \"relative edge strength.\"\nThese were both independent variables that would not normally have been combined in this type of test.  In this case, the data indicates that edges, which are a basic perceptual cue, have vastly different strengths in the techniques.  FIG. 5 shows an\nexemplary graph generated based on output data 106 illustrating these differences.  Using recommender system 102 for EDA for this input data 104, recommender system 102 has focused analysis onto a potentially insightful result in the three steps\ndiscussed above that was neither requested by the domain expert analyst nor \"conventional\" by standard practice.  Yet it does tell the user something about why the data behaves as it does, which is the ultimate goal of all data analysis.\n5.2 Use Case 2: Data Derived from Eye Tracking During a Supervisory Task\nIn a second use case, input data 104 includes data derived from tracking users' gaze during supervisory control tasks.  In such applications, the user may be monitoring and intervening in multiple automated or human performance tasks.  These\ntasks are often subject to high workload, and the hope is to determine biometric measures such as pupil diameter and eyelid opening to determine when the operator is experiencing stress or fatigue due to the workload level.  Based on input data 104,\nrecommender system 102 generates summary statistics based on an initial operation determined by recommender system 102 according to a stored policy.  In this case, the data analyst notices similarity in the distributions of two variables (measuring a\nuser's head position for the Y and Z dimensions) based on the generated summary statistics.  FIG. 6 shows exemplary graphs generated based on output data 106 showing the similarity in these distributions.  Based on this similarity, the analyst surmises\nthat there might be an error in input data 104 and requests a correlation between those two variables to be conducted via user feedback data 108.  The correlation is revealed as a perfect correlation, indicating that an error in input data 104 is likely. The analyst had familiarity with principal components analysis (PCA), so she requested that a PCA be conducted.  This served to provide further confirmation of the similarity of certain variables, including the two head position variables.  This ended\none line of investigation.\nThe analyst then returned to the summary graphs, focusing on a known issue with eye tracking data--it is often noisy, and trackers may return invalid values.  In particular, the analyst was concerned about the pupil diameter measurements.  A\nnormal maximum pupil diameter for a person working in a dark room is approximately one centimeter.  The analyst declared interest in the summary of the pupil diameter variables (for left and right eye, independently measured).  She then requested the\ncorrelation between the left and right eye data, and indicated interest in the result.  This (in addition to the correlation of the Y and Z head position variables, described above) triggered correlations of these variables with other variables, such as\nthe quality metrics associated with each measurement.  These correlations, shown in FIG. 7, indicate that the threshold for the quality metric (which was set to \"&gt;0\") needs to be much higher to ensure that only valid measures of pupil size are\nconsidered.  While this conceptual result was not surprising to the analyst, the exact values were unknown prior to this analysis.\nThe analysis finished with a request for the known repeated-measures ANOVA results for the variable Difficulty (shown in FIG. 8).  A recommendation for a previously unexplored ANOVA operation was recommended because it included a dependent\nmeasure (left pupil diameter, PupDiLt) that was involved in results in which the analyst showed interest, and because the repeated measures ANOVA results were labeled as interesting.  This analysis helped identify a need for a more restrictive outlier\nremoval threshold.\n<BR><BR>6.  Exemplary Recommender System Embodiments\nAs discussed above, recommender system 102 can be implemented in a variety of environments, including embodiments using hardware, software, or a combination of hardware and software.  In an embodiment, recommender system 102 is implemented as a\nsoftware program stored in memory 120, and host device 101 is a general purpose computer that executes code for recommender system 102.  Code for recommender system 102 can use agent-based or non-agent based methods to implement functionality of\nrecommender system 102.\n6.1 Exemplary Agent-Based Recommender System\nIn an embodiment, recommender system 102 uses a multi-agent feature-based recommender framework.  Recommendations can be provided by mapping users through shared features to recommend items.  Such features can be statistically analyzed data\ncombinations with characteristics that indicate other data combinations (e.g., items).  Similarity in user preferences or analyzed-data combinations favored by other users can be used to infer relevant items for user exploration or additional processing. The use of agents can provide scalability (e.g., by enabling the use of parallel processing techniques) and adaptive capabilities demanded by an EDA application.\nIn an embodiment, operations can be conducted using a system of automated agents which run hidden in the background of recommender system 102.  Such an agent-based system can increase efficiency because a master agent can balance the\ncomputational load across the available resources.  Any number of agents (e.g., from 1 to any number, limited only by the computational power and operating system of host device 101 and/or recommender system 102) may be employed, and the agents may run\non any number of physical or virtual computational platforms.\nFIG. 9 shows a block diagram of an exemplary agent-based environment for a recommender system in accordance with an embodiment of the present disclosure.  The environment shown in FIG. 9 includes EDA decision support layer 902 and distributed\nintelligent agent layer 904.  In an embodiment, EDA decision support layer 902 includes user interface and visualization engine 906, data management subsystem 908, and user preference and recommender subsystem 910.  For example, in an embodiment, user\ninterface and visualization engine 906 can be used to generate the UI provided to the user (e.g., generated using results generator 114 as part of output data 106).\nData management subsystem 908 can be used to store information used to determine operations to be performed using input data 104 and/or gathered data 105.  For example, in an embodiment, domain database (DB) 912 of data management subsystem 908\ncan store data received via input data 104 and/or user feedback data 108, and system data 914 can include data from previous usages of recommender system 102 and/or information regarding potential recommendations that should be made based on expert\nknowledge and known best practices.  In an embodiment, user preference and recommender subsystem 910 can communicate with user interface and visualization engine 906 and data management subsystem 908 to make recommendations to the user regarding\npotential operations to be performed using input data 104 and/or gathered data 105.  For example, in an embodiment user preference and recommender subsystem 910 can implement functionality of data analyzer 112 and/or user feedback analyzer 116 by using\nmultiple agents, implemented using distributed intelligent agent layer 904.\nIn an embodiment, distributed intelligent agent layer 904 includes interface agent subsystem 916, process and data whiteboard 918, filter agent subsystem 920, and analysis agent subsystem 922.  In an embodiment, each of interface agent subsystem\n916, filter agent subsystem 920, and analysis agent subsystem 922 can be used to distribute operations performed by data analyzer 112 among a plurality of agents, and process and data whiteboard 918 can be used to store temporary data (e.g., in memory\n120 or another memory accessible by recommender system 102) used when performing these operations.  For example, in an embodiment, interface agent subsystem 916 includes one or more UI agents used to generate and update the UI for the user.  In an\nembodiment, filter agent subsystem 920 includes one or more filter agents used to determine, filter, and/or rank operations to be performed on input data 104 and/or gathered data 105 (e.g., based on a stored policy, rules, and/or interest values for\ncorresponding to respective operations).  In an embodiment, analysis agent subsystem 922 includes one or more analytical agents used to perform the operations determined by filter agent subsystem 920.\nIn an embodiment, UI agents of interface agent subsystem 916 can use a web framework (e.g., Django) using scripts (e.g., Python scripts) to ingest data in comma-separate value (CSV) files.  In an embodiment, data management subsystem 908 can\nstores data in a database (e.g., a MongoDB3 database) and passes interest values to the agents of distributed intelligent agent layer 904.  The number and distribution of agents can be hidden from the user.  The analytical agents of analysis agent\nsubsystem 922 can use statistical computing software to perform statistical computations (e.g., using software such as that provided by the R Project).\nIn an embodiment, when EDA decision support layer 902 collects data from the analytical agents of analysis agent subsystem 922, it can pass output data 106 back to the user interface as plain text tables, which can be parsed and loaded into the\ndatabase management subsystem 908.  In an embodiment, database management subsystem 908 implements a table of all variables and potential operations, as well as results (operations) and user ratings for interest.  Interest can be distributed from user\nfeedback on analytical results to variables and operations and accumulated from statistical significance.  In an embodiment, analytical agents of analysis agent subsystem 922 perform analytical processes either based on rules (e.g., summary statistics\ncan be computed upon loading data) or as guided/inferred by the user's interaction with the UI inclusive of items marked as interesting.  Recommendations can be formed based on statistical results from processing filtered against the rule-based system,\nas well as a user's current exploration or explicit rating.  In an embodiment, once data is stored in the database provided by data management subsystem 908, users can interact with the system by accessing a locally-run web server using a standard web\nbrowser.\n6.2 Special Purpose Device Embodiments\nIn an embodiment, recommender system 102 can be implemented using a special purpose device (e.g., instead of using a general purpose computer).  For example, in an embodiment, recommender system 102 and/or host device 101 can be implemented\nusing stand-alone hardware designed to receive input data 104 and user feedback data 108 and to generate output data 106 to a user (e.g., via a screen or other output device coupled to the hardware used to implement recommender system 102 and/or host\ndevice 101 or in communication with the hardware used to implement recommender system 102 and/or host device 101).\nFor example, in an embodiment, recommender system 102 can be implemented on a chip of a special purpose recommender device that includes one or more input ports for receiving input data 104 and user feedback data 108 and one or more output ports\nfor generating output data 106.  In an embodiment, the hardware used to implement recommender system 102 and/or host device 101 can include a built-in display used to display output data 106 and/or a built-in input device used to receive input data 104\nand user feedback data 108.\nAs discussed above, in an embodiment, input data 104 and/or user feedback data 108 can be actively or passively gathered.  For example, in an embodiment, input data 104 is received via one or more sensors that can receive and/or monitor data in\nthe environment and generate input data 104 without further input from a user.  In an embodiment, such a sensor can be implemented in the hardware of recommender system 102 and/or host device 101.  Alternatively, such a sensor can be implemented\nseparately from the hardware of recommender system 102 and/or host device 101 but still in communication with recommender system 102.  In an embodiment, a hardware sensor can be used to send information to a general purpose computer running code for\nrecommender system 102.  A variety of sensors can be used in accordance with embodiments of the present disclosure, including biometric sensors, infrared sensors, motion detection sensors, acoustic sensors, electrical sensors, cameras, microphones, etc.\nIn an embodiment, sensor 1002 (and/or data gatherer 110) is configured to detect a signal from a sensor used to receive input data 104 and to transform the signal into a different format.  For example, in an embodiment, sensor 1002 can receive a\nwireless signal propagated through a medium, such as air or water, and transform the signal into an electrical format.  In an embodiment, data gatherer 110 can decode the received signal to determine information transmitted in the signal and can send\nthis information to data analyzer 112.\nFIG. 10 shows a block diagram of an exemplary recommender system including a sensor in accordance with an embodiment of the present disclosure.  In FIG. 10, sensor 1002 receives input data from the environment and sends the data to data gatherer\n110 for further processing.  In FIG. 10, user feedback data 108 is manually input from a user and is received by user feedback analyzer 116.  However, it should be understood that, in an embodiment, user feedback data 108 can also be received using\nsensor 1002.\nIn an embodiment, sensor 1002 can detect a wireless signal propagated through a medium, such as air or water.  For example, this signal can be a collection of sounds detected in a particular area that sensor 1002 can sense.  Sensor 1002 sends\ninformation corresponding to these detected signals to data gatherer 110, which stores this information in a database (e.g., in memory 120) as signals are received.  Data gather generates gathered data 105 based on sensed information and/or user feedback\ninformation 108 sent via user feedback analyzer 116.  Data analyzer 112 can determine operations to be performed on gathered data and send information to results generator 114, which sends output data 106 to the user.  The user can provide user feedback\ndata 108 to user feedback analyzer 116.  Data analyzer 112 can continually determine new operations to perform on gathered data 105 as more input data 104 is sensed by sensor 1002 and/or more user feedback data 108 is received.\n<BR><BR>7.  Conclusion\nIt is to be appreciated that the Detailed Description, and not the Abstract, is intended to be used to interpret the claims.  The Abstract may set forth one or more but not all exemplary embodiments of the present disclosure as contemplated by\nthe inventor(s), and thus, is not intended to limit the present disclosure and the appended claims in any way.\nThe present disclosure has been described above with the aid of functional building blocks illustrating the implementation of specified functions and relationships thereof.  The boundaries of these functional building blocks have been\narbitrarily defined herein for the convenience of the description.  Alternate boundaries can be defined so long as the specified functions and relationships thereof are appropriately performed.\nThe foregoing description of the specific embodiments will so fully reveal the general nature of the disclosure that others can, by applying knowledge within the skill of the art, readily modify and/or adapt for various applications such\nspecific embodiments, without undue experimentation, without departing from the general concept of the present disclosure.  Therefore, such adaptations and modifications are intended to be within the meaning and range of equivalents of the disclosed\nembodiments, based on the teaching and guidance presented herein.  It is to be understood that the phraseology or terminology herein is for the purpose of description and not of limitation, such that the terminology or phraseology of the present\nspecification is to be interpreted by the skilled artisan in light of the teachings and guidance.\nAny representative signal processing functions described herein can be implemented using computer processors, computer logic, application specific integrated circuits (ASIC), digital signal processors, etc., as will be understood by those\nskilled in the art based on the discussion given herein.  Accordingly, any processor that performs the signal processing functions described herein is within the scope and spirit of the present disclosure.\nThe above systems and methods may be implemented as a computer program executing on a machine, as a computer program product, or as a tangible and/or non-transitory computer-readable medium having stored instructions.  For example, the functions\ndescribed herein could be embodied by computer program instructions that are executed by a computer processor or any one of the hardware devices listed above.  The computer program instructions cause the processor to perform the signal processing\nfunctions described herein.  The computer program instructions (e.g., software) can be stored in a tangible non-transitory computer usable medium, computer program medium, or any storage medium that can be accessed by a computer or processor.  Such media\ninclude a memory device such as a RAM or ROM, or other type of computer storage medium such as a computer disk or CD ROM.  Accordingly, any tangible non-transitory computer storage medium having computer program code that cause a processor to perform the\nsignal processing functions described herein are within the scope and spirit of the present disclosure.\nWhile various embodiments of the present disclosure have been described above, it should be understood that they have been presented by way of example only, and not limitation.  It will be apparent to persons skilled in the relevant art that\nvarious changes in form and detail can be made therein without departing from the spirit and scope of the disclosure.  Thus, the breadth and scope of the present disclosure should not be limited by any of the above-described exemplary embodiments.", "application_number": "14944802", "abstract": " Systems and methods for enhancing exploratory data analysis using a\n     recommender system are provided. The recommender system receives feedback\n     when a set of raw data is analyzed (e.g., from one or more data analysts\n     exploring a data set). Based on the collected feedback, the recommender\n     system can automatically infer the need for certain analytical operations\n     to be performed on a data set. These inferences can be used by the\n     recommender system to infer analytical operations when new data sets are\n     analyzed.\n", "citations": ["20090158179"], "related": ["62081706"]}, {"id": "20170343368", "patent_code": "10317230", "patent_name": "Machine learning travel management system with wearable device integration", "year": "2019", "inventor_and_country_data": " Inventors: \nRangan; Trilok (Bangalore, IN), Nagaraj; Chaitra (Bangalore, IN), Chaudhary; Rahul (Lucknow, IN)  ", "description": "<BR><BR>PRIORITY\nThe present application claims priority under 35 U.S.C.  119(a)-(d) to Indian patent application number 201641018604, having a filing date of May 31, 2016, the disclosure of which is hereby incorporated by reference in its entirety.\n<BR><BR>BACKGROUND\nThe way people have booked their travel plans has evolved over time.  Initially, travel bookings were done by travel agents.  Then, online bookings became popular through various web sites, which offer reviews as well as links for booking\nhotels, purchasing airline tickets, etc.\nAlso, people have changed the way they travel and what they do when they travel.  For example, it is not uncommon for travelers to prefer to rent people's homes rather than stay in hotels.  Also, travelers often share their travel experiences\nwith friends through social media.  Also, many travelers may prefer site seeing on their own instead of with a guide.  Even with the availability of travel web sites, it is still time consuming and laborious to book travel plans, especially given the\nvariation and ever changing travel habits of individuals. <BR><BR>BRIEF DESCRIPTION OF THE DRAWINGS\nFeatures of the present disclosure are illustrated by way of example and not limited in the following figure(s), in which like numerals indicate like elements, in which:\nFIG. 1 shows a system diagram of a machine learning travel management system, according to an example of the present disclosure;\nFIG. 2A shows an example of a software architecture of the system shown in FIG. 1;\nFIG. 2B shows an example of a data flow diagram for the system shown in FIG. 1;\nFIG. 2C shows a flow chart of a method for determining a travel solution for a user;\nFIG. 2D shows a flow chart of a method for providing waypoints for a travel solution for a user;\nFIGS. 3A-E illustrate examples of screen shots that may be generated in a website or mobile application;\nFIGS. 4A-E show examples of screen shots for mapping and active band services;\nFIG. 5 shows an example of a screen shot for active band management; and\nFIGS. 6-7 show methods, according to examples of the present disclosure.\n<BR><BR>DETAILED DESCRIPTION\nFor simplicity and illustrative purposes, the present disclosure is described by referring mainly to an example thereof.  In the following description, numerous specific details are set forth in order to provide a thorough understanding of the\npresent disclosure.  It will be readily apparent however, that the present disclosure may be practiced without limitation to these specific details.  In other instances, some methods and structures readily understood by one of ordinary skill in the art\nhave not been described in detail so as not to unnecessarily obscure the present disclosure.  As used herein, the terms \"a\" and \"an\" are intended to denote at least one of a particular element, the term \"includes\" means includes but not limited to, the\nterm \"including\" means including but not limited to, and the term \"based on\" means based at least in part on.\nAccording to an example of the present disclosure, a machine learning travel management system is operable to provide end-to-end travel offers and bookings based on machine-learning-assisted choice and selection of travel offers.  Travel offers\nmay include destination choices, which in many instances is one of the most difficult decisions made by travelers.  Generating travel offers is automated, intelligent and dynamic.  The travel offers may be personalized and customized based on\npreferences.  Also, safety during travel may be considered when generating travel offers.  For example, destinations may be selected based on language and medical services offered.  Also, the system may provide for creation of interactive social\ncommunities and provide unique loyalty programs.\nAdditionally, the system may interact with active bands, which comprise wearable RFID devices.  The wearable RFID devices may provide for identification and location determination to provide location-based services, including providing of\ncoupons, loyalty programs, and other services during travel.  Also, the system may include a mobile application that provides mapping of travel routes and waypoints, which can interact with location information determined based on the active bands.\nAccording to an example of the present disclosure, data from a plurality of data sources is captured and collated and through machine learning and/or data mining techniques to identify data patterns.  The captured data may be travel-related and\nmay include social media data, demographics, user preferences, and/or other data.  A query from a user may be received for travel information.  For example, a query may be received for determining where to vacation.  A travel solution may be determined\nbased on the query, user preferences for the user and data patterns determined from the collated data.  The travel solution may include one or more destinations, a travel itinerary including the destinations and travel arrangements that conform to the\ntravel itinerary, such as flights, car rental, hotels, etc. The system may connect to online booking services or cloud travel services to automatically book the travel solution, including the travel arrangements.\nThe system may also communicate with mobile applications and electronic wearable devices, which may include RFID tags, to provide travel-related services at a destination.  For example, the system may determine waypoints estimated to be of\ninterest to the user at a travel destination of the travel solution based on the collated data.  A waypoint may be a location, which may be for an activity, estimated to be of interest to the user.  The system determines a travel route based on the\nwaypoints.  Through a mobile application executed on a user device such as a smartphone, a map may be displayed that includes the travel route and the waypoints on the travel route.  The travel route and waypoints may be dynamic.  For example, the travel\nroute and waypoints may be modified as the user is detected at different waypoints, such as through the RFID wearable device or other location tracking mechanisms.\nAlso, the system may generate messages and offers through the mobile application that incentivizes the user to visit different waypoints.  Accordingly, the system can provide gamification, such as a treasure hunt based user experience, for\nvisiting different waypoints that are estimated to be of interest to the user based on the data mining of the collated data.  For example, an offer may include a discount for goods or services offered at a waypoint that incentives a user to visit the\nwaypoint.  The offers may be geo-tagged for a micro-location and may be on previous history, such as if you are biker as determined by social media, you may get an offer to visit a bike store.\nOnce the user is detected at a waypoint, such as by an RFID reader detecting an active band worn by the user, additional waypoints may be determined that are based on interests of the user, such as waypoints for museums if the user is interested\nin visiting museums.  The waypoints can be dynamically modified as the user is detected at different waypoints to further the treasure hunt based experience.  In an example, the travel route is initially determined with 6-7 waypoints and may be shown as\ngreen destinations on a displayed travel route.  Additional destinations may be determined and shown in red as the user travels, and the user may select a red destination to turn it to green and add it to the travel route.  Additional destinations may be\npresented with offers to incentivize visits to the destinations.  Once the user visits a destination, new destinations may be added and may be selected by the user to add to the travel route.\nFurthermore, the system can determine waypoints that are micro-locations.  A micro-location may be a location within a GPS coordinate.  For example, waypoints on a travel route may be at different GPS coordinates.  Micro-locations may be\nmultiple locations within a single GPS coordinate.  For example, a market may have multiple stalls within close proximity.  The stalls may be in a single GPS coordinate because they are located close to each other.  In an example, a distance between\nconsecutive GPS coordinates may range from 60 feet to one mile.  A market may have multiple stalls within that distance range.  Each stall may have its own micro-location.  The user may be tracked at the different micro-locations by RFID readers at the\nmicro-locations reading the RFID tag in the active band or other device of the user.  Based on the detection of the user at a micro-location, new micro-locations and incentives may be communicated to the user via the mobile application.  A new travel\nroute with new waypoints may be generated and displayed via the mobile application.  The waypoints may include a new set of micro-locations and other waypoints.  In an example, the system may store micro-location sub-maps for different waypoints.  A\nmicro-location sub-map may include a map of micro-locations within close proximity, such as within a single GPS coordinate.  The micro-location sub-map may be transmitted to the mobile application for display to the user, and the user may use the\nmicro-location sub-map to navigate to a micro-location on the map.  The mobile application display a travel route to micro-locations in the sub-map that may be of interest to the user and may be modified as the user travels the route.  The mobile\napplication may track the user's movements within a micro-location sub-map based on detection by RFID readers at the micro-locations and based on direction of travel which may be determined based on a compass or other movement measurements performed by a\nmobile device hosting the mobile application.\nFIG. 1 shows a diagram of a system 100, according to an example of the present disclosure.  The system 100 is a machine learning travel management system.  The system 100 in FIG. 1 may be implemented in a distributed manner across multiple\ncomputers (e.g., servers) and systems, or some (or all) components may be implemented on the same computer or server.  Components on separate computers may use any suitable communications technique to transmit data (represented by the arrows) between one\nanother.  The system 100 may reside on the cloud and be offered as a cloud service.\nThe system 100 is referred to as machine learning because it may use machine learning and natural language processing functions to make predictions on user choices.  In an example, the machine learning and natural language processing functions\nare used to generate voice bots which may understand user's spoken input (or other form of user input), determine context, and use the input and context to select travel offers to present to the user.  It should be understood that the system 100 may\ninclude additional components and that one or more of the components described herein may be removed and/or modified without departing from a scope of the system 100.\nThe system 100 may include a travel services server 132, a machine learning server 131 and a data repository 175.  The travel services server 132 and the machine learning server 131 include computers that provide functionalities described below\nfor other devices.  The data repository 175 may include a data storage system that allows data to be stored and retrieved.  The travel services server 132 provides travel services to online users 130, for example, via network 119, which may include the\nInternet and/or other networks.  The users 130 may interact with the system 100 via a web site 152 and/or a mobile application 150 to perform various operations as is discussed below.  By way of example, user 130a interacts with the system 100 via web\nsite 152 and the system 100 may generate and display a travel route to the user 130a via the web site 152.  User 130b may interact with the system 100 via mobile app 150, and user 130c may interact with the system 100 via mobile app 150 and active band\n151.  The travel services provided by the travel services server 132 may include travel bookings 115, active band services 116 and other travel services 117.  The travel bookings 115 may include providing travel offers for selection by the online user\nand booking of an accepted travel offer.  The active band services 116 may include providing location-based travel services, which are further described below.  For example, online user 130c may have an active band with an RFID tag (active or passive)\nthat may be read at various locations and used to provide services, including coupons, to the online user 130c when traveling.  Other online travel services may also be provided by the travel services server 132.\nThe machine learning server 131 may include a classifier builder 162 which may generate machine learning classifiers based on training sets and validation sets.  For example, neural networks may be trained and validated to create the\nclassifiers.  In an example, machine learning and natural language processing functions are used to create voice bots 160 which may understand user's spoken input (or other form of user input), determine context, and use the input and context to select\ntravel offers to present to the user.  Service demand estimator 161 may make predictions on travel services needed by a user, such as car rentals, bicycle rentals, restaurant choices, site seeing choices, etc. The predictions may be based on historical\nanalysis of travel data.  The predictions may be determined from regression analysis of the collated data in the data repository 175.\nThe network 119 may include local area networks (LANs) and wide area networks (WANs), such as the Internet.  The network 119 may include signal bearing mediums that may be controlled by software, applications and/or logic.  The network 119 may\ninclude a combination of network elements to support data communication services.  The network 119 may encompass wired and/or wireless network technologies.\nServer platform 190 is an example of hardware that may be used for the travel services server 132 and the machine learning server 131.  It should be understood that the server platform 190 may include additional components and that one or more\nof the components described herein may be removed and/or modified as is known to one of ordinary skill in the art.\nThe server platform 190 may include one or more processors 191, data storage 193, and an input/output (I/O) interface 192.  The components of the server platform 190 are shown on a single computer or server as an example and in other examples\nthe components may exist on multiple computers or servers.  The server platform 190 may store data in the data storage 193 and/or may manage the storage of data stored in a separate computing device, for instance, through the I/O interface 192.  The data\nstorage 193 may include physical memory, a hard drive, an optical drive, a flash drive, an array of drives, or any combinations thereof, and may include volatile and/or non-volatile data storage.  The data storage 193 may include a non-transitory\ncomputer readable medium that can store machine readable instructions 194 which are executable by the processor 191 to perform the functions of the travel services server 132 and the machine learning server 131.  The data storage 193 may include one or\nmore non-transitory computer readable mediums.\nThe processor 191, which may comprise a microprocessor, a micro-controller, an application specific integrated circuit (ASIC), Graphical Processing Unit (GPU) or the like, is to perform various processing functions of the respective server.  The\nprocessing functions may include the functions and operations described above.\nThe I/O interface 192 includes a hardware and/or a software interface.  The I/O interface 192 may be a network interface connected to a network through a network device, such as a router.  For example, the I/O interface 192 may be a wireless\nlocal area network (WLAN) or a network interface controller (NIC).  The WLAN may link to the network device through a radio signal.  Similarly, the NIC may link to a network device through a physical connection, such as a cable.\nThe data repository 175 may include a database comprised of database tables or another type of data storage system.  The data repository 175 can be implemented as a standalone or distributed repository.  The data repository 175 may store any\ndata used by the system 100.\nFIG. 2A shows an example of a software architecture of the system 100 shown in FIG. 1.  The software architecture may include operations for connecting to users, e.g., client device endpoints and service endpoints.  Application program\ninterfaces (APIs) may be managed and executed to connect to service endpoints which may provide various functions used by the system 100.  Service endpoints may include cloud services or software applications that are remotely located and are accessed\nthrough the Internet or through other networks.  In an example, the APIs may connect the system 100 to online booking services to automatically book a travel itinerary determined by the system 100.  A load-balanced service fabric cluster provides\nmicroservices of the system 100, such offer generation and travel bookings, rentals, payments, etc. Stateless and/or stateful computing may be used to provide various microservices.  Hybrid connections may be used to connect the web applications and\nmobile applications to on-premises computer resources behind a firewall.  Express route circuits may be used to connect on-premises infrastructure to a service through a connectivity provider.  The architecture may include security functions as well.\nFIG. 2B shows a data flow diagram for the system 100.  User input, for example provided via a voice bot, is received at the system 100 and ingested or prepared and ingested for analysis.  Also, data is captured and stored from a plurality of\ndata sources.  Data may be stored on the cloud.  Data preparation may include moving data, executing data translations, orchestration, etc. Analysis may include machine learning analysis or some form of analytics to determine a travel solution, travel\nroutes and new waypoints.  The output of the services is published or presented to the user via the website 152 or mobile application 150.\nFIG. 2C shows a flow chart of a method 250 for determining a travel solution for a user.  The method 250 is described by way of example as being performed by the system 100 but may be performed by other systems.\nAt 251 data is captured and stored in the data repository 175.  The captured data may include travel-related data from a plurality of data sources.  Travel-related data may include data about travel destinations and user interests that may be\nassociated with the travel destinations and activities that may be performed at the destinations.  The captured data may include social media data from social media applications, demographics of travelers, user preferences of travelers, etc. User\npreferences and user profile data may include data entered via mobile application 150 or web site 152 by users.  The captured data may be collated in a data store, such as a data lake store of the data repository 175.\nAt 252, the system 100 may data mine the travel-related data in the data repository 175.  Data mining may be continually or periodically performed as travel-related data is continually or periodically stored in the data repository 175.  Data\nmining may be performed to determine data patterns in the travel-related data.  An example of the data mining may include clustering, such as k-means clustering.  The clustering may identify groups of users having related attributes and may be used to\nidentify travel solutions for a user related to previous travel solutions provided for members of the group.  For example, if a group of users is related by demographics, travel solutions previously used by members of the group may be used to determine a\ntravel solution for another member of the group that is using the system 100 to determine a travel solution.  Clustering and other types of conventional data mining techniques may be performed by the machine learning server 131 to determine data patterns\nin the captured data stored in the data repository 175.  In an example, collating data may include capturing and storing data and may also include executing data mining operations to determine data patterns in the stored data.\nAt 253, the machine learning server 131 identifies tags in the captured data.  The tags may include identifiers or other types of meta data that specifies attributes of the captured data.  For example, social media data may include tags of likes\nof users or tags identifying topics in the most recent trends, which may be related to current events.  The tags may be stored with the captured data and may be used to weight query results generated by the system 100 as is further discussed below.\nAt 254, the system 100 receives a user query for a travel solution.  The user query may be received via the mobile application 150 of the web site 152.  The user query may be received via one of the voice bots 160, and the machine learning\nserver 131 executes natural language processing on the user query to determine a context of the query.  Known natural language processing may be performed to remove stop words and determine context of the query.  Cortana.RTM.  by Microsoft.RTM.  may be\nused for executing natural language processing on a user query to determine a context of the query.\nAt 255, the machine learning server 131 determines a set of travel destinations based on the query, a user profile of the user, the captured data, and the data mining of the captured data.  For example, the natural language processing may\ndetermine keywords from the query such as vacation, New York City and summer.  The query may be received through the mobile application 150.  User profile information for the user may be determined, which may include information entered by the user\nthrough the mobile application and information from the captured data.  The machine learning server 131 may determine a set of travel destinations that match the query based on the user profile information and clusters the user belongs to which were\ndetermined through the data mining.  For example, the machine learning server 131 searches for previous itineraries of users in the same cluster as the user that include summer months and New York City and attributes determined from the user profile to\ndetermine a set of itineraries matching the query.\nAt 256, the machine learning server 131 determines an ordered visual representation of the set of travel destinations based on the weighted social media data.  For example, the weighted data may include weights given to tags captured from social\nmedia data that represent trends and recency of trends identified in social media data.  The machine learning server 131 determines whether the travel destinations include any of the weighted tags or whether the social media data or other data indicates\nthe travel destinations are associated with any of the weighted tags.  If so, the travel destinations may be displayed in an ordered fashion, similar to search results displayed by search engine, according to the weights.  Travel destinations that are\nweighted higher because they may include destinations, activities, etc., associated with recent trends may be displayed closer to the top of a displayed list of the travel solutions.  The travel destinations may be displayed in a graphical user interface\nof the mobile application 150 or via web site 152.\nAt 257, the machine learning server 131 receives a selection of one of the travel destinations, for example, via the mobile application 150.  The user may select one of the travel destinations displayed through the mobile application 150.  If\nthe user decides that none of the travel destinations are satisfactory, the mobile application 150 may determine a new set of travel destinations which may be based on further user input.\nAt 258, travel solution may be determined for the selected travel destination.  The travel solution may include a travel itinerary and travel arrangements, which may be determined based on previous trips to the travel destination by one or more\nusers.  At 259, the machine learning server 131 sends the travel itinerary and travel arrangements that conform to the travel itinerary for display via the mobile app 150.  Travel arrangements that conform to the travel itinerary may include travel\narrangements that have associated dates, times, and locations (intermediate and final destinations) that fit into the travel itinerary.  Also, the availability and rates of various travel arrangements, such as airline flights, hotel accommodations, and\nrental cars, may be displayed for the user to select the final travel solution.\nThe user is presented with the travel itinerary and the travel arrangements via the mobile application 150, and the user determines whether to book the travel itinerary and the travel arrangements of the selected travel solution.  At 260, the\nmachine learning server 131 determines whether additional user input is received to modify the travel solution, such as any of the travel itinerary and the travel arrangements for the travel solution.  If additional user input is received, such as via\none of the voice bots 160, the machine learning server 131 determines a new travel solution (258) based at least on the additional user input.  Then, the steps 259-260 are repeated.  At 260, if the machine learning server 131 determines no additional\nuser input is received to modify any of the travel itinerary and the travel arrangements of the selected travel solution, the machine learning server 131 may send the selected travel solution to the travel services server 132 to book the travel itinerary\nand the travel arrangements of the travel solution at 261.  Bookings may be done via APIs to online booking services.  For example, calls may be executed to the APIs to connect to at least one booking service to book the travel solution according to the\ntravel itinerary and the travel arrangements in the travel solution.\nFIG. 2D shows a flow chart of a method 270 for providing waypoints for a travel solution for a user.  The method 270 is described by way of example as being performed by the system 100 but may be performed by other systems.  The method 270 may\nbe performed after the method 250 is performed to determine the travel solution.  The method 270 may dynamically determine waypoints for a travel destination in the travel solution.\nAt 271, after the travel solution is determined in the method 250, an option is presented to the user to obtain an active band for the travel solution.  For example, the option is presented via the mobile app 150 or the web site 152.  The active\nband may include a wearable RFID tag.\nAt 272, if the user selects the option to obtain the active band, the active band is linked to the travel solution and the user.  For example, the RFID tag may be programmed with a unique ID, and a record is stored in the data repository 175\nthat associates the unique ID of the active band with the user's travel solution and the user profile of the user.  Then, the user receives the active band.  There may be multiple ways for the user to obtain the active band.  The active band may be\npicked up at a designated location or shipped to the user.\nAt 273, the system 100 determines waypoints for the travel destination.  The waypoints may be determined based on data mining or machine learning that detects patterns in historical data for the user and the travel destination and based on\npreferences of the user.  The waypoints may be determined by analysis of the collated data for other users similar to the user, e.g., having the same demographics and based on the user's data and preferences and the likes and interests of the user.\nAt 274, the system 100 determines a travel route based on the waypoints.  The travel route may be determined by selecting a map for the travel destination.  For example, if the travel destination is New York City, a map of Manhattan is retrieved\nfrom the data repository 175.  The waypoints are located and pinned on the map, and the travel route is determined that includes the waypoints.\nAt 275, the system 100 transmits the travel route and the waypoints to the user, such as to the mobile app 150.  The mobile app 150 displays the travel route to the user on the mobile device.\nAt 276, the system 100 receives an indication the user is at one of the waypoints.  In an example, the RFID tag is read by a reader at a waypoint.  An indication may be transmitted from a device at the waypoint, via a network, to the system 100\nthat the user is at the waypoint.  The mobile app 150 or another device at the waypoint may transmit a message with the indication to the system 100 via the network.  In another example, the user's location is tracked via global positioning system (GPS)\nto determine whether the user is at a waypoint, and the mobile app 150 sends the location of the user to the system 100.\nAt 277, at least one new waypoint that is not currently on the travel route is determined, and, at 278, a new travel route including a new set of waypoints comprising at least one new waypoint and at least one of the waypoints in the previous\ntravel route is generated by the system 100 for the user.  At 279, the new travel route is sent to the mobile app 150.  The mobile app 150 displays the new travel route and the new set of waypoints on the map.\nFor example, at 277, to determine at least new waypoint, the system 100 may identify waypoints that are near the current location of the user, which may be the last waypoint where the user was detected.  To identify waypoints that are near the\ncurrent location, the system 100 may have a database of waypoints and their locations, and may identify waypoints that are within a predetermined distance of the current location of the user.  The system 100 may filter the set of close-by way points\nbased on user preferences and likes, and based on analysis of the collated data for other users similar to the user, e.g., having the same demographics.  For example, a subset of the close-by waypoints may be selected for the new travel route based on\nuser preferences and an analysis of historic travel-related data, and the new travel route may be transmitted to the mobile app 150 for display to the user.  In an example, after determining the subset of the close-by waypoints, the subset of the\nclose-by waypoints may be presented to the user with offers, and the user may select one or more of the displayed waypoints to be added to a new travel route.  According to an example, a subset of the waypoints in the new travel route may include\nmicro-locations.  A sub-map may be determined for a set of micro-locations and transmitted from the system 100 to the mobile app 150 when the user is determined to be at a GPS coordinate for the set of micro-locations.  The mobile app 150 can display the\nmicro-locations on the sub-map and a walking travel route to each of the micro-locations.  The user may be detected at a micro-location if the active band is read by an RFID reader at the micro-location, and new micro-locations may be determined and\npresented to the user that may be of interest.  Also, a new travel route may be determined and displayed in response to selection of new micro-location waypoints.\nAdditionally, purchases may be made with the travel band if a payment authorization, such as credit card authorization, is linked to the RFID tag in the system 100.  Transactions may be transmitted with the RFID tag to the system 100 to make\npurchases and track user behavior.  Also, new offers may be generated based on tracked behavior.  The offers may be presented to the user via mobile app 150 and may be associated with micro-location way points that can be selected and added to the travel\nroute.  The method 270 may be repeated as needed.  For example, as the user travels to different waypoints, the user may be presented with new potential waypoints that are estimated to be of interest to the user and which may be selected for creating a\nnew travel route.\nFIGS. 3A-E illustrate examples of screen shots that may be generated in the website 152 or mobile app 150.  Operations described above that are performed via the mobile app 150 may also be performed via the web site 152.  In an example, one or\nmore of the screen shots of FIGS. 3A-E may be presented to the user to determine a travel destination for a travel solution during the method 250.\nFIG. 3A shows an example for a login screen.  The user may enter a name and password to login.  FIG. 3B shows an example where the user enters preferences, such as interests.  The interests and other preferences may be used to determine travel\noffers.  Interests may also be determined from social media applications such as FACEBOOK, INSTAGRAM, TWITTER, etc. FIG. 3C shows additional preferences determined from the user's TWITTER account.\nIn the phase where the travel solution is being determined, the system 100 may select a destination based on user preferences and/or a user query, which may be received via one of the voice bots 160.  FIG. 3D shows an example of destinations\nthat may be selected based on user preferences and presented to the user.  The user, for example, selects New York.  FIG. 3E shows that the user may be presented with the option of adding an active band.  The system 100 may interact with the active band,\nwhich comprises a wearable RFID device.  The active band may provide for identification and location determination to provide location-based services, including providing of coupons and other services during travel.  For example, RFID readers may be\nprovided at various locations, and the user may present their active band to be read by an RFID reader to receive location-based services.  The user may also have the option of linking their credit card, so rentals or other purchases may be performed\nthough the mobile app 150 or via the active band 151.\nFIGS. 4A-E show examples of screen shots for mapping and active band services provided by the system 100.  In an example, one or more of the screen shots of FIGS. 4A-E may be presented to the user during the method 270.\nFor example, the mobile app 150 may display a map with waypoints that represents places of interest to be visited by the user, such as shown in FIG. 4A.  The waypoints may be determined as part of the travel solution and may be displayed to the\nuser via the mobile app 150 at the travel destination of the travel solution.  Also, a travel route may be generated and shown to provide the shortest path between waypoints.\nAs discussed above with respect to the method 270, new waypoints may be dynamically added and a new travel route may be created with the new waypoints.  The system 100 determines a new waypoint in Times Square that may be of interest to the\nuser, and the new waypoint may be displayed differently, such as in a different color, from the waypoints that already on the travel route.  For example, the new waypoint in Times Square may be displayed in red, and the user may click on the new waypoint\nto determine more information about it or to select it to add to the travel route.  FIG. 43 shows that the user selects the new waypoint in Times Square to be added to the travel route.  The system 100 automatically adds it to the travel route, creating\na new travel route with the new waypoint.  As shown in FIG. 4C, the system 100 may provide descriptions of waypoints or potential new waypoints, which may be tagged by the user and visited.  FIGS. 4D-E show examples of the mobile app 150 presenting\ninformation for new waypoints that may be added to the travel route.  For example, FIG. 4D shows that tourer bike rentals are available at new potential close-by waypoints.  FIG. 4E shows an example of an offer that may be presented for a new potential\nclose-by waypoint.  For example, a 20% discount is offered for a retailer at the new potential close-by waypoint.  The new potential close-by waypoints may be determined based on the user's current location which may be determined from the active band\n151, and also based on preferences and data mining techniques and artificial intelligence predictions.  In an example, regression modeling may be used to determine the demand for goods or services associated with available offers for new potential\nclose-by waypoints, and one or more of the new potential close-by waypoints may be selected for display to the user based on the demand determined from the regression modeling.\nFIG. 5 shows an example of a screen shot that may be displayed in the mobile app 150 or web site 152 for active band management and services.  For example, a user may use the screen shown in figure to control monitoring usage, messaging,\npricing, etc., associated with the active band.\nFIG. 6 shows an example of a method 600 that may be performed by the system 100.  The method 600 is similar to the method 250 discussed above but provides additional details for selecting the final travel solution.  At 601, user input is\nreceived, for example, via a voice bot of the voice bots 160.  At 602, user preferences are determined.  Preferences may be determined from the user's social media accounts and/or user input.  At 603, a set of destinations are determined based on the\npreferences.  At 604, a user selection of a destination from the set is received.  At 605, a travel solution is determined for the destination and based on the preferences.  The travel solution may include airfare, hotel, and other suitable travel\nservices.  At 606, the travel solution is presented.  At 607, a determination is made as to whether the travel solution is accepted.  If not, another travel solution is presented at 608.  The travel solution may be for the same destination but may be\nmodified, such as different hotel or airline or some other modification.  Alternatively, other destinations may be displayed for selection of a new destination and generation of a new travel solution for the selected destination.  If the travel solution\nis accepted, at 609, the user is presented with an option to receive an active band for the trip.  The user may purchase the active band in an example.  The active band may be used to provide additional services during the trip.\nFIG. 7 illustrates a method 700 that is associated with the active band and mapping services provided by the system 100.  The method 700 is similar to the method 270 discussed above.  At 701, a travel route is generated and displayed on a map,\nincluding waypoints that are of interest to the user.  At 702, a waypoint may be added or removed and a new travel route is generated.  In an example, the system 100 predicts waypoints that may be of interest to the user and the user has the option of\nadding the waypoints.\nRFID readers may be located along the travel route.  At 703, the system 100 receives notification that the user's active band was read at an RFID reader at a particular location.  At 704, location-based services are provided, such as provided a\ncoupon, or information about rentals, or any information that may be useful to the user at their present or future waypoints.\nWhat has been described and illustrated herein are examples of the disclosure along with some variations.  The terms, descriptions and figures used herein are set forth by way of illustration only and are not meant as limitations.  Many\nvariations are possible within the scope of the disclosure, which is intended to be defined by the following claims--and their equivalents--in which all terms are meant in their broadest reasonable sense unless otherwise indicated.", "application_number": "15603077", "abstract": " A machine learning travel management system is operable to provide\n     end-to-end travel solutions and bookings based on\n     machine-learning-assisted choice and selection of travel destinations.\n     Travel solutions may include travel destination choices, which in many\n     instances is one of the most difficult decisions made by travelers.\n     Additionally, the system may interact with active bands, which comprise\n     wearable RFID devices. The wearable RFID devices may provide for\n     identification and location determination to provide location-based\n     services. Also, the system may include a mobile application that provides\n     mapping of travel routes and waypoints, which can interact with location\n     information determined based on the active bands.\n", "citations": ["5948040", "20090267728", "20120330935", "20140114705", "20150112910", "20150241238", "20150330805"], "related": []}, {"id": "20180013516", "patent_code": "10256942", "patent_name": "Receiver for receiving data in a broadcast system using redundancy data", "year": "2019", "inventor_and_country_data": " Inventors: \nZoellner; Jan (Braunschweig, DE), Stadelmeier; Lothar (Stuttgart, DE)  ", "description": "<BR><BR>BACKGROUND\n<BR><BR>Field of the Disclosure\nThe present disclosure relates to receiver and a corresponding receiving method for receiving data in a broadcast system.  Further, the present disclosure relates to a broadband server and a corresponding method.\nThe present disclosure relates, for instance, to the field of Digital Video Broadcasting (DVB) utilizing Orthogonal Frequency Division Multiplexing (OFDM).  Further, the present disclosure can be applied in other systems, such as a DAB (Digital\nAudio Broadcasting), DRM, MediaFlo, ISDB, ATSC (e.g. 3.0) or LTE broadcast system.\n<BR><BR>Description of Related Art\nThe transmission parameters of known broadcast systems, such as the broadcast systems in accordance with the DVB-T2 standard (second generation digital terrestrial television broadcast systems standard), are generally optimized for fixed\nreception with stationary receivers, e.g. with roof-top antennas.  In future broadcast systems, such as the DVB-NGH (DVB Next Generation Handheld; in the following also referred to as NGH) standard or ATSC3.0 standard, a mobile receiver (which is the\nmain focus of this upcoming standard) shall be enabled to receive data correctly also in bad reception situations, e.g. despite suffering from multipath propagation, fading effects and Doppler shifts.  Such broadcast systems are particularly\ncharacterized by the fact that there is generally no feedback channel and no signalling from receivers to transmitters.\nThe main use of redundancy data is the increase of the coverage area for terrestrial broadcasting.  Subscribers located at the edge of the coverage area of a broadcast system (also called broadcast network) are suffering from low receptions\nlevels, which may hinder error-free decoding.  This is also true for indoor reception or if large objects attenuate the transmitted signal.  To counter this problem the utilization of a (wired or wireless) broadband system (also called broadband network)\nfor providing additional redundancy for enabling error-free reception has been proposed.  In many cases only a few dBs received signal level are missing for the correct demodulation and decoding of the broadcast data, resulting in an additional\nredundancy data stream of few hundred kbit/s. Furthermore other channel impairments like burst noise or narrowband interferer create decoding errors in a sheer broadcast reception scenario which are corrected with the additional redundancy data stream. \nEmbodiments of the disclosure are described with respect to broadcast communications.  The disclosure is not so limited and other communications mechanisms and networks are envisaged.\nWO 2014/082915 A1 discloses a receiver for receiving data in a broadcast system comprising a broadcast receiver that receives, via said broadcast system, a receiver input data stream comprising a plurality of channel symbols represented by\nconstellation points in a constellation diagram.  A demodulator demodulates said channel symbols into codewords and a decoder decodes said codewords into output data words.  A broadband receiver obtains redundancy data via a broadband system, said\nredundancy data for a channel symbol including one or more least robust bits of the channel symbol or a constellation subset identifier indicating a subset of constellation points including the constellation point representing the channel symbol.  Said\ndemodulator and/or said decoder is configured to use said redundancy data to demodulate the respective channel symbol and to decode the respective codeword, respectively\nThe \"background\" description provided herein is for the purpose of generally presenting the context of the disclosure.  Work of the presently named inventor(s), to the extent it is described in this background section, as well as aspects of the\ndescription which may not otherwise qualify as prior art at the time of filing, are neither expressly or impliedly admitted as prior art against the present disclosure.\n<BR><BR>SUMMARY\nSome embodiments of the disclosure provide a receiver for receiving data in a broadcast system using redundancy data providing improved efficiency, implementation complexity and/or end-to-end network delay.  It is a further object to provide a\ncorresponding receiving method, a broadband server, a broadband method, as well as a corresponding computer program and a non-transitory computer-readable recording medium for implementing said methods.\nAccording to an aspect there is provided a receiver for receiving data comprising:\na broadcast receiver configured to receive, via a broadcast system, a receiver input data stream comprising a plurality of channel symbols represented by constellation points in a constellation diagram,\na demodulator configured to demodulate said channel symbols into codewords,\na decoder that configured to decode said codewords into output data words,\na redundancy unit configured to select or request via a broadband system, if demodulation of a channel symbol and/or decoding of a codeword is erroneous or likely to fail, redundancy data for demodulation of future channel symbols and/or\ndecoding of future codewords,\na broadband receiver configured to obtain said redundancy data via said broadband system, wherein said demodulator and/or said decoder is configured to use the obtained redundancy data to demodulate the respective future channel symbols and to\ndecode the respective future codewords, respectively.\nAccording to an aspect there is provided a receiver for receiving data comprising:\na broadcast receiver configured to receive, via a broadcast system, a receiver input data stream comprising a plurality of channel symbols represented by constellation points in a constellation diagram,\na demodulator configured to demodulate said channel symbols into codewords,\na decoder that configured to decode said codewords into output data words,\na selection unit configured to select, if demodulation of a channel symbol and/or decoding of a codeword is erroneous or likely to fail, one of at least two redundancy data sources providing redundancy data at different redundancy data rates via\na broadband system for correct demodulation and decoding by use of the originally received channel symbol and additional redundancy data, and\na broadband receiver configured to obtain said redundancy data via said broadband system, wherein said demodulator and/or said decoder is configured to use the obtained redundancy data to demodulate the respective channel symbols and to decode\nthe respective codewords, respectively.\nAccording to a further aspect there is provided a broadband server for providing redundancy data to a receiver of a broadcast system via a broadband system, comprising:\na data receiving unit configured to receive data from a broadcast transmitter of said broadcast system,\na data conversion unit configured to convert the received data into at least two redundancy data streams of redundancy data having different redundancy data rates,\nat least two redundancy data sources each configured to provide one of said at least two redundancy data streams at a different redundancy data rate for use by a receiver of said broadcast system for correct demodulation and decoding by use of\nsaid redundancy data and data received by said receiver via said broadcast system.\nAccording to still further aspects corresponding methods, a computer program comprising program means for causing a computer to carry out the steps of the methods disclosed herein, when said computer program is carried out on a computer, as well\nas a non-transitory computer-readable recording medium that stores therein a computer program product, which, when executed by a processor, causes the methods disclosed herein to be performed are provided.\nFurther embodiments are defined in the dependent claims.  It shall be understood that the claimed methods, the claimed broadband server, the claimed computer program and the claimed computer-readable recording medium have similar and/or\nidentical further embodiments as the claimed receiver and as defined in the dependent claims.\nOne of the aspects of the disclosure is to make use of the known concept of using redundancy data and to provide improvements to enable a less complex operation of the overall system and its components.  On the one hand alternative receiver\narchitectures allow for a decreased latency in receiving redundancy data on the broadband path, therefore reducing the size of a redundancy synchronization buffer significantly.  Next, and potentially also allowing for lower latencies, low complexity\nreceiving methods are disclosed to determine the redundancy data.  Finally, a broadband server architecture is disclosed that is in some embodiments based on the multicast provision of different redundancy data stream data rates, therefore allowing less\ncomplex broadband server realizations.\nIt is to be understood that both the foregoing general description of the disclosure and the following detailed description are exemplary, but are not restrictive of the disclosure. <BR><BR>BRIEF DESCRIPTION OF THE DRAWINGS\nA more complete appreciation of the disclosure and many of the attendant advantages thereof will be readily obtained as the same becomes better understood by reference to the following detailed description when considered in connection with the\naccompanying drawings, wherein:\nFIG. 1 shows a schematic diagram of a broadcast system,\nFIG. 2 shows a more detailed diagram of a broadcast system including a first embodiment of a receiver,\nFIG. 3 shows a schematic diagram of a second embodiment of a receiver,\nFIG. 4 shows diagrams illustrating the use of least significant bits as redundancy data,\nFIG. 5 shows diagrams illustrating the use of puncturing,\nFIG. 6 shows diagrams illustrating the use of a constellation subset identifier as redundancy data,\nFIG. 7 shows a schematic diagram of a peer to peer architecture between RoD server and RoD clients,\nFIG. 8 shows a diagram illustrating the identification of subcarriers having a low CNR,\nFIG. 9 shows a schematic diagram of a third embodiment of a receiver for use in a peer to peer architecture,\nFIG. 10 shows a schematic diagram of a fourth embodiment of a receiver for use in a peer to peer architecture,\nFIG. 11 shows a schematic diagram of a fifth embodiment of a receiver having a forward loop for use in a peer to peer architecture,\nFIG. 12 shows a schematic diagram of a sixth embodiment of a receiver having a forward loop for use in a peer to peer architecture,\nFIG. 13 shows a schematic diagram of a seventh embodiment of a receiver having a feedback loop for use in a peer to peer architecture,\nFIG. 14 shows a schematic diagram of an eighth embodiment of a receiver having a feedback loop for use in a peer to peer architecture,\nFIG. 15 shows a schematic diagram of a multicast architecture between RoD server and RoD clients,\nFIG. 16 shows a schematic diagram of a ninth embodiment of a receiver having a forward loop for use in a multicast architecture,\nFIG. 17 shows a schematic diagram of a tenth embodiment of a receiver having a forward loop for use in a multicast architecture,\nFIG. 18 shows a schematic diagram of a eleventh embodiment of a receiver having a feedback loop for use in a multicast architecture,\nFIG. 19 shows a schematic diagram of a twelfth embodiment of a receiver having a feedback loop for use in a multicast architecture,\nFIG. 20 shows a diagram of the relationship between overall cost for transmission and transmitter power consumption,\nFIG. 21 shows a schematic diagram of a dynamic broadcast system which may use the present disclosure,\nFIG. 22 shows a schematic diagram of a control device for use in a broadcast system,\nFIG. 23 shows a schematic diagram of another embodiment of a broadcast system,\nFIG. 24 shows a schematic diagram of another embodiment of a broadcast system,\nFIG. 25 shows a diagram illustrating the average estimated Mutual Information with and without knowledge of the transmitted bits,\nFIG. 26 shows a schematic diagram of another embodiment of a broadcast server,\nFIG. 27 shows a diagram illustrating cooperative decoding with a server controlling the data exchange, and\nFIG. 28 shows a diagram illustrating cooperative decoding without a server controlling the data exchange.\n<BR><BR>DESCRIPTION OF THE EMBODIMENTS\nReferring now to the drawings, wherein like reference numerals designate identical or corresponding parts throughout the several views, FIG. 1 shows a schematic diagram of a broadcast system 1 as generally disclosed in WO 2014/082915 A1, in\nwhich the receivers and the broadband server according to the present disclosure may be applied.  It comprises a broadcast transmitter 2 that transmits, via said broadcast system, a receiver input data stream comprising a plurality of channel symbols\nrepresented by constellation points in a constellation diagram.  Further, it comprises one or more receivers 3, in this case two receivers indicated as \"user A\" and \"user B\" arranged at different distances from the broadcast transmitter 2, according to\nthe present disclosure for receiving data transmitted by the broadcast transmitter 2.  Still further, the broadcast system 1 comprises a broadband server 4 (also called broadband provider), in this case a redundancy server that provides redundancy data\nvia a broadband system for reception by said receiver.  The broadband server 4 is preferably configured as disclosed herein.  Due to the use of transmission of data via broadcast and via broadband the broadcast system 1 may also be called a hybrid\nbroadcast system or a broadcast broadband system.\nIn this scheme the transmission in terrestrial network remains unchanged, but for a poor reception the receiver (also called terminal device) can fetch additional data via the broadband network to improve error correction performance.  The\nreceiver evaluates the data received from the terrestrial network, and according to the signal quality it requires certain amount of additional data to assure quasi-error-free (QEF) reception.  Under more severe conditions more additional data is needed. In this way, for instance, a smooth or seamless transition between pure terrestrial broadcast and complete delivery via the broadband network can be realized.  This creates a new degree of freedom for the broadcast network management and may reduce the\noverall delivery cost and energy consumption.\nThe data received via both networks is combined for decoding in the receiver.  What kind of additional data is transmitted via the broadband network depends on the technology used in the terrestrial broadcast network.  FIG. 2 a known broadcast\nsystem 1 as disclosed in WO 2014/082915 A1 in more detail, employing Redundancy on Demand (RoD) concept on the example of DVB-T2.\nThe RoD capable terminal (i.e. a receiver) 3a comprises a broadcast receiver 31 that receives, via said broadcast system 1, a receiver input data stream comprising a plurality of channel symbols represented by constellation points in a\nconstellation diagram.  A demodulator 32 demodulates said channel symbols into codewords, a decoder 33 decodes said codewords into output data words and a de-multiplexer 35 de-multiplexes the desired data from the output data words.  The receiver is\nfurther equipped with a RoD client 34, that performs a request to the RoD server (i.e. the broadband server) 4 if the reception conditions do not allow for error free decoding based on the data received from the broadcast transmitter 2.  The RoD server 4\nis then transmitting the required amount of redundancy, which is generally generated from the initially transmitted data stream, to the receiver 3a.  Different convergence levels for generating the RoD data are possible, i.e. the transmitted redundancy\ndata can either be generated from the output of the multiplexer (MUX), the channel coding unit or the modulation unit.  The proposed RoD scheme is backwards compatible, since receivers that are not capable of a broadband connection for improving the\nreception remain unchanged, such as the receiver 5 shown in FIG. 2.\nThere are different architectures that can be used in order to realize the data exchange between the RoD server 4 and the RoD client 34.  These architectures and example advantages and disadvantages are discussed in the following.\nFIG. 3 shows a schematic diagram of the general layout of a receiver 3b according to the present disclosure.  It comprises a broadcast receiver 31 that receives, via said broadcast system 1, a receiver input data stream comprising a plurality of\nchannel symbols represented by constellation points in a constellation diagram.  A demodulator 32 demodulates said channel symbols into codewords and a decoder 33 decodes said codewords into output data words.  A redundancy unit 36 selects or requests\n(depending on the particular implementation), if demodulation of a channel symbol and/or decoding of a codeword is erroneous or likely to fail (which may be checked in a corresponding check step), redundancy data for demodulation of future channel\nsymbols and/or decoding of future codewords via a broadband system.  A broadband receiver 37 obtains said redundancy data via said broadband system.  According to the present disclosure said demodulator 32 and/or said decoder 33 is configured to use the\nobtained redundancy data to demodulate the respective future channel symbols and to decode the respective future codewords, respectively.  The redundancy unit 36 and the broadband receiver 34 are preferably part of an RoD client 34 as shown in FIG. 2.\nThere are different (known and new) approaches for generating the redundancy data.  A known approach for generating redundancy, which is described in WO 2011/080020 A1, is the retransmission of erroneously received packets with the so-called\nAutomatic Repeat Request (ARQ) scheme.  The generation and reinsertion of redundant packets therefore takes place in the multiplexer included in the modulator of the broadcast transmitter 2 (see FIG. 3).  Possible convergence levels are e.g. IP-Packets,\nFEC Frames or Generic Stream Encapsulation (GSE) Packets for DVB-Systems.  However, a drawback of this approach is the reduced granularity for generating the redundancy.  If the reception conditions are slightly worse than required for error free\nreception (e.g. 1 dB below the target SNR), each packet needs to be retransmitted via the broadband system requiring a lot of transmission capacity.\nAnother known approach is the usage of the least robust bits (or, generally, the bits having the highest bit error rate, BER), in particular the least significant bits (LSB), of the used constellation (e.g. of a QAM constellation) as redundancy\ndata.  The receiver demodulates the QAM constellations, but uses the least robust bits, e.g. the LSBs, from the broadband network instead of the ones from the terrestrial broadcast network, because the least robust bits typically carry the lowest amount\nof information within the channel symbol (e.g. a QAM symbol).\nAs the bits from the broadband network are very reliable, the demodulator 32 (in particular the demapper included within the demodulator in various embodiments, e.g. used in OFDM receivers) is able to reduce the number of possible constellation\npoints.  Thus, the average Euclidean distance between the remaining constellation points increases, leading to improved performance.  This approach is shown in an example in FIG. 4 according to which the LSBs are considered as least robust bits.  The\nLSBs received via the broadband network in the constellation diagram shown in FIG. 4A is 0.  The crosses 40 denote the possible constellation points and the lines 50 show the decision thresholds.  In the constellation diagrams shown in FIGS. 4B and 4C\ntwo LSBs are known (00 and 01), reducing the remaining constellation points 41, 42 (indicated by crosses) to four and reducing the number of decision thresholds 51, 52.  The same principle also holds for soft-decision demapping.  In this case the\nknowledge of the redundancy data is used to enhance the reliability of the soft-decision output values of the demapper.\nIn another embodiment the demodulator 32 is configured to use said least robust bits of a channel symbol received as redundancy data to replace the least robust bits of the channel symbol received by said broadcast receiver to obtain an improved\nchannel symbol and to demodulate said improved channel symbol.\nIn still another embodiment the receiver can also utilize the least robust bits (e.g. the LSBs) from the broadband network for improving the demapping and/or decoding of the more robust bits (e.g. the MSBs) from the broadcast network.  This\nconcept is similar to \"Genie-aided\" demapping, i.e. an easily implementable soft-decision demapping approach, where the knowledge of the transmitted bits is used to enhance the reliability of the soft-decision output values of the demapper.  Thus, the\ndecoder 33 is configured according to this embodiment to use said least robust bits of a channel symbol received as redundancy data to replace obtained input values of the decoder with their ideal values derived from the known bits contained in the\nredundancy data and, thus, to obtain an improved codeword and to decode said improved codeword.  Typically, the input values of the decoder are soft-decision input values (generally log-likelihood ratios, LLRs) so that obtained uncertain soft-decision\ninput values are set to the ideal values having indefinite likelihood (i.e. perfect knowledge) which are then used in the decoding.\nThe bit rate of the generated redundancy data can be controlled firstly by selecting the number of least robust bits out of each channel symbol, and secondly by puncturing the complete least robust bit stream, as illustrated in FIG. 5.  Here,\nFIG. 5A shows a redundant data stream with bitrate R, FIG. 5B shows a redundant data stream with bitrate R/2, and FIG. 5C shows a redundant data stream with bitrate R/3.  This is important to control the optimum amount of redundancy data.  On the one\nhand the amount of transmitted redundancy data must be sufficient to allow for error-free decoding and/or demodulation, but on the other hand the amount should be as low as possible to avoid transmission of unnecessary redundancy data.\nInstead of retransmitting the initially transmitted bits, it is also possible to define constellation point subsets that are excluded in the receiver.  This allows for increasing the Euclidian distance between the remaining constellation points. If bit sequences with unequal probabilities are transmitted, Huffman coding may be conducted on the selected bits, to enable the receiver to separate them easily and reduce the overhead for the transmission.  This is meaningful if constellation shaping\nis used, altering the probabilities of the subset identifiers, i.e. some subset identifiers occur with higher probability than others.  This is directly related to constellation shaping of (e.g. QAM) constellations, with some constellation points\noccurring with higher probability than others.  In the normal case of equal probabilities, Huffman coding does not provide any gain.\nAn example of a Huffman coding for a 16-QAM constellation is as follows:\nTABLE-US-00001 Original bit sequence Probability Huffman coded bits XXX0 1/2 0 XX10 1/4 01 X0X1 1/4 10 1111 1/16 11\nAfter the identification of the sub-carriers with heavy distortion, redundant bits will be generated from the constellation points of these sub-carriers.  Since the distortion levels of these identified sub-carriers may also vary, the redundant\nbits required for each sub-carrier may also be different.\nAs an example, it shall be supposed that all the N constellation points build a set S. Through the re-labeling S will be divided into sub-sets {S1, S2, .  . . , Sm}, i.e. not bits but (e.g. QAM) subset identifiers are transmitted.  The division\noperation increases the average robustness of the constellation points within each sub-set.  This operation is dependent on the statistical properties of the broadcast signal and the distortion.  The mathematical deviation is omitted here.  A simple\nexample using 16 constellation points of a QAM constellation is shown in FIG. 6.  If the receiver receives a \"0\" (i.e. 16-QAM Gray Mapping with LSB known to be 0), it indicates the original point locates in a first sub-set comprising the constellation\npoints 60 (indicated by crosses) as shown in FIG. 6A.  If the subsets are optimized for maximum average Euclidian distance, the original point is located in a sub-set comprising the constellation points 61 (indicated by crosses) as shown in FIG. 6B.\nThe various division schemes for different distortion levels and forms can be pre-calculated and stored in a look-up table, for example in electronic memory, to simplify the online operation.  This approach enables a maximal utilization of the\ncapacity of the communication channel.\nIn an embodiment a peer to peer architecture may thus be used in the broadband system connecting the RoD server 4 and multiple (i.e. n) RoD clients 34a, 34b, .  . . , 34n of various receivers as schematically shown in FIG. 7.  In this\narchitecture the RoD server 4 generates a response individually for each RoD client 34a, 34b, .  . . , 34n.  This has the advantage that the redundancy data rate exactly matches the client's requirements, but has the disadvantages that a high processing\nload is required on RoD server side to handle the large number of different requests and that the redundancy data rate is fixed and cannot be reduced.\nIn an initial step, a receiver needs to be informed about the location (e.g. the IP address and port) of the RoD server respectively the CDN (content delivery network, providing distributed content server for increased data services and delivery\nspeeds for web content, such as internet HbbTV services etc.).  The location of the RoD server can e.g. be signaled in the PHY specific L signalling table, being typically located at the beginning of a T2 frame or an ATSC3.0 frame.  Very robust signaling\nstages should be used to signal the location in order to allow receivers to identify the RoD server even in difficult channel conditions.  In case of DVB-T2 L-pre or L1-config can be used.  As an example an extended L-pre table is shown below.\nTABLE-US-00002 L1-pre Parameter Bits TYPE 8 BWT_EXT 1 .  . . . . . ROD_SERVER_IP_ADDR 32 ROD_SERVER_PORT 16 CRC_32 32\nAnother option is to signal the RoD in a way as chosen by other combined broadcast/broadband systems, as e.g. in HbbTV: HbbTV embeds the server information into a so-called AI (application identifier) table, which contains e.g. an URL link to\nthe content server respectively a dedicated html page.  Such tables are for example provided in Service Information (SI) or other signalling.\nA well defined signalling interface is preferably used to enable a standardized way of exchanging RoD data.  In particular the format for the RoD request and RoD response shall be defined.  In the following an example interface is described that\ncan be used as interface for the peer to peer TX architecture shown in FIG. 7.  The proposed message blocks are embedded into suitable packet formats and transmission protocols (e.g. IP packets and TCP/IP protocol).\nFor the handshake of the RoD client with the RoD server (upstream, initialization) the following parameters may be used (information in brackets indicate possible locations in signalling fields of a DVB-T2 system):\nTABLE-US-00003 Parameter Bits Comment CELL_ID (L1-pre) 16 To identify network NETWORK_ID (L1-pre) 16 To identify network T2_SYSTEM_ID (L1-pre) 16 To identify network Sum = 48 Bits\nFor the request from the RoD client to the RoD server (upstream) the following parameters may be used:\nTABLE-US-00004 Parameter Bits Comment REQUEST_ID (custom) 10 Request counter PLP_ID (L1-config) 8 To identify PLP FRAME_IDX (L1-dynamic) 8 T2-frame ID TI_BLOCK_ID (custom) 8 TI Block ID in T2-frame FEC_FRAME_ID (custom) 8 FECFrame ID in T2-frame\nNUMBER_ROD_BITS 16 RoD Bits per FECFrame (custom) Sum = 58 Bits\nFor the response of the RoD server to the RoD client (downstream) the following parameters may be used:\nTABLE-US-00005 Parameter Bits Comment REQUEST_ID (custom) 10 Request counter SUCCESS_FLAG (custom) 1 Flag if request was successful PLP_ID (L1-config) 8 To identify PLP FRAME_IDX (L1-dynamic) 8 T2-frame ID TI_BLOCK_ID (custom) 8 TI Block ID in\nT2-frame FEC_FRAME_ID (custom) 8 FECFrame ID in T2-frame NUMBER_ROD_BITS 16 RoD Bits per FECFrame (custom) ROD_DATA_VECTOR NUMBER_ROD_BITS Actual RoD data (custom) Sum = 59 Bits + NUMBER_ROD_BITS\nReserved bits for a predefined set of error messages and further functionality may be added.  In case of a failed response when e.g. the request was sent to the wrong RoD server, the RoD server may for example respond the IP address of the RoD\nserver being responsible for the request.\nA receiver for use in such a peer to peer architecture may be implemented in different ways.  The different embodiments mainly differ in terms of efficiency (i.e. required redundancy data rate for a given receiver quality), receiver and\ntransmitter complexity and additional delay of the service representation.  The different receiver embodiments will be discussed in the following.\nIn a multi-carrier communication system, the distortion each sub-carrier bears varies much in both time domain and frequency domain.  In case of portable mobile and stable receptions, the broadcast channel has slow-changing and slow-fading\ncharacteristics.  Furthermore, low signal power and narrow band interferences are the main hinders for an error-free reception.  FIG. 8 illustrates such a broadcast channel exemplarily, in particular the variance of signal strength in frequency domain. \nThe first step is to identify the sub-carriers which are bearing severe distortion and have hence an insufficiently low carrier-to-noise-ratio (CNR).  In FIG. 8, they are the ones in the marked area 70.  Redundancy data is then only needed for these\nidentified sub-carriers.  In this way, the required bandwidth in the broadband network is reduced.  Because the channel state may also change temporally, the identification process is carried out periodically or in an event-based manner.\nFor the sub-carriers with low CNR, some or even all of the bits from their constellation points need to be transmitted by the broadband connection, so that a correct decoding can be achieved.  The selection of the bits as redundancy depends on\nthe distortion, the strength of the signal, the deployed mapping scheme.  Moreover, which additional bits should be selected as redundancy data is also dependent on the previously selected bits.  A mathematical derivation is omitted here.\nAn embodiment of a receiver 3c making use of this approach in a more general way is shown in FIG. 9.  In addition to the receiver 3b shown in FIG. 3 it comprises a quality detector 39 that identifies the quality of received channel symbols and a\nbroadband request unit 38 that requests channel symbols having the lowest quality and/or a quality below a predetermined quality threshold as redundancy data.\nIn a further embodiment, as explained above with reference to FIG. 7, said broadcast receiver 31 is configured to receive said receiver input data stream via a multi-carrier broadcast system, e.g. an OFDM broadcast system (such as a broadcast\nsystem in accordance with a DVB standard).  Said receiver input data stream comprises a plurality of channel symbols carried by multiple frequency sub-carriers.  In this embodiment the quality detector 39 is configured to identify the quality of said\nfrequency sub-carriers, and said broadband request unit 38 is configured to request channel symbols carried by sub-carriers having the lowest quality and/or a quality below a predetermined quality threshold as redundancy data.\nIn an embodiment the broadband receiver 31 is configured to receive redundancy data via a broadband system.  Thus, the broadband server or any other appropriate unit that is able to transmit data through the broadband system thus actively\ntransmits the redundancy data to the receiver.  For instance, it can be estimated, e.g. by the broadband transmitter or the broadcast transmitter, if the decoding and/or demodulation at a receiver will be erroneous due to the channel characteristics, so\nthat actively redundancy data will be sent, even without explicit request by the receiver.  Further, channel information can be used to select the redundancy data requiring the smallest amount of additional redundancy data.\nIn another embodiment, as shown in FIG. 10, the receiver 3d comprises a broadband request unit 38 that requests, if demodulation of a channel symbol and/or decoding of a codeword without redundancy data is erroneous, one or more least robust\nbits or constellation subset identifiers of the corresponding channel symbol via said broadband system as redundancy data.  Thus, the receiver 3d actively requests redundancy data in this embodiment.\nSaid broadband request unit 38 may alternatively, in another embodiment, transmit receiver specific broadcast channel information via said broadband system to a server (e.g. as shown in FIG. 3) that determines the quality of least robust bits\nand/or channel symbols received by the broadcast receiver 31 and transmits least robust bits and/or channel symbols as redundancy data to the receiver via said broadband system.  Further, preferably, said broadband request unit 38 is configured to\ncompress said channel information by precoding before transmitting it to a server.\nIn an embodiment the channel state information (CSI) is estimated in the receivers, but the identification of the sub-carriers and the constellation points re-labelling can be carried out in either receivers or the server.  If the receiver makes\nthe decisions, it needs only transmit back a request for the specific bits.  If the server makes the decisions, the CSI should be transmitted back from the receiver to the server.  This CSI can be pre-coded before transmitting.  For instance, the CSI can\nbe transmitted incrementally, which means only the difference to last estimation is required by the server.  In this case, the CSI can also be seen as two-dimensional spaces with the axis frequency and time.  Furthermore, the CSI has specific\ncharacteristics in both dimensions, e.g. the variation in the time direction may be very slow in case of stationary reception.  Therefore, one could use algorithms similar to MPEG video encoding (e.g. differential encoding) that take benefit of these\ncharacteristics for an efficient transmission of the CSI back to the transmitter.\nA schematic, more detailed diagram of a third embodiment of a receiver 3e having a forward loop for use in a peer to peer architecture is shown in FIG. 11.  It comprises an OFDM demodulator 300, a PLP extraction unit 301, a time deinterleaver\n(TDI) 302 an IQ/CSI buffer 303, a first QAM demapper 304, a BICM decoder 305, a BB deframing unit 306, a second QAM demapper 307, an estimation unit 308, a broadband interface 309 and a response extraction unit 310.\nIn this embodiment the request of the redundancy data is made individually for each FEC frame.  The number of redundancy data bits is individually calculated for each FEC frame based on mutual information (MI).  An adaptation to fast channel\nchanges is possible thanks to the forward loop because there is no loop delay.  Thus, this embodiment provides an optimum performance.  However, there is a high latency due to IQ/CSI buffering in the buffer 303 (at least due to the round trip delay of\nthe broadband connection from the Rod client to the RoD server).  Mutual Information is for example described in Capacity and Mutual Information of Wideband Multipath Fading Channels, Emre Telatar, IEEE TRANSACTIONS ON INFORMATION THEORY, VOL. 46, NO. 4,\nJULY 2000.\nA schematic, more detailed diagram of a fourth embodiment of a receiver 3f having a forward loop for use in a peer to peer architecture is shown in FIG. 12.  Compared to the receiver 3e shown in FIG. 11 the receiver 3f has a reduced delay.  In\nthis embodiment a request of redundancy data is made for each time interleaver (TI) frame, i.e. the number of redundancy data bits is calculated per TI frame based on the MI.  The estimation is based on first n cells of a TI frame (before\ndeinterleaving).  No estimation per FEC frame is possible since processing takes place before the time deinterleaving.\nThe required redundancy data rate may be slightly increased compared to the receiver 3e since an adaption per FEC frame becomes impossible.  However, the latency is reduced by the TDI duration, i.e. the latency becomes zero if the round trip\ndelay of the network connection is smaller than the TDI duration.  Depending on the network delay either the RoD responses or the IQ/CSI data arrive earlier at the buffer and must hence be buffered to synchronize both streams.  The RoD responses are\nbuffered if the TDI duration is larger than the network round trip delay (the RoD response duration is shorter than the TDI duration).  IQ/CSI data is buffered if TDI duration is smaller than the network round trip delay (the TDI duration is shorter than\nthe RoD response duration).  Also in this embodiment an adaptation to fast channel changes is still possible thanks to the forward loop because there is no loop delay.\nAs the time deinterleaver 302 is one of the main contributors for latency in the broadcast decoding path (depending on PLP bit rate and settings up to e.g. 200 msec), the overall latency until the redundancy data is provided at the buffer 303\ncan be significantly decreased.  It has been shown that as soon as one FEC block inside a TI block is corrupted, in the very most cases the whole TI frame can be considered as broken (for example by block errors in a TV picture).  Therefore the request\nof redundancy data for each TI frame as well as the calculation of required RoD bits per TI-frame based on MI is a realistic scenario.  As a result, the buffer size (and related costs) can be significantly decreased, too.\nNext, two embodiments of a receiver 3g, 3h having a feedback loop for use in a peer to peer architecture will be described with reference to FIGS. 13 and 14.  In these embodiments redundancy data are requested for each TI frame or FEC frame for\ndemodulation of future channel symbols and/or decoding of future codewords.  Different from the embodiments shown in FIGS. 11 and 12 a redundancy request unit 312 for generating the redundancy request and a response buffer 311 for storing the received\nredundancy data for use in the demodulation/decoding of the next data received via the broadcast system are provided.\nIn the receiver 3g the number of redundancy data bits is adjusted with the feedback loop such that a target iteration number is reached.  The target iteration number is set such that error free decoding is just reached, i.e. the target iteration\nnumber is slightly below the maximum number of LDPC iterations.  If the maximum number is set to 50 (corresponding to erroneous reception), the target iteration number could be in the order of 30-40 or even lower.\nHence, a tradeoff between RoD overhead and power in the BICM decoder (in particular an LDPC decoder) is possible by adjusting the target iteration number.  Thus, a simple approach is provided since no estimation of the number of redundancy bits\nis necessary.\nThe request for TI frames/FEC frames that have not been received by the receiver, but are already known in the RoD server, is suggested, to compensate for network delay.  This is denoted as requesting \"future\" TI frames/FEC frames in the\nfollowing.  Requesting future FEC frames is possible due to the distribution delay in the broadcast network and the decoding delay in the broadcast receiver.  Preferably, the number of frames requested in advance is adjusted depending on the buffer\nstatus of the receiver.  The buffer 311 stores RoD responses instead of IQ/CSI, i.e. when requesting future FEC frames the responses ideally arrive before the IQ/CSI data.  Thus, no additional latency is caused by the RoD if the redundancy is requested\nearly enough in advance.  The time difference for which FEC frames can be requested in advance is obviously limited by the availability of the FEC frames in the RoD server.  If FEC frames are requested too early, they are not known in the RoD server yet. The drawback of requesting future FEC frames is that no adaption to fast channel changes is possible since the adjustment of the redundancy data rate based on the feedback loop is slower compared to the forward loop.  This embodiment is preferably\nsuitable for stationary/portable reception.\nThe feedback loop can also be controlled using the overall MI before LDPC decoding (the target MI is known from code rate) instead of using the number of LDPC iterations.  A corresponding embodiment of a receiver 3h is shown in FIG. 14.\nIn the above different embodiments of a receiver for use in a peer to peer architecture (as shown in FIG. 7) are described.  The present disclosure may also be used in a multicast architecture of the broadband system connecting the RoD server 4'\nand multiple (generally n) RoD clients 34a', 34b', .  . . , 34n' of various receivers as schematically shown in FIG. 15.  In this architecture the RoD server 4' does not generate a response individually for each RoD client 34a', 34b', .  . . , 34n', but\ngenerates a number of separate redundancy data streams with different redundancy data rates, among which a particular RoD client 34a', 34b', .  . . , 34n' can select.\nThe broadband server 4' particularly comprises a data receiving unit 80 configured to receive data (\"ideal data\") 90 from a broadcast transmitter (2 in FIG. 1) of the broadcast system (1 in FIG. 1).  A data conversion unit 81, also called\nreencoder, is provided to convert the received data 90 into at least two (generally m) redundancy data streams 91a, 91b, .  . . , 91m of redundancy data having different redundancy data rates.  At least two (generally m) redundancy data sources 82a, 82b,\n.  . . , 82m (e.g. separate multicast servers, or separate streams, interfaces or channels provided by a single server) are provided for providing one of said at least two redundancy data streams 91a, 91b, .  . . , 91m at a different redundancy data rate\nfor use by a receiver of said broadcast system for correct demodulation and decoding by use of said redundancy data and data received by said receiver via said broadcast system.\nThus, the RoD server 4' generates a (preferably) fixed number m of redundancy data streams with different redundancy data rates (e.g. 10%, 20%, .  . . redundancy data with respect to the payload data rate) which is provided as a multicast\nchannel.  Each RoD client 34a', 34b', .  . . , 34m' then selects the multicast channel corresponding to the actual demand.  The selected redundancy data stream is then transmitted using IP multicast to the subscribed RoD clients, i.e. the RoD clients\nwhich selected this redundancy data stream.\nThe data exchange between the RoD clients and the RoD server 4' including the handshake from an RoD client to the RoD server 4' and the transmission of the redundancy data from the RoD server 4' to an RoD client may generally be made via any\nkind of network 1000, such as an IP network, the internet, a communications network, a computer network, etc.\nThe RoD server 4' preferably further comprises a signalling unit 83 (e.g. a signalling server) configured to signal a redundancy data source address list 92 for use by a receiver (i.e. a RoD client of the receiver) to select a redundancy data\nsource and to subscribe to a selected redundancy data source.  Said redundancy data source address list 92 particularly indicates the addresses of the at least two redundancy data sources 82a, 82b, .  . . , 82m, e.g. their IP addresses.\nThis multicast architecture provides the advantage of a reduced processing load in the RoD server 4', since only limited number (m) of redundancy data streams needs to be generated, but not separate redundancy data for each particular RoD client\nwhich individually requests redundancy data.  Further, the network load (e.g. in IP networks supporting multicast) is reduced since with RoD client specific redundancy data requests (e.g. per FEC packet), as used in a peer to peer architecture, the RoD\nserver 4 could be overloaded with redundancy data request (especially in large networks with a large number of RoD clients).  The resulting overhead depends on the number of redundancy data streams and corresponds to the difference in redundancy data\nrate between two redundancy data streams divided by two, when assuming an equal distribution of the required redundancy data rates amongst all clients.  For instance, in case of a difference of 10% between the redundancy data rates of the redundancy data\nstreams, the required overhead is 5% on average.\nSince the transmission in case of multicast is stream based without a dedicated request/response structure, a simplified signalling solution can be applied.  A standardized way of encapsulating the redundancy data with the given stream data rate\nis hence sufficient.  An example for a signalling interface is may be as follows:\nTABLE-US-00006 Parameter Bits Comment REQUEST_ID (custom) 10 Request counter PLP_ID (L1-config) 8 To identify PLP FRAME_IDX (L1-dynamic) 8 T2-frame ID TI_BLOCK_ID (custom) 8 TI Block ID in T2-frame FEC_FRAME_ID (custom) 8 FECFrame ID in T2-frame\nNUMBER_ROD_BITS 16 RoD Bits per FECFrame (custom) ROD_DATA_VECTOR NUMBER_ROD_BITS Actual RoD data (custom)\nIn the following various embodiments of a receiver for use in a multicast architecture as shown in FIG. 15 will be described with reference to FIGS. 16 to 19.\nFIGS. 16 and 17 show schematic diagrams of embodiments of a receiver 3i and 3j having a forward loop for use in a multicast architecture, which are similar to the receivers 3e and 3f, respectively, shown in FIGS. 11 and 12.  However, with these\nembodiments no request for redundancy data is generated, but a redundancy data stream providing the desired redundancy data rate (or the next highest redundancy data rate to the desired redundancy data rate) is selected in a selection unit 313.\nFIGS. 18 and 19 show schematic diagrams of embodiments of a receiver 3k and 31 having a feedback loop for use in a multicast architecture, which are similar to the receivers 3g and 3h, respectively, shown in FIGS. 13 and 14.  Also with these\nembodiments no request for redundancy data is generated, but a redundancy data stream providing the desired redundancy data rate (or the next highest redundancy data rate to the desired redundancy data rate) is selected in a selection unit 313.  Again,\nsince the selection can be made in advance, the responses arrive before their respective FEC frames.  Hence, the responses are buffered instead of the IQ/CSI data of the FEC frames (as in the receivers 3i and 3j).\nTo achieve best possible picture or data quality when switching between two redundancy data streams with different redundancy data rates, both redundancy data streams might be received simultaneously for the (limited) transition period.\nThe usage of a multicast stream structure with different redundancy data rates may have some implications on the overall system architecture.  For example, the redundancy data streams should be provided with a sufficiently high latency that\nallows all requesting RoD terminals (i.e. receivers) to access their respective redundancy data stream.  Consequently, the latency in output should exceed the highest broadband delay of any terminal (broadband round trip time RTT).  As a possible\nsolution, the terminals that experience RTTs below a certain threshold may access the multicast redundancy data streams, while terminals with very high RTT values may use a peer-to-peer access of redundancy data (i.e. a terminal specific unicast).\nThe multicast signalling address server (i.e. the signalling unit 83 as shown in FIG. 15) might accordingly contain the multicast based redundancy data server address as well as an additional entry for peer-to-peer redundancy data (for terminals\noutside of the required latency threshold).  This latency threshold (i.e. delay of output of multicast redundancy data streams on the broadband path) can be adjusted dynamically, e.g. to maintain a certain percentage of RoD terminals associated to the\nmulticast redundancy data streams.\nIn the following some application scenarios in which embodiments of the present disclosure can be applied will be explained.\nWhen a poor QoS is noticed by the receiver and the availability of the redundancy data is proved, a question may be displayed in a GUI of the receiver for the user asking about whether acquiring redundancy data via broadband network is allowed\nto improve the decoding quality.  Once the user accepts this or does choose for permanent allowance, the presentation of the current media content is paused and the broadcast data stream is buffered for a very short interval to equalize the delays in\nboth networks.  Then the broadcast data stream and redundancy data stream are synchronized and decoded jointly.  Afterwards the media content is displayed without any perceptive errors.\nAnother advantage of the use of redundancy data is the possibility to efficiently counteract time varying distortions like man-made-noise.  Man-made-noise is known to be especially severe in the VHF-Band, causing narrowband as well as broadband\ndistortions that can be either constant over time or time varying.  Especially the impact on the QoS of time varying distortions like impulsive noise, which are e.g. caused by switching events of the mains, can be avoided by means of the concept of\nredundancy data.  Heavy noise impulses typically cause a service dropout, since the error correction (e.g. the forward error correction (FeC) as applied in DVB broadcast systems) is not able to correct such strong distortions.  This is especially the\ncase for OFDM-based systems, as a short noise impulse in the time domain distorts a complete OFDM symbol in the frequency domain, due to the so called noise-buck effect of OFDM.  The VHF band is therefore not used anymore in some countries (like Germany)\nfor digital terrestrial transmission, because of problems with man-made-noise.  The use of redundancy data could allow for the reintroduction of terrestrial broadcasting in the VHF-band in such countries.\nIn current broadcast networks, to achieve a \"quasi-error-free\" (QEF) viewing experience, a certain level of signal-to-noise ratio (SNR) is required.  For receivers which have a poor receiving condition, this SNR threshold cannot be reached, thus\na successful decoding of the broadcast signal would be impossible.  The TV services can only be provided completely by other means, e.g. IPTV and the corrupted broadcast signal has to be discarded.  For the proposed concept of using redundancy data,\nhowever, the amount of additional redundancy is dependent on the quality of the broadcast signal: if the distortion is heavier, more redundancy will be needed; if lighter, then less redundancy will be needed.  In a worst case, if the desired amount of\nredundancy data is even larger than that of the original TV content itself, the TV content will be delivered directly to the receiver as a normal IPTV system (100% broadband).  Therefore, the data size that have to be transmitted as redundancy data is\nalways less than without using this approach.\nCompared to traditional systems, with the concept of redundancy data a soft-transition between pure broadcast and complete IPTV can be realized.  This has an influential impact on the network planning, when a high proportion of the receivers are\ncapable of using this concept.  For instance, if a certain area shall be covered with a terrestrial broadcasting network and a certain data rate shall be provided in the broadcast channel.  Previously, after selecting the network setting (code rate,\nmodulation scheme, etc.) the transmitter power had to be increased to ensure a sufficient SNR at each location in this area.  Now, with the concept of redundancy data the transmitter power can be reduced and the receivers located at edge area can be\nserved with some redundancy data via broadband network, so that their demodulation and decoding of the broadcast signal is also \"quasi-error-free\".  Equivalently, the same transmitter power can be maintained, but modulation and error correction rates\nwith higher spectral efficiencies could be applied.  The transmitter power can be reduced to a level, when a further decrease of power consumption or transmission cost is no more possible.  This power level and the achievable power or cost savings are\ngenerally determined by the viewer number, distribution of receivers, cost factors, man-made-noise and so on.  Most of these parameters are changing temporally, therefore online monitoring, optimization and adaption are preferably used.  For instance,\nthe transmitter power is set to lower level during morning, when less people are watching television.  The lower signal strength is compensated by more redundancy data via the broadband network for the relatively small number of receivers.\nThe relation between the overall power consumption/transmission cost and the transmitter power may look as depicted in FIG. 20.  The optimal operation point moves at different time and changes for different network settings, such that a dynamic\nadaption of the network is meaningful.\nThe proposed ideas can also be applied in a dynamic broadcast system as, for instance, described in US 2013/254828 A1, which is herein incorporated by reference in its entirety.  The so-called dynamic broadcast concept applied in such a dynamic\nbroadcast system describes a flexible terrestrial broadcast system, utilizing an internet broadband connection and a hard disc in the terminal, to optimize the spectrum usage and the power consumption of the transmitter network, by choosing the optimal\ndelivery means depending on the content type (realtime, non-realtime) and the viewer count.  The relationship of the concept of redundancy (on demand) with respect to the dynamic broadcast concept is depicted in FIG. 21 showing a schematic diagram of a\ndynamic broadcast system 100 in which the devices and methods according to the present disclosure can be used.\nThe system 100 involves a broadcast (BC) network, a broadband network (BB), hybrid broadcast broadband (HBB) terminals (receivers) and other wireless communication networks.  Their cooperation is managed by the dynamic broadcast network.  The\nfunctions of the blocks shown in FIG. 21 are explained in the following.\nFirst, the packaging of media content unit 112 is described.  The TV content is provided by broadcasters 110 and is segmented into Real-Time (RT) and Non-Real-Time (NRT) events.  For real-time events, (certain elements of) news programs for\ninstance, their content becomes available only at the announced on-air time, so they have to be delivered live; while for non-real-time events, like movies, music, drama etc., their content may be available in advance, so they can be pre-downloaded. \nWith pre-download (broadcast or broadband) network capacity can be used for instance over night, when capacity has been identified to be available, whereas during daytime and in the evening network capacity will be freed for other uses.  The choice of\ncontent that can be pre-downloaded will be based on rules used in a decision logic 114.  These rules will be generated from usage patterns of viewers derived from information available over the broadband network.  In conjunction with other measures the\ndownload of such material will take place as network capacity becomes available--either over the broadcast or the broadband network.  A program schedule therefore should be created that indicates which content comes over the air in real-time and which\ncontent can be played from the storage device in the user terminal.\nNext, a monitoring and signaling unit 116 is described.  To optimize the network operation, knowledge about actual network usage is important.  Two kinds of information should hence be collected from HBB terminals 118 (also called \"terminals\",\n\"user terminals\" or \"receivers\" hereinafter) and transmitted to the decision logic 114 through broadband connection.  The first kind of information is about whether or not programs or pieces of media content are used and by how many people.  This\npopularity can be estimated by monitoring the watching activities of some or all users, as done in today's IPTV networks.  Knowing the accurate popularity and usage pattern of the media content can help the decision logic 114 determining which content\nshould be delivered via the broadband network and/or pre-downloaded as mentioned above.  The second kind of information is about the momentary technical Quality of Service (QoS) of the transmission links.  This can be obtained with integrated measuring\ndevices in HBB terminals 18.  With information about the actual signal quality, the decision logic 14 can manage the network most efficiently.\nThe signaling which delivers data to the HBB terminals 118 will provide information about content items presented for `delivery in advance` (also called `offline delivery, i.e. delivery in advance of the official broadcast time), the time of the\nbroadcast transmission and/or the time of play out over the broadband network.  It will include a program schedule and it will deliver information about the various parameters selected by the dynamic multiplexing and a joint control unit 120.  The\nsignaling information can be transmitted via both networks and in both push and pull modes, so that the HBB terminals 114 can get the current network information even if it is just switched on for the first time.\nThe decision logic 114 is in charge of the management of the whole network and it aims to keep the operation at a minimal cost while assuring required QoS.  Facilitated with the monitoring reports from the HBB terminals 118, and based on\nadditional business rules, cost functions, realistic constraints etc. the decision logic 114 may change the packaging of real-time and non-real-time events, or command a re-multiplexing of the transport streams in broadcast and broadband channels or\nadjust of the transmission parameters and transmitter power.  Before the decision logic 114 has made any changes to the previous program schedule or network settings, it should acknowledge all HBB terminals 18 about the modification through signalling.\nNext, a multiplexing and content distribution unit 122 is described.  The flexible distribution of media content through broadcast and broadband network requires content items and complete or partial audio, data and video programs to be\nmultiplexed dynamically.  In consequence, the former fixed mapping between transmission parameters and TV programs has to be eliminated.  Information about such re-multiplexing should be signaled to the HBB terminals 118, so that they are able to follow\nthe changes.  By the reason that the popularity of the different TV programs in one transport stream changes continuously, re-multiplexing may take place online, which means some content being transmitted may be reallocated in other physical channels or\nstill in the current channel but with new transmission parameters.  All these actions should be carried out in a way unnoticeable by the users.\nNext, the joint control unit 120 for control of transmission parameters is described.  In traditional digital broadcast systems the modulation of the transmitted signal and the degree of Forward Error Correction (FEC) used are decided once and\nthey then stay stable.  The transmitter power is selected according to the coverage requirements of the network.  In terrestrial networks, the coverage area is defined by the aforementioned parameters and in addition by the coverage pattern determined by\nthe transmit antenna.  This static network planning leads to inefficient usage of the valuable spectrum, because strong time-variant factors like channel popularity and user terminals receiving conditions have not been taken into consideration.\nDynamic multiplexing can reduce the useful data rate transmitted on a specific channel if the multiplex on that channel is not fully loaded with program items at the moment.  Initiated by the decision logic 114 the joint control unit 120 will\nthen change the FEC settings and/or modify the modulation scheme used on that channel.  This will result in an enhanced robustness of the signal which in consequence will allow the transmitter power to be adapted thus reducing the power density--and the\ncost of transmission.  This creates economical benefits, as well as ecological benefits, since the exposure to radiation and carbon emission will be reduced as a consequence of the lowered transmitter power.  In another case, it shall be supposed that\nsignaling provided from user terminals to the broadcast network including information about technical parameters of the received signal in networks indicate a better-than-required or worse-than-required signal quality as a result of changes in man-made\nnoise (i.e. noise generated by any devices used by anybody in the environment)--which has been found to fluctuate greatly and periodically over time--or due to changes in weather conditions.  Initiated by the decision logic 114 the joint control unit 120\nwill modify the parameters (FEC, modulation, transmitter power) in order to accommodate broadcast QoS at a minimum cost.  In addition, the joint control unit 120--in negotiation with dynamic multiplexing via the decision logic 114--will initiate the\nre-configuration of multiplexes such that the data rate transmitted in heavily disturbed channels will be reduced and the robustness of the signal enhanced as required.\nIn the HBB terminal 118 some content will have to be stored \"off-line\" upon receipt of the appropriate downstream signaling and besides, which content to store should also be decided by the HBB terminal 118.  Therefore it should be capable of\npredicting user's preferences, storing relevant TV content automatically and managing the stored content dynamically.  To accomplish this, a recommender system should be implemented in the HBB terminal 118.  On the other hand some content will be made\navailable via the co-operating broadband network.  The HBB terminal 118 will receive a program schedule, and a delivery network indicator which indicate for which period of time and how often this stored content is to be used instead of content that in\ntraditional broadcasting would be received live.  In addition it will be informed via which of the co-operating networks content will be delivered.  The received content from different networks should be managed properly by the HBB terminal 118.  Content\nitems are often interrelated.  This is obviously true for audio and video but in addition, a plethora of data services like software applications are created by the content owners that will have to be available in the terminal 118 and started, paused or\ncancelled in relation to the audio and video content.  Additional downstream signaling information embedded in the broadcast stream is received by the HBB terminal 18, which indicates the dynamic multiplex configurations and the parameters selected by\njoint control.  Upstream signaling will be generated in HBB terminals 118 for transmission on the broadband network.  The user terminal 118 thus becomes an active component of the dynamic broadcast network instead of being a passive device as in\ntraditional broadcasting.\nSpectrum freed by dynamic broadcast can be offered to secondary wireless networks, like Cellular (LTE), Wi-Fi, etc. for a certain period of time.  To avoid interference, usage of the new \"white space\" created by dynamic broadcast should be\ncoordinated through resource signaling which is an output of the dynamic broadcast system 100 and informs wireless network operators about the dynamically chosen parameters of the broadcast network.  It includes also information about the period of\nvalidity of the multiplex configuration and the spectrum resources which will be freed including an indication of the period of time during which the spectrum will be available.\nMore details about the general concept of dynamic broadcast can be found in the above mentioned US 2013/254828 A1 and \"Dynamic broadcast\", Junge Qi; Neumann, Peter; Reimers, U. 2011 14th ITG Conference on Electronic Media Technology (CEMT) pages\n1-6.\nAs the concept of redundancy on demand provides a \"seamless transition\" option between complete broadcast or broadband transmission, it can be efficiently combined with the dynamic broadcast concept, introducing another degree of freedom, so\nthat the dynamic broadcast network can be further optimized in the sense of transmission cost, energy consumption, and spectrum efficiency.  This is indicated in FIG. 21 by the arrow output by the joint control unit 120 that controls the output of RoD\ndata via the broadband network to the HBB terminal 118.\nRedundancy data can also be used in another application as an encryption way to protect the pre-downloaded media content.  The pre-download of the media content can be transmitted with a network configuration of high data rate but week error\ncorrection.  The redundancy data can then be used as a triggering signal to enable the recovery of the original data.\nFurther, conditional access to data can be realized by use of redundancy data.  Conditional access to video services is crucial for pay-TV transmission.  Redundancy data can be used to control the access to pay-TV services by means of the\nbroadband connection.  The corresponding service is transmitted via terrestrial broadcast to achieve low network cost.  However, not the full data rate is transmitted via terrestrial broadcast, but only a specific amount, e.g. like 95% of the data rate. \nThe users that subscribed to the pay-TV service then receive the remaining 5% via the broadband connection as redundancy data.  This allows the network operator for restricting the access to the pay-TV service via the broadband connection only to the\nusers with the corresponding service subscription.  Other users without the additional redundancy data over broadband are not able to decode the service, since the received Mutual Information via terrestrial broadcast is not sufficient for error free\ndecoding.  For this purpose even a slight decrease of the transmitted Mutual Information over the terrestrial broadcast suffices to avoid access of unregistered users to the pay-TV service.\nA schematic diagram of a control device 200 for use in a broadcast system according to the present disclosure is shown in FIG. 22.  Such a control device 200 may e.g. be used as joint control unit 120 in the broadcast system 100 shown in FIG.\n21.  The control device 200 comprises a broadcast control unit 201 and a broadband control unit 202.  The broadcast control unit 201 controls a broadcast transmitter of said broadcast system that broadcasts broadcast signals in a coverage area for\nreception by terminals comprising a broadcast receiver and a broadband receiver.  The broadband control unit 202 controls a broadband server of a broadband system that provides redundancy data to terminals within said coverage area.  The broadband\ncontrol unit 202 is configured to control the provision of redundancy data by said broadband server for use by one or more terminals which use said redundancy data together with broadcast signals received via said broadcast system for recovering content\nreceived within said broadcast signals and/or provided via said broadband system.  Additional optional elements are shown in dashed boxes and will be explained below.\nIn an embodiment said broadcast control unit 201 is configured to change one or more transmission parameters of said broadcast transmitter depending on one or more parameters of a group of parameters comprising the time of the day, the number,\nlocation, profile and/or parameters of active terminals, cost factors of the transmission of data by said broadcast transmitter and/or said broadband server, channel state information (in particular noise and/or reception level) and/or feedback of\nterminals.  Further, said broadband control unit 202 is configured to provide redundancy data to one or more active terminals which receive broadcast signals with insufficient quality and which use said redundancy data to compensate for the insufficient\nquality of reception of broadcast signals.  Optionally, the control device 200 further comprises a monitoring unit 203 that continuously or repeatedly monitors one or more parameters of said group of parameters.\nIn another embodiment said broadcast control unit 201 is configured to control the transmit power and/or one or more physical layer parameters, in particular modulation and/or code rate, parameters of an interleaver and/or an FFT unit, used by\nsaid broadcast transmitter.\nIn another embodiment said broadcast control unit 201 is configured to adaptively change the transmit power and/or the efficiency of the applied modulation and/or code depending on one or more parameters of a group of parameters comprising the\ntime of the day, the number, location, profile and/or parameters of active terminals, cost factors of the transmission of data by said broadcast transmitter and/or said broadband server, channel state information (in particular noise and/or reception\nlevel) and/or feedback of terminals.\nIn another embodiment said broadband control unit 201 is configured to adaptively change the amount of redundancy data transmitted to one or more active terminals depending on one or more parameters of a group of parameters comprising the time\nof the day, the number, location, profile and/or parameters of active terminals, cost factors of the transmission of data by said broadcast transmitter and/or said broadband server, channel state information, noise and/or feedback of terminals,\npreferably depending on the number of active terminals.  Preferably, in this embodiment the broadcast control unit 201 is configured to reduce the transmit power and/or to apply a modulation and/or code with a higher efficiency and said broadband control\nunit is configured to increase the amount of redundancy data transmitted to one or more active terminals if the number of active terminals is below a lower predetermined threshold and/or to decrease the amount of redundancy data transmitted to one or\nmore active terminals if the number of active terminals is above an upper predetermined threshold.  Even further, the amount of redundancy data may be controlled based on the costs of the transmission, i.e. based on an estimation if it is more cost\nefficient to increase or decrease the amount of redundancy data versus use of broadcast for transmitting data.\nStill further, in an embodiment the control device 200 comprises an optional request receiving unit 204, as also shown in FIG. 22, that receives requests for transmission of redundancy data from terminals.  In this embodiment said broadband\ncontrol unit 202 is configured to control the broadband server to provide redundancy data to requesting terminals.  The requests from terminals may generally differ in the quantity of requested redundancy data, the quality of the requests, the use\nprofiles, etc. For instance, there may be premium users (which may have paid an extra service charge), which may always receive an extra amount of redundancy data in order to ensure a high quality of the transmission in all situations.\nIn another embodiment the control device 200 is particularly designed for use in a dynamic broadcast system as shown in FIG. 21, wherein said broadcast control unit 201 and said broadband control unit 202 are configured to dynamically control\ntransmission parameters, transmission times and transmission paths used for broadcasting and providing content by use of said broadcast transmitter configured to broadcast content via said broadcast system and/or said broadband server configured to\nprovide content via said broadband system.  In this embodiment the control device 200 further comprises an optional decision unit 205 (also shown in FIG. 22) that dynamically decides transmission parameters, transmission times and transmission paths used\nfor broadcasting and providing content by use of said broadcast transmitter and for providing content by said broadband server.\nSaid decision unit 205 is preferably configured to dynamically decide transmission parameters, transmission times and transmission paths used for broadcasting and providing content based on monitoring data carrying information on user specific\ncontent usage and/or transmission quality data carrying information on the quality of a transmission link between said broadband server and a terminal and/or of a reception of content broadcast by said broadcast transmitter.\nFurther, said redundancy data is preferably provided for providing a seamless transition between broadcast and broadband reception and/or recovery of content from signals received via said broadcast system and said broadband system.\nIn another embodiment said broadcast control unit 201 and/or said broadband control unit 202 is configured to control said broadcast transmitter and/or said broadband server to transmit content in a form that does not allow complete recovery in\na terminal without the use of redundancy data, and to control the transmission of redundancy data via said broadband system to terminals that shall be enabled to completely recover received content.\nPreferably, in said embodiment said broadcast control unit 201 and/or said broadband control unit 202 is configured to control said broadcast transmitter and/or said broadband server to transmit content in encrypted form and/or with insufficient\nand/or low quality and wherein said redundancy data is provided for being used for decryption and/or increasing the quality of the received content.  For instance, in an exemplary use scenario, via broadcast a \"normal\" (lower) image quality (e.g. in SD\nformat) is obtained, while by use of the redundancy data (which may then be regarded as \"additional data\" or \"auxiliary data\") received via broadband an \"improved\" (higher) image quality (e.g. in HD format) is obtained.\nFurther, in said embodiment said broadcast control unit 201 is preferably configured to control said broadcast transmitter to adaptively change the mutual information between transmitted and received signals to transmit content in a form that\ndoes not allow complete recovery in a terminal without the use of redundancy data.\nA broadcast system 1a comprising such a control device 200 is schematically depicted in FIG. 23.  The broadcast system 1a comprises a broadcast transmitter 2a that broadcasts broadcast signals in a coverage area for reception by terminals 3\ncomprising a broadcast receiver and a broadband receiver.  The broadcast system 1a further comprises a broadband server 4a that provides redundancy data to terminals within said coverage area.  Finally, the broadcast system 1a comprises a control device\n200 as explained above with reference to FIG. 22 that controls said broadcast transmitter 2a and said broadband server 4a.\nIn the following it will be described in more detail how the required amount of redundancy data can be estimated or determined.  In particular, the estimation of the Mutual Information, the estimation of the number of redundancy data bits and\nthe stream synchronization will be described by use of various embodiments.  The following description will refer to elements shown in FIG. 24 depicting the interaction of a broadband server (called RoD server) 4b and a receiver (called terminal in this\nembodiment) 3m used in a broadcast system 1b.\nGenerally, a receiver (see also the above described embodiments of a receiver, e.g. as shown in FIGS. 3, 9 and 10) for receiving data in such a broadcast system comprises a broadcast receiver (31 in FIG. 10) that receives via said broadcast\nsystem a receiver input data stream comprising a plurality of channel symbols represented by constellation points in a constellation diagram, a demodulator (32 in FIG. 10) that demodulates said channel symbols into codewords and a decoder (33 in FIG. 10)\nthat decodes said codewords into output data words.  An optional redundancy calculator (not separately shown in FIG. 3; may be a separate element or included in the broadband request unit 38; separately provided as unit 314 in the receiver 3m shown in\nFIG. 24) determines a required amount of redundancy data for correct demodulation and decoding by use of the originally received channel symbol and additional redundancy data.  A broadband request unit (38 in FIG. 10) requests, if demodulation of a\nchannel symbol and/or decoding of a codeword is erroneous or likely to fail, a required amount of redundancy data via a broadband system and a broadband receiver (37 in FIG. 10) receives redundancy data via said broadband system.  The demodulator and/or\nthe decoder are configured to use said redundancy data to demodulate the respective channel symbol and to decode the respective codeword, respectively.  These elements are generally also provided in the receiver 3m shown in FIG. 24 even if not explicitly\ndepicted.\nThe broadband server 4b for providing redundancy data to a receiver of such a broadcast system via said broadband system generally comprises a receiving unit 401 that receives requests from receivers of said broadcast system via said broadband\nsystem to provide redundancy data to the respective receivers via said broadband system to enable correct demodulation of a channel symbol and/or decoding of a codeword, a request including channel state information, a redundancy calculator 402 that\ndetermines the required amount of redundancy data required for correct demodulation and decoding by use of said channel state information, and a transmitting unit 403 that provides redundancy data in at least said required amount to the receiver that\nrequested redundancy data.\nOne task of a system using redundancy data is to correctly determine the required amount of redundancy data for successful decoding in the terminal (=receiver).  If too few redundancy data is transferred from the redundancy provider (i.e. a\nbroadband server) to the terminal, the decoding process will fail and additional redundancy data need to be requested in a second step.  This causes network overhead and increases the system delay until successful decoding is achieved due to the multiple\nredundancy data requests.  If on the other hand too much redundancy data is transferred to the terminal, the system efficiency is reduced, since data is transmitted via the broadband connection in vain.  The calculation of the correct redundancy data\namount is therefore very important, since it influences the performance of the overall system.\nA possible metric for the estimation of the required redundancy data amount in the receiver is the Mutual Information (MI) between transmitted (code) bits and received soft values, belonging to one codeword (e.g. a FEC word).  The Mutual\nInformation is a figure of merit from stochastic and is especially suited for determining the required amount of redundancy data, since it is independent from the channel characteristics and the modulation order of the QAM constellation, but only depends\non the applied code.  If the code rate of the applied code is e.g. 0.5, decoding is successful if the Mutual Information exceeds the value of 0.5.  However, this only holds for an ideal encoder, operating at the maximum channel capacity (Shannon\ncapacity), which is not possible with practical error correction codes.  For instance, the DVB-T2 64 K LDPC code with a code rate 0.5 requires a Mutual Information of 0.55 for successful decoding.  There are only very slight deviations in the performance\nof this code depending on the modulation order and the channel characteristics.  The required Mutual Information for the utilized codes can be stored in a table in the broadband server or the terminal, such that the required mutual information that needs\nto be transmitted via redundancy data can be calculated in the terminal or the broadband server.  Hence, in an embodiment the redundancy calculator 38 is configured to estimate said required amount of redundancy data based on channel state information\nand/or Mutual Information between transmitted and received data, in particular between transmitted bits of output data words or codewords and received values representing bits of output data words or codewords.\nThere are two locations in the receiver where the log-likelihood ratios (LLRs) can be extracted to calculate the Mutual Information: Either directly after QAM demapping or after FEC decoding.  If the LLRs after FEC decoding are used, less\nredundancy data needs to be transmitted in principal (because FEC decoding, though not successful, increases the reliability of the LLRs).  Using the estimated Mutual Information it is possible to estimate the meaningfulness to perform FEC decoding. \nWhen the Mutual Information is clearly lower than the required Mutual Information for FEC decoding, FEC decoding should be omitted.  This is the case because on the one hand the Mutual Information increase by the FEC decoder is typically negligible in\nsuch situations, especially for state-of-the-art FEC codes like LDPC or turbo codes, and on the other hand this allows a reduction of the power consumption of the terminal.\nThe Mutual Information is determined based on the Log-Likelihood-Ratios (LLR) at the output of the QAM-demapper and is a good measure if the following FEC is able to successfully decode the FEC codeword.  An LLR is defined here as\n.times..function..function.  ##EQU00001## The Mutual Information of a single Bit based on its LLR value is defined as MI=1-log 2(1+e.sup.-inputLLR) If transmitted bit=1: MI=1-log 2(1+e.sup.+inputLLR).  If transmitted bit=0:\nThe Mutual Information is typically averaged over one FEC block to decide if successful decoding is possible.  However, the knowledge of the transmitted bit is required for the calculation, which is not available in a receiver.  To avoid the\nneed for the reference data for the calculation of the Mutual Information, the formula is weighted by the linear probability that a 1 or a 0 is transmitted, respectively.  The linear probability (in the range [0,1]) that a 1 is transmitted is calculated\nfrom its LLR value by\n##EQU00002##\nAfter weighting the initial Mutual Information formulas (assuming bit 1 or bit 0 was transmitted) with the probability p and l-p, respectively, the following formulas are resulting: MI.sub.1=1-p*log 2(1+e.sup.-inputLLR) MI.sub.0=1-(1-p)*log\n2(1+e.sup.+inputLLR) The estimated Mutual Information without reference is then resulting from their sum MI.sub.estimated=MI.sub.1+MI.sub.0=1-p*log 2(1+e.sup.-inputLLR)+1-(1-p)*log 2(1+e.sup.+inputLLR)1-p*log 2(1+e.sup.-inputLLR)+1-(1-p)*log\n2(1+e.sup.+inputLLR)\nThe comparison of the Mutual Information estimation with its ideal values is shown in FIG. 25 for different channel models and modulation sizes with a large amount of averaged bits and ideal channel knowledge.  It can be observed that estimated\nMutual Information exactly corresponds to the ideal Mutual Information.  In practice, the Mutual Information is estimated for a particular codeword (or a Time Interleaver Frame, consisting of several codewords), which results in a smaller amount of bits\navailable for averaging.  This would result in some degradation of the estimation.  Other metrics to compute the amount of required redundancy can be the estimated signal-to-noise ratio (SNR), the average absolute value of the LLRs or the estimated\nmodulation error rate (given by the deviation of the received QAM symbols to the possible transmit QAM symbols).\nBased on the estimated mutual information the required number of bits for the redundancy data transmission to the receiver needs to be calculated.  This can be done without knowledge of the channel state information (CSI), or taking the CSI into\naccount.  If CSI is available at the broadband server, the bits that experienced strong attenuation from the transmission channel are preferably transmitted first.  If no CSI is available this is not possible.\nTo allow for optimum performance of iterative FEC codes, the transmitted redundancy data bits should be uniformly distributed over the FEC codeword.  This avoids that the transmitted redundancy data is only located e.g. at the beginning of the\nFEC codeword.  This can be achieved by means of a pseudo random address generator that generates the addresses of the bits within the FEC codeword selected for transmission.  Thanks to the random nature of the generated addresses the selected bits are\nuniformly distributed within the FEC codeword.  The random address generator must be known to both the broadband server and the receiver, to allow for unambiguous decoding in the receiver based on the transmitted redundancy data bits.  In case of the\ntransmission of least robust bits (e.g. LSBs) first, as explained in an embodiment above, the random addresses of the least robust bits of all QAM symbols that carry a FEC codeword are used for generating the redundancy data bits first.  Afterwards the\nsecond least robust bits are used, and so on, until the required amount of redundancy data bits is reached.\nThe calculation of the amount of required redundancy data bits is carried out in the receiver, based on the estimated Mutual Information and the required Mutual Information for successful decoding of the utilized FEC code.  The required Mutual\nInformation is known for all code rates (see e.g. FIG. 25 for 64 K LDPC of rate 1/2) by simulation and are stored in the server and the receiver.  Depending on the resulting SNR of each received QAM symbol (determined by the CSI), the additional Mutual\nInformation can be calculated that results in the receiver when a particular bit is perfectly known.  This additional Mutual Information is added to the available Mutual Information for each pseudo randomly generated bit location until the threshold of\nthe overall Mutual Information for error free decoding is reached.  By this means, the number of required redundancy data bits can be assessed in the receiver and a request with this number of bits is sent to the broadband server.  The broadband server\nthen uses the same pseudo random address generator to generate the redundancy data bits in the receiver.\nAs random address generator a linear feedback shift register (LFSR) with a polynomial representing a maximum length sequence (MLS) can be used.  For instance for a FEC block size of 64800 the register values generated by a 16-bit LFSR with a\ncycle length of 2.sup.16-1=65535 could be used.  However, only register values smaller or equal to 64800 are used as bit addresses, since the usage of the modulo-operator to truncate larger values could lead to a manifold generation of the same bit\naddress.  Other algorithms like the Mersenne-Twister can be used as well, but are not that simple to implement compared to an LFSR.  Preferably, the requested bits are only information bits in case the FEC code is systematic.  It shall be assumed that\nthe channel completely erased a codeword (of N bits--where K bits are information bits, i.e., the code rate is K/N).  In this case, instead of requesting the complete codeword again (N&gt;K), it would be sufficient to retransmit only the information bits\n(K).\nThe required number of bits in the receiver can then be computed based on the knowledge of the current Mutual Information.  Iteratively new pseudo random bit addresses are generated of bits that are transmitted as redundancy.  After each newly\ngenerated bit the additional Mutual Information is calculated that results from ideally knowing the additional bit at the generated address in the receiver.  The additional Mutual Information is easily accessible from a look up table that can be\npre-computed by means of Monte Carlo Simulation.  Based on the additional Mutual Information the current Mutual Information is updated by adding the additional Mutual Information.  This is iteratively repeated until the current Mutual Information exceeds\nthe required Mutual Information for successful decoding.  In pseudo code the algorithm for the calculation of the number of required bits in the receiver is the following:\nTABLE-US-00007 RoD bits to request = 0 while (current mutual information &lt; required mutual information) { generate bit address within FEC codeword; look up additional mutual information for QAM symbol from LUT current mutual information =\ncurrent mutual information + additional mutual information RoD bits to request = RoD bits to request + 1; }\nIn short: The algorithm describes a method to estimate the number of retransmitted pseudo random information bits (i.e. without utilizing the channel state information) for error free decoding.\nAll Mutual Information here corresponds to bitwise mutual information, such that the values are normalized to 1 to allow for direct comparison with the required mutual information value independent of the modulation order.\nThe table of the additional mutual information per QAM symbol depending on the number of known redundancy data bits within the QAM symbol is stored in the receiver as a look up table (LUT), e.g. in the storage 40.  The additional mutual\ninformation depends on the SNR of the QAM symbol that carries the bit, and the bits that are known within the QAM symbol.  For instance a LUT that stores the additional mutual information for the SNR range of 1 up to 30 dB for 256-QAM requires\n30*256=7680 entries.  If it is assumed that the LSBs are transmitted first, and so on, only 30*8=240 entries are required, since only 8 states are possible for each QAM symbol (1 bit known, .  . . , 8 bits known).  The values of the LUT entries are\ndetermined by Monte-Carlo simulation in advance, based on the formula of the ideal Mutual Information.\nSince the LSBs of QAM symbols carry less Mutual Information and are therefore well suited as redundancy data bits, it is meaningful to optimize the algorithm such that it first generates the bit addresses of the LSBs, then the addresses of the\nbits with the next lower order within the QAM symbols (LSB-1), and so on.  By this means the bits with the highest order, providing the most additional Mutual Information, are transmitted first, reducing the required number of redundancy bits.\nThus, in such an embodiment the redundancy calculator 314 is configured to estimate said required amount of redundancy data based on a comparison between estimated Mutual Information and required Mutual Information for correct demodulation and\ndecoding.  For estimating the Mutual Information a mutual information estimation unit 308 is preferably provided.  Further, in an embodiment a storage 315 is additionally provided that stores the required Mutual Information for a plurality of codes, in\nparticular for a plurality of code rates and/or codeword lengths.\nAccordingly the redundancy calculator 402 of the broadcast server 4b is preferably configured to estimate said required amount of redundancy data based on channel state information and/or Mutual Information between transmitted and received data,\nin particular between transmitted bits of output data words or codewords and received values representing bits of output data words or codewords.  Further, the redundancy calculator 402 is preferably configured to estimate said required amount of\nredundancy data based on a comparison between estimated Mutual Information and required Mutual Information for correct demodulation and decoding.  Still further, preferably a storage 404 is provided that stores the required Mutual Information for a\nplurality of codes, in particular for a plurality of code rates and/or codeword lengths.\nThe algorithm above requires a lot of computations to determine the number of required bits, since the mutual information must be calculated for every additional bit per QAM symbol, to reflect the actual noise of each QAM symbol.  However, the\nalgorithm can be simplified by assuming an average noise level throughout the FEC codeword.  Based on the average noise level the average additional Mutual Information is calculated for the current bit order (LSBs transmitted first).  Based on the\naverage Mutual Information the number of additional bits is calculated to provide the amount of required Mutual Information for error free decoding.  If the number of required bits of this bit order is not sufficient, all bits of this bit order are\nflagged for transmission and this is the same is then iteratively calculated for the next bit order, and so on.  If the current bit order provides enough bits to bridge the remaining gap to the required Mutual Information, the number of redundancy bits\nis calculated by adding the (N/M) bits for each bit order that is completely transmitted, plus the additionally required bits of the current bit order.  This algorithm requires only one calculation for each of the M bit levels, instead of one calculation\nper bit, since the additional Mutual Information for each bit order is assumed to be the same throughout all (N/M) bits of this bit order.  The pseudocode for this simplified calculation of the required number of bits is the following:\nTABLE-US-00008 If (current MI &lt; required MI) { missing MI = required MI - current MI; for (int i = 0; i &lt; M; i++) { get additional MI from LUT (additional MI per QAM symbol if i+1 Bits are known instead of only i Bits, assuming an average\nSNR for all QAM symbols) calculate the number of required QAM symbols to bridge the gap of missing MI if one additional bit is known if (number of required QAM symbols &lt; N/M) { RoD bits to request = i * (N/M) + number of required QAM symbols; break; }\nelse { current MI = current MI + additional MI * (N/M) missing MI = required MI - current MI; } } }\nIn short: The algorithm describes a method to estimate the number of retransmitted pseudo random information bits (i.e. without utilizing the channel state information) for error free decoding, with reduced computational complexity but also\nreduced accuracy compared to algorithm 1.\nThus, in such an embodiment the redundancy calculator 314 of the receiver 3m is configured to determine an average additional Mutual Information for a channel symbol and to add said average additional Mutual Information to available Mutual\nInformation for each bit location of a particular codeword until a threshold of an overall Mutual Information required for correct decoding is reached and to determine the required amount of redundancy data required for correct decoding of said\nparticular codeword based thereon.  Accordingly, the redundancy calculator 402 of the broadband server 4b is configured to determine an average additional Mutual Information for a channel symbol and to add said average additional Mutual Information to\navailable Mutual Information for each bit location of a particular codeword until a threshold of an overall Mutual Information required for correct decoding is reached and to determine the required amount of redundancy data required for correct decoding\nof said particular codeword based thereon.\nAlternatively, the following calculation of the required number of redundancy based on estimated Mutual Information can be used, if it is assumed that the redundancy consists of already transmitted code bits.\nThe estimated Mutual Information shall be denoted as MI.sub.old, the required number of redundancy data as n, the number of bits in the codeword as N (e.g., N=64800 in a 64 k LDPC).  The new Mutual Information MI.sub.new after n (already\ntransmitted) redundant bits have been re-transmitted via a unicast system (generally, the broadband system) is then obtained by:\n##EQU00003##\nThe n redundant bits from the broadband server are received with substantially perfect knowledge, since a unicast system can guarantee error-free transmission.  The formula is due to the mixing property of the EXIT chart, see \"A. Ashikhmin, G.\nKramer, and S. ten Brink, \"Extrinsic information transfer functions: model and erasure channel properties,\" IEEE Trans.  Inform.  Theory, vol. 50, no. 11, pp.  2657-2673, November 2004.\nFrom the previous formula, it is obtained:\n.times..times.&gt; ##EQU00004## n will be lower bounded by 0 (if MIold&gt;MInew) and upper bounded by the number of information bits K in the codeword, if MInew is set to the code rate (or slightly above) R=K/N, in case MIold=0.\nIn short: The formula computes the amount n of redundancy that has to be retransmitted.  The new Mutual Information is computed, which is the weighted sum of the old Mutual Information and perfect Mutual Information for those n bits, and\ncompared with the desired Mutual Information that is required for successful decoding.\nIf the CSI of the receiver is available at the broadband server, the calculation of the required redundancy data bits can alternatively be carried out in the server.  The receiver then first transmits the CSI to the server (a possible CSI\ncompression scheme is described below).  Based on the SNR of each QAM symbol (determined from the CSI), the server is able to find the bit in the FEC codeword by means of the LUT that provides the largest additional mutual information.  This way the bits\nthat experienced deep fading are used first as redundancy data bits, since the additional mutual information of these bits is the largest.  The algorithm is very similar to the algorithm without CSI knowledge.  The important difference is that instead of\npseudo random bits, the bits providing the maximum additional information are used as redundancy bits.  This is iteratively repeated until the threshold of the required Mutual Information for error free decoding is reached.  The algorithm for the\ncalculation of the redundancy data bits in the server based on the receivers CSI in pseudo code is the following:\nTABLE-US-00009 RoD bits to request = 0 while (current MI &lt; required MI) { for (all bits in FEC codeword) { find bit with maximum additional MI (by means of LUT) } current MI = current MI + additional MI RoD bits to request = RoD bits to\nrequest + 1; }\nIn short: The algorithm describes a method to estimate the number of retransmitted bits for error free decoding, based on the channel state information, with optimum performance, but high computational complexity.\nThus, in such an embodiment the redundancy calculator 314 is configured to add additional Mutual Information resulting in the receiver, when a particular bit is known, to available Mutual Information for each bit location of a particular\ncodeword until a threshold of an overall Mutual Information required for correct decoding is reached and to determine the required amount of redundancy data required for correct decoding of said particular codeword based thereon.  Preferably, said\nredundancy calculator 314 is configured to determine said additional Mutual Information for several or all bits of a channel symbol.  Also in such an embodiment the receiver 3m preferably comprises a storage 315 that stores said additional Mutual\nInformation for a plurality of codes, in particular for a plurality of code rates and/or codeword lengths.\nAccordingly, in such an embodiment the redundancy calculator 402 is configured to add additional Mutual Information resulting in the receiver, when a particular bit is known, to available Mutual Information for each bit location of a particular\ncodeword until a threshold of an overall Mutual Information required for correct decoding is reached and to determine the required amount of redundancy data required for correct decoding of said particular codeword based thereon.  Further, preferably the\nredundancy calculator 402 is configured to determine said additional Mutual Information for several or all bits of a channel symbol.  Still further, preferably a storage 404 is provided that stores said additional Mutual Information for a plurality of\ncodes, in particular for a plurality of code rates and/or codeword lengths.  In still another embodiment the redundancy calculator 402 is configured to use bits of a channel symbol providing the maximum additional Mutual Information, resulting in the\nreceiver, when a particular bit is known, as redundancy data.  In a similar way, the receiver could, using channel state information, determine the required number of bits of a channel symbol providing the maximum additional Mutual Information.\nThe broadband server then transmits the redundancy data bits to the receiver via broadband, which is then able to calculate the positions of the redundancy data bit within the FEC codeword with the same algorithm that has been used in the\nredundancy data server to generate the bits.  The receiver is then able to recombine and decode the FEC codeword.\nTo reduce the number of comparisons to find the optimal bit from the LUT, the LSBs only can be transmitted first, then the bits at bit position LSB-1 within the QAM symbol, and so on, since these bits have a high probability to carry the lowest\nMutual Information.  This is neglected in the pseudo code for simplicity.\nIn principle it is also possible to determine the number of required bits based on other parameters like SNR or MER.  However, SNR and MER do not allow for such an accurate estimation taking the CSI into account.  Rough numbers for the required\nRoD amount must be stored in the server and receiver that have been determined by simulation for different delta SNR values (required SNR-actual SNR).  That is, the estimation of the required number of redundancy data bits based on SNR or MER is less\naccurate compared to the Mutual Information and therefore not well suited here.\nIn the following synchronization between receiver and broadband server will be explained.\nThe signaling about how the received data must be combined in the receiver generally takes place in the broadband network.  As a result the frame structure employed in the broadcast network does not necessarily need any extension.  However, at\nthe physical layer an identification of the FEC-encoded data segments is required for the synchronization between the data from both terrestrial and broadband networks.  Besides, at the application layer the redundancy data can be signaled as an\nadditional service, therefore a linkage to the respective original service shall be given.\nCurrent terrestrial broadcasting systems like DVB-T or DVB-T2 contain no suitable mechanism for a unique identification of FEC packets/BBFrames, although the available timestamp of DVB-T2 (ISSY counter) might be applicable to some extent. \nHowever the limited time range of the ISSY counter might prevent a reliable packet identification An unambiguous mechanism is therefore required to inform the broadband server, which BBFrames could not be correctly decoded.  One solution would e.g. be a\ncounter related to each FEC packet, whose value is increased after each FEC packet, allowing for the unique identification of a FEC packet.  If it is intended to introduce the concept of using redundancy (on demand; RoD) in broadcasting systems without\nsuch unique packet identification alternative approaches need to be used.  A specific amount of soft-information (LLR) values of the LDPC or BCH parity block (in case of DVB-T2) of the erroneous packet can be used as a fingerprint that identifies the\npacket.  This is possible, since even a slight difference in the payload between packets leads to different parity blocks.  Based on the sequence of LLR values, the broadband server can perform a correlation to achieve the synchronization.  This allows\nfor the synchronization between broadband server and the receiver even if the required SNR in the receiver is too low to decode any FEC packets correctly.\nThus, in an embodiment of a broadband server 4c depicted in FIG. 26 it comprises, in addition to the elements of the broadband server 4b shown in FIG. 24, an identification unit 405 that identifies a data packet for which redundancy data shall\nbe determined by use of a correlation using soft information values of data of said data packet, in particular of parity data, contained in a request received from a receiver, wherein said redundancy calculator 402 is configured to use the information\nabout the identity of the data packet to determine redundancy data for said data packet.  In the same way, the receiver could identify the data packet to which received redundancy data belong based on the correlation using soft information of the\ndemodulator and/or the decoder.\nIf the receiver was already able to decode some FEC packets, the transmission of soft-information for correlation in the broadband server is not necessary, since a subset of the parity blocks of correctly decoded preceding FEC packets can be\nused for packet identification.  In such cases the known and hard decided fingerprint of the last correctly received packet and the number of erroneous packets is transmitted to the broadband server, which then sends the required amount of redundancy for\nthe requested packets.  For this identification approach even a small amount of bits is sufficient, since no correlation in the receiver is required.  It must only be assured that the fingerprint uniquely identifies the FEC packet.  Assuming that the\nparity blocks are binary sequences with equal distribution, the probability that a fingerprint sequence with length n is not unique for m preceding FEC packets is\n.times..times..times.  ##EQU00005##\nBased on this formula the required number of bits can easily be calculated for a given maximum misdetection probability p and the number of FEC packets the identification is carried out with.  The misdetection probability p is given in the\nfollowing table for exemplary values of m and n. It becomes clear that increasing the fingerprint length m, decreases the probability for misdetection.\nTABLE-US-00010 n m 8 16 24 32 40 48 56 64 2 3.91E-03 1.53E-05 5.96E-08 2.33E-10 9.09E-13 3.55E-15 1.39E-17 5.42E-20 10 1.63E-01 0.00068644 2.68E-06 1.05E-08 4.09E-11 1.60E-13 6.25E-16 2.44E-- 18 25 0.702147 0.00456774 1.79E-05 6.98E-08 2.73E-10\n1.07E-12 4.16E-15 1.63E-- 17 100 1 0.0727845 0.000295 1.15E-06 4.50E-09 1.76E-11 6.87E-14 2.68E-16 250 1 0.378447 0.00185348 7.25E-06 2.83E-08 1.11E-10 4.32E-13 1.69E-15 1000 1 0.999529 0.0293343 0.000116292 4.54E-07 1.77E-09 6.93E-12 2.71E-14 2500 1 1\n0.169892 0.00072704 2.84E-06 1.11E-08 4.34E-11 1.69E-13 10000 1 1 0.949234 0.0115729 4.55E-05 1.78E-07 6.94E-10 2.71E-12\nHowever, the success rate can be further increased if the frame number and the number of the FEC block within the frame are transmitted.\nThus, in such an embodiment of a broadband server 4c depicted in FIG. 26 the identification unit 405 identifies a data packet for which redundancy data shall be determined by use of a number of bits, in particular parity bits, of the last\ncorrectly decoded codewords contained in a request received from a receiver.  Further, the redundancy calculator 402 is configured to use the information about the identity of the data packet to determine redundancy data for said data packet.  In another\nembodiment a packet counter or a timestamp (ISSY) can be used for packet identification.\nIn the following cooperative decoding with distributed receivers will be explained.\nMost TV devices nowadays are integrated with terrestrial broadcast receiver.  But the TV devices work alone with the locally received signals.  However, as home networks are being installed in more and more household, the receivers can be\nconnected to each other as well, so that a cooperative decoding of the broadcast signal becomes realizable.  A space-diversity will be created when the receivers can carry out the decoding jointly and thus an improvement of the signal quality will also\nbe possible.  This concept is operating without a server that has perfect knowledge of the transmitted signal.  Instead the redundancy data is generated in a cooperative fashion.  In some embodiments of cooperative decoding, one or more receivers may act\nas servers.\nIn the embodiment of a broadcast system shown in FIG. 27, n receivers Rx1, Rx2, .  . . , R are connected via a server, which may be located separately or together with one of the receivers.  After receiving the broadcast signal each receiver\nchecks whether and where (temporally or spectrally) redundancy data is required and makes a request to the server.  Having the requests from each receiver, the server requires the necessary data from each receiver, encode it, and distribute it to the\nreceivers that need it.\nAssuming an example with two receivers, Rx1 and Rx2, three cases may happen to each signal part (temporally or spectrally).\n1.  Both receivers can decode it correctly by themselves.  No data exchange is needed in this case.\n2.  Both receivers cannot decode it correctly by themselves.  The LLRs of the signal are quantized and transmitted to the server, who adds them together and multicasts the signal to both receivers.  Afterwards the receivers precede the decoding\nprocess with help of the received LLRs.  3.  One receiver can decode it correctly by itself while the other not.  In best case, another signal part can be found where the situation is reversed and the LLRs of these two signal parts can be added and\nforwarded by the server.  Then each receiver can achieve the desired part by subtracting their own signal (network coding alike).\nFor example:\nFehler! Es ist nicht moglich, durch die Bearbeltung von Feldfunktionen Objekte zu erstellen.\nRx1 send S2 and Rx2 send S1' to the server.  The server transmitted then S2+S1 back to each receiver, which can get the desired signal with subtraction.\nSuch a broadcast system thus comprises a broadcast transmitter that broadcasts broadcast signals in a coverage area for reception by terminals comprising a broadcast receiver and a broadband receiver, a broadband server that provides redundancy\ndata to terminals within said coverage area, and one or more terminals comprising a broadcast receiver and a broadband receiver, wherein said broadband server is configured to obtain redundancy data required by a terminal from one or more other\nterminals.\nThe information exchange can take place autonomously when the receivers are somehow connected to each other (e.g. by a home network via Ethernet) such that a distributed network is resulting.  This approach is shown in FIG. 28.  In this case,\nthe server is not necessary and data request, coding and flow control are controlled by receivers themselves.  Such a broadcast system thus comprises a broadcast transmitter that broadcasts broadcast signals in a coverage area for reception by terminals\ncomprising a broadcast receiver and a broadband receiver, and one or more terminals comprising a broadcast receiver, wherein said terminals are configured to obtain redundancy data required by a terminal from one or more other terminals.\nObviously, numerous modifications and variations of the present disclosure are possible in light of the above teachings.  It is therefore to be understood that within the scope of the appended claims, the disclosure may be practiced otherwise\nthan as specifically described herein.\nIn the claims, the word \"comprising\" does not exclude other elements or steps, and the indefinite article \"a\" or \"an\" does not exclude a plurality.  A single element or other unit may fulfill the functions of several items recited in the claims. The mere fact that certain measures are recited in mutually different dependent claims does not indicate that a combination of these measures cannot be used to advantage.\nIn so far as embodiments of the disclosure have been described as being implemented, at least in part, by software-controlled data processing apparatus, it will be appreciated that a non-transitory machine-readable medium carrying such software,\nsuch as an optical disk, a magnetic disk, semiconductor memory or the like, is also considered to represent an embodiment of the present disclosure.  Further, such a software may also be distributed in other forms, such as via the Internet or other wired\nor wireless telecommunication systems.\nThe elements of the claimed devices and apparatus may be implemented by corresponding hardware and/or software elements, for instance appropriated circuits.  A circuit is a structural assemblage of electronic components including conventional\ncircuit elements, integrated circuits including application specific integrated circuits, standard integrated circuits, application specific standard products, and field programmable gate arrays.  Further a circuit includes central processing units,\ngraphics processing units, and microprocessors which are programmed or configured according to software code.  A circuit does not include pure software, although a circuit includes the above-described hardware executing software.\nAny reference signs in the claims should not be construed as limiting the scope.\nIt follows a list of further embodiments of the disclosed subject matter:\n1.  A receiver for receiving data, comprising:\na broadcast receiver configured to receive, via a broadcast system, a receiver input data stream comprising a plurality of channel symbols represented by constellation points in a constellation diagram,\na demodulator configured to demodulate said channel symbols into codewords,\na decoder that configured to decode said codewords into output data words,\na redundancy unit configured to select or request via a broadband system, if demodulation of a channel symbol and/or decoding of a codeword is erroneous or likely to fail, redundancy data for demodulation of future channel symbols and/or\ndecoding of future codewords,\na broadband receiver configured to obtain said redundancy data via said broadband system,\nwherein said demodulator and/or said decoder is configured to use the obtained redundancy data to demodulate the respective future channel symbols and to decode the respective future codewords, respectively.\n2.  The receiver as defined in one of the preceding embodiments,\nwherein said redundancy unit comprises a selection unit configured to select one of at least two redundancy data sources providing redundancy data at different redundancy data rates.\n3.  The receiver as defined in one of the preceding embodiments,\nwherein said redundancy unit comprises a broadband request unit configured to request an amount of redundancy data from a redundancy data source via said broadband system.\n4.  The receiver as defined in one of the preceding embodiments,\nwherein said redundancy unit comprises a quality detector configured to identify the quality of received channel symbols and said redundancy unit is configured to select or request redundancy data based on the identified quality.\n5.  The receiver as defined in one of the preceding embodiments,\nwherein said redundancy unit comprises a redundancy calculator configured to determine a required amount of redundancy data required for correct demodulation of future channel symbols and correct decoding of future codewords by use of obtained\nredundancy data and wherein said redundancy unit is configured to select or request redundancy data based on the required amount of redundancy data.  6.  The receiver as defined in one of the preceding embodiments, wherein said redundancy unit is\nconfigured to select or request redundancy data based on channel state information and/or Mutual Information between transmitted and received data.  7.  The receiver as defined in one of the preceding embodiments, wherein said redundancy unit is\nconfigured to select or request redundancy data based on the number of decoding iterations so that a target iteration number is reached.  8.  A receiver for receiving data, comprising:\na broadcast receiver configured to receive, via a broadcast system, a receiver input data stream comprising a plurality of channel symbols represented by constellation points in a constellation diagram,\na demodulator configured to demodulate said channel symbols into codewords,\na decoder that configured to decode said codewords into output data words,\na selection unit configured to select, if demodulation of a channel symbol and/or decoding of a codeword is erroneous or likely to fail, one of at least two redundancy data sources providing redundancy data at different redundancy data rates via\na broadband system for correct demodulation and decoding by use of the originally received channel symbol and additional redundancy data, and\na broadband receiver configured to obtain said redundancy data via said broadband system,\nwherein said demodulator and/or said decoder is configured to use the obtained redundancy data to demodulate the respective channel symbols and to decode the respective codewords, respectively.\n9.  The receiver as defined in one of the preceding embodiments,\nwherein said selection unit is configured to select a multicast redundancy server or a multicast redundancy data stream as redundancy data source.\n10.  The receiver as defined in one of the preceding embodiments,\nwherein said selection unit is configured to subscribe to a selected redundancy data source for providing redundancy data.\n11.  The receiver as defined in embodiment 10,\nwherein said selection unit is configured to select a redundancy data source based on a redundancy data source address list indicating the addresses of the at least two redundancy data sources and to subscribe to a selected redundancy data\nsource by forwarding an identification of the receiver to the selected redundancy data source.  11a.  The receiver as defined in one of the preceding embodiments, wherein it is configured to access a multicast redundancy data stream if it experiences\nround trip delays below a predetermined threshold and to use a peer-to-peer access of redundancy data if it experiences round trip delays above said predetermined threshold.  12.  A broadband server for providing redundancy data to a receiver of a\nbroadcast system via a broadband system, comprising:\na data receiving unit configured to receive data from a broadcast transmitter of said broadcast system,\na data conversion unit configured to convert the received data into at least two redundancy data streams of redundancy data having different redundancy data rates,\nat least two redundancy data sources each configured to provide one of said at least two redundancy data streams at a different redundancy data rate for use by a receiver of said broadcast system for correct demodulation and decoding by use of\nsaid redundancy data and data received by said receiver via said broadcast system.\n13.  The broadband server as defined in embodiment 12,\nwherein said data receiving unit is configured to receive data that have been or will be broadcasted by the broadcast transmitter and wherein said data conversion unit is configured to generate the at least two redundancy data streams from said\ndata.\n14.  The broadband server as defined in one of the preceding embodiments 12 to 13, further comprising a signalling unit configured to signal a redundancy data source address list for use by a receiver to select a redundancy data source and to\nsubscribe to a selected redundancy data source, said redundancy data source address list indicating the addresses of the at least two redundancy data sources.  15.  The broadband server as defined in one of the preceding embodiments 12 to 14, wherein\nsaid at least two redundancy data sources comprise at least two multicast redundancy servers.  16.  The broadband server as defined in embodiment 15, wherein each of said at least two multicast redundancy servers is configured to multicast its redundancy\ndata stream receivers that have selected said redundancy data stream.  17.  A receiving method for receiving data, comprising:\nreceiving, via a broadcast system, a receiver input data stream comprising a plurality of channel symbols represented by constellation points in a constellation diagram,\ndemodulating said channel symbols into codewords,\na decoding said codewords into output data words,\nselecting or requesting via a broadband system, if demodulation of a channel symbol and/or decoding of a codeword is erroneous or likely to fail, redundancy data for demodulation of future channel symbols and/or decoding of future codewords,\nobtaining said redundancy data via said broadband system,\nwherein said demodulating and/or said decoding is configured to use the obtained redundancy data to demodulate the respective future channel symbols and to decode the respective future codewords, respectively.\n18.  A receiving method for receiving data, comprising:\nreceiving, via a broadcast system, a receiver input data stream comprising a plurality of channel symbols represented by constellation points in a constellation diagram,\ndemodulating said channel symbols into codewords,\ndecoding said codewords into output data words,\nselecting, if demodulation of a channel symbol and/or decoding of a codeword is erroneous or likely to fail, one of at least two redundancy data sources providing redundancy data at different redundancy data rates via a broadband system for\ncorrect demodulation and decoding by use of the originally received channel symbol and additional redundancy data, and\nobtaining said redundancy data via said broadband system,\nwherein said demodulating and/or said decoding is configured to use the obtained redundancy data to demodulate the respective channel symbols and to decode the respective codewords, respectively.\n19.  A method for providing redundancy data to a receiver of a broadcast system, comprising:\nreceiving data from a broadcast transmitter of a broadcast system,\nconverting the received data into at least two redundancy data streams of redundancy data having different redundancy data rates, and\nproviding said at least two redundancy data streams at a different redundancy data rate for use by a receiver of said broadcast system for correct demodulation and decoding by use of said redundancy data and data received by said receiver via\nsaid broadcast system.\n20.  A non-transitory computer-readable recording medium that stores therein a computer program product, which, when executed by a processor, causes the method according to embodiment 17, 18 or 19 to be performed.\n21.  A computer program comprising program code means for causing a computer to perform the steps of said method according to embodiment 17, 18 or 19 when said computer program is carried out on a computer.", "application_number": "15544346", "abstract": " A receiver for receiving data in a broadcast system includes a broadcast\n     receiver configured to receive, via the broadcast system, a receiver\n     input data stream including a plurality of channel symbols represented by\n     constellation points in a constellation diagram. A demodulator\n     demodulates the channel symbols into codewords and a decoder decodes the\n     codewords into output data words. A redundancy unit selects or requests,\n     if demodulation of a channel symbol and/or decoding of a codeword is\n     erroneous or likely to fail, redundancy data for demodulation of future\n     channel symbols and/or decoding of future codewords via a broadband\n     system and a broadband receiver obtains the redundancy data via the\n     broadband system. The demodulator and/or the decoder is configured to use\n     the obtained redundancy data to demodulate the respective future channel\n     symbols and to decode the respective future codewords, respectively.\n", "citations": ["8775908", "8887030", "9385752", "9444582", "9692630", "20010017900", "20040114576", "20100260179", "20120254684", "20130254828", "20150236818"], "related": []}, {"id": "20180046968", "patent_code": "10318900", "patent_name": "Job profile generation based on intranet usage", "year": "2019", "inventor_and_country_data": " Inventors: \nCarter; Brian T. (Navan, IE), Cronin; Patrick J. (Cork, IE), Dunning; Paul C. J. (Ratoath, IE), Quigley; Shane (Dublin, IE)  ", "description": "<BR><BR>BACKGROUND\nThe present invention relates generally to for the field of data processing, and more particularly to job profile generation.\nA job profile, or job description, is a document that presents a summary of information related to a particular employment role, such as responsibilities, necessary skills, desired skills, and required education and credentials.  A sufficiently\ndescriptive job profile may be used by hiring personnel to successfully fill an open position by identifying and prioritizing desired candidate skills.  Furthermore, application requirements included within a job profile may help job candidates determine\ntheir eligibility for an open position prior to submitting an application.\n<BR><BR>SUMMARY\nEmbodiments of the present invention disclose a method, computer program product, and system for job profile generation, the method, computer program product, and system include receiving employee intranet usage data, storing the employee\nintranet usage data in a database, identifying a portion of the employee intranet usage data which is associated with the former employee, transmitting the portion to a recommender system, where the recommender system identifies one or more required job\nskills of the former employee, based on the transmitted portion, and generating a job profile based on the one or more identified required job skills. <BR><BR>BRIEF DESCRIPTION OF THE DRAWINGS\nThe following detailed description, given by way of example and not intended to limit the invention solely thereto, will best be appreciated in conjunction with the accompanying drawings, in which:\nFIG. 1 depicts a functional block diagram of a networked computer environment, in accordance with an embodiment of the present invention;\nFIG. 2 depicts a flowchart of operational steps of a job profile generation program within the data processing environment of FIG. 1, in accordance with an embodiment of the present invention;\nFIG. 3 depicts a block diagram of internal and external components of computers and servers of FIG. 1, in accordance with an embodiment of the present invention;\nFIG. 4 depicts a cloud computing environment, in accordance with an embodiment of the present disclosure; and\nFIG. 5 depicts abstraction model layers, in accordance with an embodiment of the present invention.\nThe drawings are not necessarily to scale.  The drawings are merely schematic representations, not intended to portray specific parameters of the invention.  The drawings are intended to depict only typical embodiments of the invention.  In the\ndrawings, like numbering represents like elements.\n<BR><BR>DETAILED DESCRIPTION\nDetailed embodiments of the claimed structures and methods are disclosed herein; however, it can be understood that the disclosed embodiments are merely illustrative of the claimed structures and methods that may be embodied in various forms. \nThis invention may, however, be embodied in many different forms and should not be construed as limited to the exemplary embodiments set forth herein.  In the description, details of well-known features and techniques may be omitted to avoid\nunnecessarily obscuring the presented embodiments.\nReferences in the specification to \"one embodiment\", \"an embodiment\", \"an example embodiment\", etc., indicate that the embodiment described may include a particular feature, structure, or characteristic, but every embodiment may not necessarily\ninclude the particular feature, structure, or characteristic.  Moreover, such phrases are not necessarily referring to the same embodiment.  Further, when a particular feature, structure, or characteristic is described in connection with an embodiment,\nit is submitted that it is within the knowledge of one skilled in the art to affect such feature, structure, or characteristic in connection with other embodiments whether or not explicitly described.\nIn the interest of not obscuring the presentation of embodiments of the present invention, in the following detailed description, some processing steps or operations that are known in the art may have been combined together for presentation and\nfor illustration purposes and in some instances may have not been described in detail.  In other instances, some processing steps or operations that are known in the art may not be described at all.  It should be understood that the following description\nis rather focused on the distinctive features or elements of various embodiments of the present invention.\nEmbodiments of the present invention are related to the field of data processing, and more particularly to job profile generation.  The following described exemplary embodiments provide a system, method, and program product to, among other\nthings, create an employee job profile based on an employee's intranet usage.  Therefore, the present embodiment has the capacity to improve the technical field of job profile generation by assisting users, for example, human resources employees,\nidentify candidates with skills closely matching those of former and leaving employees, which may ensure a newly hired employee is a better fit within the team.  Additionally, employer resources expended to fill a job opening may be reduced as less time\nmay be spent generating a job profile manually and interviewing unqualified applicants.\nAs previously described, a job profile, or job description, is a document that presents a summary of information related to a particular employment role, such as responsibilities, necessary skills, desired skills, and required education and\ncredentials.  A sufficiently descriptive job profile may be used by hiring personnel to successfully fill an open position by identifying and prioritizing desired candidate skills.  Furthermore, application requirements included within a job profile may\nhelp job candidates determine their eligibility for an open position prior to submitting an application.\nTypically, job postings may include generic attributes.  For example, a job posting may include a basic, company-specific job profile, a list of necessary job skills, a list of employer-desired skills, a required educational degree level,\nrequired candidate credentials, and fluency in certain languages.\nGeneric job postings may attract candidates without specific skills important to the job role.  Additionally, generic job postings may not include hidden skills which the former or leaving employee frequently utilized to fulfil job requirements. For example, an original employee hired under a generic job posting, such as for a Java developer, may use and develop skills not included in the original posting, for example, design a Single Sign-On for a project.  The newly used and developed skills\nshould ideally be added to either the necessary skills or the desired skills in the job profile in order to identify desired candidate skills, and increase the chance that a backfill or candidate for an open position is as effective as the previous\nemployee.\nFurthermore, generic job postings may not identify specific skills used by a team in order to make their product or service effective.  For example, a human resources department may lack requisite knowledge of the specific job requirements\nnecessary for a qualified candidate and may spend time and resources to generate an accurate job description.  Job postings that lack specific skill requirements may unnecessarily waste employer resources by interviewing job candidates who do not possess\nnecessary skills for an open position.  Additionally, candidate resources may be wasted due to the candidate lacking a clear understanding of the job requirements or possessing unrealistic expectations of the work environment.  As such, it may be\nadvantageous to, among other things, implement a system to identify and prioritize desired candidate skills by analyzing a former or leaving employee's intranet usage.\nThe present invention generally relates to data processing and more specifically to job profile generation.  One way to generate a job profile may be to utilize evolutionary algorithms.  An embodiment by which to use evolutionary algorithms to\ngenerate a job profile is described in detail below by referring to the accompanying drawings in FIGS. 1 to 5.  Those skilled in the art will readily appreciate that the detailed description given herein with respect to these figures is for explanatory\npurposes as the invention extends beyond these limited embodiments.\nIn order to generate an effective job profile for a leaving employee, an intranet history of the leaving employee can be analyzed and used to create a job profile.  The job profile may useful in identifying job candidates to fill the job opening\nleft by the leaving employee.  Furthermore, the skills and effectiveness of the previous employee can be identified by using evolutionary algorithms to generate the job profile based on the leaving employee's intranet history.  An employer may create an\nintranet of a local or restricted communications network for employee use.\nEvolutionary algorithms can be used to generate the job profile.  In artificial intelligence, an evolutionary algorithm is a subset of evolutionary computation.  Evolutionary computation is a generic population-based metaheuristic optimization\nalgorithm.  Evolutionary algorithms are designed to take a generic population and use a mechanism inspired by nature, e.g. mutation, reproduction, recombination, or selection, to create new generations of the population which steadily improve problem\nsolving or fulfilling a particular criteria based off a fitness function.  A type of evolutionary algorithm used in this method is grammatical evolution.  Grammatical evolution is an evolutional search algorithm typically used to generate a program\nfragment that may achieve a good fitness value for a given objective function.\nAn accurate job profile may assist in identifying qualified job candidates with skills closely matching those of the leaving employee.  Qualified job candidates may prove to be better replacements for a leaving employee within a team.  An\naccurate job profile may also help reduce the amount of time spent by a hiring employee responsible for interviewing applicants by eliminating those applicants without the required skills for the job opening.  Additionally, current employees may not need\nto spend as much time on-boarding and training new hires with necessary and desired skills.  Furthermore, more specific job qualifications may be included within a job profile to assist applicants determine their eligibility for an open position prior to\nsubmitting an application.\nFurthermore, as previously described, a company using accurate job postings generated using evolutionary algorithms may utilize fewer resources hiring new employees possessing necessary job skills since the hiring employee may spend less time\nidentifying qualified candidates.  Additionally, the evolutionary algorithms could be used to create accurate job profiles of all current employees.  Such profiles may be useful in a variety of circumstances, such as when a team is expanding and planning\nto hire an additional employee or when an employee is out-of-office and coverage is needed for the employee's duties.\nFurthermore, third party tools capable of tagging or identifying keywords in an intranet search history, and which lend to the use of keywords that can be used in the generation of a job posting, may be used to create an accurate job profile. \nThird party tools capable of tagging abilities may include a collaborative change management tool, such as IBM.RTM.  Rational Team Concert.TM.  (IBM Rational Team Concert and all IBM Rational Team Concert-based trademarks and logos are trademarks or\nregistered trademarks of International Business Machines Corporation and/or its affiliates), a business social network, such as IBM.RTM.  Connections.TM.  (IBM Rational Team Concert and all IBM Rational Team Concert-based trademarks and logos are\ntrademarks or registered trademarks of International Business Machines Corporation and/or its affiliates), and internet search systems.  Such third party tools or systems may assist in ingesting tracking data about employees to be used in job postings.\nReferring now to FIG. 1, a functional block diagram illustrating a system 100 in a networked computer environment, in accordance with an embodiment of the present invention, is shown.  The system 100 may include a client computing device 102 and\na server 112.  The client computing device 102 may communicate with the server 112 via a network 114.  The client computing device 102 may include a processor 104, a data storage device 106, a job profile generation program 110A, and a recommender system\n118A.  The client computing device 102 may be enabled to run the job profile generation program 110A.  The job profile generation program 110A may communicate with and utilize the recommender system 118A.  The client computing device 102 may be enabled\nto interface with a user and communicate with the server 112.\nThe server 112 may also include a processor, a database 116, a job profile generation program 110B and a recommender system 118B.  The server 112 may be enabled to run the job profile generation program 110B.  The job profile generation program\n110B may communicate with and utilize the recommender system 118B.\nIn an embodiment, the client computing device 102 may operate as an input device that includes a user interface while the job profile generation program 110B may run primarily on the server 112.  In an alternative embodiment, the job profile\ngeneration program 110A may run primarily on the client computing device 102 while the server 112 may be used for processing a storage of data used by the job profile generation program 110A.  The job profile generation program 110A may be substantially\nthe same as the job profile generation program 110B.\nIn an embodiment, the recommender system 118B may run primarily on the server 112.  In an alternative embodiment, the recommender system 118A may run primarily on the client computing device 102 while the server 112 may be used for processing a\nstorage of data used by the recommender system 118A.  The recommender system 118A may be substantially the same as the recommender system 118B.  The recommender system 118A may run primarily on the client computing device 102 while the job profile\ngeneration program 110A, 110B may run primarily on either the client computing device 102 or the server 112.  Alternatively, the recommender system 118B may run primarily on the server 112 while the job profile generation program 110A, 110B may run\nprimarily on either the client computing device 102 or the server 112.\nProcessing for the job profile generation program 110A, 110B may, in some instances, be shared amongst the client computing device 102 and the server 112 in any ratio.  In another embodiment, the job profile generation program 110A, 110B may\noperate on more than one server 112, client computing device 102, or some combination of servers 112 and client computing devices 102, for example, a plurality of client computing devices 102 communicating across the network 114 with a single server 112.\nThe network 114 may include wired connections, wireless connections, fiber optic connections, or some combination thereof.  In general, the network 114 can be any combination of connections and protocols that will support communications between\nthe client computing device 102 and the server 112.  The network 114 may include various types of networks, such as, for example, a local area network (LAN), a wide area network (WAN) such as the Internet, a telecommunication network, a wireless network,\na public switched network and/or a satellite network.\nIn various embodiments, the client computing device 102 and the server 112 may be, for example, a laptop computer, tablet computer, netbook computer, personal computer (PC), a desktop computer, a personal digital assistant (PDA), a smart phone,\na mobile device, or any programmable electronic device capable of communicating with the server 112 and the client computing device 102, respectively, via the network 114.  Additionally, the server 112 may also operate in a cloud computing service model,\nsuch as Software as a Service (SaaS), Platform as a Service (PaaS), or Infrastructure as a Service (IaaS).  The server 112 may also be located in a cloud computing deployment model, such as a private cloud, community cloud, public cloud, or hybrid cloud. As described below with reference to FIG. 3, the client computing device 102 and the server 112 may each include internal and external components.  In other embodiments, the server 112 may be implemented in a cloud computing environment, for example,\ncloud computing nodes 510, as described in relation to FIGS. 4 and 5 below.  Similarly, the client computing device 102 may be implemented in the cloud computing environment, for example, laptop computer 540C as shown in FIG. 4.\nIn an embodiment, the system 100 may include any number of client computing devices 102 and/or servers 112; however only one of each is shown for illustrative purposes only.  It may be appreciated that FIG. 1 provides only an illustration of an\nimplementation and does not imply any limitations with regard to the environments in which different embodiments may be implemented.  Many modifications to the depicted environments may be made based on design and implementation requirements.\nThe system 100 may be generally configured to perform actions to generate a job profile.  The job profile generation program 110A, 110B and associated methods, and the recommender system 118A, 118B, are described and explained in further detail\nbelow with reference to FIGS. 2-5.\nReferring now to FIG. 2, an operational flowchart of a job profile generation process 200 is depicted, according to an embodiment.  A method for job profile generation may include receiving employee intranet usage data by the job profile\ngeneration program 110A, 110B and storing employee intranet usage data, in step 202.  The employee intranet usage data may include, for instance, version control systems and internal social networks.  The intranet usage data may also include information\ncollected from tracking each employee's interactions with the intranet, such as websites visited and the associated link for each website, commands executed, text entered, searches executed, and other interactions with the intranet.  The granularity of\nthe stored employee intranet usage data may be configured by a user.  For example, a high level of granularity of storing the employee intranet usage data may include storing an employee's browsing history, click path on an intranet page and words typed\nin a fillable entry box.  Alternatively, a low level of granularity may include a click path on an intranet page, but not a browsing history or words typed in a fillable entry box.\nThe user may determine that specific websites or employee actions be included in the stored employee intranet usage data, while other websites or employee actions may not be included.  For example, known programs and/or applications may be\nincluded, such as an application website, while a human resources department intranet website may not be included in the stored employee intranet usage data.  The employee intranet usage data may be stored, for example, in the data storage device 106, or\nthe database 116, both as shown in FIG. 1.  Alternatively, the employee intranet usage data may be stored in an external database.\nIdentifying an employee who has left the company may be performed in step 204.  The position of the former employee may require the hiring of a replacement employee, and a job profile may need to be created to assist in the identification of\nrequired qualifications of potential candidates to fill the open position.  Alternatively, an employee who is planning to leave the company may be identified, or an additional employee may be needed who possesses skills similar to an existing employee. \nThe open position may be identified by a company human resources department, a hiring manager, or by other means.\nIdentifying the intranet usage data of the former employee from the stored employee intranet usage data may be performed at step 206.  The former employee intranet usage data may be copied into, for example, the data storage device 106, or the\ndatabase 116, if the intranet usage data was stored in an external database.  The former employee intranet usage data may be formatted in a table as follows:\nTABLE-US-00001 Date Event Associated Performed Description Associated Link Tags Keywords Dec.  4, commit of http:// Ethical PBKDDFF2, 2008 PBKDDFF2 projectAmanager/ hacking, ODF, implementation workitem23 high, ODF projectA\nIn the formatted example above, a first column, date performed, shows a date of an event in the former employee intranet usage data.  A second column, event description, is a description of an action of the former employee.  In this example, the\nformer employee executed a program.  A third column, associated link, identifies a web address at which the former employee performed the event.  A fourth column, associated tags, shows any system tags which may be associated with the associated link, or\nthe event description.  The associated tags may help to categorize the associated link or event description, however, a particular event may not have any associated tags.  Additionally, the associated tags may be generated by the job profile generation\nprogram 110A, 110B by using machine learning.  In an alternate embodiment, a user may create the associated tags and manually enter each associated tag into the job profile generation program 110A, 110B.  Furthermore, machine learning may be utilized to\nupdate the associated tags by the job profile generation program 110A, 110B over time.  The fifth column, keywords, may include keywords associated with the event description, the associated link, or the associated tags that may help categorize the\nevent.  The keywords may be generated by the job profile generation program 110A, 110B, and may be created by a user or obtained by another method, such as data mining.\nThe formatting of the table may be performed by the job profile generation program 110A, 110B, or by an external program.  Words associated with each event description may be transformed into a set of associated tags and an associated link.  The\ntransformation may be performed by aggregating all adjectives and nouns together.  Duplicate event descriptions may be removed and an occurrence number identified for each event.  The occurrence number for each event may be a number of times the same\nevent description has occurred.  The resulting events may each be stored as a metadata variable, which may be stored in database 116.\nFiltering of the former employee intranet usage data may be performed at step 208.  Filtering of the former employee intranet usage data may include removing website information, which is common to all employees.  For example, a companywide\ntraining utilized by all employees, such as a business conduct guidelines review, may be common to all employees and filtered out.  The scale of the filtering may be dependent on a company size.  For example, a large company with diverse job types may\nrequire more filtering of the intranet usage of the former employee.  Alternatively, a small company which has many employees with a similar job role may require less filtering.\nTransmitting the filtered intranet usage data of the former employee through a recommender system 118A, 118B, as shown in FIG. 1, may be performed at step 210.  The recommender system 118A, 118B may produce a list of skills related to job\nresponsibilities of the former employee.\nThe recommender system 118A, 118B, or recommendation system, is a subclass of an information filtering system that may predict a weight, a rating, to an item which may be assigned by a user.  The item may be an item from a group of items, or the\nitem may be a list from a group of lists.  In an example, the item may be a list or a set of keywords, phrases, or associated tags.  The recommender system 118A, 118B may also be a natural computing system which can be trained by using sample sets or\nlists of historical events.  The training or learning may be performed by running the recommender system 118A, 118B repetitively using intranet usage data of sample employees, and comparing the recommender system 118A, 118B results with a corresponding\nan employee-provided skill set.\nIn an embodiment, the recommender system 118A, 118B may be trained using several sample lists.  The several sample lists may include terms which are randomly generated from associated tags and keywords from events from the employee intranet\nusage data for a current employee.  Each of the terms may be associated with a skill.  The association of a term with a skill may be performed by the job profile generation program 110A, 110B, by the recommender system 118A, 118B, or by a user.  The\nrecommender system 118A, 118B may identify a best list of the several sample lists.  The best list may contain terms which may be related to skills which most closely align with a list of skills provided by the current employee.  Training may be repeated\nwith additional current employees, in order to improve the accuracy of the recommender system 118A, 118B.  This training may help improve the identification of a list of skills related to job responsibilities of a selected employee.\nDuring operation, the recommender system 118A, 118B may randomly generate several sample lists that each contain terms or groups of words.  The terms may come from the associated tags and the keywords from the filtered intranet usage data of the\nformer employee.  Occurrence information as well as a date performed of each event may help to give a weight or assign a relative importance to each term of the set of terms.  For example, associated tags and keywords of a recently occurring event may\nhave greater weight than associated tags and keywords of an older event, while associated tags and keywords of a particular event description with a higher occurrence number may have a greater weight than associated tags and keywords of another event\ndescription.\nThe recommender system 118A, 118B may compare random subsets of lists of the several sample lists, and assign a rating to each list of the subsets of lists.  The rating may be based on comparison of the terms in each list of the subsets of where\na higher rating may indicate a higher probability that a list of the multiple lists is more likely to contain terms more closely related to an employee-provided list of skills.\nThe recommender system 118A, 118B may perform the comparison for several generations, for example, 40 generations, of comparing random subsets of lists.  The random subsets of lists may be ranked based on a probability that each list aligns with\nthe required skills and the preferred skills performed by the former employee.\nIn an embodiment, multiple randomly generated lists of roughly equal size to an average size of a skill list may be created by the recommender system 118A, 118B.  For example, 1,000 randomly generated lists may each include 10 associated tags\nand keywords.  The recommender system 118A, 118B may identify a weight or rank to each of the several sample lists.  The recommender system 118A, 118B may identify a best list of the several sample lists to be the most likely to contain terms most\nclosely related to the job skills of the former employee.  The recommender system 118A, 118B may be able to identify a best list of necessary skills and a best list of desired skills most closely related to the job skills of the former employee.\nThe ranking or comparison of each list may take into account a fitness function associated with each list.  The fitness function may compare terms of each list to terms associated with an employee-generated skill list and a higher fitness\nfunction may indicate a closer match of terms.  The ranking or comparison of each list also take into account a Backus-Naur Form Grammar.  The Backus-Naur Form Grammar is a set of rules which define a language, which is used to define the words used in\neach list.  Crossover is when two lists are combined to generate an offspring list.  The point of the grammar is that crossover can occur at any of the point with a bar symbol, \"|\", as shown in the equation below.  If a grammar is not used, crossover\ncould potentially occur in the middle of associated words, or between an adjective and its noun if they were grouped together as a skill.\nIn an example, the Backus-Naur Form Grammar and Fitness Function may be used as a basis for an evolutionary algorithm, as shown below: Backus-Naur Form Grammar: &lt;skill_list&gt;::=&lt;skill&gt; &lt;separator&gt;\n&lt;skill_list&gt;|&lt;skill&gt; &lt;skill&gt;::=&lt;adjective&gt;|&lt;noun&gt;|&lt;adjective&gt; &lt;noun&gt; Fitness Function: Result=(skill match effectiveness*every matched skill-unmatched word effectiveness*every unmatched word)*(average date of\nskill list-day of leaving/days in the company)*(occurrence effectiveness*average occurrence)\nIn this example, occurrence effectiveness, the skill match effectiveness, and the unmatched word effectiveness may each be a real value between 0 and 1, where each variable has an initial value of 1.  Additionally, the occurrence effectiveness,\nthe skill match effectiveness, and the unmatched word effectiveness may be adjusted over time by the job profile generation program 110A, 110B, the recommender system 118A, 118B, or by a user.  In an embodiment, the skill match effectiveness and the\nunmatched word effectiveness may be different numbers to prevent multiplication by zero, which would remove the relevance of the remaining data.  Once optimal, or close to optimal, variables have been found and verified as correct to a reasonable\npercentage against a separate training set, the algorithm may be used as a system to generate a list of skills based on a list of events, described above, representing an employee's intranet history.\nOnce created by the recommender system 118A, 118B, the best list of skills of the former employee may be transmitted to the job profile generation program 110A, 110B.\nGenerating a job profile may then be performed by the job profile generation program 110A, 110B, at step 212.  The best list of skills can be edited and merged into a generic recruitment template to provide the job profile for the open position\nof the former employee.  The job profile may be a specific list of the required skills and preferred skills to assist the user when recruiting candidates for the open position.\nOnce created by the job profile generation program 110A, 110B, the job profile may be posted on a recruitment web site, either internal or external, to assist in finding potential candidates to fill the job opening for the open position.\nIn an alternate embodiment a team may be expanding and require an additional employee or a new hire, or alternatively, a temporary employee is needed due to a leave of absence.  Therefore, the job profile generation program 110A, 110B may use\nthe employee intranet usage data of one or more employees in a similar position to the new hire, or of the employee on a temporary leave of absence to identify a list of required skills and generate a job profile.\nReferring now to FIG. 3, a block diagram of components of a computing device, such as the client computing device 102 or the server 112, of the system 100 of FIG. 1, in accordance with an embodiment of the present invention is shown.  It should\nbe appreciated that FIG. 3 provides only an illustration of an implementation and does not imply any limitations with regard to the environments in which different embodiments may be implemented.  Many modifications to the depicted environment may be\nmade.\nThe computing device may include one or more processors 402, one or more computer-readable RAMs 404, one or more computer-readable ROMs 406, one or more computer readable storage media 408, device drivers 412, read/write drive or interface 414,\nnetwork adapter or interface 416, all interconnected over a communications fabric 418.  Communications fabric 418 may be implemented with any architecture designed for passing data and/or control information between processors (such as microprocessors,\ncommunications and network processors, etc.), system memory, peripheral devices, and any other hardware components within a system.\nOne or more operating systems 410, and one or more application programs 411, for example, the job profile generation program 110A, 110B, are stored on one or more of the computer readable storage media 408 for execution by one or more of the\nprocessors 402 via one or more of the respective RAMs 404 (which typically include cache memory).  In the illustrated embodiment, each of the computer readable storage media 408 may be a magnetic disk storage device of an internal hard drive, CD-ROM,\nDVD, memory stick, magnetic tape, magnetic disk, optical disk, a semiconductor storage device such as RAM, ROM, EPROM, flash memory or any other computer-readable tangible storage device that can store a computer program and digital information.\nThe computing device may also include a R/W drive or interface 414 to read from and write to one or more portable computer readable storage media 426.  Application programs 411 on the computing device may be stored on one or more of the portable\ncomputer readable storage media 426, read via the respective R/W drive or interface 414 and loaded into the respective computer readable storage media 408.\nThe computing device may also include the network adapter or interface 416, such as a TCP/IP adapter card or wireless communication adapter (such as a 4G wireless communication adapter using OFDMA technology).  Application programs 411 on the\ncomputing device may be downloaded to the computing device from an external computer or external storage device via a network (for example, the Internet, a local area network or other wide area network or wireless network) and network adapter or\ninterface 416.  From the network adapter or interface 416, the programs may be loaded onto computer readable storage media 408.  The network may comprise copper wires, optical fibers, wireless transmission, routers, firewalls, switches, gateway computers\nand/or edge servers.\nThe computing device may also include a display screen 420, a keyboard or keypad 422, and a computer mouse or touchpad 424.  Device drivers 412 interface to display screen 420 for imaging, to keyboard or keypad 422, to computer mouse or touchpad\n424, and/or to display screen 420 for pressure sensing of alphanumeric character entry and user selections.  The device drivers 412, R/W drive or interface 414 and network adapter or interface 416 may comprise hardware and software (stored on computer\nreadable storage media 408 and/or ROM 406).\nThe programs described herein are identified based upon the application for which they are implemented in a specific embodiment of the invention.  However, it should be appreciated that any particular program nomenclature herein is used merely\nfor convenience, and thus the invention should not be limited to use solely in any specific application identified and/or implied by such nomenclature.\nIt is to be understood that although this disclosure includes a detailed description on cloud computing, implementation of the teachings recited herein are not limited to a cloud computing environment.  Rather, embodiments of the present\ninvention are capable of being implemented in conjunction with any other type of computing environment now known or later developed.\nCloud computing is a model of service delivery for enabling convenient, on-demand network access to a shared pool of configurable computing resources (e.g., networks, network bandwidth, servers, processing, memory, storage, applications, virtual\nmachines, and services) that can be rapidly provisioned and released with minimal management effort or interaction with a provider of the service.  This cloud model may include at least five characteristics, at least three service models, and at least\nfour deployment models.\nCharacteristics of cloud computing include on-demand self-service, broad network access, resource pooling, rapid elasticity, and measured service, which are each described below.\nOn-demand self-service: a cloud consumer can unilaterally provision computing capabilities, such as server time and network storage, as needed automatically without requiring human interaction with the service's provider.\nBroad network access: capabilities are available over a network and accessed through standard mechanisms that promote use by heterogeneous thin or thick client platforms (e.g., mobile phones, laptops, and PDAs).\nResource pooling: the provider's computing resources are pooled to serve multiple consumers using a multi-tenant model, with different physical and virtual resources dynamically assigned and reassigned according to demand.  There is a sense of\nlocation independence in that the consumer generally has no control or knowledge over the exact location of the provided resources but may be able to specify location at a higher level of abstraction (e.g., country, state, or datacenter).\nRapid elasticity: capabilities can be rapidly and elastically provisioned, in some cases automatically, to quickly scale out and rapidly released to quickly scale in. To the consumer, the capabilities available for provisioning often appear to\nbe unlimited and can be purchased in any quantity at any time.\nMeasured service: cloud systems automatically control and optimize resource use by leveraging a metering capability at some level of abstraction appropriate to the type of service (e.g., storage, processing, bandwidth, and active user accounts). Resource usage can be monitored, controlled, and reported, providing transparency for both the provider and consumer of the utilized service.\nService Models include Software as a Service, Platform as a Service, and Infrastructure as a Service, which are each described below.\nSoftware as a Service (SaaS): the capability provided to the consumer is to use the provider's applications running on a cloud infrastructure.  The applications are accessible from various client devices through a thin client interface such as a\nweb browser (e.g., web-based e-mail).  The consumer does not manage or control the underlying cloud infrastructure including network, servers, operating systems, storage, or even individual application capabilities, with the possible exception of limited\nuser-specific application configuration settings.\nPlatform as a Service (PaaS): the capability provided to the consumer is to deploy onto the cloud infrastructure consumer-created or acquired applications created using programming languages and tools supported by the provider.  The consumer\ndoes not manage or control the underlying cloud infrastructure including networks, servers, operating systems, or storage, but has control over the deployed applications and possibly application hosting environment configurations.\nInfrastructure as a Service (IaaS): the capability provided to the consumer is to provision processing, storage, networks, and other fundamental computing resources where the consumer is able to deploy and run arbitrary software, which can\ninclude operating systems and applications.  The consumer does not manage or control the underlying cloud infrastructure but has control over operating systems, storage, deployed applications, and possibly limited control of select networking components\n(e.g., host firewalls).\nDeployment Models include private cloud, community cloud, public cloud, and hybrid cloud, which are each described below.\nPrivate cloud: the cloud infrastructure is operated solely for an organization.  It may be managed by the organization or a third party and may exist on-premises or off-premises.\nCommunity cloud: the cloud infrastructure is shared by several organizations and supports a specific community that has shared concerns (e.g., mission, security requirements, policy, and compliance considerations).  It may be managed by the\norganizations or a third party and may exist on-premises or off-premises.\nPublic cloud: the cloud infrastructure is made available to the general public or a large industry group and is owned by an organization selling cloud services.\nHybrid cloud: the cloud infrastructure is a composition of two or more clouds (private, community, or public) that remain unique entities but are bound together by standardized or proprietary technology that enables data and application\nportability (e.g., cloud bursting for load-balancing between clouds).\nA cloud computing environment is service oriented with a focus on statelessness, low coupling, modularity, and semantic interoperability.  At the heart of cloud computing is an infrastructure that includes a network of interconnected nodes.\nReferring now to FIG. 4, illustrative cloud computing environment 500 is depicted.  As shown, cloud computing environment 500 includes one or more cloud computing nodes 510 with which local computing devices used by cloud consumers, such as, for\nexample, personal digital assistant (PDA) or cellular telephone 540A, desktop computer 540B, laptop computer 540C, and/or automobile computer system 540N may communicate.  Cloud computing nodes 510 may communicate with one another.  They may be grouped\n(not shown) physically or virtually, in one or more networks, such as Private, Community, Public, or Hybrid clouds as described hereinabove, or a combination thereof.  This allows cloud computing environment 500 to offer infrastructure, platforms and/or\nsoftware as services for which a cloud consumer does not need to maintain resources on a local computing device.  It is understood that the types of computing devices 54A-N shown in FIG. 5 are intended to be illustrative only and that cloud computing\nnodes 510 and cloud computing environment 500 can communicate with any type of computerized device over any type of network and/or network addressable connection (e.g., using a web browser).\nReferring now to FIG. 5, a set of functional abstraction layers provided by cloud computing environment 500 (for example, the network 114 of FIG. 1) is shown.  It should be understood in advance that the components, layers, and functions shown\nin FIG. 5 are intended to be illustrative only and embodiments of the invention are not limited thereto.  As depicted, the following layers and corresponding functions are provided:\nHardware and software layer 660 includes hardware and software components.  Examples of hardware components include: mainframes 661; RISC (Reduced Instruction Set Computer) architecture based servers 662; servers 663; blade servers 664; storage\ndevices 665; and networks and networking components 666.  In some embodiments, software components include network application server software 667 and database software 668.\nVirtualization layer 670 provides an abstraction layer from which the following examples of virtual entities may be provided: virtual servers 671; virtual storage 672, for example the data storage device 106 and the database 116 as shown in FIG.\n1; virtual networks 673, including virtual private networks; virtual applications and operating systems 674; and virtual clients 675.\nIn an example, management layer 680 may provide the functions described below.  Resource provisioning 681 provides dynamic procurement of computing resources and other resources that are utilized to perform tasks within the cloud computing\nenvironment.  Metering and Pricing 682 provide cost tracking as resources are utilized within the cloud computing environment, and billing or invoicing for consumption of these resources.  In an example, these resources may include application software\nlicenses.  Security provides identity verification for cloud consumers and tasks, as well as protection for data and other resources.  User portal 683 provides access to the cloud computing environment for consumers and system administrators.  Service\nlevel management 684 provides cloud computing resource allocation and management such that required service levels are met.  Service Level Agreement (SLA) planning and fulfillment 685 provide pre-arrangement for, and procurement of, cloud computing\nresources for which a future requirement is anticipated in accordance with an SLA.\nWorkloads layer 690 provides examples of functionality for which the cloud computing environment may be utilized.  Examples of workloads and functions which may be provided from this layer include: mapping and navigation 691; software\ndevelopment and lifecycle management 692; virtual classroom education delivery 693; data analytics processing 694; transaction processing 695; and employee job profile generation 696.  Employee job profile generation 696 may relate to using employee\nintranet usage data to generate a job profile, for example, the job profile generation program 110A, 110B.\nThe present invention may be a system, a method, and/or a computer program product at any possible technical detail level of integration.  The computer program product may include a computer readable storage medium (or media) having computer\nreadable program instructions thereon for causing a processor to carry out aspects of the present invention.\nThe computer readable storage medium can be a tangible device that can retain and store instructions for use by an instruction execution device.  The computer readable storage medium may be, for example, but is not limited to, an electronic\nstorage device, a magnetic storage device, an optical storage device, an electromagnetic storage device, a semiconductor storage device, or any suitable combination of the foregoing.  A non-exhaustive list of more specific examples of the computer\nreadable storage medium includes the following: a portable computer diskette, a hard disk, a random access memory (RAM), a read-only memory (ROM), an erasable programmable read-only memory (EPROM or Flash memory), a static random access memory (SRAM), a\nportable compact disc read-only memory (CD-ROM), a digital versatile disk (DVD), a memory stick, a floppy disk, a mechanically encoded device such as punch-cards or raised structures in a groove having instructions recorded thereon, and any suitable\ncombination of the foregoing.  A computer readable storage medium, as used herein, is not to be construed as being transitory signals per se, such as radio waves or other freely propagating electromagnetic waves, electromagnetic waves propagating through\na waveguide or other transmission media (e.g., light pulses passing through a fiber-optic cable), or electrical signals transmitted through a wire.\nComputer readable program instructions described herein can be downloaded to respective computing/processing devices from a computer readable storage medium or to an external computer or external storage device via a network, for example, the\nInternet, a local area network, a wide area network and/or a wireless network.  The network may comprise copper transmission cables, optical transmission fibers, wireless transmission, routers, firewalls, switches, gateway computers and/or edge servers. \nA network adapter card or network interface in each computing/processing device receives computer readable program instructions from the network and forwards the computer readable program instructions for storage in a computer readable storage medium\nwithin the respective computing/processing device.\nComputer readable program instructions for carrying out operations of the present invention may be assembler instructions, instruction-set-architecture (ISA) instructions, machine instructions, machine dependent instructions, microcode, firmware\ninstructions, state-setting data, configuration data for integrated circuitry, or either source code or object code written in any combination of one or more programming languages, including an object oriented programming language such as Smalltalk, C++,\nor the like, and procedural programming languages, such as the \"C\" programming language or similar programming languages.  The computer readable program instructions may execute entirely on the user's computer, partly on the user's computer, as a\nstand-alone software package, partly on the user's computer and partly on a remote computer or entirely on the remote computer or server.  In the latter scenario, the remote computer may be connected to the user's computer through any type of network,\nincluding a local area network (LAN) or a wide area network (WAN), or the connection may be made to an external computer (for example, through the Internet using an Internet Service Provider).  In some embodiments, electronic circuitry including, for\nexample, programmable logic circuitry, field-programmable gate arrays (FPGA), or programmable logic arrays (PLA) may execute the computer readable program instructions by utilizing state information of the computer readable program instructions to\npersonalize the electronic circuitry, in order to perform aspects of the present invention.\nAspects of the present invention are described herein with reference to flowchart illustrations and/or block diagrams of methods, apparatus (systems), and computer program products according to embodiments of the invention.  It will be\nunderstood that each block of the flowchart illustrations and/or block diagrams, and combinations of blocks in the flowchart illustrations and/or block diagrams, can be implemented by computer readable program instructions.\nThese computer readable program instructions may be provided to a processor of a general purpose computer, special purpose computer, or other programmable data processing apparatus to produce a machine, such that the instructions, which execute\nvia the processor of the computer or other programmable data processing apparatus, create means for implementing the functions/acts specified in the flowchart and/or block diagram block or blocks.  These computer readable program instructions may also be\nstored in a computer readable storage medium that can direct a computer, a programmable data processing apparatus, and/or other devices to function in a particular manner, such that the computer readable storage medium having instructions stored therein\ncomprises an article of manufacture including instructions which implement aspects of the function/act specified in the flowchart and/or block diagram block or blocks.\nThe computer readable program instructions may also be loaded onto a computer, other programmable data processing apparatus, or other device to cause a series of operational steps to be performed on the computer, other programmable apparatus or\nother device to produce a computer implemented process, such that the instructions which execute on the computer, other programmable apparatus, or other device implement the functions/acts specified in the flowchart and/or block diagram block or blocks.\nThe flowchart and block diagrams in the Figures illustrate the architecture, functionality, and operation of possible implementations of systems, methods, and computer program products according to various embodiments of the present invention. \nIn this regard, each block in the flowchart or block diagrams may represent a module, segment, or portion of instructions, which comprises one or more executable instructions for implementing the specified logical function(s).  In some alternative\nimplementations, the functions noted in the blocks may occur out of the order noted in the Figures.  For example, two blocks shown in succession may, in fact, be executed substantially concurrently, or the blocks may sometimes be executed in the reverse\norder, depending upon the functionality involved.  It will also be noted that each block of the block diagrams and/or flowchart illustration, and combinations of blocks in the block diagrams and/or flowchart illustration, can be implemented by special\npurpose hardware-based systems that perform the specified functions or acts or carry out combinations of special purpose hardware and computer instructions.\nThe descriptions of the various embodiments of the present invention have been presented for purposes of illustration, but are not intended to be exhaustive or limited to the embodiments disclosed.  Many modifications and variations will be\napparent to those of ordinary skill in the art without departing from the scope and spirit of the invention.  The terminology used herein was chosen to best explain the principles of the embodiment, the practical application or technical improvement over\ntechnologies found in the marketplace, or to enable others of ordinary skill in the art to understand the embodiments disclosed herein.", "application_number": "15232911", "abstract": " A method, computer program product, and system for job profile\n     generation, the method, computer program product, and system include\n     receiving employee intranet usage data, storing the received employee\n     intranet usage data in a database, identifying a portion of the stored\n     employee intranet usage data associated with the former employee,\n     transmitting the portion to a recommender system, where the recommender\n     system identifies one or more required job skills of the former employee,\n     based on the transmitted portion, and generating a job profile based on\n     the one or more identified required job skills.\n", "citations": ["7146574", "7188074", "8063799", "8200584", "8914383", "20070054248", "20120215795", "20130198098", "20140214711", "20140278821", "20140279629", "20150006422", "20150317753", "20170213272"], "related": []}, {"id": "20180048423", "patent_code": "10291353", "patent_name": "Receiver for receiving data in a broadcast system using redundancy data", "year": "2019", "inventor_and_country_data": " Inventors: \nQi; Junge (Braunschweig, DE), Robert; Joerg (Vreden, DE), Zoellner; Jan (Braunschweig, DE)  ", "description": "<BR><BR>BACKGROUND\nField of the Disclosure\nThe present disclosure relates to receiver and a corresponding receiving method for receiving data in a broadcast system.  Further, the present disclosure relates to a broadcast system.\nThe present invention relates, for instance, to the field of Digital Video Broadcasting (DVB) utilizing Orthogonal Frequency Division Multiplexing (OFDM).  Further, the present invention can be applied in other systems, such as a DAB (Digital\nAudio Broadcasting), DRM, MediaFlo, ISDB, ATSC (e.g. 3.0) or LTE broadcast system.\nDescription of Related Art\nThe transmission parameters of known broadcast systems, such as the broadcast systems in accordance with the DVB-T2 standard (second generation digital terrestrial television broadcast systems standard), are generally optimized for fixed\nreception with stationary receivers, e.g. with roof-top antennas.  In future broadcast systems, such as the upcoming DVB-NGH (DVB Next Generation Handheld; in the following also referred to as NGH) standard, a mobile receiver (which is the main focus of\nthis upcoming standard) shall be enabled to receive data correctly also in bad reception situations, e.g. despite suffering from multipath propagation, fading effects and Doppler shifts.  Such broadcast systems are particularly characterized by the fact\nthat there is generally no feedback channel and no signalling from receivers to transmitters.\nA receiver for receiving data in a broadcast system by which the probability of error-free reception/reconstruction of data by a mobile receiver is increased compared to receivers in known broadcast systems, even under bad reception conditions,\nis disclosed in WO 2011/080020 A1.  The disclosed receiver comprises a broadcast receiver unit for receiving from said broadcast system a receiver input data stream segmented into frames, wherein basic codeword portions of codewords are mapped onto said\nframes, a codeword comprising said at least a basic codeword portion generated from an input data word according to a first code, a data demapper for demapping the basic codeword portions from said frames of the receiver input data stream, a decoder for\nerror correction code decoding said codewords into output data words of at least one output data stream in a regular decoding step by use of the basic codeword portion comprised in a codeword, a check unit for checking if the regular decoding of a\ncodeword is erroneous, a unicast request unit for requesting, if said regular decoding of a codeword is erroneous, through a unicast system an auxiliary codeword portion of the erroneously decoded codeword for use as incremental redundancy in an\nadditional decoding step, a unicast receiver unit for receiving from said unicast system an auxiliary codeword portion of the erroneously decoded codeword, wherein said decoder is adapted to decode the respective codeword again in an additional decoding\nstep by additionally using the received auxiliary codeword portion, and a data output for outputting said at least one receiver output data stream segmented into said decoded output data words.\nThe main use of redundancy data is the increase of the coverage area for terrestrial broadcasting.  Subscribers located at the edge of the coverage area of a broadcast system (also called broadcast network) are suffering from low receptions\nlevels, which may hinder error-free decoding.  This is also true for indoor reception or if large objects attenuate the transmitted signal.  To counter this problem the utilization of a (wired or wireless) broadband system (also called broadband network)\nfor providing additional redundancy for enabling error-free reception has been proposed.  In many cases only a few dBs received signal level are missing for the correct demodulation and decoding of the broadcast data, resulting in an additional\nredundancy data stream of few hundred kbit/s. Furthermore other channel impairments like burst noise or narrowband interferer create decoding errors in a sheer broadcast reception scenario which are corrected with the additional redundancy data stream.\nThe \"background\" description provided herein is for the purpose of generally presenting the context of the disclosure.  Work of the presently named inventor(s), to the extent it is described in this background section, as well as aspects of the\ndescription which may not otherwise qualify as prior art at the time of filing, are neither expressly or impliedly admitted as prior art against the present invention.\n<BR><BR>SUMMARY\nIt is an object to provide a receiver for receiving data in a broadcast system using redundancy data for further increasing the probability of error-free reception/reconstruction of broadcast data.  It is a further object to provide a\ncorresponding receiving method, a broadcast system, as well as a corresponding computer program for implementing said receiving method and a non-transitory computer-readable recording medium for implementing receiving method.\nAccording to an aspect there is provided a receiver for receiving data in a broadcast system comprising: a broadcast receiver that receives, via said broadcast system, a receiver input data stream comprising a plurality of channel symbols\nrepresented by constellation points in a constellation diagram, a demodulator that demodulates said channel symbols into codewords, a decoder that decodes said codewords into output data words, a broadband receiver that obtains redundancy data via a\nbroadband system, said redundancy data for a channel symbol including one or more least robust bits of the channel symbol or a constellation subset identifier indicating a subset of constellation points including the constellation point representing the\nchannel symbol, wherein said demodulator and/or said decoder is configured to use said redundancy data to demodulate the respective channel symbol and to decode the respective codeword, respectively.\nAccording to a further aspect there is provided a corresponding receiving method for receiving data in a broadcast system comprising: receiving, via said broadcast system, a receiver input data stream comprising a plurality of channel symbols\nrepresented by constellation points in a constellation diagram, demodulating said channel symbols into codewords, decoding said codewords into output data words, obtaining redundancy data via a broadband system, said redundancy data for a channel symbol\nincluding one or more least robust bits of the channel symbol or a constellation subset identifier indicating a subset of constellation points including the constellation point representing the channel symbol, wherein said demodulating and/or said\ndecoding is configured to use said redundancy data to demodulate the respective channel symbol and to decode the respective codeword, respectively.\nAccording to a further aspect there is provided a broadcast system comprising: a broadcast transmitter that transmits, via said broadcast system, a receiver input data stream comprising a plurality of channel symbols represented by constellation\npoints in a constellation diagram, a receiver as disclosed herein that receives data transmitted by said broadcast transmitter, a broadband server that provides redundancy data via a broadband system for reception by said receiver\nAccording to still further aspects a computer program comprising program means for causing a computer to carry out the steps of the method disclosed herein, when said computer program is carried out on a computer, as well as a non-transitory\ncomputer-readable recording medium that stores therein a computer program product, which, when executed by a processor, causes the method disclosed herein to be performed are provided.\nPreferred embodiments are defined in the dependent claims.  It shall be understood that the claimed receiving method, the claimed broadcast system, the claimed computer program and the claimed computer-readable recording medium have similar\nand/or identical preferred embodiments as the claimed receiver and as defined in the dependent claims.\nOne of the aspects of the disclosure is to make use of the known concept of using redundancy data (in the known system obtained via a unicast system, but generally obtainable via a broadband system) and to further define in which way redundancy\ndata can best be obtained.  It has been found that one or more least robust bits of the channel symbol or a constellation subset identifier indicating a subset of constellation points including the constellation point representing the channel symbol are\nvery efficient ways of providing redundancy data which are used to improve the demodulation and/or decoding at the receiver.\nIt is to be understood that both the foregoing general description of the invention and the following detailed description are exemplary, but are not restrictive of the invention. <BR><BR>BRIEF DESCRIPTION OF THE DRAWINGS\nA more complete appreciation of the disclosure and many of the attendant advantages thereof will be readily obtained as the same becomes better understood by reference to the following detailed description when considered in connection with the\naccompanying drawings, wherein:\nFIG. 1 shows a schematic diagram of a broadcast system according to the present disclosure,\nFIG. 2 shows a schematic diagram of a first embodiment of a receiver according to the present disclosure,\nFIG. 3 shows a more detailed diagram of a broadcast system according to the present disclosure,\nFIG. 4A is a diagram illustrating the use of least significant bits as redundancy data according to the present disclosure,\nFIG. 4B is another diagram illustrating the use of least significant bits as redundancy data according to the present disclosure,\nFIG. 4C is a further diagram illustrating the use of least significant bits as redundancy data according to the present disclosure,\nFIG. 5A is a diagram illustrating the use of puncturing according to aspects of the present disclosure,\nFIG. 5B is another diagram illustrating the use of puncturing according to aspects of the present disclosure,\nFIG. 5C is a further diagram illustrating the use of puncturing according to aspects of the present disclosure,\nFIG. 6A is a diagram illustrating the use of a constellation subset identifier as redundancy data according to aspects of the present disclosure,\nFIG. 6B is another diagram illustrating the use of a constellation subset identifier as redundancy data according to aspects of the present disclosure,\nFIG. 7 shows a diagram illustrating the identification of subcarriers having a low CNR,\nFIG. 8 shows a schematic diagram of a second embodiment of a receiver according to the present disclosure,\nFIG. 9 shows a schematic diagram of a third embodiment of a receiver according to the present disclosure,\nFIG. 10 shows a diagram of the relationship between overall cost for transmission and transmitter power consumption,\nFIG. 11 shows a schematic diagram of a dynamic broadcast system using the present invention,\nFIG. 12 shows a schematic diagram of a control device for use in a broadcast system according to the present disclosure,\nFIG. 13 shows a schematic diagram of another embodiment of a broadcast system according to the present disclosure,\nFIG. 14 shows a schematic diagram of another embodiment of a broadcast system according to the present disclosure,\nFIG. 15 shows a diagram illustrating the average estimated Mutual Information with and without knowledge of the transmitted bits,\nFIG. 16 shows a schematic diagram of another embodiment of a broadcast server according to the present disclosure,\nFIG. 17 shows a diagram illustrating cooperative decoding with a server controlling the data exchange, and\nFIG. 18 shows a diagram illustrating cooperative decoding without a server controlling the data exchange.\n<BR><BR>DESCRIPTION OF THE EMBODIMENTS\nReferring now to the drawings, wherein like reference numerals designate identical or corresponding parts throughout the several views, FIG. 1 shows a schematic diagram of a broadcast system 1 according to the present disclosure.  It comprises a\nbroadcast transmitter 2 that transmits, via said broadcast system, a receiver input data stream comprising a plurality of channel symbols represented by constellation points in a constellation diagram.  Further, it comprises one or more receivers 3, in\nthis case two receivers indicated as \"user A\" and \"user B\" arranged at different distances from the broadcast transmitter 2, according to the present disclosure for receiving data transmitted by the broadcast transmitter 2.  Still further, the broadcast\nsystem 1 comprises a broadband server 4 (also called broadband provider), in this case a redundancy server that provides redundancy data via a broadband system for reception by said receiver.  Due to the use of transmission of data via broadcast and via\nbroadband the broadcast system 1 may also be called a hybrid broadcast system or a broadcast broadband system.\nFIG. 2 shows a schematic diagram of a receiver 3 according to the present disclosure.  It comprises a broadcast receiver 31 that receives, via said broadcast system 1, a receiver input data stream comprising a plurality of channel symbols\nrepresented by constellation points in a constellation diagram.  A demodulator 32 demodulates said channel symbols into codewords and a decoder 33 decodes said codewords into output data words.  A broadband receiver 34 obtains redundancy data via a\nbroadband system, said redundancy data for a channel symbol including one or more least robust bits of the channel symbol or a constellation subset identifier indicating a subset of constellation points including the constellation point representing the\nchannel symbol.  According to the present disclosure said demodulator 32 and/or said decoder 33 is configured to use said redundancy data to demodulate the respective channel symbol and to decode the respective codeword, respectively.\nIn the proposed scheme the transmission in terrestrial network remains unchanged, but for a poor reception the receiver (also called terminal device) can fetch additional data via the broadband network to improve error correction performance. \nThe receiver evaluates the data received from the terrestrial network, and according to the signal quality it requires certain amount of additional data to assure quasi-error-free (QEF) reception.  Under more severe conditions more additional data is\nneeded.  In this way, for instance, a smooth or seamless transition between pure terrestrial broadcast and complete delivery via the broadband network can be realized.  This creates a new degree of freedom for the broadcast network management and may\nreduce the overall delivery cost and energy consumption.\nThe data received via both networks is combined for decoding in the receiver.  What kind of additional data is transmitted via the broadband network depends on the technology used in the terrestrial broadcast network.  FIG. 3 illustrates the\nproposed broadcast system 1 in more detail, employing the proposed Redundancy on Demand (RoD) concept on the example of DVBT-2.  A RoD capable terminal (i.e. a receiver according to the present disclosure) 3a is equipped with a RoD client 34', that\nsubstantially corresponds to the broadband receiver 34 (see FIG. 2), that performs a request to the RoD server (i.e. the broadband server) 4 if the reception conditions do not allow for error free decoding based on the data received from the broadcast\ntransmitter 2.  The RoD server 4 is then transmitting the required amount of redundancy, which is generally generated from the initially transmitted data stream, to the receiver 3a.  Different convergence levels for generating the RoD data are possible,\ni.e. the transmitted redundancy can either be generated from the output of the multiplexer (MUX), the channel-coding or the modulation block.  The proposed RoD scheme is backwards compatible, since receivers that are not capable of a broadband connection\nfor improving the reception remain unchanged, such as the receiver 5 shown in FIG. 3.\nA known approach for generating redundancy, which is described in WO 2011/080020 A1, is the retransmission of erroneously received packets with the so cold Automatic Repeat Request (ARQ) scheme.  The generation and reinsertion of redundant\npackets therefore takes place in the multiplexer included in the modulator of the broadcast transmitter 2 (see FIG. 3).  Possible convergence levels are e.g. IP-Packets, FEC Frames or Generic Stream Encapsulation (GSE) Packets for DVB-Systems.  However,\na drawback of this approach is the reduced granularity for generating the redundancy.  If the reception conditions are slightly worse than required for error free reception (e.g. 1 dB below the target SNR), each packet needs to be retransmitted via the\nbroadband system requiring a lot of transmission capacity.\nAnother approach as proposed according to the present disclosure is the usage of the least robust bits (or, generally, the bits having the highest bit error rate, BER), in particular the least significant bits (LSB), of the used constellation\n(e.g. of a QAM constellation) as redundancy data.  The receiver demodulates the QAM constellations, but uses the least robust bits, e.g. the LSBs, from the broadband network instead of the ones from the terrestrial broadcast network, because the least\nrobust bits typically carry the lowest amount of information within the channel symbol (e.g. a QAM symbol).\nAs the bits from the broadband network are very reliable, the demodulator 32 (in particular the demapper included within the demodulator in various embodiments, e.g. used in OFDM receivers) is able to reduce the number of possible constellation\npoints.  Thus, the average Euclidean distance between the remaining constellation points increases, leading to improved performance.  This approach is shown in an example in FIG. 4 according to which the LSBs are considered as least robust bits.  The\nLSBs received via the broadband network in the constellation diagram shown in FIG. 4A is 0.  The crosses 40 denote the possible constellation points and the lines 50 show the decision thresholds.  In the constellation diagrams shown in FIGS. 4B and 4C\ntwo LSBs are known (00 and 01), reducing the remaining constellation points 41, 42 (indicated by crosses) to four and reducing the number of decision thresholds 51, 52.  The same principle also holds for soft-decision demapping.  In this case the\nknowledge of the redundancy data is used to enhance the reliability of the soft-decision output values of the demapper.\nIn another embodiment the demodulator 32 is configured to use said least robust bits of a channel symbol received as redundancy data to replace the least robust bits of the channel symbol received by said broadcast receiver to obtain an improved\nchannel symbol and to demodulate said improved channel symbol.\nIn still another embodiment the receiver can also utilize the least robust bits (e.g. the LSBs) from the broadband network for improving the demapping and/or decoding of the more robust bits (e.g. the MSBs) from the broadcast network.  This\nconcept is similar to \"Genie-aided\" demapping, i.e. an easily implementable soft-decision demapping approach, where the knowledge of the transmitted bits is used to enhance the reliability of the soft-decision output values of the demapper.  Thus, the\ndecoder 33 is configured according to this embodiment to use said least robust bits of a channel symbol received as redundancy data to replace obtained input values of the decoder with their ideal values derived from the known bits contained in the\nredundancy data and, thus, to obtain an improved codeword and to decode said improved codeword.  Typically, the input values of the decoder are soft-decision input values (generally log-likelihood ratios, LLRs) so that obtained uncertain soft-decision\ninput values are set to the ideal values having indefinite likelihood (i.e. perfect knowledge) which are then used in the decoding.\nThe bit rate of the generated redundancy data can be controlled firstly by selecting the number of least robust bits out of each channel symbol, and secondly by puncturing the complete least robust bit stream, as illustrated in FIG. 5.  Here,\nFIG. 5A shows a redundant data stream with bitrate R, FIG. 5B shows a redundant data stream with bitrate R/2, and FIG. 5C shows a redundant data stream with bitrate R/3.  This is important to control the optimum amount of redundancy data.  On the one\nhand the amount of transmitted redundancy data must be sufficient to allow for error-free decoding and/or demodulation, but on the other hand the amount should be as low as possible to avoid transmission of unnecessary redundancy data.\nInstead of retransmitting the initially transmitted bits, it is also possible to define constellation point subsets that are excluded in the receiver.  This allows for increasing the Euclidian distance between the remaining constellation points. If bit sequences with unequal probabilities are transmitted, Huffman coding may be conducted on the selected bits, to enable the receiver to separate them easily and reduce the overhead for the transmission.  This is meaningful if constellation shaping\nis used, altering the probabilities of the subset identifiers, i.e. some subset identifiers occur with higher probability than others.  This is directly related to constellation shaping of (e.g. QAM) constellations, with some constellation points\noccurring with higher probability than others.  In the normal case of equal probabilities, Huffman coding does not provide any gain.\nAn example of a Huffman coding for a 16-QAM constellation is as follows:\nTABLE-US-00001 Original bit sequence Probability Huffman coded bits XXX0 1/2 0 XX10 1/4 01 X0X1 1/4 10 1111 1/16 11\nAfter the identification of the sub-carriers with heavy distortion, redundant bits will be generated from the constellation points of these sub-carriers.  Since the distortion levels of these identified sub-carriers may also vary, the redundant\nbits required for each sub-carrier may also be different.\nAs an example, it shall be supposed that all the N constellation points build a set S. Through the re-labeling S will be divided into sub-sets {S1, S2, .  . . , Sm}, i.e. not bits but (e.g. QAM) subset identifiers are transmitted.  The division\noperation increases the average robustness of the constellation points within each sub-set.  This operation is dependent on the statistical properties of the broadcast signal and the distortion.  The mathematical deviation is omitted here.  A simple\nexample using 16 constellation points of a QAM constellation is shown in FIG. 6.  If the receiver receives a \"0\" (i.e. 16-QAM Gray Mapping with LSB known to be 0), it indicates the original point locates in a first sub-set comprising the constellation\npoints 60 (indicated by crosses) as shown in FIG. 6A.  If the subsets are optimized for maximum average Euclidian distance, the original point is located in a sub-set comprising the constellation points 61 (indicated by crosses) as shown in FIG. 6B.\nThe various division schemes for different distortion levels and forms can be pre-calculated and stored in a look-up table to simplify the on-line operation.  This approach enables a maximal utilization of the capacity of the communication\nchannel\nIn a multi-carrier communication system, the distortion each sub-carrier bears varies much in both time domain and frequency domain.  In case of portable mobile and stable receptions, the broadcast channel has slow-changing and slow-fading\ncharacteristics.  Furthermore, low signal power and narrow band interferences are the main hinders for an error-free reception.  FIG. 7 illustrates such a broadcast channel exemplarily, in particular the variance of signal strength in frequency domain. \nThe first step is to identify the sub-carriers which are bearing severe distortion and have hence an insufficiently low carrier-to-noise-ratio (CNR).  In FIG. 7, they are the ones in the marked area 70.  Redundancy data is then only needed for these\nidentified sub-carriers.  In this way, the required bandwidth in the broadband network is reduced.  Because the channel state may also change temporally, the identification process is carried out periodically or in an event-based manner.\nFor the sub-carriers with low CNR, some or even all of the bits from their constellation points need to be transmitted by the broadband connection, so that a correct decoding can be achieved.  The selection of the bits as redundancy depends on\nthe distortion, the strength of the signal, the deployed mapping scheme.  Moreover, which additional bits should be selected as redundancy data is also dependent on the previously selected bits.  A mathematical derivation is omitted here.\nAn embodiment of a receiver 3b according to the present disclosure making use of this approach in a more general way is shown in FIG. 8.  In addition to the receiver 3 it comprises a quality detector 35 that identifies the quality of received\nchannel symbols and a broadband request unit 36 that requests channel symbols having the lowest quality and/or a quality below a predetermined quality threshold as redundancy data.\nIn a further embodiment, as explained above with reference to FIG. 7, said broadcast receiver 31 is configured to receive said receiver input data stream via a multi-carrier broadcast system, e.g. an OFDM broadcast system (such as a broadcast\nsystem in accordance with a DVB standard).  Said receiver input data stream comprises a plurality of channel symbols carried by multiple frequency sub-carriers.  In this embodiment the quality detector 35 is configured to identify the quality of said\nfrequency sub-carriers, and said broadband request unit 36 is configured to request channel symbols carried by sub-carriers having the lowest quality and/or a quality below a predetermined quality threshold as redundancy data.\nIn an embodiment the broadband receiver 31 is configured to receive redundancy data via a broadband system.  Thus, the broadband server or any other appropriate unit that is able to transmit data through the broadband system thus actively\ntransmits the redundancy data to the receiver.  For instance, it can be estimated, e.g. by the broadband transmitter or the broadcast transmitter, if the decoding and/or demodulation at a receiver will be erroneous due to the channel characteristics, so\nthat actively redundancy data will be sent, even without explicit request by the receiver.  Further, channel information can be used to select the redundancy data requiring the smallest amount of additional redundancy data.\nIn another embodiment, as shown in FIG. 9, the receiver 3c comprises a broadband request unit 37 that requests, if demodulation of a channel symbol and/or decoding of a codeword without redundancy data is erroneous, one or more least robust bits\nor constellation subset identifiers of the corresponding channel symbol via said broadband system as redundancy data.  Thus, the receiver 3c actively requests redundancy data in this embodiment.\nSaid broadband request unit 37 may alternatively, in another embodiment, transmit receiver specific broadcast channel information via said broadband system to a server (e.g. as shown in FIG. 3) that determines the quality of least robust bits\nand/or channel symbols received by the broadcast receiver 31 and transmits least robust bits and/or channel symbols as redundancy data to the receiver via said broadband system.  Further, preferably, said broadband request unit 37 is configured to\ncompress said channel information by precoding before transmitting it to a server.\nIn an embodiment the channel state information (CSI) is estimated in the receivers, but the identification of the sub-carriers and the constellation points re-labelling can be carried out in either receivers or the server.  If the receiver makes\nthe decisions, it needs only transmit back a request for the specific bits.  If the server makes the decisions, the CSI should be transmitted back from the receiver to the server.  This CSI can be pre-coded before transmitting.  For instance, the CSI can\nbe transmitted incrementally, which means only the difference to last estimation is required by the server.  In this case, the CSI can also be seen as two-dimensional spaces with the axis frequency and time.  Furthermore, the CSI has specific\ncharacteristics in both dimensions, e.g. the variation in the time direction may be very slow in case of stationary reception.  Therefore, one could use algorithms similar to MPEG video encoding (e.g. differential encoding) that take benefit of these\ncharacteristics for an efficient transmission of the CSI back to the transmitter.\nIn the following some application scenarios in which embodiments of the present disclosure can be applied will be explained.\nWhen a poor QoS is noticed by the receiver and the availability of the redundancy data is proved, a question may be popped up to the user asking about whether acquiring redundancy data via broadband network is allowed to improve the decoding\nquality.  Once the user accepts this or does choose for permanent allowance, the presentation of the current media content is paused and the broadcast data stream is buffered for a very short interval to equalize the delays in both networks.  Then the\nbroadcast data stream and redundancy data stream are synchronized and decoded jointly.  Afterwards the media content is displayed without any perceptive errors.\nAnother advantage of the use of redundancy data is the possibility to efficiently counteract time varying distortions like man-made-noise.  Man-made-noise is known to be especially severe in the VHF-Band, causing narrowband as well as broadband\ndistortions that can be either constant over time or time varying.  Especially the impact on the QoS of time varying distortions like impulsive noise, which are e.g. caused by switching events of the mains, can be avoided by means of the concept of\nredundancy data.  Heavy noise impulses typically cause a service dropout, since the error correction (e.g. the forward error correction (FeC) as applied in DVB broadcast systems) is not able to correct such strong distortions.  This is especially the\ncase for OFDM-based systems, as a short noise impulse in the time domain distorts a complete OFDM symbol in the frequency domain, due to the so called noise-buck effect of OFDM.  The VHF band is therefore not used anymore in some countries (like Germany)\nfor digital terrestrial transmission, because of problems with man-made-noise.  The use of redundancy data could allow for the reintroduction of terrestrial broadcasting in the VHF-band in such countries.\nIn current broadcast networks, to achieve a \"quasi-error-free\" (QEF) viewing experience, a certain level of signal-to-noise ratio (SNR) is required.  For receivers which have a poor receiving condition, this SNR threshold cannot be reached, thus\na successful decoding of the broadcast signal would be impossible.  The TV services can only be provided completely by other means, e.g. IPTV and the corrupted broadcast signal has to be discarded.  For the proposed concept of using redundancy data,\nhowever, the amount of additional redundancy is dependent on the quality of the broadcast signal: if the distortion is heavier, more redundancy will be needed; if lighter, then less redundancy will be needed.  In a worst case, if the desired amount of\nredundancy data is even larger than that of the original TV content itself, the TV content will be delivered directly to the receiver as a normal IPTV system (100% broadband).  Therefore, the data size that have to be transmitted as redundancy data is\nalways less than without using this approach.\nCompared to traditional systems, with the concept of redundancy data a soft-transition between pure broadcast and complete IPTV can be realized.  This has an influential impact on the network planning, when a high proportion of the receivers are\ncapable of using this concept.  For instance, if a certain area shall be covered with a terrestrial broadcasting network and a certain data rate shall be provided in the broadcast channel previously, after selecting the network setting (code rate,\nmodulation scheme, etc.) the transmitter power had to be increased to ensure a sufficient SNR at each location in this area.  Now, with the concept of redundancy data the transmitter power can be reduced and the receivers located at edge area can be\nserved with some redundancy data via broadband network, so that their demodulation and decoding of the broadcast signal is also \"quasi-error-free\".  Equivalently, the same transmitter power can be maintained, but modulation and error correction rates\nwith higher spectral efficiencies could be applied.  The transmitter power can be reduced to a level, when a further decrease of power consumption or transmission cost is no more possible.  This power level and the achievable power or cost savings are\ngenerally determined by the viewer number, distribution of receivers, cost factors, man-made-noise and so on.  Most of these parameters are changing temporally, therefore online monitoring, optimization and adaption are preferably used.  For instance,\nthe transmitter power is set to lower level during morning, when less people are watching television.  The lower signal strength is compensated by more redundancy data via the broadband network for the relatively small number of receivers.\nThe relation between the overall power consumption/transmission cost and the transmitter power may look as depicted in FIG. 10.  The optimal operation point moves at different time and changes for different network settings, such that a dynamic\nadaption of the network is meaningful.\nThe proposed ideas can also be applied in a dynamic broadcast system as, for instance, described in U.S.  patent application Ser.  No. 13/428,743 filed on Mar.  23, 2012, which description is herein incorporated by reference.  The so-called\ndynamic broadcast concept applied in such a dynamic broadcast system describes a flexible terrestrial broadcast system, utilizing an internet broadband connection and a hard disc in the terminal, to optimize the spectrum usage and the power consumption\nof the transmitter network, by choosing the optimal delivery means depending on the content type (realtime, non-realtime) and the viewer count.  The relationship of the concept of redundancy (on demand) with respect to the dynamic broadcast concept is\ndepicted in FIG. 11 showing a schematic diagram of a dynamic broadcast system 100 according to the present disclosure.\nThe system 100 involves a broadcast (BC) network, a broadband network (BB), hybrid broadcast broadband (HBB) terminals (receivers) and other wireless communication networks.  Their cooperation is managed by the dynamic broadcast network.  The\nfunctions of the blocks shown in FIG. 11 are explained in the following.\nFirst, the packaging of media content unit 112 is described.  The TV content is provided by broadcasters 110 and is segmented into Real-Time (RT) and Non-Real-Time (NRT) events.  For real-time events, (certain elements of) news programs for\ninstance, their content becomes available only at the announced on-air time, so they have to be delivered live; while for non-real-time events, like movies, music, drama etc., their content may be available in advance, so they can be pre-downloaded. \nWith pre-download (broadcast or broadband) network capacity can be used for instance over night, when capacity has been identified to be available, whereas during daytime and in the evening network capacity will be freed for other uses.  The choice of\ncontent that can be pre-downloaded will be based on rules used in a decision logic 114.  These rules will be generated from usage patterns of viewers derived from information available over the broadband network.  In conjunction with other measures the\ndownload of such material will take place as network capacity becomes available--either over the broadcast or the broadband network.  A program schedule therefore should be created that indicates which content comes over the air in real-time and which\ncontent can be played from the storage device in the user terminal.\nNext, a monitoring and signaling unit 116 is described.  To optimize the network operation, knowledge about actual network usage is important.  Two kinds of information should hence be collected from HBB terminals 118 (also called \"terminals\",\n\"user terminals\" or \"receivers\" hereinafter) and transmitted to the decision logic 114 through broadband connection.  The first kind of information is about whether or not programs or pieces of media content are used and by how many people.  This\npopularity can be estimated by monitoring the watching activities of some or all users, as done in today's IPTV networks.  Knowing the accurate popularity and usage pattern of the media content can help the decision logic 114 determining which content\nshould be delivered via the broadband network and/or pre-downloaded as mentioned above.  The second kind of information is about the momentary technical Quality of Service (QoS) of the transmission links.  This can be obtained with integrated measuring\ndevices in HBB terminals 18.  With information about the actual signal quality, the decision logic 14 can manage the network most efficiently.\nThe signaling which delivers data to the HBB terminals 118 will provide information about content items presented for `delivery in advance` (also called `offline delivery, i.e. delivery in advance of the official broadcast time), the time of the\nbroadcast transmission and/or the time of play out over the broadband network.  It will include a program schedule and it will deliver information about the various parameters selected by the dynamic multiplexing and a joint control unit 120.  The\nsignaling information can be transmitted via both networks and in both push and pull modes, so that the HBB terminals 114 can get the current network information even if it is just switched on for the first time.\nThe decision logic 114 is in charge of the management of the whole network and it aims to keep the operation at a minimal cost while assuring required QoS.  Facilitated with the monitoring reports from the HBB terminals 118, and based on\nadditional business rules, cost functions, realistic constraints etc. the decision logic 114 may change the packaging of real-time and non-real-time events, or command a re-multiplexing of the transport streams in broadcast and broadband channels or\nadjust of the transmission parameters and transmitter power.  Before the decision logic 114 has made any changes to the previous program schedule or network settings, it should acknowledge all HBB terminals 18 about the modification through signalling.\nNext, a multiplexing and content distribution unit 122 is described.  The flexible distribution of media content through broadcast and broadband network requires content items and complete or partial audio, data and video programs to be\nmultiplexed dynamically.  In consequence, the former fixed mapping between transmission parameters and TV programs has to be eliminated.  Information about such re-multiplexing should be signaled to the HBB terminals 118, so that they are able to follow\nthe changes.  By the reason that the popularity of the different TV programs in one transport stream changes continuously, re-multiplexing may take place online, which means some content being transmitted may be reallocated in other physical channels or\nstill in the current channel but with new transmission parameters.  All these actions should be carried out in a way unnoticeable by the users.\nNext, the joint control unit 120 for control of transmission parameters is described.  In traditional digital broadcast systems the modulation of the transmitted signal and the degree of Forward Error Correction (FEC) used are decided once and\nthey then stay stable.  The transmitter power is selected according to the coverage requirements of the network.  In terrestrial networks, the coverage area is defined by the aforementioned parameters and in addition by the coverage pattern determined by\nthe transmit antenna.  This static network planning leads to inefficient usage of the valuable spectrum, because strong time-variant factors like channel popularity and user terminals receiving conditions have not been taken into consideration.\nDynamic multiplexing can reduce the useful data rate transmitted on a specific channel if the multiplex on that channel is not fully loaded with program items at the moment.  Initiated by the decision logic 114 the joint control unit 120 will\nthen change the FEC settings and/or modify the modulation scheme used on that channel.  This will result in an enhanced robustness of the signal which in consequence will allow the transmitter power to be adapted thus reducing the power density--and the\ncost of transmission.  This creates economical benefits, as well as ecological benefits, since the exposure to radiation and carbon emission will be reduced as a consequence of the lowered transmitter power.  In another case, it shall be supposed that\nsignaling provided from user terminals to the broadcast network including information about technical parameters of the received signal in networks indicate a better-than-required or worse-than-required signal quality as a result of changes in man-made\nnoise (i.e. noise generated by any devices used by anybody in the environment)--which has been found to fluctuate greatly and periodically over time--or due to changes in weather conditions.  Initiated by the decision logic 114 the joint control unit 120\nwill modify the parameters (FEC, modulation, transmitter power) in order to accommodate broadcast QoS at a minimum cost.  In addition, the joint control unit 120--in negotiation with dynamic multiplexing via the decision logic 114--will initiate the\nre-configuration of multiplexes such that the data rate transmitted in heavily disturbed channels will be reduced and the robustness of the signal enhanced as required.\nIn the HBB terminal 118 some content will have to be stored \"off-line\" upon receipt of the appropriate downstream signaling and besides, which content to store should also be decided by the HBB terminal 118.  Therefore it should be capable of\npredicting user's preferences, storing relevant TV content automatically and managing the stored content dynamically.  To accomplish this, a recommender system should be implemented in the HBB terminal 118.  On the other hand some content will be made\navailable via the co-operating broadband network.  The HBB terminal 118 will receive a program schedule, and a delivery network indicator which indicate for which period of time and how often this stored content is to be used instead of content that in\ntraditional broadcasting would be received live.  In addition it will be informed via which of the co-operating networks content will be delivered.  The received content from different networks should be managed properly by the HBB terminal 118.  Content\nitems are often interrelated.  This is obviously true for audio and video but in addition, a plethora of data services like software applications are created by the content owners that will have to be available in the terminal 118 and started, paused or\ncancelled in relation to the audio and video content.  Additional downstream signaling information embedded in the broadcast stream is received by the HBB terminal 18, which indicates the dynamic multiplex configurations and the parameters selected by\njoint control.  Upstream signaling will be generated in HBB terminals 118 for transmission on the broadband network.  The user terminal 118 thus becomes an active component of the dynamic broadcast network instead of being a passive device as in\ntraditional broadcasting.\nSpectrum freed by dynamic broadcast can be offered to secondary wireless networks, like Cellular (LTE), Wi-Fi, etc. for a certain period of time.  To avoid interference, usage of the new \"white space\" created by dynamic broadcast should be\ncoordinated through resource signaling which is an output of the dynamic broadcast system 100 and informs wireless network operators about the dynamically chosen parameters of the broadcast network.  It includes also information about the period of\nvalidity of the multiplex configuration and the spectrum resources which will be freed including an indication of the period of time during which the spectrum will be available.\nMore details about the general concept of dynamic broadcast can be found in the above mentioned US patent application and other publications about dynamic broadcast systems.\nAs the concept of redundancy on demand provides a \"seamless transition\" option between complete broadcast or broadband transmission, it can be efficiently combined with the dynamic broadcast concept, introducing another degree of freedom, so\nthat the dynamic broadcast network can be further optimized in the sense of transmission cost, energy consumption, and spectrum efficiency.  This is indicated in FIG. 11 by the arrow output by the joint control unit 120 that controls the output of RoD\ndata via the broadband network to the HBB terminal 118.\nRedundancy data can also be used in another application as an encryption way to protect the pre-downloaded media content.  The pre-download of the media content can be transmitted with a network configuration of high data rate but week error\ncorrection.  The redundancy data can then be used as a triggering signal to enable the recovery of the original data.\nFurther, conditional access to data can be realized by use of redundancy data.  Conditional access to video services is crucial for pay-TV transmission.  Redundancy data can be used to control the access to pay-TV services by means of the\nbroadband connection.  The corresponding service is transmitted via terrestrial broadcast to achieve low network cost.  However, not the full data rate is transmitted via terrestrial broadcast, but only a specific amount, e.g. like 95% of the data rate. \nThe users that subscribed to the pay-TV service then receive the remaining 5% via the broadband connection as redundancy data.  This allows the network operator for restricting the access to the pay-TV service via the broadband connection only to the\nusers with the corresponding service subscription.  Other users without the additional redundancy data over broadband are not able to decode the service, since the received Mutual Information via terrestrial broadcast is not sufficient for error free\ndecoding.  For this purpose even a slight decrease of the transmitted Mutual Information over the terrestrial broadcast suffices to avoid access of unregistered users to the pay-TV service.\nA schematic diagram of a control device 200 for use in a broadcast system according to the present invention is shown in FIG. 12.  Such a control device 200 may e.g. be used as joint control unit 120 in the broadcast system 100 shown in FIG. 11. The control device 200 comprises a broadcast control unit 201 and a broadband control unit 202.  The broadcast control unit 201 controls a broadcast transmitter of said broadcast system that broadcasts broadcast signals in a coverage area for reception\nby terminals comprising a broadcast receiver and a broadband receiver.  The broadband control unit 202 controls a broadband server of a broadband system that provides redundancy data to terminals within said coverage area.  The broadband control unit 202\nis configured to control the provision of redundancy data by said broadband server for use by one or more terminals which use said redundancy data together with broadcast signals received via said broadcast system for recovering content received within\nsaid broadcast signals and/or provided via said broadband system.  Additional optional elements are shown in dashed boxes and will be explained below.\nIn an embodiment said broadcast control unit 201 is configured to change one or more transmission parameters of said broadcast transmitter depending on one or more parameters of a group of parameters comprising the time of the day, the number,\nlocation, profile and/or parameters of active terminals, cost factors of the transmission of data by said broadcast transmitter and/or said broadband server, channel state information (in particular noise and/or reception level) and/or feedback of\nterminals.  Further, said broadband control unit 202 is configured to provide redundancy data to one or more active terminals which receive broadcast signals with insufficient quality and which use said redundancy data to compensate for the insufficient\nquality of reception of broadcast signals.  Optionally, the control device 200 further comprises a monitoring unit 203 that continuously or repeatedly monitors one or more parameters of said group of parameters.\nIn another embodiment said broadcast control unit 201 is configured to control the transmit power and/or one or more physical layer parameters, in particular modulation and/or code rate, parameters of an interleaver and/or an FFT unit, used by\nsaid broadcast transmitter.\nIn another embodiment said broadcast control unit 201 is configured to adaptively change the transmit power and/or the efficiency of the applied modulation and/or code depending on one or more parameters of a group of parameters comprising the\ntime of the day, the number, location, profile and/or parameters of active terminals, cost factors of the transmission of data by said broadcast transmitter and/or said broadband server, channel state information (in particular noise and/or reception\nlevel) and/or feedback of terminals.\nIn another embodiment said broadband control unit 201 is configured to adaptively change the amount of redundancy data transmitted to one or more active terminals depending on one or more parameters of a group of parameters comprising the time\nof the day, the number, location, profile and/or parameters of active terminals, cost factors of the transmission of data by said broadcast transmitter and/or said broadband server, channel state information, noise and/or feedback of terminals,\npreferably depending on the number of active terminals.  Preferably, in this embodiment the broadcast control unit 201 is configured to reduce the transmit power and/or to apply a modulation and/or code with a higher efficiency and said broadband control\nunit is configured to increase the amount of redundancy data transmitted to one or more active terminals if the number of active terminals is below a lower predetermined threshold and/or to decrease the amount of redundancy data transmitted to one or\nmore active terminals if the number of active terminals is above an upper predetermined threshold.  Even further, the amount of redundancy data may be controlled based on the costs of the transmission, i.e. based on an estimation if it is more cost\nefficient to increase or decrease the amount of redundancy data versus use of broadcast for transmitting data.\nStill further, in an embodiment the control device 200 comprises an optional request receiving unit 204, as also shown in FIG. 12, that receives requests for transmission of redundancy data from terminals.  In this embodiment said broadband\ncontrol unit 202 is configured to control the broadband server to provide redundancy data to requesting terminals.  The requests from terminals may generally differ in the quantity of requested redundancy data, the quality of the requests, the use\nprofiles, etc. For instance, there may be premium users (which may have paid an extra service charge), which may always receive an extra amount of redundancy data in order to ensure a high quality of the transmission in all situations.\nIn another embodiment the control device 200 is particularly designed for use in a dynamic broadcast system as shown in FIG. 11, wherein said broadcast control unit 201 and said broadband control unit 202 are configured to dynamically control\ntransmission parameters, transmission times and transmission paths used for broadcasting and providing content by use of said broadcast transmitter configured to broadcast content via said broadcast system and/or said broadband server configured to\nprovide content via said broadband system.  In this embodiment the control device 200 further comprises an optional decision unit 205 (also shown in FIG. 12) that dynamically decides transmission parameters, transmission times and transmission paths used\nfor broadcasting and providing content by use of said broadcast transmitter and for providing content by said broadband server.\nSaid decision unit 205 is preferably configured to dynamically decide transmission parameters, transmission times and transmission paths used for broadcasting and providing content based on monitoring data carrying information on user specific\ncontent usage and/or transmission quality data carrying information on the quality of a transmission link between said broadband server and a terminal and/or of a reception of content broadcast by said broadcast transmitter.\nFurther, said redundancy data is preferably provided for providing a seamless transition between broadcast and broadband reception and/or recovery of content from signals received via said broadcast system and said broadband system.\nIn another embodiment said broadcast control unit 201 and/or said broadband control unit 202 is configured to control said broadcast transmitter and/or said broadband server to transmit content in a form that does not allow complete recovery in\na terminal without the use of redundancy data, and to control the transmission of redundancy data via said broadband system to terminals that shall be enabled to completely recover received content.\nPreferably, in said embodiment said broadcast control unit 201 and/or said broadband control unit 202 is configured to control said broadcast transmitter and/or said broadband server to transmit content in encrypted form and/or with insufficient\nand/or low quality and wherein said redundancy data is provided for being used for decryption and/or increasing the quality of the received content.  For instance, in an exemplary use scenario, via broadcast a \"normal\" (lower) image quality (e.g. in SD\nformat) is obtained, while by use of the redundancy data (which may then be regarded as \"additional data\" or \"auxiliary data\") received via broadband an \"improved\" (higher) image quality (e.g. in HD format) is obtained.\nFurther, in said embodiment said broadcast control unit 201 is preferably configured to control said broadcast transmitter to adaptively change the mutual information between transmitted and received signals to transmit content in a form that\ndoes not allow complete recovery in a terminal without the use of redundancy data.\nA broadcast system 1a comprising such a control device 200 is schematically depicted in FIG. 13.  The broadcast system 1a comprises a broadcast transmitter 2a that broadcasts broadcast signals in a coverage area for reception by terminals 3\ncomprising a broadcast receiver and a broadband receiver.  The broadcast system 1a further comprises a broadband server 4a that provides redundancy data to terminals within said coverage area.  Finally, the broadcast system 1a comprises a control device\n200 as explained above with reference to FIG. 12 that controls said broadcast transmitter 2a and said broadband server 3a.\nIn the following it will be described in more detail how the required amount of redundancy data can be estimated or determined.  In particular, the estimation of the Mutual Information, the estimation of the number of redundancy data bits and\nthe stream synchronization will be described by use of various embodiments.  The following description will refer to elements shown in FIG. 14 depicting the interaction of a broadband server (called RoD server) 4b and a receiver (called terminal in this\nembodiment) 3d used in a broadcast system 1b according to the present disclosure.\nGenerally, a receiver (see also the embodiment of a receiver shown in FIG. 9) for receiving data in such a broadcast system comprises a broadcast receiver (31 in FIG. 9) that receives via said broadcast system a receiver input data stream\ncomprising a plurality of channel symbols represented by constellation points in a constellation diagram, a demodulator (32 in FIG. 9) that demodulates said channel symbols into codewords and a decoder (33 in FIG. 9) that decodes said codewords into\noutput data words.  A redundancy calculator (not separately shown in FIG. 9; may be a separate element or included in the broadband request unit 37; separately provided as unit 38 in the receiver 3d shown in FIG. 14) determines a required amount of\nredundancy data for correct demodulation and decoding by use of the originally received channel symbol and additional redundancy data.  A broadband request unit (37 in FIG. 9) requests, if demodulation of a channel symbol and/or decoding of a codeword is\nerroneous or likely to fail, a required amount of redundancy data via a broadband system and a broadband receiver (34 in FIG. 9) receives redundancy data via said broadband system.  The demodulator and/or the decoder are configured to use said redundancy\ndata to demodulate the respective channel symbol and to decode the respective codeword, respectively.  These elements are generally also provided in the receiver 3d shown in FIG. 14 even if not explicitly depicted.\nThe broadband server 4b for providing redundancy data to a receiver of such a broadcast system via said broadband system generally comprises a receiving unit 41 that receives requests from receivers of said broadcast system via said broadband\nsystem to provide redundancy data to the respective receivers via said broadband system to enable correct demodulation of a channel symbol and/or decoding of a codeword, a request including channel state information, a redundancy calculator 42 that\ndetermines the required amount of redundancy data required for correct demodulation and decoding by use of said channel state information, and a transmitting unit 43 that provides redundancy data in at least said required amount to the receiver that\nrequested redundancy data.\nAn essential task of a system using redundancy data is to correctly determine the required amount of redundancy data for successful decoding in the terminal (=receiver).  If too few redundancy data is transferred from the redundancy provider\n(i.e. a broadband server) to the terminal, the decoding process will fail and additional redundancy data need to be requested in a second step.  This causes network overhead and increases the system delay until successful decoding is achieved due to the\nmultiple redundancy data requests.  If on the other hand too much redundancy data is transferred to the terminal, the system efficiency is reduced, since data is transmitted via the broadband connection in vain.  The calculation of the correct redundancy\ndata amount is therefore very important, since it influences the performance of the overall system.\nA possible metric for the estimation of the required redundancy data amount in the receiver is the Mutual Information (MI) between transmitted (code) bits and received soft values, belonging to one codeword (e.g. a FEC word).  The Mutual\nInformation is a figure of merit from stochastic and is especially suited for determining the required amount of redundancy data, since it is independent from the channel characteristics and the modulation order of the QAM constellation, but only depends\non the applied code.  If the code rate of the applied code is e.g. 0.5, decoding is successful if the Mutual Information exceeds the value of 0.5.  However, this only holds for an ideal encoder, operating at the maximum channel capacity (Shannon\ncapacity), which is not possible with practical error correction codes.  For instance, the DVB-T2 64K LDPC code with a code rate 0.5 requires a Mutual Information of 0.55 for successful decoding.  There are only very slight deviations in the performance\nof this code depending on the modulation order and the channel characteristics.  The required Mutual Information for the utilized codes can be stored in a table in the broadband server or the terminal, such that the required mutual information that needs\nto be transmitted via redundancy data can be calculated in the terminal or the broadband server.  Hence, in an embodiment the redundancy calculator 38 is configured to estimate said required amount of redundancy data based on channel state information\nand/or Mutual Information between transmitted and received data, in particular between transmitted bits of output data words or codewords and received values representing bits of output data words or codewords.\nThere are two locations in the receiver where the log-likelihood ratios (LLRs) can be extracted to calculate the Mutual Information: Either directly after QAM demapping or after FEC decoding.  If the LLRs after FEC decoding are used, less\nredundancy data needs to be transmitted in principal (because FEC decoding, though not successful, increases the reliability of the LLRs).  Using the estimated Mutual Information it is possible to estimate the meaningfulness to perform FEC decoding. \nWhen the Mutual Information is clearly lower than the required Mutual Information for FEC decoding, FEC decoding should be omitted.  This is the case because on the one hand the Mutual Information increase by the FEC decoder is typically negligible in\nsuch situations, especially for state-of-the-art FEC codes like LDPC or turbo codes, and on the other hand this allows a reduction of the power consumption of the terminal.\nThe Mutual Information is determined based on the Log-Likelihood-Ratios (LLR) at the output of the QAM-demapper and is a good measure if the following FEC is able to successfully decode the FEC codeword.  An LLR is defined here as\n.times..function..function.  ##EQU00001## The Mutual Information of a single Bit based on its LLR value is defined as If transmitted bit=1: MI=1-log 2(1+e.sup.-inputLLR) If transmitted bit=0: MI=1-log 2(1+e.sup.+inputLLR).\nThe Mutual Information is typically averaged over one FEC block to decide if successful decoding is possible.  However, the knowledge of the transmitted bit is required for the calculation, which is not available in a receiver.  To avoid the\nneed for the reference data for the calculation of the Mutual Information, the formula is weighted by the linear probability that a 1 or a 0 is transmitted, respectively.  The linear probability (in the range [0,1]) that a 1 is transmitted is calculated\nfrom its LLR value by\n##EQU00002##\nAfter weighting the initial Mutual Information formulas (assuming bit 1 or bit 0 was transmitted) with the probability p and 1-p, respectively, the following formulas are resulting: MI.sub.1=1-p*log 2(1+e.sup.-inputLLR) MI.sub.0=1-(1-p)*log\n2(1+e.sup.+inputLLR) The estimated Mutual Information without reference is then resulting from their sum MI.sub.estimated=MI.sub.1+MI.sub.0=1-p*log 2(1+e.sup.-inputLLR)+1-(1-p)*log 2(1+e.sup.+inputLLR)\nThe comparison of the Mutual Information estimation with its ideal values is shown in FIG. 15 for different channel models and modulation sizes with a large amount of averaged bits and ideal channel knowledge.  It can be observed that estimated\nMutual Information exactly corresponds to the ideal Mutual Information.  In practice, the Mutual Information is estimated for a particular codeword (or a Time Interleaver Frame, consisting of several codewords), which results in a smaller amount of bits\navailable for averaging.  This would result in some degradation of the estimation.  Other metrics to compute the amount of required redundancy can be the estimated signal-to-noise ratio (SNR), the average absolute value of the LLRs or the estimated\nmodulation error rate (given by the deviation of the received QAM symbols to the possible transmit QAM symbols).\nBased on the estimated mutual information the required number of bits for the redundancy data transmission to the receiver needs to be calculated.  This can be done without knowledge of the channel state information (CSI), or taking the CSI into\naccount.  If CSI is available at the broadband server, the bits that experienced strong attenuation from the transmission channel are preferably transmitted first.  If no CSI is available this is not possible.\nTo allow for optimum performance of iterative FEC codes, the transmitted redundancy data bits should be uniformly distributed over the FEC codeword.  This avoids that the transmitted redundancy data is only located e.g. at the beginning of the\nFEC codeword.  This can be achieved by means of a pseudo random address generator that generates the addresses of the bits within the FEC codeword selected for transmission.  Thanks to the random nature of the generated addresses the selected bits are\nuniformly distributed within the FEC codeword.  The random address generator must be known to both the broadband server and the receiver, to allow for unambiguous decoding in the receiver based on the transmitted redundancy data bits.  In case of the\ntransmission of least robust bits (e.g. LSBs) first, as explained in an embodiment above, the random addresses of the least robust bits of all QAM symbols that carry a FEC codeword are used for generating the redundancy data bits first.  Afterwards the\nsecond least robust bits are used, and so on, until the required amount of redundancy data bits is reached.\nThe calculation of the amount of required redundancy data bits is carried out in the receiver, based on the estimated Mutual Information and the required Mutual Information for successful decoding of the utilized FEC code.  The required Mutual\nInformation is known for all code rates (see e.g. FIG. 15 for 64K LDPC of rate 1/2) by simulation and are stored in the server and the receiver.  Depending on the resulting SNR of each received QAM symbol (determined by the CSI), the additional Mutual\nInformation can be calculated that results in the receiver when a particular bit is perfectly known.  This additional Mutual Information is added to the available Mutual Information for each pseudo randomly generated bit location until the threshold of\nthe overall Mutual Information for error free decoding is reached.  By this means, the number of required redundancy data bits can be assessed in the receiver and a request with this number of bits is sent to the broadband server.  The broadband server\nthen uses the same pseudo random address generator to generate the redundancy data bits in the receiver.\nAs random address generator a linear feedback shift register (LFSR) with a polynomial representing a maximum length sequence (MLS) can be used.  For instance for a FEC block size of 64800 the register values generated by a 16-bit LFSR with a\ncycle length of 2.sup.16-1=65535 could be used.  However, only register values smaller or equal to 64800 are used as bit addresses, since the usage of the modulo-operator to truncate larger values could lead to a manifold generation of the same bit\naddress.  Other algorithms like the Mersenne-Twister can be used as well, but are not that simple to implement compared to an LFSR.  Preferably, the requested bits are only information bits in case the FEC code is systematic.  It shall be assumed that\nthe channel completely erased a codeword (of N bits--where K bits are information bits, i.e., the code rate is K/N).  In this case, instead of requesting the complete codeword again (N&gt;K), it would be sufficient to retransmit only the information bits\n(K).\nThe required number of bits in the receiver can then be computed based on the knowledge of the current Mutual Information.  Iteratively new pseudo random bit addresses are generated of bits that are transmitted as redundancy.  After each newly\ngenerated bit the additional Mutual Information is calculated that results from ideally knowing the additional bit at the generated address in the receiver.  The additional Mutual Information is easily accessible from a look up table that can be\npre-computed by means of Monte Carlo Simulation.  Based on the additional Mutual Information the current Mutual Information is updated by adding the additional Mutual Information.  This is iteratively repeated until the current Mutual Information exceeds\nthe required Mutual Information for successful decoding.  In pseudo code the algorithm for the calculation of the number of required bits in the receiver is the following:\nTABLE-US-00002 RoD bits to request = 0 while (current mutual information &lt; required mutual information) { generate bit address within FEC codeword; look up additional mutual information for QAM symbol from LUT current mutual information =\ncurrent mutual information + additional mutual information RoD bits to request = RoD bits to request + 1; }\nIn short: The algorithm describes a method to estimate the number of retransmitted pseudo random information bits (i.e. without utilizing the channel state information) for error free decoding.\nAll Mutual Information here corresponds to bitwise mutual information, such that the values are normalized to 1 to allow for direct comparison with the required mutual information value independent of the modulation order.\nThe table of the additional mutual information per QAM symbol depending on the number of known redundancy data bits within the QAM symbol is stored in the receiver as a look up table (LUT), e.g. in the storage 40.  The additional mutual\ninformation depends on the SNR of the QAM symbol that carries the bit, and the bits that are known within the QAM symbol.  For instance a LUT that stores the additional mutual information for the SNR range of 1 up to 30 dB for 256-QAM requires\n30*256=7680 entries.  If it is assumed that the LSBs are transmitted first, and so on, only 30*8=240 entries are required, since only 8 states are possible for each QAM symbol (1 bit known, .  . . , 8 bits known).  The values of the LUT entries are\ndetermined by MonteCarlo simulation in advance, based on the formula of the ideal Mutual Information.\nSince the LSBs of QAM symbols carry less Mutual Information and are therefore well suited as redundancy data bits, it is meaningful to optimize the algorithm such that it first generates the bit addresses of the LSBs, then the addresses of the\nbits with the next lower order within the QAM symbols (LSB-1), and so on.  By this means the bits with the highest order, providing the most additional Mutual Information, are transmitted first, reducing the required number of redundancy bits.\nThus, in such an embodiment the redundancy calculator 38 is configured to estimate said required amount of redundancy data based on a comparison between estimated Mutual Information and required Mutual Information for correct demodulation and\ndecoding.  For estimating the Mutual Information a mutual information estimation unit 39 is preferably provided.  Further, in an embodiment a storage 40 is additionally provided that stores the required Mutual Information for a plurality of codes, in\nparticular for a plurality of code rates and/or codeword lengths.\nAccordingly the redundancy calculator 42 of the broadcast server 4b is preferably configured to estimate said required amount of redundancy data based on channel state information and/or Mutual Information between transmitted and received data,\nin particular between transmitted bits of output data words or codewords and received values representing bits of output data words or codewords.  Further, the redundancy calculator 42 is preferably configured to estimate said required amount of\nredundancy data based on a comparison between estimated Mutual Information and required Mutual Information for correct demodulation and decoding.  Still further, preferably a storage 44 is provided that stores the required Mutual Information for a\nplurality of codes, in particular for a plurality of code rates and/or codeword lengths.\nThe algorithm above requires a lot of computations to determine the number of required bits, since the mutual information must be calculated for every additional bit per QAM symbol, to reflect the actual noise of each QAM symbol.  However, the\nalgorithm can be simplified by assuming an average noise level throughout the FEC codeword.  Based on the average noise level the average additional Mutual Information is calculated for the current bit order (LSBs transmitted first).  Based on the\naverage Mutual Information the number of additional bits is calculated to provide the amount of required Mutual Information for error free decoding.  If the number of required bits of this bit order is not sufficient, all bits of this bit order are\nflagged for transmission and this is the same is then iteratively calculated for the next bit order, and so on.  If the current bit order provides enough bits to bridge the remaining gap to the required Mutual Information, the number of redundancy bits\nis calculated by adding the (N/M) bits for each bit order that is completely transmitted, plus the additionally required bits of the current bit order.  This algorithm requires only one calculation for each of the M bit levels, instead of one calculation\nper bit, since the additional Mutual Information for each bit order is assumed to be the same throughout all (N/M) bits of this bit order.  The pseudocode for this simplified calculation of the required number of bits is the following:\nTABLE-US-00003 If (current MI &lt; required MI) { missing MI = required MI - current MI; for (int i = 0; i &lt; M; i++) { get additional MI from LUT (additional MI per QAM symbol if i+1 Bits are known instead of only i Bits, assuming an average\nSNR for all QAM symbols) calculate the number of required QAM symbols to bridge the gap of missing MI if one additional bit is known if (number of required QAM symbols &lt; N/M) { RoD bits to request = i * (N/M) + number of required QAM symbols; break; }\nelse { current MI = current MI + additional MI * (N/M) missing MI = required MI - current MI; } } }\nIn short: The algorithm describes a method to estimate the number of retransmitted pseudo random information bits (i.e. without utilizing the channel state information) for error free decoding, with reduced computational complexity but also\nreduced accuracy compared to algorithm 1.\nThus, in such an embodiment the redundancy calculator 38 of the receiver 3d is configured to determine an average additional Mutual Information for a channel symbol and to add said average additional Mutual Information to available Mutual\nInformation for each bit location of a particular codeword until a threshold of an overall Mutual Information required for correct decoding is reached and to determine the required amount of redundancy data required for correct decoding of said\nparticular codeword based thereon.  Accordingly, the redundancy calculator 42 of the broadband server 4b is configured to determine an average additional Mutual Information for a channel symbol and to add said average additional Mutual Information to\navailable Mutual Information for each bit location of a particular codeword until a threshold of an overall Mutual Information required for correct decoding is reached and to determine the required amount of redundancy data required for correct decoding\nof said particular codeword based thereon.\nAlternatively, the following calculation of the required number of redundancy based on estimated Mutual Information can be used, if it is assumed that the redundancy consists of already transmitted code bits.\nThe estimated Mutual Information shall be denoted as MI.sub.old, the required number of redundancy data as n, the number of bits in the codeword as N (e.g., N=64800 in a 64 k LDPC).  The new Mutual Information MI.sub.new after n (already\ntransmitted) redundant bits have been re-transmitted via a unicast system (generally, the broadband system) is then obtained by:\n##EQU00003##\nThe n redundant bits from the broadband server are received with substantially perfect knowledge, since a unicast system can guarantee error-free transmission.  The formula is due to the mixing property of the EXIT chart, see \"A. Ashikhmin, G.\nKramer, and S. ten Brink, \"Extrinsic information transfer functions: model and erasure channel properties,\" IEEE Trans.  Inform.  Theory, vol. 50, no. 11, pp.  2657-2673, November 2004.\nFrom the previous formula, it is obtained:\n.times..times.&gt; ##EQU00004## n will be lower bounded by 0 (if MIold&gt;MInew) and upper bounded by the number of information bits K in the codeword, if MInew is set to the code rate (or slightly above) R=K/N, in case MIold=0.\nIn short: The formula computes the amount n of redundancy that has to be retransmitted.  The new Mutual Information is computed, which is the weighted sum of the old Mutual Information and perfect Mutual Information for those n bits, and\ncompared with the desired Mutual Information that is required for successful decoding.\nIf the CSI of the receiver is available at the broadband server, the calculation of the required redundancy data bits can alternatively be carried out in the server.  The receiver then first transmits the CSI to the server (a possible CSI\ncompression scheme is described below).  Based on the SNR of each QAM symbol (determined from the CSI), the server is able to find the bit in the FEC codeword by means of the LUT that provides the largest additional mutual information.  This way the bits\nthat experienced deep fading are used first as redundancy data bits, since the additional mutual information of these bits is the largest.  The algorithm is very similar to the algorithm without CSI knowledge.  The important difference is that instead of\npseudo random bits, the bits providing the maximum additional information are used as redundancy bits.  This is iteratively repeated until the threshold of the required Mutual Information for error free decoding is reached.  The algorithm for the\ncalculation of the redundancy data bits in the server based on the receivers CSI in pseudo code is the following:\nTABLE-US-00004 RoD bits to request = 0 while (current MI &lt; required MI) { for (all bits in FEC codeword) { find bit with maximum additional MI (by means of LUT) } current MI = current MI + additional MI RoD bits to request = RoD bits to\nrequest + 1; }\nIn short: The algorithm describes a method to estimate the number of retransmitted bits for error free decoding, based on the channel state information, with optimum performance, but high computational complexity.\nThus, in such an embodiment the redundancy calculator 38 is configured to add additional Mutual Information resulting in the receiver, when a particular bit is known, to available Mutual Information for each bit location of a particular codeword\nuntil a threshold of an overall Mutual Information required for correct decoding is reached and to determine the required amount of redundancy data required for correct decoding of said particular codeword based thereon.  Preferably, said redundancy\ncalculator 38 is configured to determine said additional Mutual Information for several or all bits of a channel symbol.  Also in such an embodiment the receiver 3d preferably comprises a storage 40 that stores said additional Mutual Information for a\nplurality of codes, in particular for a plurality of code rates and/or codeword lengths.\nAccordingly, in such an embodiment the redundancy calculator 42 is configured to add additional Mutual Information resulting in the receiver, when a particular bit is known, to available Mutual Information for each bit location of a particular\ncodeword until a threshold of an overall Mutual Information required for correct decoding is reached and to determine the required amount of redundancy data required for correct decoding of said particular codeword based thereon.  Further, preferably the\nredundancy calculator 42 is configured to determine said additional Mutual Information for several or all bits of a channel symbol.  Still further, preferably a storage 44 is provided that stores said additional Mutual Information for a plurality of\ncodes, in particular for a plurality of code rates and/or codeword lengths.  In still another embodiment the redundancy calculator 42 is configured to use bits of a channel symbol providing the maximum additional Mutual Information, resulting in the\nreceiver, when a particular bit is known, as redundancy data.  In a similar way, the receiver could, using channel state information, determine the required number of bits of a channel symbol providing the maximum additional Mutual Information.\nThe broadband server then transmits the redundancy data bits to the receiver via broadband, which is then able to calculate the positions of the redundancy data bit within the FEC codeword with the same algorithm that has been used in the\nredundancy data server to generate the bits.  The receiver is then able to recombine and decode the FEC codeword.\nTo reduce the number of comparisons to find the optimal bit from the LUT, the LSBs only can be transmitted first, then the bits at bit position LSB-1 within the QAM symbol, and so on, since these bits have a high probability to carry the lowest\nMutual Information.  This is neglected in the pseudo code for simplicity.\nIn principle it is also possible to determine the number of required bits based on other parameters like SNR or MER.  However, SNR and MER do not allow for such an accurate estimation taking the CSI into account.  Rough numbers for the required\nRoD amount must be stored in the server and receiver that have been determined by simulation for different delta SNR values (required SNR-actual SNR).  That is, the estimation of the required number of redundancy data bits based on SNR or MER is less\naccurate compared to the Mutual Information and therefore not well suited here.\nIn the following synchronization between receiver and broadband server will be explained.\nThe signaling about how the received data must be combined in the receiver generally takes place in the broadband network.  As a result the frame structure employed in the broadcast network does not necessarily need any extension.  However, at\nthe physical layer an identification of the FEC-encoded data segments is required for the synchronization between the data from both terrestrial and broadband networks.  Besides, at the application layer the redundancy data can be signaled as an\nadditional service, therefore a linkage to the respective original service shall be given.\nCurrent terrestrial broadcasting systems like DVB-T or DVB-T2 contain no suitable mechanism for a unique identification of FEC packets/BBFrames, although the available timestamp of DVB-T2 (ISSY counter) might be applicable to some extent. \nHowever the limited time range of the ISSY counter might prevent a reliable packet identification An unambiguous mechanism is therefore required to inform the broadband server, which BBFrames could not be correctly decoded.  One solution would e.g. be a\ncounter related to each FEC packet, whose value is increased after each FEC packet, allowing for the unique identification of a FEC packet.  If it is intended to introduce the concept of using redundancy (on demand; RoD) in broadcasting systems without\nsuch unique packet identification alternative approaches need to be used.  A specific amount of soft-information (LLR) values of the LDPC or BCH parity block (in case of DVB-T2) of the erroneous packet can be used as a fingerprint that identifies the\npacket.  This is possible, since even a slight difference in the payload between packets leads to different parity blocks.  Based on the sequence of LLR values, the broadband server can perform a correlation to achieve the synchronization.  This allows\nfor the synchronization between broadband server and the receiver even if the required SNR in the receiver is too low to decode any FEC packets correctly.\nThus, in an embodiment of a broadband server 4c depicted in FIG. 16 it comprises, in addition to the elements of the broadband server 4b shown in FIG. 14, an identification unit 45 that identifies a data packet for which redundancy data shall be\ndetermined by use of a correlation using soft information values of data of said data packet, in particular of parity data, contained in a request received from a receiver, wherein said redundancy calculator 42 is configured to use the information about\nthe identity of the data packet to determine redundancy data for said data packet.  In the same way, the receiver could identify the data packet to which received redundancy data belong based on the correlation using soft information of the demodulator\nand/or the decoder.\nIf the receiver was already able to decode some FEC packets, the transmission of soft-information for correlation in the broadband server is not necessary, since a subset of the parity blocks of correctly decoded preceding FEC packets can be\nused for packet identification.  In such cases the known and hard decided fingerprint of the last correctly received packet and the number of erroneous packets is transmitted to the broadband server, which then sends the required amount of redundancy for\nthe requested packets.  For this identification approach even a small amount of bits is sufficient, since no correlation in the receiver is required.  It must only be assured that the fingerprint uniquely identifies the FEC packet.  Assuming that the\nparity blocks are binary sequences with equal distribution, the probability that a fingerprint sequence with length n is not unique for m preceding FEC packets is\n.times..times..times.  ##EQU00005##\nBased on this formula the required number of bits can easily be calculated for a given maximum misdetection probability p and the number of FEC packets the identification is carried out with.  The misdetection probability p is given in the\nfollowing table for exemplary values of m and n. It becomes clear that increasing the fingerprint length m, decreases the probability for misdetection.\nTABLE-US-00005 m\\n 8 16 24 32 40 48 56 64 2 3.91E-03 1.53E-05 5.96E-08 2.33E-10 9.09E-13 3.55E-15 1.39E-17 5.42E-20 10 1.63E-01 0.00068644 2.68E-06 1.05E-08 4.09E-11 1.60E-13 6.25E-16 2.44E-- 18 25 0.702147 0.00456774 1.79E-05 6.98E-08 2.73E-10\n1.07E-12 4.16E-15 1.63E-- 17 100 1 0.0727845 0.000295 1.15E-06 4.50E-09 1.76E-11 6.87E-14 2.68E-16 250 1 0.378447 0.00185348 7.25E-06 2.83E-08 1.11E-10 4.32E-13 1.69E-15 1000 1 0.999529 0.0293343 0.000116292 4.54E-07 1.77E-09 6.93E-12 2.71E-14 2500 1 1\n0.169892 0.00072704 2.84E-06 1.11E-08 4.34E-11 1.69E-13 10000 1 1 0.949234 0.0115729 4.55E-05 1.78E-07 6.94E-10 2.71E-12\nHowever, the success rate can be further increased if the frame number and the number of the FEC block within the frame are transmitted.\nThus, in such an embodiment of a broadband server 4c depicted in FIG. 16 the identification unit 45 identifies a data packet for which redundancy data shall be determined by use of a number of bits, in particular parity bits, of the last\ncorrectly decoded codewords contained in a request received from a receiver.  Further, the redundancy calculator 42 is configured to use the information about the identity of the data packet to determine redundancy data for said data packet.  In another\nembodiment a packet counter or a timestamp (ISSY) can be used for packet identification.\nIn the following cooperative decoding with distributed receivers will be explained.\nMost TV devices nowadays are integrated with terrestrial broadcast receiver.  But the TV devices work alone with the locally received signals.  However, as home networks are being installed in more and more household, the receivers can be\nconnected to each other as well, so that a cooperative decoding of the broadcast signal becomes realizable.  A space-diversity will be created when the receivers can carry out the decoding jointly and thus an improvement of the signal quality will also\nbe possible.  This concept is operating without a server that has perfect knowledge of the transmitted signal.  Instead the redundancy data is generated in a cooperative fashion.\nIn the embodiment of a broadcast system shown in FIG. 17, n receivers Rx1, Rx2, .  . . , R are connected via a server, which may be located separately or together with one of the receivers.  After receiving the broadcast signal each receiver\nchecks whether and where (temporally or spectrally) redundancy data is required and makes a request to the server.  Having the requests from each receiver, the server requires the necessary data from each receiver, encode it, and distribute it to the\nreceivers that need it.\nAssuming an example with two receivers, Rx1 and Rx2, three cases may happen to each signal part (temporally or spectrally).  1.  Both receivers can decode it correctly by themselves.  No data exchange is needed in this case.  2.  Both receivers\ncannot decode it correctly by themselves.  The LLRs of the signal are quantized and transmitted to the server, who adds them together and multicasts the signal to both receivers.  Afterwards the receivers precede the decoding process with help of the\nreceived LLRs.  3.  One receiver can decode it correctly by itself while the other not.  In best case, another signal part can be found where the situation is reversed and the LLRs of these two signal parts can be added and forwarded by the server.  Then\neach receiver can achieve the desired part by subtracting their own signal (network coding alike).\nFor example:\n##STR00001## Rx1 send S2 and Rx2 send S1' to the server.  The server transmitted then S2+S1 back to each receiver, which can get the desired signal with subtraction.\nSuch a broadcast system thus comprises a broadcast transmitter that broadcasts broadcast signals in a coverage area for reception by terminals comprising a broadcast receiver and a broadband receiver, a broadband server that provides redundancy\ndata to terminals within said coverage area, and one or more terminals comprising a broadcast receiver and a broadband receiver, wherein said broadband server is configured to obtain redundancy data required by a terminal from one or more other\nterminals.\nThe information exchange can take place autonomously when the receivers are somehow connected to each other (e.g. by a home network via Ethernet) such that a distributed network is resulting.  This approach is shown in FIG. 18.  In this case,\nthe server is not necessary and data request, coding and flow control are controlled by receivers themselves.  Such a broadcast system thus comprises a broadcast transmitter that broadcasts broadcast signals in a coverage area for reception by terminals\ncomprising a broadcast receiver and a broadband receiver, and one or more terminals comprising a broadcast receiver, wherein said terminals are configured to obtain redundancy data required by a terminal from one or more other terminals.\nObviously, numerous modifications and variations of the present disclosure are possible in light of the above teachings.  It is therefore to be understood that within the scope of the appended claims, the invention may be practiced otherwise\nthan as specifically described herein.\nIn the claims, the word \"comprising\" does not exclude other elements or steps, and the indefinite article \"a\" or \"an\" does not exclude a plurality.  A single element or other unit may fulfill the functions of several items recited in the claims. The mere fact that certain measures are recited in mutually different dependent claims does not indicate that a combination of these measures cannot be used to advantage.\nIn so far as embodiments of the invention have been described as being implemented, at least in part, by software-controlled data processing apparatus, it will be appreciated that a non-transitory machine-readable medium carrying such software,\nsuch as an optical disk, a magnetic disk, semiconductor memory or the like, is also considered to represent an embodiment of the present invention.  Further, such a software may also be distributed in other forms, such as via the Internet or other wired\nor wireless telecommunication systems.\nThe elements of the claimed devices and apparatus may be implemented by corresponding hardware and/or software elements, for instance appropriated circuits.  A circuit is a structural assemblage of electronic components including conventional\ncircuit elements, integrated circuits including application specific integrated circuits, standard integrated circuits, application specific standard products, and field programmable gate arrays.  Further a circuit includes central processing units,\ngraphics processing units, and microprocessors which are programmed or configured according to software code.  A circuit does not include pure software, although a circuit includes the above-described hardware executing software.\nAny reference signs in the claims should not be construed as limiting the scope.", "application_number": "15723537", "abstract": " A receiver for receiving data in a broadcast system includes a broadcast\n     receiver that receives, via the broadcast system, a receiver input data\n     stream including plural channel symbols represented by constellation\n     points in a constellation diagram. A demodulator demodulates the channel\n     symbols into codewords and a decoder decodes the codewords into output\n     data words. A broadband receiver obtains redundancy data via a broadband\n     system, the redundancy data for a channel symbol including one or more\n     least robust bits of the channel symbol or a constellation subset\n     identifier indicating a subset of constellation points including the\n     constellation point representing the channel symbol. The demodulator\n     and/or the decoder is configured to use the redundancy data to demodulate\n     the respective channel symbol and to decode the respective codeword,\n     respectively.\n", "citations": ["4800559", "5191410", "5311194", "6788729", "8284727", "8775908", "9503297", "9538214", "9692630", "9755781", "20010043575", "20020004369", "20030058810", "20080101304", "20090037797", "20110158257", "20120051469", "20120272117", "20120314655", "20130254828"], "related": ["14422919", "2013074363"]}, {"id": "20180052709", "patent_code": "10310908", "patent_name": "Dynamic usage balance of central processing units and accelerators", "year": "2019", "inventor_and_country_data": " Inventors: \nFong; Liana L. (Irvington, NY), Tan; Wei (Elmsford, NY)  ", "description": "<BR><BR>BACKGROUND\nA hybrid computing infrastructure may contain heterogeneous processors.  For instance, a hybrid computing infrastructure may be comprised of general processors, such as central processing units (CPUs) and one or more accelerators, such as\ngraphical processing units (GPUs).  As sequential and parallel operations are being employed together in complex software programs, coordination between CPU and GPU resources is a challenge.\n<BR><BR>SUMMARY\nIllustrative embodiments of the invention provide techniques for dynamically balancing usage of central processing units and accelerators.\nFor example, in one illustrative embodiment, a method comprises receiving a task request for associated with a workload.  A utility value is calculated for a plurality of strategies for executing the workload.  At least two of the plurality of\nstrategies are associated with a distribution of the workload between a CPU and the one or more accelerators.  A strategy having a maximum utility value is selected from the plurality of strategies, and the task is executed according to the selected\nstrategy.\nMore particularly, in one illustrative embodiment, the CPU comprises at least one core comprising at least one thread.  In one illustrative embodiment, each accelerator is a GPU.\nThe embodiments described herein may further be embodied in a computer program product and a system. <BR><BR>BRIEF DESCRIPTION OF THE DRAWINGS\nFIG. 1A illustrates an exemplary architectural relationship hierarchy of a hybrid computing infrastructure, in accordance with at least one embodiment.\nFIG. 1B illustrates a block diagram comparing a CPU with a GPU, in accordance with at least one embodiment.\nFIG. 2 illustrates CPU threads and cores and available GPUs for hybrid cognitive computing, in accordance with at least one embodiment.\nFIG. 3 illustrates data sets distributed across a plurality of cores and coupled to a plurality of GPUs for accelerating computations, in accordance with at least one embodiment.\nFIG. 4 illustrates a system for executing a task, in accordance with at least one embodiment.\nFIG. 5 further illustrates a system for executing a task, in accordance with at least one embodiment.\nFIG. 6 still further illustrates a system for executing a task, in accordance with at least one embodiment.\nFIG. 7 illustrates a process for selecting a strategy to execute a task, in accordance with at least one embodiment.\nFIG. 8 illustrates a cloud computing environment, in accordance with at least one embodiment.\nFIG. 9 illustrates abstraction model layers, in accordance with at least one embodiment.\n<BR><BR>DETAILED DESCRIPTION\nA hybrid computing infrastructure generally refers to one or more computing systems that contain both general and special-purposed computing platforms.  Software programs (e.g., applications) may benefit from running in a hybrid computing\ninfrastructure, since such an infrastructure may serve as a platform for workload optimization.  For example, for applications running in a hybrid computing infrastructure, security and reliability priority components may be placed in one set of\ninfrastructure processors, while computation intense components may be placed in a different set of infrastructure processors.\nDifferent types of computing paradigms or applications may leverage on hybrid computing infrastructures.  One type of computing paradigm that relies heavily on a hybrid computing infrastructure is cognitive computing.  Cognitive computing is a\ncomputing paradigm that simulates human thought processes in a computer system.  The system uses machine learning algorithms for functions such as pattern recognition, data mining, and natural language processing to mimic operation of the human brain.\nFor example, in a cognitive computing environment, frameworks may provide for processing large data sets with a parallel, distributed algorithm on a cluster of computer servers or nodes, in order to scale-out the computations.  Accelerators may\nbe provided on individual nodes in order to scale-up, i.e., to accelerate the computation.\nFIG. 1A illustrates an exemplary architectural relationship hierarchy 100a of a hybrid computing infrastructure.  As shown, CPU 110 is at a top level of hierarchy 110a.  Below CPU 110 are sockets 120-1 and 120-2.  In one embodiment, sockets\n120-1 and 120-2 are PCIe sockets.  One or more accelerators, such as one or more GPUs, may be placed below sockets 120-1 and 120-2 in hierarchy 100a.  In one embodiment, and as shown, GPU.sub.1 130-1 and GPU.sub.2 130-2 are connected to socket 120-1, and\nGPU.sub.3 130-3 and GPU.sub.4 130-4 are connected to socket 120-2.  It is to be understood and appreciated that the number of CPUs, sockets, and GPUs shown in FIG. 1A is purely exemplary, and should not be considered limiting.\nFIG. 1B is illustrates a block diagram 100b comparing an exemplary CPU 140 with an exemplary GPU 150.  For the purposes of the illustrative embodiment depicted in FIG. 1B, CPU 140 is shown as having a set of arithmetic logical units (ALUs) 142\nand L2 cache 144.  Set of ALUs 142 is shown including four ALUs.  However, the number of ALUs of the CPU should not be considered limiting.  CPU 140 is further shown as having dynamic random-access memory (DRAM) 146.  However, any type of RAM may be\nimplemented within CPU 140 in accordance with the embodiments described herein.  CPU 140 is further shown as having control unit 148.\nFor the purposes of the illustrative embodiment depicted in FIG. 1B, GPU 150 is shown with set of ALUs 152a, set of ALUs 152b and L2 cache 154.  Each set of ALUs 152a and 152b is shown including hundreds of ALUs.  However, the number of ALUs of\nthe GPU should not be considered limiting.  GPU 150 is further shown as having DRAM 156.  However, any type of RAM may be implemented within the GPU in accordance with the embodiments described herein.\nThe differences between the exemplary CPU 140 and the exemplary GPU 150 discussed in relation to FIG. 1B correspond to differences in performance between a CPU and a GPU.  To illustrate such differences in performance metrics, an exemplary\nIntel.RTM.  Xeon.RTM.  Processor E5-2687w CPU (\"Xeon\") will be compared with an exemplary NVIDIA.RTM.  Tesla.RTM.  K40 GPU accelerator (\"Tesla\").  The Xeon has 2.27B transistors, 8 cores and 16 threads, and operates at a base frequency of 3.1 GHz. \nAdditionally, the Xeon has a SP TFLOP (single precision teraflop) value of 0.35 and a DP TFLOP (double precision teraflop) value of 0.17.  As is known in the art, the term flop refers to floating-point operations per second.  With respect to memory\nspecifications, the Xeon has a maximum memory size of 256 GB, and has a DDR3 SDRAM memory with a sample rate of 1600 megatransfers per second (MT/s).\nIn contrast to the Xeon, the Tesla has 7.1B transistors, 2880 cores and 30720 threads, and operates at a base frequency of 745 MHz.  Additionally, the Tesla has a SP TFLOP value of 4.29, and a DP TFLOP value of 1.43.  With respect to memory\nspecifications, the Tesla has a maximum memory size of 12 GB, and has a GDDR5 memory with a sample rate of 3 GHz.\nBased on the foregoing performance metric comparison, a GPU has a slower clock and fewer cache.  Thus, the GPU is not optimized for latency.  However, a GPU has more transistors to compute with, as compared to a CPU, as well as higher FLOP\nvalues and memory bandwidth.  Accordingly, a GPU is optimized for data-parallel, high-throughput workloads.\nAs compared to CPUs, GPUs generally have a smaller main memory.  Operation may be slowed down due to data fetches to GPUs from CPU memory.  In one embodiment, a fast scheme to perform a context switch between tasks may be implemented by a GPU to\nhide latency.  In other words, task waiting for data fetches may yield to other tasks with data already in memory.\nFIG. 2 illustrates a hybrid computing infrastructure 200.  It is to be appreciated that, in one embodiment, infrastructure 200 can be implemented via the hierarchy shown in FIG. 1A, and the CPU/GPU specifications shown in FIG. 1B.\nIn one embodiment, infrastructure 200 is a hybrid cognitive computing system.  Infrastructure 200 comprises CPU 202 and one or more accelerators 208-1, 208-2, 208-3, .  . . , 208-n. In one embodiment, and as shown in FIG. 2, each accelerator is\na GPU.  CPU 202 comprises a plurality of processing cores (or simply, cores) 204 with each core being configured to execute a plurality of threads 206.  Each thread, such as thread 206a, may provide a single line of commands that are processed.  In\nillustrative embodiments, the number of GPUs may be less than the number of CPU cores.  Due to constraints (e.g., memory constraints), each GPU may be unable to accommodate acceleration requests from many CPU threads.\nApache Spark.TM.  is an important scale-out framework for big data and cognitive workloads.  Apache Spark.TM.  enables programmers with an application programming interface (API) centered on resilient distributed datasets (RDDs).  RDDs are\ndistributed memory abstractions that allow performance of in-memory computations on large clusters in a fault-tolerant way, and enable efficient data reuse in-memory for a broad range of applications.  Specifically, RDDs are fault-tolerant, parallel data\nstructures that allow users to explicitly persist intermediate results in memory, control partitioning to optimize data placement for parallel processing, and manipulate them by using a rich set of operators.  The availability of RDDs in-memory\nfacilitates the implementation of both iterative algorithms, which visit their dataset multiple times in a loop, and interactive/exploratory data analysis, i.e., the repeated database-style querying of data.\nDynamically balancing instruction execution between the CPUs and accelerators (e.g., GPUs) within the hybrid computing infrastructure is a consideration with respect to usage optimization of CPUs and GPUs to meet operation objectives, such as\nshort execution time and low cost.\nFIG. 3 illustrates an embodiment of a machine learning system.  In one embodiment, the system is configured to execute a matrix factorization algorithm for a recommender system, as one software feature in a machine learning library.  For\nexample, the matrix factorization algorithm may be an optimized CUDA.RTM.-based matrix factorization algorithm, and the machine learning library may be a scalable machine learning library as a feature of the Apache Spark software.  CUDA.RTM.  is a\nregistered trademark of the NVIDIA Corporation.\nIn a non-limiting example, FIG. 3 illustrates node 300.  Node 300 is shown having eight cores, including cores 310a and 310b, four acceleration kernels written in CUDA.RTM., including kernel 312, and two GPUs, including GPU 314, in a cluster\ncomputing software framework.  It is to be understood and appreciated that the number of cores, kernels and GPUs is not to be considered limiting.\nDatasets residing on the cores are coupled to respective GPUs via respective kernels.  In one embodiment, each dataset is a resilient distributed dataset (RDD).  For example, datasets residing on cores 310a and 310b are coupled to the GPU 314\nvia kernel 312.  The datasets allow for the distribution of, for example, rating data and shuffling of parameters, while the GPUs are for offloading intense computations, such as for example, linear algebra computations.  Programs are able to run on\nmultiple nodes, with multiple GPUs per node.  The system of FIG. 3 leverages the scaling-out features of the cluster computing software framework, and the scaling-up features of the GPUs.  Accordingly, programs may run on the CPU cores or the GPU or\npartitioned to be run on both.\nFor example, at the beginning of each iteration of the matrix factorization algorithm, rating data with learned parameters are obtained from the RDD obtained from the shuffling at the end of the last iteration.  Afterward, in each node, each RDD\npartition makes necessary data transformation(s), sends the (transformed) data as matrices to a selected GPU, invokes the GPU kernels to perform linear algebra computation, collects result matrices from the previously selected GPU and stores the\ncollected result matrices in RDDs.  When this is done, the resulting RDDs are shuffled to be ready for the next iteration.\nAdvantageously, a GPU has greater computing power as compared to a CPU.  For example, a GPU may have a higher floating-point operations per second (FLOP/s) rate that is at least about ten-times greater than that of a CPU, as exemplified in FIG.\n1B.  As such, it is advantageous to offload programs or instructions from a CPU that may require the additional computing power of a GPU.\nA thread of a CPU may comprise a program instruction requiring a large amount of computation, which may benefit from being offloaded to a GPU.  A first step in attempting to offload a thread is to determine whether an appropriate GPU exists and\ncurrently available to handle the thread.  At least three strategies may be used with respect to offloading a thread to GPUs.\nFIG. 4 illustrates system 400 configured to execute a task or instruction, according to a first strategy.  The system is shown having at least one CPU 406 having multiple threads, including thread 406a.  System 400 is further shown having a\nplurality of GPUs 408-1 through 408-n, each having a queue 418-1 through 418-n, respectively.\nA first step in executing the task of thread 406a according to the first strategy is to determine an appropriate GPU among GPU 408-1 through GPU 408-n for offloading a task workload.  In one embodiment, the appropriate GPU is determined based on\none or more considerations.  One such consideration is queue length.  For example, if CPU 406 first selects GPU 408-1 to offload thread 406a, but GPU 408-1 has a long queue 418-1, the CPU can look for a GPU with a shorter queue.  Another such\nconsideration is that the CPU may choose a GPU having the memory and compute capacity required to process the instruction of thread 406a.  For example, overloading the memory and compute capacity may affect the execution time of the thread.  Yet another\nsuch consideration may be socket (channel) affinity.  For example, it may be advantageous to assign multiple threads to the same communication socket, as communication across GPUs would be more efficient if they are on the same socket.  In general, it is\nadvantageous to offload compute and memory intensive workloads, such as for example, iterative general matrix multiply (GEMM), according to the first offloading strategy described in FIG. 4.  Accordingly, the first strategy offloads the workload from the\nthread to the GPU.\nFIG. 5 illustrates system 500 configured to execute a task or instruction, according to a second strategy.  System 500 is shown having at least one CPU 506 having multiple threads, including thread 506a.  System 500 is further shown having a\nplurality of GPUs 508-1 through 508-n. In FIG. 5, each GPU 508-1 through GPU 508-n is full.  Thus, the second offloading strategy comprises CPU 506 retaining the instruction and not offloading the instruction.  In general, retaining the computation in\nthe CPU is advantageous for workloads that would run only marginally faster on a GPU, for example a one-pass data scan.  Accordingly, the second strategy uses the CPU to handle the workload if each GPU is full, thus the waiting time for GPUs would\nelongate the total thread execution time.\nFIG. 6 illustrates system 600 configured to execute a task or instruction, according to a third strategy.  System 600 is shown having at least one CPU 606 having multiple threads, including thread 606a.  System 600 is further shown having a\nplurality of GPUs 608-1 through 608-n. In FIG. 6, each GPU 608-1 through GPU 608-n has a full memory.  Although the memories of GPU 608-1 through GPU 608-n are full, the GPUs are still available for computations.  Thus, handling the instruction on thread\n606a according to the third strategy comprises determining an appropriate GPU among GPU 608-1 through GPU 608-n, and allocating working memory on host memory 620.  In general, the third strategy is advantageous for compute-intensive workloads that\ninfrequently access external memory, such as, for example some Monte-Carlo simulations.  Accordingly, the third strategy allocates needed working memory on the host and executes the workload on the GPU, even though allocation to host memory may not be as\nefficient as allocation to local GPU memory.\nFIGS. 4-6 described individual strategies that may be implemented to handle an instruction, or task.  FIG. 7 is a flow diagram 700 illustrating the workflow used for determining the strategy to be used in handling the task assignment to CPUs or\nGPUs.  In block 710, task information is collected.  The task information may include attributes such as speedup and memory allocation requirements.  In one embodiment, speedup is defined herein as performance ratio between the CPU and the GPU.  For\nexample, speedup may be derived by comparing the elapsed time of the CPU and the GPU during execution a given task.  For illustrative purposes, if the elapsed time for executing a thread on a GPU is 2 seconds and the elapsed time for executing the thread\non a CPU is 10 seconds, then the GPU has a speedup of 5.times.  compared to the CPU.\nIn block 720, GPU information is collected.  The GPU information may include the current queue length of each GPU, GPU memory utilization, GPU compute utilization, and socket affinity.  In block 730, a new task request is received.  In one\nembodiment, the new task request requires both computational time and memory allocations.  In block 740, a utility value for the task is calculated for each strategy (e.g., the first, second and third strategies described herein above) based on a utility\nfunction.  In one embodiment, the utility function is a prorated utility function.  The utility value is calculated based on the collected task information and the collected GPU information.  In one embodiment, the calculation in block 740 may also take\ninto account the cost associated with utilizing a GPU for the computations versus not utilizing a GPU.  Commonly and currently, nodes with GPUs are more expensive to rent, for example, in cloud computing environments.  As such, workloads of low priority\nmay not utilize GPUs for speed up.\nThe data collection/value collection may be \"inline\" or \"offline\".  For example, workload speedup can use data collected inline, but may be modelled and/or calculated offline and saved in a table.  In one embodiment, the queue lengths at the\nGPUs is dynamically observed during runtime.  The affinity of sockets may be static information, but may change at reboot.\nIn one embodiment, the utility value is calculated by test run, workload profiling and machine learning based techniques (e.g., regression).  The utility value that is calculated may then be normalized, such as to a value within the interval\n[0,1] (i.e., a value of 1 is the maximum utility value possible for a given strategy, and a value of 0 is the lowest utility value possible for a given strategy).  Depending on the optimization target, the utility value may represent factors, which may\ninclude execution time, cost, etc. Specific factors include, but are not limited to, infrastructure expense (e.g., GPU cycle being more expensive than a CPU cycle) and job completion time delay.\nIn block 750, a strategy is chosen that maximizes the utility value.  For example, if the utility values are normalized, then the strategy is chosen corresponding to a value closest to 1.  In block 760, the task is executed in accordance with\nthe chosen strategy, and the GPU and the task information is updated.\nThe embodiments described herein implement a process for dynamically balancing usage of CPUs and accelerators.  In one embodiment, a logic component on the CPU is configured to perform one or more steps of the process.  This process leverages\nall CPU cores and GPUs by selecting a utility-maximizing strategy for handling a work.  Accordingly, the embodiments described herein efficiently schedule workloads in a hybrid computing system.\nSuch hybrid CPU and GPU architecture can be provisioned as a cloud service to end users who do not own the hardware.  It is to be understood that although this disclosure includes a detailed description on cloud computing, implementation of the\nteachings recited herein are not limited to a cloud computing environment.  Rather, embodiments of the present invention are capable of being implemented in conjunction with any other type of computing environment now known or later developed.\nCloud computing is a model of service delivery for enabling convenient, on-demand network access to a shared pool of configurable computing resources (e.g., networks, network bandwidth, servers, processing, memory, storage, applications, virtual\nmachines, and services) that can be rapidly provisioned and released with minimal management effort or interaction with a provider of the service.  This cloud model may include at least five characteristics, at least three service models, and at least\nfour deployment models.\nCharacteristics are as follows:\nOn-demand self-service: a cloud consumer can unilaterally provision computing capabilities, such as server time and network storage, as needed automatically without requiring human interaction with the service's provider.\nBroad network access: capabilities are available over a network and accessed through standard mechanisms that promote use by heterogeneous thin or thick client platforms (e.g., mobile phones, laptops, and PDAs).\nResource pooling: the provider's computing resources are pooled to serve multiple consumers using a multi-tenant model, with different physical and virtual resources dynamically assigned and reassigned according to demand.  There is a sense of\nlocation independence in that the consumer generally has no control or knowledge over the exact location of the provided resources but may be able to specify location at a higher level of abstraction (e.g., country, state, or datacenter).\nRapid elasticity: capabilities can be rapidly and elastically provisioned, in some cases automatically, to quickly scale out and rapidly released to quickly scale in. To the consumer, the capabilities available for provisioning often appear to\nbe unlimited and can be purchased in any quantity at any time.\nMeasured service: cloud systems automatically control and optimize resource use by leveraging a metering capability at some level of abstraction appropriate to the type of service (e.g., storage, processing, bandwidth, and active user accounts). Resource usage can be monitored, controlled, and reported, providing transparency for both the provider and consumer of the utilized service.\nService Models are as follows:\nSoftware as a Service (SaaS): the capability provided to the consumer is to use the provider's applications running on a cloud infrastructure.  The applications are accessible from various client devices through a thin client interface such as a\nweb browser (e.g., web-based e-mail).  The consumer does not manage or control the underlying cloud infrastructure including network, servers, operating systems, storage, or even individual application capabilities, with the possible exception of limited\nuser-specific application configuration settings.\nPlatform as a Service (PaaS): the capability provided to the consumer is to deploy onto the cloud infrastructure consumer-created or acquired applications created using programming languages and tools supported by the provider.  The consumer\ndoes not manage or control the underlying cloud infrastructure including networks, servers, operating systems, or storage, but has control over the deployed applications and possibly application hosting environment configurations.\nInfrastructure as a Service (IaaS): the capability provided to the consumer is to provision processing, storage, networks, and other fundamental computing resources where the consumer is able to deploy and run arbitrary software, which can\ninclude operating systems and applications.  The consumer does not manage or control the underlying cloud infrastructure but has control over operating systems, storage, deployed applications, and possibly limited control of select networking components\n(e.g., host firewalls).\nDeployment Models are as follows:\nPrivate cloud: the cloud infrastructure is operated solely for an organization.  It may be managed by the organization or a third party and may exist on-premises or off-premises.\nCommunity cloud: the cloud infrastructure is shared by several organizations and supports a specific community that has shared concerns (e.g., mission, security requirements, policy, and compliance considerations).  It may be managed by the\norganizations or a third party and may exist on-premises or off-premises.\nPublic cloud: the cloud infrastructure is made available to the general public or a large industry group and is owned by an organization selling cloud services.\nHybrid cloud: the cloud infrastructure is a composition of two or more clouds (private, community, or public) that remain unique entities but are bound together by standardized or proprietary technology that enables data and application\nportability (e.g., cloud bursting for load-balancing between clouds).\nA cloud computing environment is service oriented with a focus on statelessness, low coupling, modularity, and semantic interoperability.  At the heart of cloud computing is an infrastructure that includes a network of interconnected nodes.\nReferring now to FIG. 8, illustrative cloud computing environment 50 is depicted.  As shown, cloud computing environment 50 includes one or more cloud computing nodes 10 with which local computing devices used by cloud consumers, such as, for\nexample, personal digital assistant (PDA) or cellular telephone 54A, desktop computer 54B, laptop computer 54C, and/or automobile computer system 54N may communicate.  Nodes 10 may communicate with one another.  They may be grouped (not shown) physically\nor virtually, in one or more networks, such as Private, Community, Public, or Hybrid clouds as described hereinabove, or a combination thereof.  This allows cloud computing environment 50 to offer infrastructure, platforms and/or software as services for\nwhich a cloud consumer does not need to maintain resources on a local computing device.  It is understood that the types of computing devices 54A-N shown in FIG. 1 are intended to be illustrative only and that computing nodes 10 and cloud computing\nenvironment 50 can communicate with any type of computerized device over any type of network and/or network addressable connection (e.g., using a web browser).\nReferring now to FIG. 9, a set of functional abstraction layers provided by cloud computing environment 50 (FIG. 1) is shown.  It should be understood in advance that the components, layers, and functions shown in FIG. 9 are intended to be\nillustrative only and embodiments of the invention are not limited thereto.  As depicted, the following layers and corresponding functions are provided:\nHardware and software layer 60 includes hardware and software components.  Examples of hardware components include: mainframes 61; RISC (Reduced Instruction Set Computer) architecture based servers 62; servers 63; blade servers 64; storage\ndevices 65; and networks and networking components 66.  In some embodiments, software components include network application server software 67 and database software 68.\nVirtualization layer 70 provides an abstraction layer from which the following examples of virtual entities may be provided: virtual servers 71; virtual storage 72; virtual networks 73, including virtual private networks; virtual applications\nand operating systems 74; and virtual clients 75.\nIn one example, management layer 80 may provide the functions described below.  Resource provisioning 81 provides dynamic procurement of computing resources and other resources that are utilized to perform tasks within the cloud computing\nenvironment.  Metering and Pricing 82 provide cost tracking as resources are utilized within the cloud computing environment, and billing or invoicing for consumption of these resources.  In one example, these resources may include application software\nlicenses.  Security provides identity verification for cloud consumers and tasks, as well as protection for data and other resources.  User portal 83 provides access to the cloud computing environment for consumers and system administrators.  Service\nlevel management 84 provides cloud computing resource allocation and management such that required service levels are met.  Service Level Agreement (SLA) planning and fulfillment 85 provide pre-arrangement for, and procurement of, cloud computing\nresources for which a future requirement is anticipated in accordance with an SLA.\nWorkloads layer 90 provides examples of functionality for which the cloud computing environment may be utilized.  Examples of workloads and functions which may be provided from this layer include: mapping and navigation 91; software development\nand lifecycle management 92; virtual classroom education delivery 93; data analytics processing 94; transaction processing 95; and hybrid computing infrastructure 96 in accordance with the present invention.\nThe present invention may be a system, a method, and/or a computer program product at any possible technical detail level of integration.  The computer program product may include a computer readable storage medium (or media) having computer\nreadable program instructions thereon for causing a processor to carry out aspects of the present invention.\nThe computer readable storage medium can be a tangible device that can retain and store instructions for use by an instruction execution device.  The computer readable storage medium may be, for example, but is not limited to, an electronic\nstorage device, a magnetic storage device, an optical storage device, an electromagnetic storage device, a semiconductor storage device, or any suitable combination of the foregoing.  A non-exhaustive list of more specific examples of the computer\nreadable storage medium includes the following: a portable computer diskette, a hard disk, a random access memory (RAM), a read-only memory (ROM), an erasable programmable read-only memory (EPROM or Flash memory), a static random access memory (SRAM), a\nportable compact disc read-only memory (CD-ROM), a digital versatile disk (DVD), a memory stick, a floppy disk, a mechanically encoded device such as punch-cards or raised structures in a groove having instructions recorded thereon, and any suitable\ncombination of the foregoing.  A computer readable storage medium, as used herein, is not to be construed as being transitory signals per se, such as radio waves or other freely propagating electromagnetic waves, electromagnetic waves propagating through\na waveguide or other transmission media (e.g., light pulses passing through a fiber-optic cable), or electrical signals transmitted through a wire.\nComputer readable program instructions described herein can be downloaded to respective computing/processing devices from a computer readable storage medium or to an external computer or external storage device via a network, for example, the\nInternet, a local area network, a wide area network and/or a wireless network.  The network may comprise copper transmission cables, optical transmission fibers, wireless transmission, routers, firewalls, switches, gateway computers and/or edge servers. \nA network adapter card or network interface in each computing/processing device receives computer readable program instructions from the network and forwards the computer readable program instructions for storage in a computer readable storage medium\nwithin the respective computing/processing device.\nComputer readable program instructions for carrying out operations of the present invention may be assembler instructions, instruction-set-architecture (ISA) instructions, machine instructions, machine dependent instructions, microcode, firmware\ninstructions, state-setting data, configuration data for integrated circuitry, or either source code or object code written in any combination of one or more programming languages, including an object oriented programming language such as Smalltalk, C++,\nor the like, and procedural programming languages, such as the \"C\" programming language or similar programming languages.  The computer readable program instructions may execute entirely on the user's computer, partly on the user's computer, as a\nstand-alone software package, partly on the user's computer and partly on a remote computer or entirely on the remote computer or server.  In the latter scenario, the remote computer may be connected to the user's computer through any type of network,\nincluding a local area network (LAN) or a wide area network (WAN), or the connection may be made to an external computer (for example, through the Internet using an Internet Service Provider).  In some embodiments, electronic circuitry including, for\nexample, programmable logic circuitry, field-programmable gate arrays (FPGA), or programmable logic arrays (PLA) may execute the computer readable program instructions by utilizing state information of the computer readable program instructions to\npersonalize the electronic circuitry, in order to perform aspects of the present invention.\nAspects of the present invention are described herein with reference to flowchart illustrations and/or block diagrams of methods, apparatus (systems), and computer program products according to embodiments of the invention.  It will be\nunderstood that each block of the flowchart illustrations and/or block diagrams, and combinations of blocks in the flowchart illustrations and/or block diagrams, can be implemented by computer readable program instructions.\nThese computer readable program instructions may be provided to a processor of a general purpose computer, special purpose computer, or other programmable data processing apparatus to produce a machine, such that the instructions, which execute\nvia the processor of the computer or other programmable data processing apparatus, create means for implementing the functions/acts specified in the flowchart and/or block diagram block or blocks.  These computer readable program instructions may also be\nstored in a computer readable storage medium that can direct a computer, a programmable data processing apparatus, and/or other devices to function in a particular manner, such that the computer readable storage medium having instructions stored therein\ncomprises an article of manufacture including instructions which implement aspects of the function/act specified in the flowchart and/or block diagram block or blocks.\nThe computer readable program instructions may also be loaded onto a computer, other programmable data processing apparatus, or other device to cause a series of operational steps to be performed on the computer, other programmable apparatus or\nother device to produce a computer implemented process, such that the instructions which execute on the computer, other programmable apparatus, or other device implement the functions/acts specified in the flowchart and/or block diagram block or blocks.\nThe flowchart and block diagrams in the Figures illustrate the architecture, functionality, and operation of possible implementations of systems, methods, and computer program products according to various embodiments of the present invention. \nIn this regard, each block in the flowchart or block diagrams may represent a module, segment, or portion of instructions, which comprises one or more executable instructions for implementing the specified logical function(s).  In some alternative\nimplementations, the functions noted in the blocks may occur out of the order noted in the Figures.  For example, two blocks shown in succession may, in fact, be executed substantially concurrently, or the blocks may sometimes be executed in the reverse\norder, depending upon the functionality involved.  It will also be noted that each block of the block diagrams and/or flowchart illustration, and combinations of blocks in the block diagrams and/or flowchart illustration, can be implemented by special\npurpose hardware-based systems that perform the specified functions or acts or carry out combinations of special purpose hardware and computer instructions.\nAlthough illustrative embodiments of the present invention have been described herein with reference to the accompanying drawings, it is to be understood that the invention is not limited to those precise embodiments, and that various other\nchanges and modifications may be made by one skilled in the art without departing from the scope or spirit of the invention.", "application_number": "15241754", "abstract": " Techniques for dynamically balancing usage of central processing units\n     (CPUs) and accelerators are provided. For example, a method is provided\n     for receiving a task request for associated with a workload. A utility\n     value is calculated for a plurality of strategies for executing the\n     workload. At least two of the plurality of strategies are associated with\n     a distribution of the workload between the CPU and the one or more\n     accelerators. A strategy having a maximum utility value is selected from\n     the plurality of strategies, and the task is executed according to the\n     selected strategy.\n", "citations": ["6301603", "8669990", "8843894", "9870255", "20110173155", "20140337832"], "related": []}, {"id": "20180089513", "patent_code": "10255503", "patent_name": "Enhanced content-based multimedia recommendation method", "year": "2019", "inventor_and_country_data": " Inventors: \nCremonesi; Paolo (Milan, IT), Elahi; Mehdi (Milan, IT), Deldjoo; Yashar (Lodi, IT)  ", "description": "<BR><BR>FIELD OF\nINVENTION\nThe present invention relates to a multimedia recommendation method and specifically to content-based multimedia recommendation method.\n<BR><BR>BACKGROUND ART\nRecommender systems (RSs) are powerful automatic tools that help users find interesting multimedia content (e.g., movie, music, games, .  . . ) from wide storage directories and online media services.\nRSs are characterized by the capability of filtering large information spaces and selecting the items that are likely to be more interesting and attractive to a specific user.  Particularly, they play a significant role in on-demand TV channels,\nIP Television and video-on-demand web applications (e.g. YouTube and Netflix) where very large catalogues of movies are available to the users: the main goal of RSs is to find and recommend to users the movies that are likely to be interesting to them. \nIn other words, the RSs shall match the features of a number of video items with a profile of the intended users, so as to rank the items in their order of preference to the user.\nRecommendation systems can rely substantially on two different approaches, either collaborative systems--requiring interaction with and between the users--or content-based systems--where suggestions are given based on a number of known features\nof the items.  In the present application, only this second approach is considered.\nA prerequisite for content-based RSs is the availability of information about \"explicit\" content features of the items.  In movie items, such features are associated to the items as structured meta-information (e.g., movie genre, director, cast\nand so on) or unstructured meta-information (e.g., plot, tags and textual reviews).\nAs it is apparent, this requirement represents one of the main concerns of these systems, since collecting appropriate information about features is a time and resource consuming task which, in the best conditions, at least results in a time\ndelay between the availability of the item and when it is properly tagged to be used in a RS.  This is often called also \"cold start\" problem, which result in poor recommendations when many items, without proper meta-tags, are entered in the catalogue in\na short time delay.\nAccordingly, there is a demand for a recommendation system which is able to automatically detect a number of relevant features from the item to be suggested.\nThe prior art already provides a number of systems aimed to obtain an automatic recommendation using a content-based RSs.\nFor example, KR20080107143 discloses a method for recommending music and a moving picture based on an audio fingerprint technology using signal processing.\nUS20120102033 discloses a learning system using loosely annotated multimedia data on the web, analyses it in various signal domains and builds an association graph which basically comprises visual signals, audio signals, text phrases and the\nlike that capture a multitude of objects, experiences and their attributes and the links among them.\nWO 2014054025 discloses a method for recommending multimedia contents through a multimedia platform comprising a plurality of multimedia contents observable through at least one user interface.\nUS 20090006368 is describing a method wherein the source videos are directly compared to a user selected video to determine relevance, which is then used as a basis for video recommendation.\nAll these systems are still not satisfactory since they take into consideration too many aspects of an item, resulting in a rather complex dataset which it is then difficult to handle and gives non reliable results.  Some of them require still a\ncertain manual intervention.\nMoreover, U.S.  Pat.  No. 6,741,655 discloses a recognition system for permitting a user to locate one or more video objects from one or more video clips over an interactive network.\n<BR><BR>SUMMARY OF THE INVENTION\nThe object of the invention is therefore to provide a recommendation system which is able to determine automatically some content features of video items and handle them for the purpose of giving a satisfying recommendation to the users.\nThe new system and method of the invention comprises automatic extraction of stylistic visual features of movies (based on mise-en-scene characteristics), and also audio features, in the context of recommender systems.\nThe proposed method and system represent a multimedia recommender system that automatically analyse movie contents and extracts a set of representative stylistic visual and audio features defined by the Applied Media Aesthetic theory and\nprinciples (see, for example, H. Zettl.  \"Essentials of applied media aesthetics.\" in C. Dorai and S. Venkatesh, editors, Media Computing, volume 4 of The Springer International Series in Video Computing, pages 11-38.  Springer US, 2002), that is\nconcerned with the relation of aesthetic media attributes (such as light, camera movements, and colours) with the perceptual reactions they are able to evoke in consumers of media communication, mainly movies.\nIn other words, it is provided a stylistic-based movie recommendation technique, exploiting \"implicit\" content characteristics of items, i.e., features that are \"encapsulated\" in the items and can be computationally \"extracted\" from them. \nIndeed, it has been noted that two movies can belong to the same genre, but they can be perceived differently by a user based on the movie style.  For example, \"The Fifth Element\" and the \"War of the Worlds\" are both sci-fi (science/fiction) movies about\nan alien invasion; however, they are shot completely different, with Luc Besson (The Fifth Element) using bright colours while Steven Spielberg (War of the Worlds) preferring dark scenes.  Although a viewer may not consciously notice the two different\nmovie styles, they still affect the viewer's experience of the movie.\nThere are countless ways to create a movie based on the same script simply by changing the mise-en-scene.  Furthermore, mise-en-scene characteristics of the movies can bring additional benefits to RS.  For example, mise-en-scene can be used to\ntackle with the cold start problem mentioned above, which occurs when the system is unable to accurately recommend a new item to the existing users: this is a situation that typically occurs in social movie-sharing web applications (e.g., YouTube) where\nevery day, hundred millions of hours of videos are uploaded by users and may contain no meta-data.  Traditional techniques would fail to effectively recommend these new items even if they may be relevant for recommendation purposes, as the recommender\nhas no content to analyse but video files.\nThe method of the invention is based on the assumption that the automatically extracted visual features can be viewed as aesthetics variables that contribute to establish the meaning conveyed by an artistic work to the users.  Since humans\nrespond to certain visual stimuli in ways that are predictable (up to a given extent), similar stimuli, generated by aesthetics variables, are expected to provoke similar reactions in humans.  The Applied Media Aesthetic theory tries to identify\naesthetics variables that operate to produce the desired effect in communicating emotions and meanings by analysis of media production tools such as cameras, lenses, lighting, etc.\nAs an example of such aesthetics variables, lighting in movies can be used for various purposes.  FIG. 1 shows two examples of using lighting in movies to create different effects: high contrast lighting puts the emphasis on an \"unnatural\neffect\", as the borders of objects are altered by the lights; flat lighting, on the other hand, is an almost \"neutral and realistic\" way of illuminating, whose purpose is to enable recognition of stage objects.  Another example is the use of colours in\nmovies.  The expressive quality of colours is closely related to that of lighting, sharing the same ability to set or magnify the feeling derived by a given situation.  FIG. 2 shows two examples of using colours in movies for different purposes: red hue\nis used to increase the scene sense of violence, and blue tone is used to produce the sense of coldness and fatigue experienced by the characters.\nThese aesthetic variables can be computed from the video data stream as statistical values through appropriate analysing and optimization techniques, which will be described in more detail in the following. <BR><BR>BRIEF DESCRIPTION OF THE\nDRAWINGS\nThe file of this patent contains at least one drawing executed in color.  Copies of this patent with color drawings will be provided by the Patent and Trademark Office upon request and payment of the necessary fee.\nFurther features and advantages of the invention will become more evident from the following detailed description of a preferred embodiment, given as a non-limiting example and illustrated in the accompanying drawings, wherein:\nFIG. 1 is a comparison view, showing two different mise-en-scene taken from different movies;\nFIG. 2 is a comparison view analogous to FIG. 1; and\nFIG. 3 is a diagram showing a hierarchical video representation and feature extraction according to the method of the invention.\n<BR><BR>DETAILED DESCRIPTION OF A PREFERRED EMBODIMENT\nIn general, a movie M is represented as a combination of three main modalities: M.sub.V the visual, M.sub.A the audio and M.sub.T the textual modalities respectively.  While the method of the invention can be based on extraction and use of all\nmodalities, in movie recommendation, the essential features of the invention, on which the following description is focused on, is visual modality and the visual features that can be representative of this modality, as one example of extractable\nmodality.\nFor any movie, it can be noted that M=M(M.sub.V), where M is the characterization of a movie.  The visual modality itself can be represented as M.sub.V=M.sub.V(f.sub.v) (1) where f.sub.v=(f.sub.1, f.sub.2, .  . . , f.sub.n) is a set of features\nthat describe the visual content of a video.\nOne of the main problem of the movie features extraction is that of keeping computationally feasible the process, through determining the appropriate portion of the movie to be analysed and defining the right metric for acquiring significant\ndigital features of the frames belonging to that portion.\nGenerally speaking, a video can be considered as contiguous sequence of many frames.  Consecutive video frames contain a lot of frames that are highly similar and correlated.  Considering all these frames for feature extraction not only does not\nprovide new information to the system but also is computationally inefficient.\nTherefore, the first step prior to feature extraction is structural analysis of the video, i.e. to detect shot boundaries and to extract a key frame within each shot.  A shot boundary is a frame where frames around it have significant difference\nin their visual content.\nOn the other hand, frames within a shot are highly similar each other, therefore it makes sense to take one representative frame in each shot and use that frame for feature extraction.  This frame is called the Key Frame.\nFIG. 3 illustrates the hierarchical representation of a video.  Two types of features are extracted from videos: (i) temporal features, (ii) spatial features.\nThe temporal features reflect the dynamic perspectives in a video, such as the average shot duration (or shot length) and object motion, whereas the spatial features illustrate static properties such as colour, light, etc.\nAccording to a preferred embodiment of the invention, after carefully studying the literature in computer vision and having performed various effectiveness tests, the inventors selected the five most informative and distinctive features to be\nextracted from each video, i.e.\n.times..times..mu..mu..times..times..mu..sigma..mu.  ##EQU00001## where L.sub.sh is the average shot length, .mu..sub.cv is the mean colour variance over key frames, .mu.m and .mu..sub..sigma..sub.m.sub.2 are the mean motion average and standard\ndeviation across all frames respectively and .mu..sub.lk is the mean lighting key over key frames.\nAs can be noted, some of the features are calculated across key frames and the others across all video frames (see FIG. 3).  Each of these features carry a meaning and are used in the hands of able directors to convey emotions when shooting\nmovies.  Assuming that there exists n.sub.f frames in the video, t being the index of each single frame and n.sub.sh key frames (or shots), q being the index of a numbered list of key frames, the proposed visual features and how they are calculated is\npresented in the following.\n(1) Average Shot Length (L.sub.sh).\nA shot is a single camera action and the number of shots in a video can provide useful information about the pace at which a movie is being created.  The average shot length is defined as\n##EQU00002## where n.sub.f is the number of frames and n.sub.sh the number of shots in a movie.  For example, action movies usually contain rapid movements of the camera (therefore they contain higher number of shots or shorter shot lengths)\ncompared to dramas which often contain conversations between people (thus longer average shot length).  Because movies can be made a different frame rates, L.sub.sh is further normalized by the frame rate of the movie.\n(2) Colour Variance (.mu..sub.cv)\nThe variance of colour has a strong correlation with the genre.  For instance, directors tend to use a large variety of bright colours for comedies and darker hues for horror films.  In this context, it shall be noted that reference has been\ndone to a colour space, i.e. a mathematical model for describing colours using a tuple of numbers (e.g. 3-tuple like RGB colour space or 4-tuple as in CMYK colour space); some colour spaces are popular in digital video due to their ability to handle\nvideo information.  The present inventors have preferred to use CIE 1976 (L*, u*, v*) colour space, commonly known also as CIELUV, for computing \"colour variance\" in a video frame, because this colour space can perceptually approach a uniform colour\nspace: this means that taking two points in the CIELUV space and calculating their Euclidean distance, their distance is close to their perceptual difference; it is also advantageous because it describes all the colours visible to the human eye: for\nthese reasons, this colour space is said to be better able to describe human vision.  For each key frame represented in L.sub.uv colour space, the following covariance matrix is computed:\n.rho..sigma..sigma..sigma..sigma..sigma..sigma..sigma..sigma..sigma.  ##EQU00003## where .sigma..sub.L, .sigma..sub.u, .sigma..sub.v, .sigma..sub.Lu, .sigma..sub.Lv and .sigma..sub.uv are the standard deviation over three channels L, u, v and\ntheir mutual covariance.\nThe generalized variance can be used as the representative of the colour variance in each key frame given by .SIGMA..sub.q=det(.rho.) (5) in which a key frame is a representative frame within a shot (e.g. the middle shot).  The average colour\nvariance is then calculated by\n.mu..times..SIGMA.  ##EQU00004## where n.sub.sh is the number of shots equal to number of key frames.\nIt shall be further considered that all these operations on the movie images are actually performed on the digital space made by the pixel array of each frame.\n(3) and (4) Motion\nMotion within a video can be caused mainly by the camera movement (i.e. camera motion) or movements on part of the object being filmed (i.e. object motion).  While the average shot length captures the former characteristic of a movie, it is\ndesired for the latter characteristic to be also captured.  A motion feature descriptor based on optical flow (see for example J. L. Barron, D. J. Fleet, and S. S. Beauchemin.  `Performance of optical flow techniques`.  International journal of computer\nvision, 12(1):43-77, 1994, and B. K. Horn and B. G. Schunck.  `Determining optical flow`.  In 1981 Technical Symposium East, pages 319-331.  International Society for Optics and Photonics, 1981) is used to measure a robust estimate of the motion in\nsequence of images based on velocities of images being filmed.  Because motion features are based upon sequence of images, they are calculated across all video frames.\nAt frame t, if the average motion of pixels is represented by m.sub.t and the standard deviation of pixel motions is (.sigma..sub.m.sup.2).sub.t:\n.mu..times..times..times..mu..sigma..times..sigma.  ##EQU00005## where .mu..sub.m and .mu..sub..sigma..sub.m.sub.2 represent the average of motion mean and motion standard deviation aggregated over entire n.sub.f frames.\n(5) Lighting Key\nLighting key is another distinguishing factor between movie genres in such a way that the director use it as a factor to control the type of emotion they want to be induced to a viewer.  For example, comedy movies often adopt lighting key which\nhas abundance of light (i.e. high grey-scale mean) with less contrast between the brightest and dimmest light (i.e. high grey-scale standard deviation): this trend is often known as high-key lighting.\nOn the other hand, horror movies or noir films often pick grey-scale distributions which is low in both grey-scale mean and grey-scale standard deviation, known by low-key lighting.  In order to capture both of these parameters, after\ntransforming all key-frames to HSV colour-space, it is computed the mean p and standard deviation .sigma.  of the \"value\" component which corresponds to the lightness/brightness in the HSV colour space.\nIn this context, with HSV colour space it is meant the one having components corresponding to \"colour\", \"saturation\" and \"value\".  HSV colour space is preferably used for calculating \"Lighting Key\" in a video frame because it gives a component\ndirectly related to lightness or brightness \"V\" (Value) of the scene which is of interest for computing \"lighting key\" (as opposed with RGB colour space which does not contain such information).\nTo summarize, colour space has been used for computing features related to static features in an image: colour space is used to compute \"colour variance\" and \"lighting key\" (their mean and standard deviation), while colour space is not needed in\norder to compute \"motion\" and \"shot length\" (their mean and standard deviation).\nThe scene lighting key .xi.  defined by multiplication of .mu.  and .sigma.  is used to measure the lighting of key frames .nu..sub.q=.mu..sigma.  (9)\nFor instance, comedies often contain key-frames which have a well distributed grey-scale distribution which results in both the mean and standard deviation of grey-scale values to be high: therefore for comedy genre one can state\n.xi.&gt;.tau..sub.c, whereas for horror movies the lighting key with poorly distributed lighting the situation is reverse and we will have .xi.&lt;.tau..sub.h where .tau..sub.c and .tau..sub.h are predefined thresholds.  In the situation where\n.tau..sub.h&lt;.xi.&lt;.tau..sub.c other movie genres (e.g. Drama) exists where it is hard to use the above distinguish factor for them.  The average lighting calculated over key frames is given by\n.mu..times..xi.  ##EQU00006##\nThe above visual features extracted from the movies are then fed to a content-based recommendation algorithm in order to generate personalised recommendation.  A preferred example of such algorithms is \"k-nearest neighbour\" (knn), which is\ndescribed below.\nGiven a set of users u.di-elect cons.U and a catalogue of items i.di-elect cons.I, a set of preference scores r.sub.ui given by user u to item i is collected.  Moreover, each item i.di-elect cons.I is associated to its audio-visual feature\nvector f.sub.i, extracted based on the method explained above.  For each couple of items i and j, the similarity score s.sub.ij is computed using cosine similarity:\n.times..times.  ##EQU00007##\nFor each item i the set of its nearest neighbours NN.sub.i is built, |NN.sub.i|&lt;K.\nFinally, for each user u.di-elect cons.U, the predicted preference score {circumflex over (r)}.sub.ui for an unseen item i is computed as follows\n.di-elect cons.&gt;.times..times..di-elect cons.&gt;.times.  ##EQU00008##\nThe above score result can then be made accessible to the user by means of a variety of interfaces, depending on the type of system which is being considered, for example display means such as an IPTV interface, or web services, or plain http on\na client such as a browser.\nAs it can be clearly perceived from the above, the invention supplies a solution to the technical problems stated in the preamble.  In particular, the invention is an effective solution to the cold start problem, and more particularly new item\nproblem in recommender systems (where the prior art methods may completely fail).\nMoreover, the method of the invention can be seen not only from Multimedia Recommender System point of view, but also from the Multimedia Search and Retrieval point of view.  Accordingly, the audio-visual features can be used by any multimedia\nsearch engine to enable users to search, filter, and find multimedia items based on their aesthetic audio-visual aspects.  For example, the invention enables novel search queries from users, such as finding suitable movies that include emotional\nmise-en-scene preferred by the user (e.g., they are dark or contain a lot of fast motions such as car chasing or explosions); tt also allows even more complex queries, such as finding movies that were made with a certain style (e.g., \"Hitchcock Style\").\nIt is understood that the above description is provided as a way of example and that the practical ways of implementation or the changes made by a person skilled in the field may differ without departing from the scope of protection as defined\nin the following claims.\nAlthough the invention is a sharp solution to the cold start problem situation, it can also function properly in other situations.  Indeed, if the multimedia item is not new and hence there are available meta-data (such as tag, review, genre,\nrating, etc.) the method proposed in the application can still hybridize the recommender system and significantly \"improve\" the quality.  Hence, it can combine (or perform fusion of) the above audio-visual features with available meta-data and increase\nthe quality of the recommendations: in this case, it becomes a \"Hybrid\" method.", "application_number": "15277490", "abstract": " There is disclosed a method for generating movie recommendations, based\n     on automatic extraction of features from a multimedia content, wherein\n     the extracted features are visual features representing mise-en-scene\n     characteristics of the movie defined on the basis of Applied Media\n     Aesthetic theory, said extracted features being then fed to content-based\n     recommendation algorithm in order to generate personalized\n     recommendation.\n", "citations": ["6741655", "20060288074", "20080147711", "20090006368", "20090226046", "20120102033", "20120197897"], "related": []}, {"id": "20180107964", "patent_code": "10332048", "patent_name": "Job profile generation based on intranet usage", "year": "2019", "inventor_and_country_data": " Inventors: \nCarter; Brian T. (Navan, IE), Cronin; Patrick J. (Cork, IE), Dunning; Paul C. J. (Ratoath, IE), Quigley; Shane (Dublin, IE)  ", "description": "<BR><BR>BACKGROUND\nThe present invention relates generally to for the field of data processing, and more particularly to job profile generation.\nA job profile, or job description, is a document that presents a summary of information related to a particular employment role, such as responsibilities, necessary skills, desired skills, and required education and credentials.  A sufficiently\ndescriptive job profile may be used by hiring personnel to successfully fill an open position by identifying and prioritizing desired candidate skills.  Furthermore, application requirements included within a job profile may help job candidates determine\ntheir eligibility for an open position prior to submitting an application.\n<BR><BR>SUMMARY\nEmbodiments of the present invention disclose a method, computer program product, and system for job profile generation, the method, computer program product, and system include receiving employee intranet usage data, storing the employee\nintranet usage data in a database, identifying a portion of the employee intranet usage data which is associated with the former employee, transmitting the portion to a recommender system, where the recommender system identifies one or more required job\nskills of the former employee, based on the transmitted portion, and generating a job profile based on the one or more identified required job skills. <BR><BR>BRIEF DESCRIPTION OF THE DRAWINGS\nThe following detailed description, given by way of example and not intended to limit the invention solely thereto, will best be appreciated in conjunction with the accompanying drawings, in which:\nFIG. 1 depicts a functional block diagram of a networked computer environment, in accordance with an embodiment of the present invention;\nFIG. 2 depicts a flowchart of operational steps of a job profile generation program within the data processing environment of FIG. 1, in accordance with an embodiment of the present invention;\nFIG. 3 depicts a block diagram of internal and external components of computers and servers of FIG. 1, in accordance with an embodiment of the present invention;\nFIG. 4 depicts a cloud computing environment, in accordance with an embodiment of the present disclosure; and\nFIG. 5 depicts abstraction model layers, in accordance with an embodiment of the present invention.\nThe drawings are not necessarily to scale.  The drawings are merely schematic representations, not intended to portray specific parameters of the invention.  The drawings are intended to depict only typical embodiments of the invention.  In the\ndrawings, like numbering represents like elements.\n<BR><BR>DETAILED DESCRIPTION\nDetailed embodiments of the claimed structures and methods are disclosed herein; however, it can be understood that the disclosed embodiments are merely illustrative of the claimed structures and methods that may be embodied in various forms. \nThis invention may, however, be embodied in many different forms and should not be construed as limited to the exemplary embodiments set forth herein.  In the description, details of well-known features and techniques may be omitted to avoid\nunnecessarily obscuring the presented embodiments.\nReferences in the specification to \"one embodiment\", \"an embodiment\", \"an example embodiment\", etc., indicate that the embodiment described may include a particular feature, structure, or characteristic, but every embodiment may not necessarily\ninclude the particular feature, structure, or characteristic.  Moreover, such phrases are not necessarily referring to the same embodiment.  Further, when a particular feature, structure, or characteristic is described in connection with an embodiment,\nit is submitted that it is within the knowledge of one skilled in the art to affect such feature, structure, or characteristic in connection with other embodiments whether or not explicitly described.\nIn the interest of not obscuring the presentation of embodiments of the present invention, in the following detailed description, some processing steps or operations that are known in the art may have been combined together for presentation and\nfor illustration purposes and in some instances may have not been described in detail.  In other instances, some processing steps or operations that are known in the art may not be described at all.  It should be understood that the following description\nis rather focused on the distinctive features or elements of various embodiments of the present invention.\nEmbodiments of the present invention are related to the field of data processing, and more particularly to job profile generation.  The following described exemplary embodiments provide a system, method, and program product to, among other\nthings, create an employee job profile based on an employee's intranet usage.  Therefore, the present embodiment has the capacity to improve the technical field of job profile generation by assisting users, for example, human resources employees,\nidentify candidates with skills closely matching those of former and leaving employees, which may ensure a newly hired employee is a better fit within the team.  Additionally, employer resources expended to fill a job opening may be reduced as less time\nmay be spent generating a job profile manually and interviewing unqualified applicants.\nAs previously described, a job profile, or job description, is a document that presents a summary of information related to a particular employment role, such as responsibilities, necessary skills, desired skills, and required education and\ncredentials.  A sufficiently descriptive job profile may be used by hiring personnel to successfully fill an open position by identifying and prioritizing desired candidate skills.  Furthermore, application requirements included within a job profile may\nhelp job candidates determine their eligibility for an open position prior to submitting an application.\nTypically, job postings may include generic attributes.  For example, a job posting may include a basic, company-specific job profile, a list of necessary job skills, a list of employer-desired skills, a required educational degree level,\nrequired candidate credentials, and fluency in certain languages.\nGeneric job postings may attract candidates without specific skills important to the job role.  Additionally, generic job postings may not include hidden skills which the former or leaving employee frequently utilized to fulfil job requirements. For example, an original employee hired under a generic job posting, such as for a Java developer, may use and develop skills not included in the original posting, for example, design a Single Sign-On for a project.  The newly used and developed skills\nshould ideally be added to either the necessary skills or the desired skills in the job profile in order to identify desired candidate skills, and increase the chance that a backfill or candidate for an open position is as effective as the previous\nemployee.\nFurthermore, generic job postings may not identify specific skills used by a team in order to make their product or service effective.  For example, a human resources department may lack requisite knowledge of the specific job requirements\nnecessary for a qualified candidate and may spend time and resources to generate an accurate job description.  Job postings that lack specific skill requirements may unnecessarily waste employer resources by interviewing job candidates who do not possess\nnecessary skills for an open position.  Additionally, candidate resources may be wasted due to the candidate lacking a clear understanding of the job requirements or possessing unrealistic expectations of the work environment.  As such, it may be\nadvantageous to, among other things, implement a system to identify and prioritize desired candidate skills by analyzing a former or leaving employee's intranet usage.\nThe present invention generally relates to data processing and more specifically to job profile generation.  One way to generate a job profile may be to utilize evolutionary algorithms.  An embodiment by which to use evolutionary algorithms to\ngenerate a job profile is described in detail below by referring to the accompanying drawings in FIGS. 1 to 5.  Those skilled in the art will readily appreciate that the detailed description given herein with respect to these figures is for explanatory\npurposes as the invention extends beyond these limited embodiments.\nIn order to generate an effective job profile for a leaving employee, an intranet history of the leaving employee can be analyzed and used to create a job profile.  The job profile may useful in identifying job candidates to fill the job opening\nleft by the leaving employee.  Furthermore, the skills and effectiveness of the previous employee can be identified by using evolutionary algorithms to generate the job profile based on the leaving employee's intranet history.  An employer may create an\nintranet of a local or restricted communications network for employee use.\nEvolutionary algorithms can be used to generate the job profile.  In artificial intelligence, an evolutionary algorithm is a subset of evolutionary computation.  Evolutionary computation is a generic population-based metaheuristic optimization\nalgorithm.  Evolutionary algorithms are designed to take a generic population and use a mechanism inspired by nature, e.g. mutation, reproduction, recombination, or selection, to create new generations of the population which steadily improve problem\nsolving or fulfilling a particular criteria based off a fitness function.  A type of evolutionary algorithm used in this method is grammatical evolution.  Grammatical evolution is an evolutional search algorithm typically used to generate a program\nfragment that may achieve a good fitness value for a given objective function.\nAn accurate job profile may assist in identifying qualified job candidates with skills closely matching those of the leaving employee.  Qualified job candidates may prove to be better replacements for a leaving employee within a team.  An\naccurate job profile may also help reduce the amount of time spent by a hiring employee responsible for interviewing applicants by eliminating those applicants without the required skills for the job opening.  Additionally, current employees may not need\nto spend as much time on-boarding and training new hires with necessary and desired skills.  Furthermore, more specific job qualifications may be included within a job profile to assist applicants determine their eligibility for an open position prior to\nsubmitting an application.\nFurthermore, as previously described, a company using accurate job postings generated using evolutionary algorithms may utilize fewer resources hiring new employees possessing necessary job skills since the hiring employee may spend less time\nidentifying qualified candidates.  Additionally, the evolutionary algorithms could be used to create accurate job profiles of all current employees.  Such profiles may be useful in a variety of circumstances, such as when a team is expanding and planning\nto hire an additional employee or when an employee is out-of-office and coverage is needed for the employee's duties.\nFurthermore, third party tools capable of tagging or identifying keywords in an intranet search history, and which lend to the use of keywords that can be used in the generation of a job posting, may be used to create an accurate job profile. \nThird party tools capable of tagging abilities may include a collaborative change management tool, such as IBM.RTM.  Rational Team Concert.TM.  (IBM Rational Team Concert and all IBM Rational Team Concert-based trademarks and logos are trademarks or\nregistered trademarks of International Business Machines Corporation and/or its affiliates), a business social network, such as IBM.RTM.  Connections.TM.  (IBM Rational Team Concert and all IBM Rational Team Concert-based trademarks and logos are\ntrademarks or registered trademarks of International Business Machines Corporation and/or its affiliates), and internet search systems.  Such third party tools or systems may assist in ingesting tracking data about employees to be used in job postings.\nReferring now to FIG. 1, a functional block diagram illustrating a system 100 in a networked computer environment, in accordance with an embodiment of the present invention, is shown.  The system 100 may include a client computing device 102 and\na server 112.  The client computing device 102 may communicate with the server 112 via a network 114.  The client computing device 102 may include a processor 104, a data storage device 106, a job profile generation program 110A, and a recommender system\n118A.  The client computing device 102 may be enabled to run the job profile generation program 110A.  The job profile generation program 110A may communicate with and utilize the recommender system 118A.  The client computing device 102 may be enabled\nto interface with a user and communicate with the server 112.\nThe server 112 may also include a processor, a database 116, a job profile generation program 110B and a recommender system 118B.  The server 112 may be enabled to run the job profile generation program 110B.  The job profile generation program\n110B may communicate with and utilize the recommender system 118B.\nIn an embodiment, the client computing device 102 may operate as an input device that includes a user interface while the job profile generation program 110B may run primarily on the server 112.  In an alternative embodiment, the job profile\ngeneration program 110A may run primarily on the client computing device 102 while the server 112 may be used for processing a storage of data used by the job profile generation program 110A.  The job profile generation program 110A may be substantially\nthe same as the job profile generation program 110B.\nIn an embodiment, the recommender system 118B may run primarily on the server 112.  In an alternative embodiment, the recommender system 118A may run primarily on the client computing device 102 while the server 112 may be used for processing a\nstorage of data used by the recommender system 118A.  The recommender system 118A may be substantially the same as the recommender system 118B.  The recommender system 118A may run primarily on the client computing device 102 while the job profile\ngeneration program 110A, 110B may run primarily on either the client computing device 102 or the server 112.  Alternatively, the recommender system 118B may run primarily on the server 112 while the job profile generation program 110A, 110B may run\nprimarily on either the client computing device 102 or the server 112.\nProcessing for the job profile generation program 110A, 110B may, in some instances, be shared amongst the client computing device 102 and the server 112 in any ratio.  In another embodiment, the job profile generation program 110A, 110B may\noperate on more than one server 112, client computing device 102, or some combination of servers 112 and client computing devices 102, for example, a plurality of client computing devices 102 communicating across the network 114 with a single server 112.\nThe network 114 may include wired connections, wireless connections, fiber optic connections, or some combination thereof.  In general, the network 114 can be any combination of connections and protocols that will support communications between\nthe client computing device 102 and the server 112.  The network 114 may include various types of networks, such as, for example, a local area network (LAN), a wide area network (WAN) such as the Internet, a telecommunication network, a wireless network,\na public switched network and/or a satellite network.\nIn various embodiments, the client computing device 102 and the server 112 may be, for example, a laptop computer, tablet computer, netbook computer, personal computer (PC), a desktop computer, a personal digital assistant (PDA), a smart phone,\na mobile device, or any programmable electronic device capable of communicating with the server 112 and the client computing device 102, respectively, via the network 114.  Additionally, the server 112 may also operate in a cloud computing service model,\nsuch as Software as a Service (SaaS), Platform as a Service (PaaS), or Infrastructure as a Service (IaaS).  The server 112 may also be located in a cloud computing deployment model, such as a private cloud, community cloud, public cloud, or hybrid cloud. As described below with reference to FIG. 3, the client computing device 102 and the server 112 may each include internal and external components.  In other embodiments, the server 112 may be implemented in a cloud computing environment, for example,\ncloud computing nodes 510, as described in relation to FIGS. 4 and 5 below.  Similarly, the client computing device 102 may be implemented in the cloud computing environment, for example, laptop computer 540C as shown in FIG. 4.\nIn an embodiment, the system 100 may include any number of client computing devices 102 and/or servers 112; however only one of each is shown for illustrative purposes only.  It may be appreciated that FIG. 1 provides only an illustration of an\nimplementation and does not imply any limitations with regard to the environments in which different embodiments may be implemented.  Many modifications to the depicted environments may be made based on design and implementation requirements.\nThe system 100 may be generally configured to perform actions to generate a job profile.  The job profile generation program 110A, 110B and associated methods, and the recommender system 118A, 118B, are described and explained in further detail\nbelow with reference to FIGS. 2-5.\nReferring now to FIG. 2, an operational flowchart of a job profile generation process 200 is depicted, according to an embodiment.  A method for job profile generation may include receiving employee intranet usage data by the job profile\ngeneration program 110A, 110B and storing employee intranet usage data, in step 202.  The employee intranet usage data may include, for instance, version control systems and internal social networks.  The intranet usage data may also include information\ncollected from tracking each employee's interactions with the intranet, such as websites visited and the associated link for each website, commands executed, text entered, searches executed, and other interactions with the intranet.  The granularity of\nthe stored employee intranet usage data may be configured by a user.  For example, a high level of granularity of storing the employee intranet usage data may include storing an employee's browsing history, click path on an intranet page and words typed\nin a fillable entry box.  Alternatively, a low level of granularity may include a click path on an intranet page, but not a browsing history or words typed in a fillable entry box.\nThe user may determine that specific websites or employee actions be included in the stored employee intranet usage data, while other websites or employee actions may not be included.  For example, known programs and/or applications may be\nincluded, such as an application website, while a human resources department intranet website may not be included in the stored employee intranet usage data.  The employee intranet usage data may be stored, for example, in the data storage device 106, or\nthe database 116, both as shown in FIG. 1.  Alternatively, the employee intranet usage data may be stored in an external database.\nIdentifying an employee who has left the company may be performed in step 204.  The position of the former employee may require the hiring of a replacement employee, and a job profile may need to be created to assist in the identification of\nrequired qualifications of potential candidates to fill the open position.  Alternatively, an employee who is planning to leave the company may be identified, or an additional employee may be needed who possesses skills similar to an existing employee. \nThe open position may be identified by a company human resources department, a hiring manager, or by other means.\nIdentifying the intranet usage data of the former employee from the stored employee intranet usage data may be performed at step 206.  The former employee intranet usage data may be copied into, for example, the data storage device 106, or the\ndatabase 116, if the intranet usage data was stored in an external database.  The former employee intranet usage data may be formatted in a table as follows:\nTABLE-US-00001 Date Event Associated Performed Description Associated Link Tags Keywords Dec.  commit of http:// Ethical PBKDDFF2, 4, PBKDDFF2 projectAmanager/ hacking, ODF, 2008 implementation workitem23 high, ODF projectA\nIn the formatted example above, a first column, date performed, shows a date of an event in the former employee intranet usage data.  A second column, event description, is a description of an action of the former employee.  In this example, the\nformer employee executed a program.  A third column, associated link, identifies a web address at which the former employee performed the event.  A fourth column, associated tags, shows any system tags which may be associated with the associated link, or\nthe event description.  The associated tags may help to categorize the associated link or event description, however, a particular event may not have any associated tags.  Additionally, the associated tags may be generated by the job profile generation\nprogram 110A, 110B by using machine learning.  In an alternate embodiment, a user may create the associated tags and manually enter each associated tag into the job profile generation program 110A, 110B.  Furthermore, machine learning may be utilized to\nupdate the associated tags by the job profile generation program 110A, 110B over time.  The fifth column, keywords, may include keywords associated with the event description, the associated link, or the associated tags that may help categorize the\nevent.  The keywords may be generated by the job profile generation program 110A, 110B, and may be created by a user or obtained by another method, such as data mining.\nThe formatting of the table may be performed by the job profile generation program 110A, 110B, or by an external program.  Words associated with each event description may be transformed into a set of associated tags and an associated link.  The\ntransformation may be performed by aggregating all adjectives and nouns together.  Duplicate event descriptions may be removed and an occurrence number identified for each event.  The occurrence number for each event may be a number of times the same\nevent description has occurred.  The resulting events may each be stored as a metadata variable, which may be stored in database 116.\nFiltering of the former employee intranet usage data may be performed at step 208.  Filtering of the former employee intranet usage data may include removing website information, which is common to all employees.  For example, a companywide\ntraining utilized by all employees, such as a business conduct guidelines review, may be common to all employees and filtered out.  The scale of the filtering may be dependent on a company size.  For example, a large company with diverse job types may\nrequire more filtering of the intranet usage of the former employee.  Alternatively, a small company which has many employees with a similar job role may require less filtering.\nTransmitting the filtered intranet usage data of the former employee through a recommender system 118A, 118B, as shown in FIG. 1, may be performed at step 210.  The recommender system 118A, 118B may produce a list of skills related to job\nresponsibilities of the former employee.\nThe recommender system 118A, 118B, or recommendation system, is a subclass of an information filtering system that may predict a weight, a rating, to an item which may be assigned by a user.  The item may be an item from a group of items, or the\nitem may be a list from a group of lists.  In an example, the item may be a list or a set of keywords, phrases, or associated tags.  The recommender system 118A, 118B may also be a natural computing system which can be trained by using sample sets or\nlists of historical events.  The training or learning may be performed by running the recommender system 118A, 118B repetitively using intranet usage data of sample employees, and comparing the recommender system 118A, 118B results with a corresponding\nan employee-provided skill set.\nIn an embodiment, the recommender system 118A, 118B may be trained using several sample lists.  The several sample lists may include terms which are randomly generated from associated tags and keywords from events from the employee intranet\nusage data for a current employee.  Each of the terms may be associated with a skill.  The association of a term with a skill may be performed by the job profile generation program 110A, 110B, by the recommender system 118A, 118B, or by a user.  The\nrecommender system 118A, 118B may identify a best list of the several sample lists.  The best list may contain terms which may be related to skills which most closely align with a list of skills provided by the current employee.  Training may be repeated\nwith additional current employees, in order to improve the accuracy of the recommender system 118A, 118B.  This training may help improve the identification of a list of skills related to job responsibilities of a selected employee.\nDuring operation, the recommender system 118A, 118B may randomly generate several sample lists that each contain terms or groups of words.  The terms may come from the associated tags and the keywords from the filtered intranet usage data of the\nformer employee.  Occurrence information as well as a date performed of each event may help to give a weight or assign a relative importance to each term of the set of terms.  For example, associated tags and keywords of a recently occurring event may\nhave greater weight than associated tags and keywords of an older event, while associated tags and keywords of a particular event description with a higher occurrence number may have a greater weight than associated tags and keywords of another event\ndescription.\nThe recommender system 118A, 118B may compare random subsets of lists of the several sample lists, and assign a rating to each list of the subsets of lists.  The rating may be based on comparison of the terms in each list of the subsets of where\na higher rating may indicate a higher probability that a list of the multiple lists is more likely to contain terms more closely related to an employee-provided list of skills.\nThe recommender system 118A, 118B may perform the comparison for several generations, for example, 40 generations, of comparing random subsets of lists.  The random subsets of lists may be ranked based on a probability that each list aligns with\nthe required skills and the preferred skills performed by the former employee.\nIn an embodiment, multiple randomly generated lists of roughly equal size to an average size of a skill list may be created by the recommender system 118A, 118B.  For example, 1,000 randomly generated lists may each include 10 associated tags\nand keywords.  The recommender system 118A, 118B may identify a weight or rank to each of the several sample lists.  The recommender system 118A, 118B may identify a best list of the several sample lists to be the most likely to contain terms most\nclosely related to the job skills of the former employee.  The recommender system 118A, 118B may be able to identify a best list of necessary skills and a best list of desired skills most closely related to the job skills of the former employee.\nThe ranking or comparison of each list may take into account a fitness function associated with each list.  The fitness function may compare terms of each list to terms associated with an employee-generated skill list and a higher fitness\nfunction may indicate a closer match of terms.  The ranking or comparison of each list also take into account a Backus-Naur Form Grammar.  The Backus-Naur Form Grammar is a set of rules which define a language, which is used to define the words used in\neach list.  Crossover is when two lists are combined to generate an offspring list.  The point of the grammar is that crossover can occur at any of the point with a bar symbol, \"|\", as shown in the equation below.  If a grammar is not used, crossover\ncould potentially occur in the middle of associated words, or between an adjective and its noun if they were grouped together as a skill.\nIn an example, the Backus-Naur Form Grammar and Fitness Function may be used as a basis for an evolutionary algorithm, as shown below:\nTABLE-US-00002 Backus-Naur Form Grammar: &lt;skill_list&gt; ::= &lt;skill&gt; &lt;separator&gt; &lt;skill_list&gt; | &lt;skill&gt; &lt;skill&gt; ::= &lt;adjective&gt; | &lt;noun&gt; | &lt;adjective&gt; &lt;noun&gt; Fitness Function: Result =\n(skill match effectiveness * every matched skill - unmatched word effectiveness * every unmatched word) * (average date of skill list - day of leaving/days in the company) * (occurrence effectiveness * average occurrence)\nIn this example, occurrence effectiveness, the skill match effectiveness, and the unmatched word effectiveness may each be a real value between 0 and 1, where each variable has an initial value of 1.  Additionally, the occurrence effectiveness,\nthe skill match effectiveness, and the unmatched word effectiveness may be adjusted over time by the job profile generation program 110A, 110B, the recommender system 118A, 118B, or by a user.  In an embodiment, the skill match effectiveness and the\nunmatched word effectiveness may be different numbers to prevent multiplication by zero, which would remove the relevance of the remaining data.  Once optimal, or close to optimal, variables have been found and verified as correct to a reasonable\npercentage against a separate training set, the algorithm may be used as a system to generate a list of skills based on a list of events, described above, representing an employee's intranet history.\nOnce created by the recommender system 118A, 118B, the best list of skills of the former employee may be transmitted to the job profile generation program 110A, 110B.\nGenerating a job profile may then be performed by the job profile generation program 110A, 110B, at step 212.  The best list of skills can be edited and merged into a generic recruitment template to provide the job profile for the open position\nof the former employee.  The job profile may be a specific list of the required skills and preferred skills to assist the user when recruiting candidates for the open position.\nOnce created by the job profile generation program 110A, 110B, the job profile may be posted on a recruitment web site, either internal or external, to assist in finding potential candidates to fill the job opening for the open position.\nIn an alternate embodiment a team may be expanding and require an additional employee or a new hire, or alternatively, a temporary employee is needed due to a leave of absence.  Therefore, the job profile generation program 110A, 110B may use\nthe employee intranet usage data of one or more employees in a similar position to the new hire, or of the employee on a temporary leave of absence to identify a list of required skills and generate a job profile.\nReferring now to FIG. 3, a block diagram of components of a computing device, such as the client computing device 102 or the server 112, of the system 100 of FIG. 1, in accordance with an embodiment of the present invention is shown.  It should\nbe appreciated that FIG. 3 provides only an illustration of an implementation and does not imply any limitations with regard to the environments in which different embodiments may be implemented.  Many modifications to the depicted environment may be\nmade.\nThe computing device may include one or more processors 402, one or more computer-readable RAMs 404, one or more computer-readable ROMs 406, one or more computer readable storage media 408, device drivers 412, read/write drive or interface 414,\nnetwork adapter or interface 416, all interconnected over a communications fabric 418.  Communications fabric 418 may be implemented with any architecture designed for passing data and/or control information between processors (such as microprocessors,\ncommunications and network processors, etc.), system memory, peripheral devices, and any other hardware components within a system.\nOne or more operating systems 410, and one or more application programs 411, for example, the job profile generation program 110A, 110B, are stored on one or more of the computer readable storage media 408 for execution by one or more of the\nprocessors 402 via one or more of the respective RAMs 404 (which typically include cache memory).  In the illustrated embodiment, each of the computer readable storage media 408 may be a magnetic disk storage device of an internal hard drive, CD-ROM,\nDVD, memory stick, magnetic tape, magnetic disk, optical disk, a semiconductor storage device such as RAM, ROM, EPROM, flash memory or any other computer-readable tangible storage device that can store a computer program and digital information.\nThe computing device may also include a R/W drive or interface 414 to read from and write to one or more portable computer readable storage media 426.  Application programs 411 on the computing device may be stored on one or more of the portable\ncomputer readable storage media 426, read via the respective R/W drive or interface 414 and loaded into the respective computer readable storage media 408.\nThe computing device may also include the network adapter or interface 416, such as a TCP/IP adapter card or wireless communication adapter (such as a 4G wireless communication adapter using OFDMA technology).  Application programs 411 on the\ncomputing device may be downloaded to the computing device from an external computer or external storage device via a network (for example, the Internet, a local area network or other wide area network or wireless network) and network adapter or\ninterface 416.  From the network adapter or interface 416, the programs may be loaded onto computer readable storage media 408.  The network may comprise copper wires, optical fibers, wireless transmission, routers, firewalls, switches, gateway computers\nand/or edge servers.\nThe computing device may also include a display screen 420, a keyboard or keypad 422, and a computer mouse or touchpad 424.  Device drivers 412 interface to display screen 420 for imaging, to keyboard or keypad 422, to computer mouse or touchpad\n424, and/or to display screen 420 for pressure sensing of alphanumeric character entry and user selections.  The device drivers 412, R/W drive or interface 414 and network adapter or interface 416 may comprise hardware and software (stored on computer\nreadable storage media 408 and/or ROM 406).\nThe programs described herein are identified based upon the application for which they are implemented in a specific embodiment of the invention.  However, it should be appreciated that any particular program nomenclature herein is used merely\nfor convenience, and thus the invention should not be limited to use solely in any specific application identified and/or implied by such nomenclature.\nIt is to be understood that although this disclosure includes a detailed description on cloud computing, implementation of the teachings recited herein are not limited to a cloud computing environment.  Rather, embodiments of the present\ninvention are capable of being implemented in conjunction with any other type of computing environment now known or later developed.\nCloud computing is a model of service delivery for enabling convenient, on-demand network access to a shared pool of configurable computing resources (e.g., networks, network bandwidth, servers, processing, memory, storage, applications, virtual\nmachines, and services) that can be rapidly provisioned and released with minimal management effort or interaction with a provider of the service.  This cloud model may include at least five characteristics, at least three service models, and at least\nfour deployment models.\nCharacteristics of cloud computing include on-demand self-service, broad network access, resource pooling, rapid elasticity, and measured service, which are each described below.\nOn-demand self-service: a cloud consumer can unilaterally provision computing capabilities, such as server time and network storage, as needed automatically without requiring human interaction with the service's provider.\nBroad network access: capabilities are available over a network and accessed through standard mechanisms that promote use by heterogeneous thin or thick client platforms (e.g., mobile phones, laptops, and PDAs).\nResource pooling: the provider's computing resources are pooled to serve multiple consumers using a multi-tenant model, with different physical and virtual resources dynamically assigned and reassigned according to demand.  There is a sense of\nlocation independence in that the consumer generally has no control or knowledge over the exact location of the provided resources but may be able to specify location at a higher level of abstraction (e.g., country, state, or datacenter).\nRapid elasticity: capabilities can be rapidly and elastically provisioned, in some cases automatically, to quickly scale out and rapidly released to quickly scale in. To the consumer, the capabilities available for provisioning often appear to\nbe unlimited and can be purchased in any quantity at any time.\nMeasured service: cloud systems automatically control and optimize resource use by leveraging a metering capability at some level of abstraction appropriate to the type of service (e.g., storage, processing, bandwidth, and active user accounts). Resource usage can be monitored, controlled, and reported, providing transparency for both the provider and consumer of the utilized service.\nService Models include Software as a Service, Platform as a Service, and Infrastructure as a Service, which are each described below.\nSoftware as a Service (SaaS): the capability provided to the consumer is to use the provider's applications running on a cloud infrastructure.  The applications are accessible from various client devices through a thin client interface such as a\nweb browser (e.g., web-based e-mail).  The consumer does not manage or control the underlying cloud infrastructure including network, servers, operating systems, storage, or even individual application capabilities, with the possible exception of limited\nuser-specific application configuration settings.\nPlatform as a Service (PaaS): the capability provided to the consumer is to deploy onto the cloud infrastructure consumer-created or acquired applications created using programming languages and tools supported by the provider.  The consumer\ndoes not manage or control the underlying cloud infrastructure including networks, servers, operating systems, or storage, but has control over the deployed applications and possibly application hosting environment configurations.\nInfrastructure as a Service (IaaS): the capability provided to the consumer is to provision processing, storage, networks, and other fundamental computing resources where the consumer is able to deploy and run arbitrary software, which can\ninclude operating systems and applications.  The consumer does not manage or control the underlying cloud infrastructure but has control over operating systems, storage, deployed applications, and possibly limited control of select networking components\n(e.g., host firewalls).\nDeployment Models include private cloud, community cloud, public cloud, and hybrid cloud, which are each described below.\nPrivate cloud: the cloud infrastructure is operated solely for an organization.  It may be managed by the organization or a third party and may exist on-premises or off-premises.\nCommunity cloud: the cloud infrastructure is shared by several organizations and supports a specific community that has shared concerns (e.g., mission, security requirements, policy, and compliance considerations).  It may be managed by the\norganizations or a third party and may exist on-premises or off-premises.\nPublic cloud: the cloud infrastructure is made available to the general public or a large industry group and is owned by an organization selling cloud services.\nHybrid cloud: the cloud infrastructure is a composition of two or more clouds (private, community, or public) that remain unique entities but are bound together by standardized or proprietary technology that enables data and application\nportability (e.g., cloud bursting for load-balancing between clouds).\nA cloud computing environment is service oriented with a focus on statelessness, low coupling, modularity, and semantic interoperability.  At the heart of cloud computing is an infrastructure that includes a network of interconnected nodes.\nReferring now to FIG. 4, illustrative cloud computing environment 500 is depicted.  As shown, cloud computing environment 500 includes one or more cloud computing nodes 510 with which local computing devices used by cloud consumers, such as, for\nexample, personal digital assistant (PDA) or cellular telephone 540A, desktop computer 540B, laptop computer 540C, and/or automobile computer system 540N may communicate.  Cloud computing nodes 510 may communicate with one another.  They may be grouped\n(not shown) physically or virtually, in one or more networks, such as Private, Community, Public, or Hybrid clouds as described hereinabove, or a combination thereof.  This allows cloud computing environment 500 to offer infrastructure, platforms and/or\nsoftware as services for which a cloud consumer does not need to maintain resources on a local computing device.  It is understood that the types of computing devices 54A-N shown in FIG. 5 are intended to be illustrative only and that cloud computing\nnodes 510 and cloud computing environment 500 can communicate with any type of computerized device over any type of network and/or network addressable connection (e.g., using a web browser).\nReferring now to FIG. 5, a set of functional abstraction layers provided by cloud computing environment 500 (for example, the network 114 of FIG. 1) is shown.  It should be understood in advance that the components, layers, and functions shown\nin FIG. 5 are intended to be illustrative only and embodiments of the invention are not limited thereto.  As depicted, the following layers and corresponding functions are provided:\nHardware and software layer 660 includes hardware and software components.  Examples of hardware components include: mainframes 661; RISC (Reduced Instruction Set Computer) architecture based servers 662; servers 663; blade servers 664; storage\ndevices 665; and networks and networking components 666.  In some embodiments, software components include network application server software 667 and database software 668.\nVirtualization layer 670 provides an abstraction layer from which the following examples of virtual entities may be provided: virtual servers 671; virtual storage 672, for example the data storage device 106 and the database 116 as shown in FIG.\n1; virtual networks 673, including virtual private networks; virtual applications and operating systems 674; and virtual clients 675.\nIn an example, management layer 680 may provide the functions described below.  Resource provisioning 681 provides dynamic procurement of computing resources and other resources that are utilized to perform tasks within the cloud computing\nenvironment.  Metering and Pricing 682 provide cost tracking as resources are utilized within the cloud computing environment, and billing or invoicing for consumption of these resources.  In an example, these resources may include application software\nlicenses.  Security provides identity verification for cloud consumers and tasks, as well as protection for data and other resources.  User portal 683 provides access to the cloud computing environment for consumers and system administrators.  Service\nlevel management 684 provides cloud computing resource allocation and management such that required service levels are met.  Service Level Agreement (SLA) planning and fulfillment 685 provide pre-arrangement for, and procurement of, cloud computing\nresources for which a future requirement is anticipated in accordance with an SLA.\nWorkloads layer 690 provides examples of functionality for which the cloud computing environment may be utilized.  Examples of workloads and functions which may be provided from this layer include: mapping and navigation 691; software\ndevelopment and lifecycle management 692; virtual classroom education delivery 693; data analytics processing 694; transaction processing 695; and employee job profile generation 696.  Employee job profile generation 696 may relate to using employee\nintranet usage data to generate a job profile, for example, the job profile generation program 110A, 110B.\nThe present invention may be a system, a method, and/or a computer program product at any possible technical detail level of integration.  The computer program product may include a computer readable storage medium (or media) having computer\nreadable program instructions thereon for causing a processor to carry out aspects of the present invention.\nThe computer readable storage medium can be a tangible device that can retain and store instructions for use by an instruction execution device.  The computer readable storage medium may be, for example, but is not limited to, an electronic\nstorage device, a magnetic storage device, an optical storage device, an electromagnetic storage device, a semiconductor storage device, or any suitable combination of the foregoing.  A non-exhaustive list of more specific examples of the computer\nreadable storage medium includes the following: a portable computer diskette, a hard disk, a random access memory (RAM), a read-only memory (ROM), an erasable programmable read-only memory (EPROM or Flash memory), a static random access memory (SRAM), a\nportable compact disc read-only memory (CD-ROM), a digital versatile disk (DVD), a memory stick, a floppy disk, a mechanically encoded device such as punch-cards or raised structures in a groove having instructions recorded thereon, and any suitable\ncombination of the foregoing.  A computer readable storage medium, as used herein, is not to be construed as being transitory signals per se, such as radio waves or other freely propagating electromagnetic waves, electromagnetic waves propagating through\na waveguide or other transmission media (e.g., light pulses passing through a fiber-optic cable), or electrical signals transmitted through a wire.\nComputer readable program instructions described herein can be downloaded to respective computing/processing devices from a computer readable storage medium or to an external computer or external storage device via a network, for example, the\nInternet, a local area network, a wide area network and/or a wireless network.  The network may comprise copper transmission cables, optical transmission fibers, wireless transmission, routers, firewalls, switches, gateway computers and/or edge servers. \nA network adapter card or network interface in each computing/processing device receives computer readable program instructions from the network and forwards the computer readable program instructions for storage in a computer readable storage medium\nwithin the respective computing/processing device.\nComputer readable program instructions for carrying out operations of the present invention may be assembler instructions, instruction-set-architecture (ISA) instructions, machine instructions, machine dependent instructions, microcode, firmware\ninstructions, state-setting data, configuration data for integrated circuitry, or either source code or object code written in any combination of one or more programming languages, including an object oriented programming language such as Smalltalk, C++,\nor the like, and procedural programming languages, such as the \"C\" programming language or similar programming languages.  The computer readable program instructions may execute entirely on the user's computer, partly on the user's computer, as a\nstand-alone software package, partly on the user's computer and partly on a remote computer or entirely on the remote computer or server.  In the latter scenario, the remote computer may be connected to the user's computer through any type of network,\nincluding a local area network (LAN) or a wide area network (WAN), or the connection may be made to an external computer (for example, through the Internet using an Internet Service Provider).  In some embodiments, electronic circuitry including, for\nexample, programmable logic circuitry, field-programmable gate arrays (FPGA), or programmable logic arrays (PLA) may execute the computer readable program instructions by utilizing state information of the computer readable program instructions to\npersonalize the electronic circuitry, in order to perform aspects of the present invention.\nAspects of the present invention are described herein with reference to flowchart illustrations and/or block diagrams of methods, apparatus (systems), and computer program products according to embodiments of the invention.  It will be\nunderstood that each block of the flowchart illustrations and/or block diagrams, and combinations of blocks in the flowchart illustrations and/or block diagrams, can be implemented by computer readable program instructions.\nThese computer readable program instructions may be provided to a processor of a general purpose computer, special purpose computer, or other programmable data processing apparatus to produce a machine, such that the instructions, which execute\nvia the processor of the computer or other programmable data processing apparatus, create means for implementing the functions/acts specified in the flowchart and/or block diagram block or blocks.  These computer readable program instructions may also be\nstored in a computer readable storage medium that can direct a computer, a programmable data processing apparatus, and/or other devices to function in a particular manner, such that the computer readable storage medium having instructions stored therein\ncomprises an article of manufacture including instructions which implement aspects of the function/act specified in the flowchart and/or block diagram block or blocks.\nThe computer readable program instructions may also be loaded onto a computer, other programmable data processing apparatus, or other device to cause a series of operational steps to be performed on the computer, other programmable apparatus or\nother device to produce a computer implemented process, such that the instructions which execute on the computer, other programmable apparatus, or other device implement the functions/acts specified in the flowchart and/or block diagram block or blocks.\nThe flowchart and block diagrams in the Figures illustrate the architecture, functionality, and operation of possible implementations of systems, methods, and computer program products according to various embodiments of the present invention. \nIn this regard, each block in the flowchart or block diagrams may represent a module, segment, or portion of instructions, which comprises one or more executable instructions for implementing the specified logical function(s).  In some alternative\nimplementations, the functions noted in the blocks may occur out of the order noted in the Figures.  For example, two blocks shown in succession may, in fact, be executed substantially concurrently, or the blocks may sometimes be executed in the reverse\norder, depending upon the functionality involved.  It will also be noted that each block of the block diagrams and/or flowchart illustration, and combinations of blocks in the block diagrams and/or flowchart illustration, can be implemented by special\npurpose hardware-based systems that perform the specified functions or acts or carry out combinations of special purpose hardware and computer instructions.\nThe descriptions of the various embodiments of the present invention have been presented for purposes of illustration, but are not intended to be exhaustive or limited to the embodiments disclosed.  Many modifications and variations will be\napparent to those of ordinary skill in the art without departing from the scope and spirit of the invention.  The terminology used herein was chosen to best explain the principles of the embodiment, the practical application or technical improvement over\ntechnologies found in the marketplace, or to enable others of ordinary skill in the art to understand the embodiments disclosed herein.", "application_number": "15834143", "abstract": " A method, computer program product, and system for job profile\n     generation, the method, computer program product, and system include\n     receiving employee intranet usage data, storing the received employee\n     intranet usage data in a database, identifying a portion of the stored\n     employee intranet usage data associated with the former employee,\n     transmitting the portion to a recommender system, where the recommender\n     system identifies one or more required job skills of the former employee,\n     based on the transmitted portion, and generating a job profile based on\n     the one or more identified required job skills.\n", "citations": ["7146574", "7188074", "8063799", "8200584", "8914383", "20070054248", "20120215795", "20130198098", "20140214711", "20140278821", "20140279629", "20150006422", "20150317753", "20170213272"], "related": ["15232911"]}, {"id": "20180122019", "patent_code": "10325328", "patent_name": "Determining intent of a recommendation on a mobile application", "year": "2019", "inventor_and_country_data": " Inventors: \nPattan; Neha (Mountain View, CA), Lin; Jennifer W. (San Jose, CA)  ", "description": "<BR><BR>TECHNICAL FIELD\nThe present disclosure generally relates to systems and methods for providing content to users.  More specifically, aspects of the present disclosure relate to determining the intent of a user's interaction with social recommendation tools\nprovided for presentation to the user in conjunction with an application containing content.\n<BR><BR>BACKGROUND\nAs mobile telephones, personal digital assistants, smartphones, and other similar portable user devices continue to grow more popular and more advanced in their functionalities, so does application software designed specifically for use with\nsuch devices.  Mobile application software (also commonly referred to as \"mobile applications\" or \"mobile apps\") perform a seemingly endless number of tasks and functions for consumers (hereinafter referred to simply as \"users\") who choose to use them on\ntheir portable devices.\nA user who finds a particular mobile application, such as a game or news provider service enjoyable may wish to make his or her appreciation of the application known to one or more other users (e.g., in a social network of the user, or\npublicly).  Accordingly, the user may make a recommendation of the mobile application that other users can see when they are presented with an opportunity to use (e.g., download, install, etc.) the application.  However, such mobile applications often\ncontain many different components, any one or more of which may be the underlying motivation for the user's recommendation.\n<BR><BR>SUMMARY\nThis Summary introduces a selection of concepts in a simplified form in order to provide a basic understanding of some aspects of the present disclosure.  This Summary is not an extensive overview of the disclosure, and is not intended to\nidentify key or critical elements of the disclosure or to delineate the scope of the disclosure.  This Summary merely presents some of the concepts of the disclosure as a prelude to the Detailed Description provided below.\nOne embodiment of the present disclosure relates to a method comprising: receiving, at a server, a plurality of identifiers for an application running on a user device, each of the plurality of identifiers being associated with at least one of a\nplurality of components of the application; responsive to receiving the plurality of identifiers, generating at least one component reference table based on the plurality of identifiers, the at least one component reference table including, for each of\nthe identifiers, the at least one component of the application associated with the identifier; receiving an indication that a user selected a user recommendation control in the application running on the user device, the indication including data\ncorresponding to one of the identifiers received for the application; determining that the user recommended a component of the application based on the at least one component reference table and the data corresponding to the one of the identifiers;\nresponsive to determining that the user recommended the component, generating at least one social annotation based on the component; and serving, via a network, the at least one social annotation to a second user device in a format suitable for\npresentation on the second user device.\nIn another embodiment, the indication that the user selected the user recommendation control is an indication that the user recommended the application, and the method further comprises: using the data corresponding to the identifier to\ndetermine a group of components of the application associated with the identifier; querying the user to select at least one of the group of components applicable to the recommendation; receiving from the user, in response to the query, a selection\ncorresponding to at least one of the group of components; and generating at least one social annotation based on the selection received from the user.\nIn another embodiment, the step of querying the user to select at least one of the group of components applicable to the recommendation further comprises: in response to receiving the indication that the user recommended the application,\ngenerating a user interface screen identifying the group of components; and providing the user interface screen for presentation to the user.\nIn still another embodiment of the disclosure, the method further comprises: storing the at least one component reference table for the application; and mapping the at least one component associated with each of the identifiers included in the\nat least one component reference table to the application.\nIn yet another embodiment of the disclosure, the indication that the user selected the user recommendation control is an indication that the user recommended the application, and the method further comprises: generating a user interface screen\nbased on the mapped components included in the at least one component reference table stored for the application, the user interface screen identifying the components of the application; and responsive to receiving the indication that the user\nrecommended the application, using the user interface screen to query the user to select at least one of the components applicable to the recommendation.\nIn still another embodiment, the method further comprises serving, via the network, the at least one social annotation to the second user device in a format suitable for presentation on the second user device, the at least one social annotation\nidentifying the at least one of the group of components of the application corresponding to the selection received from the user.\nAnother embodiment of the present disclosure relates to a system comprising at least one processor, and a computer-readable medium coupled to the at least one processor having instructions stored thereon which, when executed by the at least one\nprocessor, causes the at least one processor to: receive a plurality of identifiers for an application running on a user device, each of the plurality of identifiers being associated with at least one of a plurality of components of the application;\nresponsive to receiving the plurality of identifiers, generate at least one component reference table based on the plurality of identifiers, the at least one component reference table including, for each of the identifiers, the at least one component of\nthe application associated with the identifier; receive an indication that a user selected a user recommendation control in the application running on the user device, the indication including data corresponding to one of the identifiers received for the\napplication; determine that the user recommended a component of the application based on the at least one component reference table and the data corresponding to the one of the identifiers; responsive to determining that the user recommended the\ncomponent, generate at least one social annotation based on the component; and serve, via a network, the at least one social annotation to a second user device in a format suitable for presentation on the second user device.\nIn another embodiment where the indication that the user selected the user recommendation control is an indication that the user recommended the application, the at least one processor of the system is further caused to: use the data\ncorresponding to the identifier to determine a group of components of the application associated with the identifier; query the user to select at least one of the group of components applicable to the recommendation; receive from the user, in response to\nthe query, a selection corresponding to at least one of the group of components; and generate at least one social annotation based on the selection received from the user.\nIn another embodiment, the at least one processor of the system is further caused to, in response to receiving the indication that the user recommended the application, generate a user interface screen identifying the group of components; and\nprovide the user interface screen for presentation to the user.\nIn still another embodiment of the disclosure, the at least one processor of the system is further caused to: store the at least one component reference table for the application; and map the at least one component associated with each of the\nidentifiers included in the at least one component reference table to the application.\nIn yet another embodiment where the indication that the user selected the user recommendation control is an indication that the user recommended the application, the at least one processor of the system is further caused to: generate a user\ninterface screen based on the mapped components included in the at least one component reference table stored for the application, the user interface screen identifying the components of the application; and responsive to receiving the indication that\nthe user recommended the application, use the user interface screen to query the user to select at least one of the components applicable to the recommendation.\nIn another embodiment of the disclosure, the at least one processor of the system is further caused to: serve, via the network, the at least one social annotation to the second user device in a format suitable for presentation on the second user\ndevice, the at least one social annotation identifying the at least one of the group of components of the application corresponding to the selection received from the user.\nYet another embodiment of the present disclosure relates to a method comprising: receiving, at a server, an indication that a user selected a user recommendation control in an application running on a user device, the application including a\nplurality of components; traversing a view hierarchy of the application to determine a view of the application containing the selected user recommendation control; determining that the user recommended at least one of the plurality of components of the\napplication based on the view of the application containing the selected user recommendation control; responsive to determining that the user recommended the at least one component of the application, generating at least one social annotation based on\nthe at least one component; and serving, via a network, the at least one social annotation to a second user device in a format suitable for presentation on the second user device.\nIn another embodiment, the method further comprises: identifying a group of components of the application based on the view of the application containing the selected user recommendation control; querying the user to select at least one of the\ngroup of components applicable to the recommendation; receiving from the user, in response to the query, a selection corresponding to at least one of the group of components; and generating at least one social annotation based on the selection received\nfrom the user.\nIn still another embodiment, the step of querying the user to select at least one of the group of components applicable to the recommendation further includes: responsive to identifying the group of components based on the view of the\napplication containing the selected user recommendation control, generating a user interface screen identifying the group of components; and providing the user interface screen for presentation to the user.\nIn still another embodiment, the method further comprises: identifying a plurality of views of the application based on the traversed view hierarchy, wherein each of the plurality of views contains at least one of the plurality of components of\nthe application; generating at least one component reference table for the application, the at least one component reference table including, for each of the plurality of views, the at least one component of the application contained in the view; and\nstoring the at least one component reference table generated for the application.\nIn yet another embodiment, the method further comprises mapping the at least one component contained in each of the plurality of views included in the at least one component reference table to the application running on the user device.\nA further embodiment of the present disclosure relates to a system comprising at least one processor, and a computer-readable medium coupled to the at least one processor having instructions stored thereon which, when executed by the at least\none processor, causes the at least one processor to: receive an indication that a user selected a user recommendation control in an application running on a user device, the application including a plurality of components; traverse a view hierarchy of\nthe application to determine a view of the application containing the selected user recommendation control; determine that the user recommended at least one of the plurality of components of the application based on the view of the application containing\nthe selected user recommendation control; responsive to determining that the user recommended the at least one component of the application, generate at least one social annotation based on the at least one component; and serve, via a network, the at\nleast one social annotation to a second user device in a format suitable for presentation on the second user device.\nFurther scope of applicability of the present invention will become apparent from the Detailed Description given below.  However, it should be understood that the Detailed Description and specific examples, while indicating preferred embodiments\nof the invention, are given by way of illustration only, since various changes and modifications within the spirit and scope of the invention will become apparent to those skilled in the art from this Detailed Description. <BR><BR>BRIEF DESCRIPTION OF\nDRAWINGS\nThese and other objects, features and characteristics of the present disclosure will become more apparent to those skilled in the art from a study of the following Detailed Description in conjunction with the appended claims and drawings, all of\nwhich form a part of this specification.  In the drawings:\nFIG. 1 is a block diagram illustrating an example content presentation system and surrounding environment in which various embodiments of the present disclosure may be implemented.\nFIG. 2 is a data flow diagram illustrating example communications for determining the intent of an application recommendation using tags associated with components of the application according to one or more embodiments described herein.\nFIG. 3 is a data flow diagram illustrating example communications for refining an application recommendation by providing a user with a recommendation intent query according to one or more embodiments described herein.\nFIG. 4 is a flowchart illustrating a method for traversing a view hierarchy of an application to determine the intent of a recommendation of the application according to one or more embodiments described herein.\nFIG. 5A is a chart illustrating example application recommendations made by users together with tags identifying the components associated with the recommendations according to one or more embodiments described herein.\nFIG. 5B is a chart illustrating example application recommendations made by users together with components of the application identified by the users in response to a recommendation intent query according to one or more embodiments described\nherein.\nFIG. 6 is an example user interface that includes a mobile application containing various components along with a user recommendation control according to one or more embodiments described herein.\nFIG. 7 is an example user interface that includes a recommendation intent query for a user to select one or more components of a mobile application that the user intended to recommend according to one or more embodiments described herein.\nFIG. 8 is an example user interface that includes an application component recommendation made by a user and also identifies other users who have recommended components of the application according to one or more embodiments described herein.\nFIG. 9 is a block diagram illustrating an example computing device arranged for selecting and presenting content according to one or more embodiments described herein.\nThe headings provided herein are for convenience only and do not necessarily affect the scope or meaning of the claimed invention.\nIn the drawings, the same reference numerals and any acronyms identify elements or acts with the same or similar structure or functionality for ease of understanding and convenience.  The drawings will be described in detail in the course of the\nfollowing Detailed Description.\n<BR><BR>DETAILED DESCRIPTION\nVarious examples of the invention will now be described.  The following description provides specific details for a thorough understanding and enabling description of these examples.  One skilled in the relevant art will understand, however,\nthat the invention may be practiced without many of these details.  Likewise, one skilled in the relevant art will also understand that the invention can include many other obvious features not described in detail herein.  Additionally, some well-known\nstructures or functions may not be shown or described in detail below, so as to avoid unnecessarily obscuring the relevant description.\nEmbodiments of the present disclosure relate to methods and systems for determining the intent of a recommendation made by a user of a software application running on a portable user device where the application includes a plurality of separable\n(e.g., distinguishable, separately identifiable, etc.) components and/or content, any one or more of which the recommendation can apply to or be attributed to.  The software application may be, for example, a video or audio player, game, calendar, news\nservice, etc., and the components and/or content of the application can include such things as a user interface of the video or audio player, one level of the game, a feature of the calendar, an image or joke in the news service, and the like.  For\npurposes of brevity, a software application is sometimes referred to herein simply as an \"application\" or an \"app.\" Additionally, in the context of a portable user device, a software application designed specifically for such a device is sometimes\nreferred to herein as a \"mobile application\" or \"mobile app,\" also for purposes of brevity.\nA user in a social network (e.g., an online community or system that provides a forum for users who are in different geographic locations to interact with each other) may wish to indicate that he or she likes, approves, suggests, or enjoys a\nparticular mobile application such that one or more other users in the social network will be made aware of this indication when they use (e.g., access) or are presented with the opportunity to use (e.g., view, download, install, etc.) the application. \nAccordingly, the user may make a recommendation of the application.\nIn at least some embodiments of the present disclosure, a user can recommend a mobile application by interacting with (e.g., selecting) a user recommendation control (e.g., widget, tool, point, button, etc.) provided for display to the user\nwithin the application.  Depending on the implementation, this user recommendation control may be configured to allow a user to publish (e.g., make known to one or more other users in a social network and/or more broadly to the public in general) an\nopinion (e.g., emotion, reaction, perception, impression, view, etc.) that he or she has about the application.\nAccording to some embodiments of the disclosure, a mobile application in which a user recommendation control is provided for presentation to and use by a user also includes at least one tag (or other similar type of metadata) that indicates how\na recommendation of the application is to be interpreted.  For example, a developer of a mobile application containing the user recommendation control may set a tag indicating that a recommendation of the application made by a user (e.g., by interacting\nwith the user recommendation control) is to be attributed to a specific component of the application.  In this manner, the intent of a user's recommendation of an application may be determined using the corresponding tag set for the application.\nIn at least one embodiment the tag set for an application may be in the form of text (e.g., a keyword or term) or a uniform resource locator (URL), either of which may be provided by a developer of the application or by some other party\nassociated with the application.\nOne or more embodiments of the disclosure relate to providing a user with a recommendation intent query (also sometimes referred to as a \"recommendation questionnaire\") in response to the user indicating that he or she recommends a mobile\napplication.  The recommendation intent query allows for a determination to be made about the user's intent with regard to the recommendation.  For example, where a user recommends an application (e.g., a news or information service) containing a number\nof separable components and/or content (e.g., an image, a video, an advertisement, a user chat interface, etc.), the recommendation intent query allows the user's recommendation to be refined such that the recommendation can be attributed to a particular\none or more of the components and/or content.  The components and/or content of the application are separable in the sense that they each contribute to the application as a whole in one or more ways.\nIn at least some arrangements the recommendation intent query is in the form of a user interface containing a list of components, content, properties, and characteristics of the recommended application, one or more of which the user may\ndesignate (e.g., select, indicate, identify, choose, etc.) as being the intended target(s) of his or her recommendation.  The following descriptions of various embodiments and examples sometimes collectively refer to the components, content,\ncharacteristics, features, properties, etc., of a mobile software application as \"application components\" or simply \"components,\" for purposes of brevity.\nAnother embodiment of the disclosure relates to a method and system for determining the intent of a user's recommendation of a mobile application by traversing a view hierarchy of the application to determine which component(s) or content(s) of\nthe application a user recommendation control is located closest to.  A user can make a recommendation of a mobile application by interacting with (e.g., selecting) a user recommendation control integrated with or otherwise contained in the application. \nAs will be described in greater detail herein, one of the numerous layered views of the application (or more than one of the layered views in a scenario where multiple user recommendation controls are integrated into an application) contains the user\nrecommendation control selected by the user to indicate the user's intention to make a recommendation.  By identifying the application view containing the user recommendation control, a determination can be made about which one or more components of the\napplication the recommendation applies to.\nFor example, a view hierarchy of an application can be traversed by asking for the parent view (sometimes also referred to as the \"root view\") of the view currently being focused on by the user (e.g., the view of the application (e.g., screen\nshot or image(s) being displayed on the screen) that the user indicates he or she wishes to recommend).  In at least one implementation, various requests (e.g., get( ) requests, find( ) requests, etc.) can be made to determine the view with the current\nfocus by the user (e.g., findFocus( )), the parent of the current view (e.g., getParent( )), and the topmost view in the current view hierarchy (e.g., getRootView( )) of the application being used.  In another implementation, subviews and superviews\nproperties may be provided for use in traversing the view hierarchy of an application.  In such an implementation, a subviews property provides an array of subviews of the current view while a superviews property provides the parent view.\nIn either of the example implementations described above for traversing an application's view hierarchy, various information can be obtained including an application developer's view class name, top/left coordinates, and dimensions for the\nparticular application.  As will be further described below, such information allows a determination to be made about which view in an application is closest to a user recommendation control that is interacted with by a user to make a recommendation of\ncontent.\nAdditionally, one or more embodiments described herein relate to a method and system for verifying a user's recommendation of a mobile application is authentic and is accurately attributed to the intended components or content within that\napplication.  Such a verification system and process ensures that when a recommendation is made of an application running on a user device, the recommendation is in fact being made by an authorized user of the device, and not being made by a developer or\nsome other third-party associated with the application on behalf of the user.\nFurthermore, in a scenario where an application running on a user device includes a plurality of separable components, content, properties, and characteristics, the systems and methods described herein ensure that when a user intends his or her\nrecommendation of the application to apply or be attributed to a specific one or more of such components, content, properties, and characteristics, this intention of the user is not distorted when the recommendation is communicated outside of the user\ndevice.\nAs will be described in greater detail below, the methods and systems of the present disclosure that relate to verifying a user's application recommendation include proxying application recommendation requests (e.g., indications that a user\nwishes to recommend an application running on a user device) through a social network application installed on the user's device and requiring the user to confirm all such actions.  In this manner, a developer or other third-party associated with an\napplication (e.g., a \"malicious\" application) cannot send application recommendation requests, and/or requests to undo application recommendations, on its own as if it were the user making such requests.\nAt least one embodiment described herein relates to parsing an application in which a user recommendation control is provided to identify the various components of the application that may be the intended target(s) of a user's recommendation. \nAs will be further described below, the parsed application components may be used to create a database of application components that can be used (e.g., retrieved, referenced, etc.) to generate a recommendation intent query (e.g., recommendation\nquestionnaire) for presentation to a user in response to the user making a recommendation of an application.  In at least some implementations, the \"parsing\" of an application may be performed based on tags provided by a developer or other third-party\nassociated with the application, or by traversing the view hierarchy of the application as described above.  A particular application may be mapped to its respective parsed components contained in one or more component reference tables and/or stored in\none or more databases for use in generating a recommendation intent query.\nOther embodiments of the present disclosure relate to generating detailed social annotations for presentation with a recommended application based on a determination as to the user's intent for the recommendation.  As used herein, a \"social\nannotation\" (also sometimes referred to as \"social content\" or \"social network content\") refers to content associated with an action of a user in a social network that is provided for presentation to other users in the social network in conjunction with\na particular application to which the user's action was directed.  For example, a user (e.g., \"User 1\") may indicate that he or she likes, approves, recommends, suggests, etc., a news service application.  Examples of a detailed social annotation\ncorresponding to such an indication by User 1 may be \"User 1 likes the article about football\" or \"User 1 suggests the video about dogs,\" depending on what User 1 intended his or her recommendation of the news service application to be for.\nAccording to at least one implementation, these detail social annotations may be generated based on a user's response to a recommendation intent query.  For example, if a user designates a particular component of an application to which the\nuser's recommendation of the application is to apply, then when that same application is used by (e.g., accessed) or provided for use (e.g., provided for installation or download) to other users in the user's social network (e.g., other users who are in\nsome type of acquaintance relationship with the recommending user, such as the user's \"connections,\" \"friends,\" \"circles,\" etc.), the application may be presented in conjunction with an annotation detailing the user's recommendation of the designated\ncomponent.\nThe present disclosure contains some examples described in the context of advertisements.  An advertisement is an entity (e.g., video, audio file, image, text, etc.) that presents a piece of information to a user and is designed to be used in\nwhole or in part by the user.  Ads can be provided (e.g., presented) to a user in electronic form, such as banner ads on a web page, as ads presented in a user interface associated with an application (e.g., a mobile application running on a portable\nuser device), as ads presented with search results, as ads presented with emails, and the like.  Such electronic ads may also contain links to other electronic content including web pages, images, audio files video files, etc. Advertisements may also be\nreferred to as \"promotional content\" or one or more other similar such terms.\nWhen a user makes a request for online content, such as a web page, a video/audio clip, a game, or other online resource, via an application running on a user device, one or more content requests can be initiated by the application to retrieve\nthe requested content from content publishers for presentation to the user within the application.  Examples of content publishers include publishers of web sites, search engines that publish search results in response to a query, and numerous other\nsources or parties that make information and/or experiences available for use by applications running on a user device.  In some arrangements, one or more additional items of content, such as advertisements, may be provided along with the requested\ncontent.\nIn at least one scenario a user may be a member of a social network comprised of many other users, some of whom share a connection with the user or are in one of a variety of relations with the user.  In such a social network context, a user may\nwish to recommend or suggest certain content, including advertisements, to one or more other social network users.  In some scenarios this content may be a part of or contained within an application, including a mobile application running on a portable\nuser device.\nIn at least some embodiments, the recommendation intent query provided for presentation to a user in response to receiving an indication that the user recommended an application can be overlaid on the application interface being displayed. \nDepending on the implementation, the recommendation intent query can list or otherwise identify various separable components of the particular application that was recommended by the user (e.g., via a user recommendation control provided for display\nwithin the application).  For example, the recommendation intent query can list application components such as an image, a video, a user chat interface, etc., along with user-selectable checkboxes that can be used to designate one or more listed\ncomponents as the intended target(s) of the recommendation.\nIt should be noted that the recommendation intent query described herein may be referred to in numerous other ways in addition to or instead of \"recommendation intent query,\" without departing from its intended meaning and without limiting any\nof its features and/or functionalities.  For example, the recommendation intent query may also be referred to as a \"recommendation questionnaire,\" \"user intent questionnaire,\" \"user intent query\", \"user intent determination screen,\" as well as other\nidentifiers, names and labels similar in nature to those mentioned.  Irrespective of the term or phrase used to refer to the recommendation intent query, in the various embodiments described herein the recommendation intent query allows a user to\ndesignate (e.g., select, indicate, identify, choose, etc.) one or more components (e.g., subjects, characteristics, parts, features, properties, etc.) of an application to which the user's recommendation of the application applies or should otherwise be\nattributed.\nIt should also be noted that in any of the various scenarios in which the methods or systems described herein collect personal information about a user, the user may be given the option to not have his or her personal information collected\nand/or used in any way.  For example, a user may be provided with an opportunity to opt in/out of programs or features that may collect personal information, such as information about the user's geographic location, preferences, and the like. \nFurthermore, certain user data may be rendered anonymous in one or more ways before being stored and/or used, such that personally-identifiable information is removed.  For example, a user's identity may be made anonymous so that no\npersonally-identifiable information can be determined or collected for the user.  Similarly, a user's geographic location may be generalized in situations where location information is obtained (e.g., limited to a city, zip code, or state level) so that\na particular location of a user cannot be determined.\nFIG. 1 shows an example content presentation system and surrounding environment in which various embodiments described herein may be implemented.  The example system and environment shown includes a user device 105, a content management server\n110, and a social network application server 115.  The example environment also includes a network 100, such as a local area network (LAN), a wide area network (WAN), the Internet, or a combination thereof.  The network 100 connects the user device 105,\nthe content management server 110, the social network application server 115, and can also connect additional devices and/or servers of the same or different type (not shown).  The example system also includes a components database 185, a content\ndatabase 195, a tags index 190, a social content service 157, and an annotations log 194.  These and other components of the system and environment shown in FIG. 1 will be described in greater detail below.\nThe user device 105 can be any of a number of different electronic devices under control of a user and capable of requesting and receiving resources.  As used herein, a resource is any data that can be provided over the network 100, and can be\nidentified by a resource address associated with the resource.  Examples of resources include images, video, HTML pages, content (e.g., words, phrases, images, etc.), embedded information such as meta-information and hyperlinks, and also embedded\ninstructions, such as JavaScript scripts.  Examples of the user device 105 can be one or more personal computers, telephones, personal digital assistants (PDAs), television systems, etc., that are capable of sending and receiving data over the network\n100.  The user device 105 can also be a portable user device, such as a laptop computer, tablet computer, mobile communication device (e.g., cell phone, smartphone), and the like, capable of also sending and receiving data over the network 100.\nThe user device 105 may include one or more applications 120, which in some embodiments may be third-party applications separate from (e.g., not associated or affiliated with) the social network application 150, the content management server\n110, and the social network application server 115.  These applications 120 can consist of software that runs on the user device 105 and performs certain functions or tasks for a user, such as providing user interfaces for messaging services or providing\nservices related to games, videos, or music.  An application, such as application 120, may also be a mobile application consisting of software designed to run on a mobile user device, such as a cell phone or smartphone.  Some example types of\napplications include multimedia (e.g., video or audio players, graphic or image viewers, etc.), communication (e.g., news or information clients, messaging or e-mail clients, etc.), games, productivity (e.g., calculators, calendars, task managers, etc.),\nas well as numerous other categories and types.\nThe application 120 may also include a client content manager 145, designated content space 125, designated social content space 127, a user recommendation control 130, and a view hierarchy module 132.  The content space 125 may be for the\ndisplay of various types of content, such as advertisements related to web page content, video or audio content displayed within a player, web-based e-mail, and the like.  The content space 125 may also include designated social content space 127, which\nmay be for the display of relevant social network content, such as social annotations 128 provided to the user device 105 via a social network application 150 in response to the user device making a social annotations request 126.  Additionally, the\ncontent space 125 may also be for the display of various user interaction tools, such as a user recommendation control 130 configured to allow a user to make a recommendation of content, including the application 120 containing the content, to other\nusers in one or more social networks.\nThe user device 105 may also include one or more web browser tools (not shown) for viewing and interacting with web pages via a wired or wireless internet connection and/or via a mobile data exchange connection such as cellular, optical, near\nfield communication, or some combination thereof.  A web browser tool contained in the user device 105 may similarly include a client content manager 145, designated content space 125, social content space 127 for the display of content (e.g., ads,\nsocial annotations, etc.) related to the application, and a user recommendation control 130.  In at least some embodiments, the user device 105 may also include a computer processing unit (CPU) 140, a memory 135, and a social network application 150. \nFurther details regarding the social network application 150 and the user recommendation control 134 will be provided below.\nContent publishers, such as advertisers, may directly or indirectly submit, log, maintain, and utilize information in the content management server 110.  For example, content publishers may access and/or interact with the content management\nserver 110 via a content publisher interface (I/F) 160.  Additionally, depending on the implementation, content publishers may be able to access and/or interact with the content management server 110 in one or more other ways.  In at least some\nembodiments, content publishers provide content items (e.g., ads) to the content management server 110 via the content publisher interface 160, and the content management server 110, in turn, provides these content items to the user device 105 for\npresentation 124 using various methods described in greater detail below.  These items of content may be provided to the user device 105 in response to a content request 122 received at the content management server 110, where the content request may be\nfor content to be displayed within the application 120 running on the user device 105.\nIn a scenario where the content request 122 is a request for advertising (e.g., promotional) content, then the content provided for presentation 124 may be in the form of graphical ads, such as banner ads, audio ads, video ads, still image ads,\ntext-only ads, as well as ads combining one or more of any such forms.  The content (e.g., ads) received at the content management server 110, and similarly provided for presentation 124 (e.g., on a display of the user device 105) may also include\nembedded information or data, including links to one or more web pages, meta-information, and/or machine-executable instructions.\nAlthough the client content manager 145 is illustrated in FIG. 1 as being a part of the application 120, in some embodiments of the disclosure the client content manager 145 may be a logically separate unit from the application 120. \nAdditionally, the client content manager 145 may become embedded within the application 120 and may form an integral part of the application 120.  Similarly, in embodiments where the user device 105 contains one or more web browser tools (not shown), the\nclient content manager 145 may be contained or embedded within such browser tools or instead be a logically separate unit.  The client content manager 145 manages content for the application 120, including sending content requests 122 to the content\nmanagement server 110 and receiving content from the content management server 110 for presentation on (e.g., a display (not shown)) of the user device 105.  In at least one embodiment, the application 120 may request content directly from the content\nmanagement server 110, and also receive requested content from the content management server 110.\nThe social network application 150 may be client software running on the user device 105.  In at least some embodiments, the social network application 150 manages a user's personal identification information (e.g., a personal cookie) and data\nregarding the user's accounts, including a social networking account.  In one example, a social networking account is unique to a user, and represents the user for purposes of the user interacting with the content management server 110 and the social\nnetwork application server 115, as well as for social networking.\nIn one or more embodiments, the social network application server 115 includes front-end server 155 and user intent module 192.  Either or both of the front-end server 155 and the user intent module 192 may be configured to exchange data and\ninformation with social content service 157.  In some arrangements, the data and information exchanged between the front-end server 155 or the user intent module 192 and the social content service 157 may include social annotation information maintained\nin one or more social annotations logs 194.  As will be further described below, the front-end server 155 may be configured to provide social annotations 128 from the social network application server 115 to the user device 105, which in some\narrangements may be in response to a social annotations request 126 received at the social network application server 115 from the user device 105.  Additionally, the user intent module 192 contained within the social network application server 115 may\nbe configured to receive from the user device 105 a response to a recommendation intent query sent to the user device 105 when, for example, a user makes a recommendation of the application 120.\nFurthermore, in some embodiments a developer or other third-party associated with an application (e.g., application 120) contained on the user device 105 may provide information to the social network application server 115 about one or more tags\nthat can be used to identify various components of the application.  In some arrangements one or more of these tags may be included in a recommendation action 133 sent from the user device 105 (e.g., from the social network application 150 contained on\nthe user device 105) to the social network application server 115 (e.g., to the user intent module 192 contained within the social network application server 115).  As will be further described below, the tag(s) sent along with such a recommendation\naction 133 may be used by the social network application server 115 to determine which component(s) of an application (e.g., application 120) a user's recommendation of the application applies to.\nFurthermore, in one or more embodiments, the tag(s) sent along with a user's recommendation action 133 to the social network application server 115 may be used to generate a recommendation intent query.  Such a recommendation intent query may be\nused to refine a user's recommendation of an application (e.g., application 120) and determine which one or more components of the application the user's recommendation should be attributed to.\nIn various embodiments described herein, content may be provided for presentation 124 in the application 120 running on the user device 105 in conjunction with a user recommendation control 134 and one or more social annotations 128.  For\nexample, the social network application server 115 (e.g., the front-end server 155 of the social network application server 115) may provide, for display along with (e.g., as an overlay on) content provided by the content management server 110, a user\nrecommendation control 134 generated by a social content service 157.  It should be noted that the user recommendation control 130 represented by broken lines within the client content manager 145 corresponds to the providing of the user recommendation\ncontrol 134 from the social network application server 115 to the user device 105.\nThe social network application server 115 may be a web-application server, which is a front-end that hosts the social network application 150 running on the user device 105 and also the user recommendation control 134 provided to the user device\n105 for inclusion in the application 120.  The social network application server 115 may be configured to serve (e.g., via the front-end server 155 contained on the social network application server 115) the user recommendation control 134 and/or the\nsocial annotations 128 to the user device 105.  Additionally, the social network application server 115 may be configured to exchange authentication credentials (e.g., content (e.g., ad) share tokens) and user information with the social content service\n157 such that the social content service 157 retrieves social annotations and other related social content and information from annotations log 194 for use in rendering the user recommendation control 134.\nIn any of the embodiments of the present disclosure, conventional content and/or ad serving methods and systems may be utilized in conjunction with the various features described herein.  Additionally, in at least some embodiments, the content\nmanagement server 110 identifies one or more candidate content items (e.g., candidate ads) from the content database 195, selects a particular one of the candidate content items, and provides the selected candidate content item to the user device 105 for\npresentation (e.g., within a user interface associated with one or more applications 120) to a user.  Depending on the implementation, the content management server 110 may conduct an auction (e.g., a \"content auction\" or an \"ad auction\") to determine\nwhich candidate content item will be selected for presentation.\nIn scenarios where the example content presentation system of FIG. 1 is implemented in a more content-specific context, such as selecting and presenting advertisements, the content management server 110 may be referred to as an \"ad management\nserver,\" the content publisher interface 160 referred to as an \"advertiser publisher interface,\" and the content serving front-end 165 referred to as an \"ad serving front-end\" without limiting any of the features or capabilities of these components or of\nthe overall system as described herein.  It should also be understood that while the following description of various features of the content presentation system sometimes makes reference to advertisements and/or web pages, other forms of content,\nincluding other forms of sponsored content, may also be selected and provided in the content presentation system.\nIt should be noted that in any of the various scenarios in which the methods or systems described herein collect personal information about a user, the user may be given the option to not have his or her personal information collected and/or\nused in any way.  For example, a user may be provided with an opportunity to opt in/out of programs or features that may collect personal information, such as information about the user's geographic location, preferences, and the like.  Furthermore,\ncertain user data may be rendered anonymous in one or more ways before being stored and/or used, such that personally-identifiable information is removed.  For example, a user's identity may be made anonymous so that no personally-identifiable\ninformation can be determined or collected for the user.  Similarly, a user's geographic location may be generalized in situations where location information is obtained (e.g., limited to a city, zip code, or state level) so that a particular location of\na user cannot be determined.\nFIG. 2 is a data flow diagram illustrating example communications for determining the intent of a user's recommendation of an application (e.g., application 120 shown in FIG. 1) by referring to tags (e.g., text, such as keywords or terms, or a\nURL) associated with components of the application.  In at least some embodiments, an application containing a user recommendation control (e.g., application 120 containing user recommendation control 130 on user device 105 shown in FIG. 1) may have one\nor more tags set for the application, where each tag (which may also be referred to as an \"identifier,\" a \"marker,\" or other similar such term) is associated with, linked to, or otherwise references at least one component of the application.\nFor example, an application may include a number of different components (e.g., features, content, properties, etc.), some of which may be designed to enhance a user's experience or provide functionalities that the user will find useful. \nExamples of these components may include images, videos, text blocks, multiple views, user-interaction tools (e.g., a user chat screen), as well as numerous other types and variations of components in addition to or instead of those described.\nIn a scenario where such an application also contains a user recommendation control, a tag may be set associating one or more of the components with a recommendation of the application by a user.  For example, a tag may be set indicating that if\na user recommends the application (e.g., by selecting the user recommendation control), then the recommendation is to be applied to (e.g., attributed to, intended for, etc.) a particular video included in the application.  In this manner a user's\nrecommendation of an application comprised of many components can be refined such that the recommendation is applied or attributed to, or otherwise intended for a particular one or more of the many components.\nAdditionally, refining a user's recommendation of an application by using tags set for the application, as described above, allows for more detailed social annotations (e.g., social annotations 128 shown in FIG. 1) to be generated for\npresentation to one or more other users who access, download, or otherwise use the application.  For example, in addition to generating a social annotation indicating that a user recommended a particular application (e.g., \"User 1 recommends Application\nXYZ\"), the systems and methods described herein provide for generating a social annotation indicating that the user recommended a specific one or more components of the application (e.g., \"User 1 recommends the video shown in Application XYZ\"). \nDepending on the implementation and the particular application at issue, the tag(s) for an application may be set (e.g., provided within the client content manager 145 shown in FIG. 1) by a developer of the application or by some other third-party\nassociated with the application.\nIn the example communications shown in FIG. 2, client content manager 245 may send a user recommendation action with one or more encrypted tags 202 (e.g., tags associated with a particular application recommended by a user) to social network\napplication 250, which, in turn, sends the recommendation action and tag(s) 204 to social network application server 215.  The social network application server 215 may then generate one or more component reference tables based on the received tag(s)\n206.  In at least some embodiments, the component reference table(s) generated by the social network application server 215 may include, for each of the tags received, data corresponding to (e.g., identifying) one or more components of the application\nassociated with the particular tag.\nIn at least some implementations, a user identifier (not shown in FIG. 2) may be sent to the social network application server 215 along with the user recommendation action and encrypted tag(s) 204.  If a user identifier is sent with the user\nrecommendation action and encrypted tag(s) 204, then the identifier may be encrypted as well.  In such an implementation, either the social network application server 215, or a content management server (e.g., content serving front-end 165 of the content\nmanagement server 110 shown in FIG. 1) may be configured to decrypt the user identifier to make a determination as to whether the relevant user has \"opted-out\" (e.g., elected not to receive) of content associated with a social network (e.g., \"social\ncontent\"), which is the type of content involved in at least some embodiments of the present disclosure.\nFor example, a user who does not wish to share his or her information, as well as information related to the user's friends within a social network of the user, may opt-out of receiving content (e.g., ads) accompanied by social network content\n(e.g., social annotations).  In a scenario involving a user who has opted-out of social content, and thus chosen not to share his or her recommendations and suggestions, the user may or may not be presented with a recommendation intent query in response\nto making a recommendation, depending on the implementation involved.\nAfter generating the one or more component reference tables based on the received tag(s) 206, the social network application server 215 may map the user recommendation action to one or more of the components contained in the component reference\ntable(s) 208.  According to some implementations, when a user recommends an application (e.g., application 120 shown in FIG. 1), the one or more components of that application mapped to such a recommendation action can be used as the basis for\ndetermining what the user's recommendation applies to (e.g., should be attributed to).\nFIG. 3 illustrates example communications, including data and information flows, for refining a recommendation of an application made by a user by providing the user with a recommendation intent query according to one or more embodiments\ndescribed herein.  As described above, in response to a user making a recommendation of an application (e.g., recommendation action with tag(s) 133 received at social network application server 115 shown in FIG. 1), the user may be presented with a\nrecommendation intent query that allows the user to make a selection corresponding to one or more components of the application that the user intended his or her recommendation to be for.\nClient content manager 345, which in at least some embodiments may be a client module that manages content for an application running on a user device (e.g., application 120 running on user device 105 shown in FIG. 1) including sending requests\nfor content and receiving content for presentation within the application, may send a share token and an encrypted tag along with a user recommendation action (e.g., indication) 302 to social network application 350.  In at least some embodiments a user\nrecommendation action, which may be in the form of an indication that a user recommended an application, is an indication that the user selected a user recommendation control provided for presentation within the application (e.g., user recommendation\ncontrol 130 contained within application 120 running on user device 105 shown in FIG. 1).\nUpon receiving the share token, encrypted tag, and the user recommendation action 302, the social network application 350, which may be client software running on a user device, may request a user associated with the user device to confirm the\nrecommendation action 304.  In at least some embodiments, the social network application 350 may present the user with a confirmation request screen, such as that shown in the example user interface of FIG. 7.  If the user confirms the recommendation\naction (or undo recommendation action) 304, then the social network application 350 sends the share token, the encrypted tag and the confirmed user action 306 to social network application server 315, where the tag (and in some implementations the share\ntoken) can be decrypted.  For example, the social network application server 315 (or a social content service, such as social content service 157 shown in FIG. 1) may be configured to use authentication credentials for the user to decrypt the share\ntoken.\nOnce the social network application server 315 receives and decrypts the share token and the tag provided along with the confirmed user recommendation action 306, the social network application server 315 may retrieve one or more components\nmapped to the decrypted tag 308 associated with the recommended application.  For example, the social network application server 315 may retrieve the components 308 (e.g., data corresponding to the components) for the application associated with the user\nrecommendation action 302 from a components database (e.g., components database 185 shown in FIG. 1).  The social network application server 315 may retrieve the application components from the components database by using the decrypted tag received with\nthe user recommendation action and referencing a tags index (e.g., tags index 190 shown in FIG. 1).\nAfter retrieving the data corresponding to the components 308 of an application recommended by a user, the social network application server 315 may generate and provide a recommendation intent query user interface (UI) 310 to the social network\napplication 350.  The social network application 350, in turn, provides the recommendation intent query UI 312 to the client content manager 345 for presentation to a user (e.g., the user who recommended the application associated with the user\nrecommendation action (e.g., indication) 302).  In at least some embodiments, the recommendation intent query UI 312 provided to the client content manager 345 contains list of components, content, properties, characteristics, etc. of the particular\napplication recommended by the user.  Additional details regarding various features of the recommendation intent query UI will be described below with reference to FIG. 7.\nAccording to one or more embodiments of the present disclosure, the social network application server 315 may retrieve data corresponding to the components of an application recommended by a user from one or more component reference tables\nstored for the application, such as the example component reference tables shown in FIGS. 5A and 5B.  The example component reference tables illustrated in FIGS. 5A and 5B will be described in greater detail below.\nFIG. 4 is a flowchart illustrating a process of traversing a view hierarchy of a mobile application to determine the intent of a recommendation of the application made by a user according to one or more embodiments described herein.\nThe process begins at step 400 where an indication is received that a user selected a user recommendation control in an application running on a user device (e.g., user recommendation control 130 in application 120 running on user device 105\nshown in FIG. 1).  For example, a user can make a recommendation of a mobile application by interacting with (e.g., selecting, pressing, choosing, etc.) a user recommendation control integrated with, embedded within or otherwise contained in the\napplication.  In at least some embodiments, the indication may be received at a social network application server (e.g., social network application server 115 shown in FIG. 1), and may also be received from a social network application running on the\nuser device (e.g., social network application 150 running on user device 105 shown in FIG. 1).\nOnce the indication is received in step 400, the process continues to step 405 where a view hierarchy of the application is traversed to determine the view of the application containing the user recommendation control.  One of the numerous\nlayered views of the application (or more than one of the layered views in a scenario where multiple user recommendation controls are contained in or otherwise integrated into an application) contains the user recommendation control that was selected by\nthe user to indicate the user's intention to make a recommendation.  As described herein, by identifying the application view containing the user recommendation control, a determination can be made about which one or more components of the application\nthe recommendation was intended for.\nIn some embodiments, traversing the view hierarchy of the application (e.g., application 120 shown in FIG. 1) can be implemented using a view hierarchy module contained in the application (e.g., view hierarchy module 132 shown in FIG. 1).  For\nexample, in at least one arrangement, the view hierarchy of the application can be traversed in step 405 by the view hierarchy module asking the corresponding application for the parent view (sometimes also referred to as the \"root view\") of the view\ncurrently being focused on by the user (e.g., the view of the application (e.g., screen shot or image(s) being displayed on the screen) that the user indicates he or she wishes to recommend).\nIn at least one implementation, various requests (e.g., get( ) requests, find( ) requests, etc.) can be made to determine the view with the current focus by the user (e.g., findFocus( )), the parent of the current view (e.g., getParent( )), and\nthe topmost view in the current view hierarchy (e.g., getRootView( )) of the application being used.  In another implementation, subviews and superviews properties may be provided for use in traversing the view hierarchy of an application.  In such an\nimplementation, a subviews property provides an array of subviews of the current view while a superviews property provides the parent view.\nIn one or both of the example implementations described above for traversing an application's view hierarchy, as well as in numerous other similar implementations, various information can be obtained.  Some examples of the type of information\nthat can be obtained from initiating one or more of the requests described above include an application developer's view class name, top/left coordinates, and dimensions for the particular application.  Such information allows a determination to be made\nabout which view in the application either contains (or is closest to) the user recommendation control selected by the user to make a recommendation of the application, which generated the indication received in step 400.\nThe process continues to step 410 where a determination is made as to the one or more components of the application to which the user's recommendation applies to based on the view of the application containing (or located closest to) the user\nrecommendation control selected by the user as described above.  In at least one embodiment, the determination in step 410 may be made by using such information as the top/left coordinates and/or dimensions for the particular application.  In step 415 of\nthe process, an application view identifier (ID) and data corresponding to application components associated with the particular view are encrypted and then sent in step 420 to a social network application server (e.g., social network application server\n115 shown in FIG. 1).\nFIGS. 5A and 5B are tables that illustrate example components that may be identified for one or more applications (e.g., application 120 shown in FIG. 1) and used in generating a recommendation intent query for presentation to a user.  In one or\nmore embodiments, the example components included in the tables shown in FIGS. 5A and 5B may be identified based on tags (e.g., text, such as keywords or terms, or a URL) associated with the components, where the tags are received from a developer of the\napplication in exchange for the application containing a user recommendation control (e.g., user recommendation control 130 shown in FIG. 1).  In one or more other embodiments, the example components included in the tables may be identified by traversing\na view hierarchy of the application, as described above with respect to the process shown in FIG. 4.\nIn at least some embodiments, the tables shown in FIGS. 5A and 5B may be application component reference tables or charts generated (e.g., by social network application server 115 shown in FIG. 1) based on received tags and/or traversed view\nhierarchies.  Such component reference tables may be used to identify the separable components of a recommended application that are to be included in a recommendation intent query provided for presentation to a user in response to the user making a\nrecommendation (e.g., selecting a user recommendation control provided for display to the user in the application).\nFIGS. 6-8 illustrate example user interfaces that may be used in implementing any of the various methods and systems described herein.  Various features and components of the illustrative user interfaces presented in FIGS. 6-8 are described in\nthe context of an example scenario involving an Application \"XYZ\" 610 contained in user interface 600 of FIG. 6, where Application \"XYZ\" 610 includes multiple separable components.  It should be understood that this particular scenario, including the\nexample application, components, social network interfaces, and other content shown in FIGS. 6-8, are for illustrative purposes only, and are not in any way intended to limit the scope of the present disclosure.\nFIG. 6 shows an example user interface 600, which in at least some scenarios may be a user interface for a mobile Application \"XYZ\" 610 running on a portable user device (e.g., application 120 of user device 105 shown in FIG. 1).  A user\nrecommendation control 620 is provided within the Application \"XYZ\" 610.  As described above, according to some embodiments of the present disclosure, the user recommendation control 620 may be provided within the Application \"XYZ\" 610 to allow a user to\nmake a recommendation (e.g., by interacting with the user recommendation control 620) of the application.\nIn at least the example user interface 600 illustrated in FIG. 6, the user recommendation control 620 is represented as a button with a \"+1\" symbol located in the middle of it.  It should be understood that the user recommendation control 620\nmay be represented in numerous other ways in addition to or instead of the \"+1\" button shown in FIG. 6, and that the use of such an icon is not in any way intended to limit the scope of the disclosure.  Application \"XYZ\" 610 is also shown to include a\nvariety of separable components, including Topic \"A\" 625, Image \"A\" 630, Text Block \"A\" 640, Topic \"B\" 635, Text Block \"B\" 645, Image \"B\" 655, Daily Video Clip 650, and User Chat 660.\nFIG. 7 shows an example user interface 700 that includes a recommendation confirmation request 715 associated with a social content network 710.  In at least the example user interface 700, the recommendation confirmation request 715 is\npresented in conjunction with a recommendation intent query (or recommendation questionnaire) 720.\nAccording to some embodiments of the disclosure, the recommendation confirmation request 715 along with the recommendation intent query 720 may be presented as part of the user interface 700, such as in the example arrangement shown in FIG. 7. \nIn other embodiments, the recommendation confirmation request 715 and recommendation intent query 720 may be presented in one or more separate user interfaces overlaid on a different, or previous, user interface (e.g., user interface 600 shown in FIG.\n6).  In such embodiments, the separate, overlaid user interface containing the recommendation confirmation request 715 and recommendation intent query 720 may be of smaller dimensions than the underlying user interface, such that at least a portion of\nthe underlying user interface remains visible.\nThe recommendation confirmation request 715 may include an identification of the user 725 (e.g., \"User 1\"), and also a request that anyone other than the user identified 725 log out of the social content network 710.  Additionally, the\nrecommendation intent query 720 may identify an application (e.g., Application \"XYZ\") that was recommended by the identified user 725 (e.g., by the user interacting with the user recommendation control 620 shown in FIG. 6), and include a list of various\ncomponents included in the recommended application.  In at least the example user interface 700, the recommendation intent query 720 lists components of the recommended application along with user-selectable checkboxes 740 configured to allow the user to\ndesignate the one or more components of the application that the user intended his or her recommendation to be for.  The user interface 700 also may include user-selectable cancel 730 and confirm 735 buttons to allow the user to cancel or confirm the\nselection of components 705 in the recommendation intent query 720.\nFIG. 8 shows an example user interface 800 that includes a confirmation of the user's recommendation 815 within a social content network 810.  The user interface 800 includes the one or more components 805 of the recommendation application\n(e.g., Application \"XYZ\" 610 shown in the user interface 600 of FIG. 6) determined to be the intended target(s) of the user's recommendation (e.g., by the user making a selection of the intended components in response to the recommendation intent query\n720 shown in the user interface 700 of FIG. 7).\nIn at least some embodiments, the user interface 800 also identifies other users 830 in a social network who have recommended particular components of the application recommended by the user.  The other users 830 of the social network are\nidentified along with social annotations 825 that provide details as to the particular one or more components of the application that each user recommended.  If the user presented with the user interface 800 (e.g., \"User 1\") also wishes to recommend one\nor more other components of the application that one of the other users in the social network 830 has recommended, then the user interface 800 provides user recommendation controls 820 for the user to interact with.\nFIG. 9 is a block diagram illustrating an example computing device 900 that is arranged for selecting and presenting an item of content (e.g., a web page, an advertisement, etc.) to a user or user device in accordance with one or more\nembodiments of the present disclosure.  In a very basic configuration 901, computing device 900 typically includes one or more processors 910 and system memory 920.  A memory bus 930 may be used for communicating between the processor 910 and the system\nmemory 920.\nDepending on the desired configuration, processor 910 can be of any type including but not limited to a microprocessor (.mu.P), a microcontroller (.mu.C), a digital signal processor (DSP), or any combination thereof.  Processor 910 may include\none or more levels of caching, such as a level one cache 911 and a level two cache 912, a processor core 913, and registers 914.  The processor core 913 may include an arithmetic logic unit (ALU), a floating point unit (FPU), a digital signal processing\ncore (DSP Core), or any combination thereof.  A memory controller 915 can also be used with the processor 910, or in some embodiments the memory controller 915 can be an internal part of the processor 910.\nDepending on the desired configuration, the system memory 920 can be of any type including but not limited to volatile memory (e.g., RAM), non-volatile memory (e.g., ROM, flash memory, etc.) or any combination thereof.  System memory 920\ntypically includes an operating system 921, one or more applications 922, and program data 924.  In at least some embodiments, application 922 includes a selection and presentation algorithm 923 that is configured to select a content item, and provide\nthat content item to a user device for presentation to a user.  The selection and presentation algorithm is further arranged to identify annotations (e.g., content associated with a social network of a user) for presentation to a user along with the\nselected content item within the application 922.\nProgram Data 924 may include selection and presentation data 925.  In some embodiments, application 922 can be arranged to operate with program data 924 on an operating system 921 such that a request made by a user of a user device (e.g., user\ndevice 105 shown in FIG. 1) is routed via a social network application (e.g., social network application 150 shown in FIG. 1), which acts as a proxy for transmitting such requests to an appropriate server.\nComputing device 900 can have additional features and/or functionality, and additional interfaces to facilitate communications between the basic configuration 901 and any required devices and interfaces.  For example, a bus/interface controller\n940 can be used to facilitate communications between the basic configuration 901 and one or more data storage devices 950 via a storage interface bus 941.  The data storage devices 950 can be removable storage devices 951, non-removable storage devices\n952, or any combination thereof.  Examples of removable storage and non-removable storage devices include magnetic disk devices such as flexible disk drives and hard-disk drives (HDD), optical disk drives such as compact disk (CD) drives or digital\nversatile disk (DVD) drives, solid state drives (SSD), tape drives and the like.  Example computer storage media can include volatile and nonvolatile, removable and non-removable media implemented in any method or technology for storage of information,\nsuch as computer readable instructions, data structures, program modules, and/or other data.\nSystem memory 920, removable storage 951 and non-removable storage 952 are all examples of computer storage media.  Computer storage media includes, but is not limited to, RAM, ROM, EEPROM, flash memory or other memory technology, CD-ROM,\ndigital versatile disks (DVD) or other optical storage, magnetic cassettes, magnetic tape, magnetic disk storage or other magnetic storage devices, or any other medium which can be used to store the desired information and which can be accessed by\ncomputing device 900.  Any such computer storage media can be part of computing device 900.\nComputing device 900 can also include an interface bus 942 for facilitating communication from various interface devices (e.g., output interfaces, peripheral interfaces, communication interfaces, etc.) to the basic configuration 901 via the\nbus/interface controller 940.  Example output devices 960 include a graphics processing unit 961 and an audio processing unit 962, either or both of which can be configured to communicate to various external devices such as a display or speakers via one\nor more A/V ports 963.  Example peripheral interfaces 970 include a serial interface controller 971 or a parallel interface controller 972, which can be configured to communicate with external devices such as input devices (e.g., keyboard, mouse, pen,\nvoice input device, touch input device, etc.) or other peripheral devices (e.g., printer, scanner, etc.) via one or more I/O ports 973.  An example communication device 980 includes a network controller 981, which can be arranged to facilitate\ncommunications with one or more other computing devices 990 over a network communication (not shown) via one or more communication ports 982.  The communication connection is one example of a communication media.  Communication media may typically be\nembodied by computer readable instructions, data structures, program modules, or other data in a modulated data signal, such as a carrier wave or other transport mechanism, and includes any information delivery media.  A \"modulated data signal\" can be a\nsignal that has one or more of its characteristics set or changed in such a manner as to encode information in the signal.  By way of example, and not limitation, communication media can include wired media such as a wired network or direct-wired\nconnection, and wireless media such as acoustic, radio frequency (RF), infrared (IR) and other wireless media.  The term computer readable media as used herein can include both storage media and communication media.\nComputing device 900 can be implemented as a portion of a small-form factor portable (or mobile) electronic device such as a cell phone, a personal data assistant (PDA), a personal media player device, a wireless web-watch device, a personal\nheadset device, an application specific device, or a hybrid device that include any of the above functions.  Computing device 900 can also be implemented as a personal computer including both laptop computer and non-laptop computer configurations.\nThere is little distinction left between hardware and software implementations of aspects of systems; the use of hardware or software is generally (but not always, in that in certain contexts the choice between hardware and software can become\nsignificant) a design choice representing cost versus efficiency trade-offs.  There are various vehicles by which processes and/or systems and/or other technologies described herein can be effected (e.g., hardware, software, and/or firmware), and the\npreferred vehicle will vary with the context in which the processes and/or systems and/or other technologies are deployed.  For example, if an implementer determines that speed and accuracy are paramount, the implementer may opt for a mainly hardware\nand/or firmware vehicle; if flexibility is paramount, the implementer may opt for a mainly software implementation.  In one or more other scenarios, the implementer may opt for some combination of hardware, software, and/or firmware.\nThe foregoing detailed description has set forth various embodiments of the devices and/or processes via the use of block diagrams, flowcharts, and/or examples.  Insofar as such block diagrams, flowcharts, and/or examples contain one or more\nfunctions and/or operations, it will be understood by those within the art that each function and/or operation within such block diagrams, flowcharts, or examples can be implemented, individually and/or collectively, by a wide range of hardware,\nsoftware, firmware, or virtually any combination thereof.\nIn one or more embodiments, several portions of the subject matter described herein may be implemented via Application Specific Integrated Circuits (ASICs), Field Programmable Gate Arrays (FPGAs), digital signal processors (DSPs), or other\nintegrated formats.  However, those skilled in the art will recognize that some aspects of the embodiments described herein, in whole or in part, can be equivalently implemented in integrated circuits, as one or more computer programs running on one or\nmore computers (e.g., as one or more programs running on one or more computer systems), as one or more programs running on one or more processors (e.g., as one or more programs running on one or more microprocessors), as firmware, or as virtually any\ncombination thereof.  Those skilled in the art will further recognize that designing the circuitry and/or writing the code for the software and/or firmware would be well within the skill of one of skilled in the art in light of the present disclosure.\nAdditionally, those skilled in the art will appreciate that the mechanisms of the subject matter described herein are capable of being distributed as a program product in a variety of forms, and that an illustrative embodiment of the subject\nmatter described herein applies regardless of the particular type of signal-bearing medium used to actually carry out the distribution.  Examples of a signal-bearing medium include, but are not limited to, the following: a recordable-type medium such as\na floppy disk, a hard disk drive, a Compact Disc (CD), a Digital Video Disk (DVD), a digital tape, a computer memory, etc.; and a transmission-type medium such as a digital and/or an analog communication medium (e.g., a fiber optic cable, a waveguide, a\nwired communications link, a wireless communication link, etc.).\nThose skilled in the art will also recognize that it is common within the art to describe devices and/or processes in the fashion set forth herein, and thereafter use engineering practices to integrate such described devices and/or processes\ninto data processing systems.  That is, at least a portion of the devices and/or processes described herein can be integrated into a data processing system via a reasonable amount of experimentation.  Those having skill in the art will recognize that a\ntypical data processing system generally includes one or more of a system unit housing, a video display device, a memory such as volatile and non-volatile memory, processors such as microprocessors and digital signal processors, computational entities\nsuch as operating systems, drivers, graphical user interfaces, and applications programs, one or more interaction devices, such as a touch pad or screen, and/or control systems including feedback loops and control motors (e.g., feedback for sensing\nposition and/or velocity; control motors for moving and/or adjusting components and/or quantities).  A typical data processing system may be implemented utilizing any suitable commercially available components, such as those typically found in data\ncomputing/communication and/or network computing/communication systems.\nWith respect to the use of substantially any plural and/or singular terms herein, those having skill in the art can translate from the plural to the singular and/or from the singular to the plural as is appropriate to the context and/or\napplication.  The various singular/plural permutations may be expressly set forth herein for sake of clarity.\nWhile various aspects and embodiments have been disclosed herein, other aspects and embodiments will be apparent to those skilled in the art.  The various aspects and embodiments disclosed herein are for purposes of illustration and are not\nintended to be limiting, with the true scope and spirit being indicated by the following claims.", "application_number": "15860324", "abstract": " Methods and systems are provided for determining the intent of a\n     recommendation made by a user of a mobile application where the\n     application includes a plurality of separable components, any one or more\n     of which the recommendation can apply to. An application in which a user\n     recommendation control is provided for presentation to a user also\n     includes a tag indicating how a recommendation of the application should\n     be interpreted with respect to the components included therein. The tag\n     can be set by the application developer and can be in the form of text\n     (e.g., a keyword or term) or a uniform resource locator (URL). Where a\n     tag references multiple components of an application, a recommending user\n     can be presented with a recommendation intent query. The recommendation\n     intent query allows a user to designate one or more components of the\n     application to which the user's recommendation should be attributed.\n", "citations": ["6212640", "6615276", "6650629", "20040230985", "20050071867", "20050071897", "20080003990", "20080301240", "20100217670", "20100332330", "20110061068", "20120110474"], "related": ["13451351", "13271079"]}, {"id": "20180139054", "patent_code": "10333715", "patent_name": "Providing computation services with privacy", "year": "2019", "inventor_and_country_data": " Inventors: \nChu; Stephen Mingyu (Beabercreek, OH), Enders; Tobias (Mamaroneck, NY), Li; Dong Sheng (Shanghai, CN), Srivastava; Pankaj (Bedford, NY), Yan; Junichi (Shanghai, CN), Yoshioka; Tomomi (New York, NY)  ", "description": "<BR><BR>BACKGROUND\nThe subject disclosure relates generally to privacy and authorization and in particular to providing a local computation service authorized by a remote service provider while keeping local data private from the remote service provider.\n<BR><BR>SUMMARY\nThe following presents a summary to provide a basic understanding of one or more embodiments of the invention.  This summary is not intended to identify key or critical elements, or delineate any scope of the particular embodiments or any scope\nof the claims.  Its sole purpose is to present concepts in a simplified form as a prelude to the more detailed description that is presented later.  In one or more embodiments described herein, systems, computer-implemented methods, apparatus and/or\ncomputer program products that facilitates providing a local computation service authorized by a remote service provider while keeping local data private from the remote service provider are described.\nAccording to an embodiment, a system is provided.  The system includes a memory that stores computer executable components; and a processor that executes the computer executable components stored in the memory.  The computer executable\ncomponents include a security component that can, in response to sending encrypted input data to a service provider that is remote from the system, receives an encrypted signature from the service provider that is generated based on an application of a\nhomomorphic encryption public key and a homomorphic encryption equivalent defined function to the encrypted input data.  The security component also decrypts the encrypted signature with a homomorphic encryption private key that is paired with the\nhomomorphic encryption public key to generate a decrypted signature.  The computer executable components also includes a service provider application component, local to the system, that applies a defined function corresponding to the homomorphic\nencryption equivalent defined function on input data to generate a signature.  The service provider application component can also, in response to a determination that the signature matches the decrypted signature, grants the system access to a\ncomputation service of the service provider application component using the input data.\nIn another embodiment a computer-implemented method is provided.  The computer-implemented method can include transmitting, by a device operatively coupled to a processor, a homomorphic encryption public key and homomorphically encrypted input\ndata to a service provider.  The computer-implemented method can also include receiving, by the device from the service provider, a homomorphically encrypted signature generated based on the homomorphic encryption public key, the homomorphically\nencrypted input data, and a homomorphic encryption equivalent defined function.  The computer-implemented method can include, in response to a determination, based on a defined function corresponding to the homomorphic encryption equivalent defined\nfunction, that the homomorphically encrypted signature and input data are valid for a computation service, performing, by the device, the computation service on the input data.\nIn another embodiment, a computer program product for providing a local computation service for a client authorized by a remote service provider while keeping local client data private from the remote service provider.  The computer program\nproduct can include a computer readable storage medium having program instructions embodied therewith, the program instructions executable by a processing component on a device to cause the processing component to transmit a homomorphic encryption public\nkey and homomorphically encrypted input data to a service provider located remotely from the device.  The processing component can also receive, from the service provider, a homomorphically encrypted signature generated based on the homomorphic\nencryption public key, the homomorphically encrypted input data, and a homomorphic encryption equivalent defined function.  The processing component can also, in response to a determination, based on a defined function corresponding to the homomorphic\nencryption equivalent defined function, that the homomorphically encrypted signature and input data are valid for a computation service, perform the computation service on the input data. <BR><BR>DESCRIPTION OF THE DRAWINGS\nFIG. 1 illustrates a block diagram of an example, non-limiting architecture that facilitates providing a local computation service authorized by a remote service provider while keeping local data private from the remote service provider in\naccordance with one or more embodiments described herein.\nFIG. 2A illustrates a block diagram of an example, non-limiting transmission of a homomorphic encryption public key from a client device to a server device in accordance with one or more embodiments described herein.\nFIG. 2B illustrates a block diagram of an example, non-limiting transmission of a homomorphically encrypted input data from a client device to a server device in accordance with one or more embodiments described herein.\nFIG. 2C illustrates a block diagram of an example, non-limiting transmission of a homomorphically encrypted signature from a server device to a client device in accordance with one or more embodiments described herein.\nFIG. 3 illustrates a flow diagram of an example, non-limiting computer-implemented method that facilitates a client device to obtain authorization from a remote service provider for a computation service on the client device set of input data\nwhile keeping the set of input data private from the remote service provider in accordance with one or more embodiments described herein.\nFIG. 4 illustrates a flow diagram of an example, non-limiting computer-implemented method that facilitates a service provider to remotely authorize a computation service on a client device for a set of input data while keeping the set of input\ndata private from the service provider in accordance with one or more embodiments described herein.\nFIG. 5 illustrates a flow diagram of an example, non-limiting computer-implemented method that facilitates a client device generating and transmitting to a service provider a homomorphic encryption public key and homomorphically encrypted input\ndata t in accordance with one or more embodiments described herein.\nFIG. 6 illustrates a flow diagram of an example, non-limiting computer-implemented method that facilitates a client device determining whether a computation service on the client device is authorized by a remote service provider for a set of\ninput data in accordance with one or more embodiments described herein.\nFIG. 7 illustrates a flow diagram of an example, non-limiting computer-implemented method that facilitates a service provider generating a homomorphically encrypted signature from homomorphically encrypted input data in accordance with one or\nmore embodiments described herein.\nFIG. 8 illustrates a block diagram of an example, non-limiting operating environment in which one or more embodiments described herein can be facilitated.\nFIG. 9 illustrates a block diagram of an example, non-limiting cloud computing environment in accordance with one or more embodiments described herein.\nFIG. 10 illustrates a block diagram of example, non-limiting abstraction model layers in accordance with one or more embodiments described herein.\n<BR><BR>DETAILED DESCRIPTION\nThe following detailed description is merely illustrative and is not intended to limit embodiments and/or application or uses of embodiments.  Furthermore, there is no intention to be bound by any expressed or implied information presented in\nthe preceding Background or Summary sections, or in the Detailed Description section.\nOne or more embodiments are now described with reference to the drawings, wherein like referenced numerals are used to refer to like elements throughout.  In the following description, for purposes of explanation, numerous specific details are\nset forth in order to provide a more thorough understanding of the one or more embodiments.  It is evident; however in various cases, that the one or more embodiments can be practiced without these specific details.\nWith increases in network speeds and bandwidth, service providers are making many computation services available to clients over networks, such as the Internet.  The service provider can make a computation service available on their server\ndevice (e.g. server device, server system, and/or cloud computing system) that the client's device can access across the internet by sending input data and receiving output data generated by the computation service.  A computation service can include,\nbut is not limited to, a recommendation service, a data analytics service, a data mining service, a financial analysis service, a marketing analysis service, a pricing analysis service, a forecasting analysis service, a parameter tuning service, a\ntesting analysis service, or any other suitable computing service that can be provided as a remote service over a network.  For example, a company can employ a remote computation service that analyzes sales data and provides recommendations on target\ndemographics for marketing and/or sales forecasts.  In another example, a manufacturing business can employ a remote computation service that analyzes production data and provides process improvement recommendations and/or production forecasts.  In a\nfurther example, a business can employ a remote computation service that analyzes cost and pricing data and provides recommendations on product pricing.  In a non-limiting example, the client can pay a defined fee for the computation service for a\ndefined set of input data.\nHowever, a client that wants to employ a remote computation service can be hesitant to transmit input data (e.g., customer data, sales data, financial data, marketing data, pricing data, inventory data, or any other suitable input data\nemployable by a computation service) that is private over a public network and/or to a third party, and thus may not employ the remote computation service.  For example, a client that wants to employ the remote computation service might not want a\nservice provider that is providing the remote computation service to have visibility to the input data.  In another example, the client might be fearful of transmitting the input data to the remote computation service over a public or private network due\nto concerns over a third party intercepting the input data during transmission or upon arrival at a device associated with the remote computation service.  To overcome this hesitation, a service provider can provide a service provider application that\ncan run on a client's device and perform the computation service locally for the client.  Still, the service provider can want to control usage of the computation service locally for the defined set of input data for which the client has paid fees even\nwithout having visibility to the defined set of input data.  For example, the service provide can want to limit usage of the computation service only to the defined set of input data and/or for other limitations associated with the defined set of input\ndata, such as in a non-limiting example, time limit, number of computations, or any other suitable limitation on usage of the computation service.\nTo address the challenges in providing a local computation service authorized by a remote service provider while keeping local data private from the remote service provider as described herein, one or more embodiments described herein can employ\nan encryption scheme that encrypts input data for which the client wants to employ a computation service provided locally by a service provider, a signature scheme that the service provider can employ on a server device to generate a signature based on\nthe encrypted input data, and a verification scheme that service provider application can employ locally on a client device to verify that the input data is authorized to for employment by the service provider application for the computation service.\nOne or more embodiments of the subject disclosure is directed to computer processing systems, computer-implemented methods, apparatus and/or computer program products that facilitate efficiently, effectively, and automatically (e.g., without\ndirect human involvement) providing a local computation service authorized by a remote service provider while keeping local data private from the remote service provider.  The computer processing systems, computer-implemented methods, apparatus and/or\ncomputer program products can employ hardware and/or software to solve problems that are highly technical in nature (e.g., automated enablement of a local computation service authorized by a remote service provider while keeping local data private from\nthe remote service provider, generation and/or employment of one or more different detailed, specific and highly-complex authorization models) that are not abstract and that cannot be performed as a set of mental acts by a human.  For example, a human,\nor even thousands of humans, cannot efficiently, accurately and effectively manually gather and analyze thousands of data elements related to employing one or more different encryption schemes that encrypts input data for which the client wants to employ\na computation service provided locally by a service provider, a signature scheme that the service provider can employ on a server device to generate a signature based on the encrypted input data, and a verification scheme that service provider\napplication can employ locally on a client device to verify that the input data is authorized to for employment by the service provider application for the computation service.  One or more embodiments of the subject computer processing systems, methods,\napparatuses and/or computer program products can facilitate the automated enablement of a local computation service authorized by a remote service provider while keeping local data private from the remote service provider in a highly accurate and\nefficient manner.  By employing automated enablement of a local computation service authorized by a remote service provider while keeping local data private from the remote service provider, the, privacy, security, processing time, and/or accuracy\nassociated with the existing automated authorization is substantially improved.  Additionally, the nature of the problem solved is inherently related to technological advancements in Internet-based media and/or transactions that have not been previously\naddressed in this manner.  Further, one or more embodiments of the subject techniques can facilitate improved performance of automated enablement of a local computation service authorized by a remote service provider while keeping local data private from\nthe remote service provider for more efficient usage of storage resources, processing resources, and network bandwidth resources to provide privacy of defined client data for remotely authorized computation services on the defined client data, while\nrestricting usage of the computation service to only the defined client data and associated limitations (e.g., amount of time, number of computations, and/or any other suitable limitations).\nFIG. 1 illustrates a block diagram of an example, non-limiting architecture 100 that facilitates providing a local computation service authorized by a remote service provider while keeping local data private from the remote service provider in\naccordance with one or more embodiments described herein.  Aspects of architectures (e.g., architecture 100 and the like), apparatuses or processes explained in this disclosure can constitute machine-executable component(s) embodied within machine(s),\ne.g., embodied in one or more computer readable mediums (or media) associated with one or more machines.  Such component(s), when executed by the one or more machines, e.g., computer(s), computing device(s), virtual machine(s), etc. can cause the\nmachine(s) to perform the operations described.  Repetitive description of like elements employed in one or more embodiments described herein is omitted for sake of brevity.\nAs shown in FIG. 1, the architecture 100 can include a server device 102, one or more networks 112 and one or more client devices 114.  Server device 102 can include service provider authorization component 104 that can facilitate authorizing a\ncomputation service on client device 114 for a defined set of input data 124.  Server device 102 can also include or otherwise be associated with at least one included memory 108 that can store computer executable components (e.g., computer executable\ncomponents can include, but are not limited to, service provider authorization component 104 and associated components), and can store any data generated by service provider authorization component 104 and associated components.  Server device 102 can\nalso include or otherwise be associated with at least one processor 106 that executes the computer executable components stored in memory 108.  Server device 102 can further include a system bus 110 that can couple the various components including, but\nnot limited to, service provider authorization component 104, memory 108 and/or processor 106.\nClient device 114 can include security component 116 that can facilitate protecting privacy of the defined set of input data 124 from server device 102.  Client device 114 can also include service provider application component 118 that can\nfacilitate verifying authorization of the computation service on client device 114 for the defined set of input data, and performing the computation service on client device 114 for the defined set of input data.  Client device 114 can also include or\notherwise be associated with at least one included memory 120 that can store input data 124, computer executable components (e.g., computer executable components can include, but are not limited to, security component 116, service provider application\ncomponent 118, and associated components), and can store any data generated by security component 116, service provider application component 118, and associated components.  Client device 114 can also include or otherwise be associated with at least one\nprocessor 122 that executes the computer executable components stored in memory 120.  Client device 114 can further include a system bus 126 that can couple the various components including, but not limited to, security component 116, service provider\napplication component 118, memory 120 and/or processor 122.\nIt is to be appreciated that server device 102 can be associated with a service provider that provided service provider application component 118 to client device 114, and client device 114 can be associated with a client that wants to employ\nservice provider application component 118 to perform one or more computation services on a defined set of input data 124 according to one or more limitations for which the client has paid the service provider while maintaining the defined set of input\ndata private from the service provider.\nServer device 102 and/or client device 114 can be any computing device or computing system that can be communicatively coupled together, non-limiting examples of which can include, but are not limited to, a computing system, a server computer, a\ncomputer, a mobile computer, a tablet computer, a mobile phone, a mainframe computer, a network storage device, a communication device, a web server device, a network switching device, a network routing device, a gateway device, a network hub device, a\nnetwork bridge device, a control system, or any other suitable computing device.  It is to be appreciated that server device 102, and/or client device 114 can be equipped with communication components (not shown) that enable communication between server\ndevice 102 and/or client device 114 over one or more networks 112.\nThe various components (e.g., service provider authorization component 104, memory 108, processor 106, server device 102, client devices 114, security component 116, service provider application component 118, memory 120 and/or processor 122,\nand/or other components) of architecture 100 can be connected either directly or via one or more networks 112.  Such networks 112 can include wired and wireless networks, including, but not limited to, a cellular network, a wide area network (WAN) (e.g.,\nthe Internet), or a local area network (LAN), non-limiting examples of which include cellular, WAN, wireless fidelity (Wi-Fi), Wi-Max, WLAN, radio communication, microwave communication, satellite communication, optical communication, sonic\ncommunication, or any other suitable communication technology.\nSecurity component 116 can employ a homomorphic encryption scheme to generate a homomorphic encryption public key 202 and a homomorphic encryption private key.  Homomorphic encryption is a form of encryption that allows computations to be\ncarried out on ciphertext, thus generating an encrypted result which, when decrypted, matches the result of operations performed on the plaintext.  It is to be appreciated that, in some embodiments, the homomorphic encryption scheme can be non-symmetric\nso that the homomorphic encryption private key cannot be derived from the homomorphic encryption public key.  Examples of non-symmetric homomorphic encryption schemes can include, but are not limited to, Paillier cryptosystem, Damgard-Jurik cryptosystem,\nNaccache-Stern cryptosystem, Okamoto-Uchiyama cryptosystem, ElGamal encryption scheme, Boneh-Goh-Nissim Encryption Scheme, Goldwasser-Micali encryption scheme, or any other suitable homomorphic encryption scheme.\nFIG. 2A illustrates a block diagram of an example, non-limiting transmission of the homomorphic encryption public key 202 from client device 114 to server device 102 in accordance with one or more embodiments described herein.  For example,\nsecurity component 116 or another component of client device 114 can transmit the homomorphic encryption public key 202 to server device 102 over network 112.  Repetitive description of like elements employed in other embodiments described herein is\nomitted for sake of brevity.\nReferring back to FIG. 1, security component 116 can obtain a defined set of input data (e.g., input data 124) on which a client associated with client device 114 would like a computation service to be performed by service provider application\ncomponent 118.  Security component 116 can prepare the input data 124 for encryption by scaling (e.g., rounding, truncating, or any other suitable scaling mechanism) any (or, in some embodiments, one or more) values in the input data 124 that are not\nwhole integers into whole integers to generate a set of prepared input data.  Security component 116 can encrypt the prepared input data using the homomorphic encryption public key to generate a set of encrypted input data (e.g., encrypted input data\n204).\nIn an alternative example, service provider application component 118 can prepare the input data 124 for encryption by scaling any (or, in some embodiments, one or more) values in the input data 124 that are not whole integers into whole\nintegers to generate a set of prepared input data.  This can save processing resources later in cases in which the service provider application component 118 verifies input data 124 and a decrypted form of encrypted signature 206.  In some embodiments, a\nservice provider application component 118 will not provide input data 124 to server device 102 or any other components that are not authorized to have access to the input data 124.  It is to be appreciated that security component 116 can monitor and/or\nprevent service provider application component 118 from transmitting input data 124 outside of service provider application component 118.  For example, security component 116 can block transmissions by service provider application component 118.  In\nanother example, security component 116 can block intercept transmissions by service provider application component 118 and only allow transmissions that do not include any portion of input data 124.\nFIG. 2A illustrates a block diagram of an example, non-limiting transmission of the encrypted input data 204 from client device 114 to server device 102 in accordance with one or more embodiments described herein.  For example, security\ncomponent 116 or another component of client device 114 can transmit the encrypted input data 204 to server device 102 over network 112.  It is to be appreciated that while FIGS. 2A and 2B depict separate transmissions of the homomorphic encryption\npublic key 202 and encrypted input data 204 from client device 114 to server device 102, in another example, the homomorphic encryption public key 202 and encrypted input data 204 can be transmitted together from client device 114 to server device 102.\nReferring back to FIG. 1, server device 102 can receive the homomorphic encryption public key 202 and encrypted input data 204 from client device 114.  It is to be appreciated that server device 102 does not have homomorphic encryption private\nkey, and therefore cannot decrypt encrypted input data 204.  Service provider authorization component 104 can have a defined function f that can generate a signature on input data and a defined function f.sub.HE that can generate an encrypted signature\nfrom encrypted input data using a homomorphic encryption scheme.  In some embodiments, the defined function f is limited to the mathematical operations of addition and/or multiplication.  In Homomorphic Encryption (HE), additions and/or multiplications\nof integers in encrypted form can be computed.  For a non-limiting example, given two integers x1 and x2, and E( ) as a homomorphic encryption operation and given an example function z=x1+x2, then E(z)=E(x1+x2)=E(x1)*E(x2).  This means that an addition\noperation in unencrypted form can be converted to a multiplication operation in encrypted form.  Similarly, a multiplication operation in unencrypted form should be converted to an exponentiation operation in encrypted form.  For example, E(2*y) is equal\nto E(y).sup.2.  Therefore, with D( ) as a homomorphic decryption operation corresponding to homomorphic encryption operation E( ), then f=D(f.sub.HE) or equivalently E(f)=f.sub.HE.  For example, given a set of input data (a1, .  . . , a.sub.m), where m\nis a positive integer representing the number of data elements in the set of input data, and also given a set of homomorphic ally encrpypted input data (b1, .  . . , b.sub.m) encrpyted from input data (a1, .  . . , a.sub.m) then f(a1, .  . . ,\na.sub.m)=D(f.sub.HE(b1, .  . . , b.sub.m)) or equivalently E(f(a1, .  . . , a.sub.m))=f.sub.HE(b1, .  . . , b.sub.m).  It is to be appreciated that service provider authorization component 104 can generate defined function f.sub.HE from defined function\nf and/or generate defined function f from defined function f.sub.HE.\nIt is also to be appreciated that service provider authorization component 104 can provide one or more user interfaces (not shown) that allow a user and/or an operator of service provider authorization component 104 to specify defined function f\nand/or a defined function f.sub.HE.\nService provider authorization component 104 can employ a homomorphic encryption public key 202 to encrypt numerical parameters in defined function f.sub.HE, Therefore, defined function f.sub.HE for encrypted input data 204 can be the\nhomomorphic encryption equivalent of defined function f for the prepared input data used to generate encrypted input data 204 with homomorphic encryption public key 202.  In a non-limiting example, for a defined function f.sub.HE=3*x1, service provider\nauthorization component 104 can employ the homomorphic encryption public key 202 to encrypt the number 3 in f.sub.HE so that f.sub.HE=E(3)*x1.  Service provider authorization component 104 can then employ defined function f.sub.HE with the encrypted\nnumerical parameters on encrypted input data 204 to generate an encrypted signature 206.\nIt is to be appreciated that, in some embodiments, the defined function f is also known to service provider application component 118, but defined function f and defined function f.sub.HE are not known to other components of client device 114. \nThis can prevent client device 114 from generating a valid decrypted signature for use with service provider application component 118.\nFIG. 2C illustrates a block diagram of an example, non-limiting transmission of the encrypted signature 206 from server device 102 to client device 114 in accordance with one or more embodiments described herein.  For example, service provider\nauthorization component 104 or another component of server device 102 can transmit the encrypted signature 206 from server device 102 to client device 114 over network 112.  Repetitive description of like elements employed in other embodiments described\nherein is omitted for sake of brevity.\nReferring back to FIG. 1, client device 114 can receive encrypted signature 206 from server device 102.  Security component 116 can employ the homomorphic encryption private key to decrypt encrypted signature 206 to generate a decrypted\nsignature.  It is to be appreciated that in some embodiments service provider application component 118 does not have access to the homomorphic encryption private key to prevent the homomorphic encryption private key from becoming available to server\ndevice 102 or any other unauthorized components from service provider application component 118.  Security component 116 can provide input data 124 and the decrypted signature to service provider application component 118.  It is to be appreciated that\nsecurity component 116 can monitor and/or prevent service provider application component 118 from transmitting input data 124 outside of service provider application component 118.  Furthermore, in some embodiments, service provider application component\n118 does not have access to the homomorphic encryption private key to prevent the homomorphic encryption private key from becoming available to server device 102 or any other unauthorized components from service provider application component 118.\nService provider application component 118 can prepare the input data 124 by scaling any (or, in some embodiments, one or more) values in the input data 124 that are not whole integers into whole integers to generate the prepared input data, and\nemploy defined function f to generate a signature on the prepared input data.  Service provider application component 118 can compare the signature to the decrypted signature to verify whether the to perform the computation service on input data 124.  If\nservice provider application component 118 determines that the signature matches the decrypted signature, then service provider application component 118 can perform the computation service on input data 124 according to any associated limitations on\nperformance of the computation service with input data 124, and generate any results (e.g., analysis output, recommendation, report, data value, or any other suitable result) of the computation service on input data 124.  If service provider application\ncomponent 118 determines that the signature does not match the decrypted signature, then service provider application component 118 can reject performing the computation service on input data 124.\nIn an alternative embodiment, prepared input data can comprise a subset of input data 124.  For example, a large set of input data 124 can require considerable usage of storage, processing, and/or network bandwidth resources.  To reduce usage of\nstorage, processing, and/or network bandwidth resources, a subset of input data 124 can be employed as the prepared input data that is used for verification of authorization by security component 116, service provider authorization component 104, and/or\nservice provider application component 118 for the computation service on the set of input data 124.  For example, service provider application component 118 can employ a predefined sampling algorithm, a random sampling, or any other suitable mechanism\nfor determining a subset of input data 124 to be employed for prepared input data.\nWhile FIG. 1 depicts separate components in server device 102 and/or client device 114, it is to be appreciated that two or more components can be implemented in a common component.  Further, it is to be appreciated that the design of the server\ndevice 102 and/or client device 114 can include other component selections, component placements, etc., to facilitate automatically providing a local computation service authorized by a remote service provider while keeping local data private from the\nremote service provider in accordance with one or more embodiments described herein.  Moreover, the aforementioned systems and/or devices have been described with respect to interaction between several components.  It should be appreciated that such\nsystems and components can include those components or sub-components specified therein, some of the specified components or sub-components, and/or additional components.  Sub-components could also be implemented as components communicatively coupled to\nother components rather than included within parent components.  Further yet, one or more components and/or sub-components can be combined into a single component providing aggregate functionality.  The components can also interact with one or more other\ncomponents not specifically described herein for the sake of brevity, but known by those of skill in the art.\nFurther, some of the processes performed can be performed by specialized computers for carrying out defined tasks related to automatically providing a local computation service authorized by a remote service provider while keeping local data\nprivate from the remote service provider.  The subject computer processing systems, methods apparatuses and/or computer program products can be employed to solve new problems that arise through advancements in technology, computer networks, the Internet\nand the like.  The subject computer processing systems, methods apparatuses and/or computer program products can provide technical improvements to systems automatically providing a local computation service authorized by a remote service provider while\nkeeping local data private from the remote service provider in a live environment by improving processing efficiency among processing components in these systems, reducing delay in processing performed by the processing components, reducing storage\nrequirements, reducing network bandwidth usage, and/or improving the accuracy in which the processing systems automatically determine provide a local computation service authorized by a remote service provider while keeping local data private from the\nremote service provider.\nThe embodiments of devices described herein can employ artificial intelligence (AI) to facilitate automating one or more features described herein.  The components can employ various AI-based schemes for carrying out various embodiments/examples\ndisclosed herein.  In order to provide for or aid in the numerous determinations (e.g., determine, ascertain, infer, calculate, predict, prognose, estimate, derive, forecast, detect, compute) described herein, components described herein can examine the\nentirety or a subset of the data to which it is granted access and can provide for reasoning about or determine states of the system, environment, etc. from a set of observations as captured via events and/or data.  Determinations can be employed to\nidentify a specific context or action, or can generate a probability distribution over states, for example.  The determinations can be probabilistic--that is, the computation of a probability distribution over states of interest based on a consideration\nof data and events.  Determinations can also refer to techniques employed for composing higher-level events from a set of events and/or data.\nSuch determinations can result in the construction of new events or actions from a set of observed events and/or stored event data, whether or not the events are correlated in close temporal proximity, and whether the events and data come from\none or several event and data sources.  Components disclosed herein can employ various classification (explicitly trained (e.g., via training data) as well as implicitly trained (e.g., via observing behavior, preferences, historical information,\nreceiving extrinsic information, etc.)) schemes and/or systems (e.g., support vector machines, neural networks, expert systems, Bayesian belief networks, fuzzy logic, data fusion engines, etc.) in connection with performing automatic and/or determined\naction in connection with the claimed subject matter.  Thus, classification schemes and/or systems can be used to automatically learn and perform a number of functions, actions, and/or determination.\nA classifier can map an input attribute vector, z=(z1, z2, z3, z4, zn), to a confidence that the input belongs to a class, as by f(z)=confidence(class).  Such classification can employ a probabilistic and/or statistical-based analysis (e.g.,\nfactoring into the analysis utilities and costs) to determinate an action to be automatically performed.  A support vector machine (SVM) can be an example of a classifier that can be employed.  The SVM operates by finding a hyper-surface in the space of\npossible inputs, where the hyper-surface attempts to split the triggering criteria from the non-triggering events.  Intuitively, this makes the classification correct for testing data that is near, but not identical to training data.  Other directed and\nundirected model classification approaches include, e.g., naive Bayes, Bayesian networks, decision trees, neural networks, fuzzy logic models, and/or probabilistic classification models providing different patterns of independence can be employed. \nClassification as used herein also is inclusive of statistical regression that is utilized to develop models of priority.\nFIG. 3 illustrates a flow diagram of an example, non-limiting computer-implemented method 300 that facilitates a client device to obtain authorization from a remote service provider for a computation service on the client device set of input\ndata, while keeping the set of input data private from the remote service provider in accordance with one or more embodiments described herein.  Repetitive description of like elements employed in other embodiments described herein is omitted for sake of\nbrevity.\nAt 302, method 300 can include transmitting, by a device operatively coupled to a processor, a homomorphic encryption public key and a homomorphically encrypted input data to a service provider (e.g., via a security component 116, and/or a\nclient device 114).  At 304, method 300 can include receiving, by the device from the service provider, a homomorphically encrypted signature generated based on the homomorphic encryption public key, the homomorphically encrypted input data, and a\nhomomorphic encryption equivalent defined function (e.g., via a security component 116, service provider application component 118, and/or a client device 114).  At 306, method 300 can include, in response to a determination, by the device based on a\ndefined function corresponding to the homomorphic encryption equivalent defined function, that the homomorphically encrypted signature and input data corresponding to the homomorphically encrypted input data is valid for a computation service, performing\nthe computation service on the input data (e.g., via a security component 116, service provider application component 118, and/or a client device 114).\nFIG. 4 illustrates a flow diagram of an example, non-limiting computer-implemented method 400 that facilitates a service provider to remotely authorize a computation service on a client device for a set of input data, while keeping the set of\ninput data private from the service provider in accordance with one or more embodiments described herein.  Repetitive description of like elements employed in other embodiments described herein is omitted for sake of brevity.\nAt 402, method 400 can include receiving, by a device operatively coupled to a processor, a homomorphic encryption public key and a homomorphically encrypted input data from a client device (e.g., via a service provider authorization component\n104 and/or a server device 102).  At 404, method 400 can include generating, by the device, a homomorphically encrypted signature based on the homomorphic encryption public key, the homomorphically encrypted input data, and a homomorphic encryption\nequivalent defined function (e.g., via a service provider authorization component 104 and/or a server device 102).  At 406, method 400 can include transmitting, by the device, the homomorphically encrypted signature to the client device (e.g., via a\nservice provider authorization component 104 and/or a server device 102).\nFIG. 5 illustrates a flow diagram of an example, non-limiting computer-implemented method 500 that facilitates a client device generating and transmitting to a service provider a homomorphic encryption public key and homomorphically encrypted\ninput data in accordance with one or more embodiments described herein.  Repetitive description of like elements employed in other embodiments described herein is omitted for sake of brevity.\nAt 502, method 500 can include generating, by a device operatively coupled to a processor, a homomorphic encryption public key and a homomorphic encryption private key using a non-symmetric homomorphic encryption algorithm (e.g., via a security\ncomponent 116, and/or a client device 114).  At 504, method 500 can include transmitting, by the device, the homomorphic encryption public key to a service provider remote from the device and that authorizes usage of a computation service on the device\n(e.g., via a security component 116, and/or a client device 114).  At 506, method 500 can include obtaining, by the device, input data on which the computation service is to be performed (e.g., via a security component 116, and/or a client device 114). \nAt 508, method 500 can include scaling, by the device, values in the input data that are not whole integers into whole integers to generate prepared input data (e.g., via a security component 116, and/or a client device 114).  At 510, method 500 can\ninclude encrypting, by the device using the homomorphic encryption public key, the input data to generate homomorphically encrypted input data (e.g., via a security component 116, and/or a client device 114).  At 512, method 500 can include transmitting,\nby the device, the homomorphically encrypted input data to the service provider (e.g., via a security component 116, and/or a client device 114).\nFIG. 6 illustrates a flow diagram of an example, non-limiting computer-implemented method 600 that a client device determining whether a computation service on the client device is authorized by a remote service provider for a set of input data\nin accordance with one or more embodiments described herein.  Repetitive description of like elements employed in other embodiments described herein is omitted for sake of brevity.\nAt 602, method 600 can include receiving, by a device operatively coupled to a processor, from a service provider remote from the device and that authorizes usage of a service provider application component to peform a computation service on the\ndevice, a homomorphically encrypted signature based on a homomorphic encryption public key, homomorphically encrypted input data, and a homomorphic encryption equivalent defined function (e.g., via a security component 116, service provider application\ncomponent 118, and/or a client device 114).  At 604, method 600 can include decrpyting, by the device, homomorphically encrypted signature using a homomorphic encryption private key corresponding to the homomorphic encryption public key to generate a\ndecrypted signature (e.g., via a security component 116 and/or a client device 114).  At 606, method 600 can include providing, by the device to a service provider application component enabled to perform the computation service, the decrypted signature\nand input data corresponding to the homomorphically encrypted input data (e.g., via a security component 116 and/or a client device 114).  At 608, method 600 can include generating, by the device via the service provider application component, a\nsignature based on the input data and a defined function corresponding to the homomorphic encryption equivalent defined function (e.g., via a service provider application component 118 and/or a client device 114).  At 610, method 600 can include, in\nresponse to a determination, by the device via the service provider application component, that the signature matches the homomorphically encrypted signature, performing, by the service provider application component, the computation service on the input\ndata (e.g., via a service provider application component 118 and/or a client device 114).\nFIG. 7 illustrates a flow diagram of an example, non-limiting computer-implemented method 700 that facilitates a service provider generating a homomorphically encrypted signature from homomorphically encrypted input data in accordance with one\nor more embodiments described herein.  Repetitive description of like elements employed in other embodiments described herein is omitted for sake of brevity.\nAt 702, method 700 can include encrypting, by a device operatively coupled to a processor, numerical parameters of a homomorphic encryption equivalent defined function using a homomorphic encryption public key (e.g., via a service provider\nauthorization component 104 and/or a server device 102).  At 704, method 700 can include generating, by the device, a homomorphically encrypted signature from homomorphically encrypted input data using the homomorphic encryption equivalent defined\nfunction (e.g., via a service provider authorization component 104 and/or a server device 102).\nFor simplicity of explanation, the computer-implemented methodologies are depicted and described as a series of acts.  It is to be understood and appreciated that the subject innovation is not limited by the acts illustrated and/or by the order\nof acts, for example acts can occur in various orders and/or concurrently, and with other acts not presented and described herein.  Furthermore, not all illustrated acts can be required to implement the computer-implemented methodologies in accordance\nwith the disclosed subject matter.  In addition, those skilled in the art will understand and appreciate that the computer-implemented methodologies could alternatively be represented as a series of interrelated states via a state diagram or events. \nAdditionally, it should be further appreciated that the computer-implemented methodologies disclosed hereinafter and throughout this specification are capable of being stored on an article of manufacture to facilitate transporting and transferring such\ncomputer-implemented methodologies to computers.  The term article of manufacture, as used herein, is intended to encompass a computer program accessible from any computer-readable device or storage media.\nIn order to provide a context for the various aspects of the disclosed subject matter, FIG. 8 as well as the following discussion are intended to provide a general description of a suitable environment in which the various aspects of the\ndisclosed subject matter can be implemented.  FIG. 8 illustrates a block diagram of an example, non-limiting operating environment in which one or more embodiments described herein can be facilitated.  Repetitive description of like elements employed in\nother embodiments described herein is omitted for sake of brevity.\nWith reference to FIG. 8, a suitable operating environment 800 for implementing various aspects of this disclosure can also include a computer 812.  The computer 812 can also include a processing unit 814, a system memory 816, and a system bus\n818.  The system bus 818 couples system components including, but not limited to, the system memory 816 to the processing unit 814.  The processing unit 814 can be any of various available processors.  Dual microprocessors and other multiprocessor\narchitectures also can be employed as the processing unit 814.  The system bus 818 can be any of several types of bus structure(s) including the memory bus or memory controller, a peripheral bus or external bus, and/or a local bus using any variety of\navailable bus architectures including, but not limited to, Industrial Standard Architecture (ISA), Micro-Channel Architecture (MSA), Extended ISA (EISA), Intelligent Drive Electronics (IDE), VESA Local Bus (VLB), Peripheral Component Interconnect (PCI),\nCard Bus, Universal Serial Bus (USB), Advanced Graphics Port (AGP), Firewire (IEEE 894), and Small Computer Systems Interface (SCSI).  The system memory 816 can also include volatile memory 820 and nonvolatile memory 822.  The basic input/output system\n(BIOS), containing the basic routines to transfer information between elements within the computer 812, such as during start-up, is stored in nonvolatile memory 822.  By way of illustration, and not limitation, nonvolatile memory 822 can include read\nonly memory (ROM), programmable ROM (PROM), electrically programmable ROM (EPROM), electrically erasable programmable ROM (EEPROM), flash memory, or nonvolatile random access memory (RAM) (e.g., ferroelectric RAM (FeRAM).  Volatile memory 820 can also\ninclude random access memory (RAM), which acts as external cache memory.  By way of illustration and not limitation, RAM is available in many forms such as static RAM (SRAM), dynamic RAM (DRAM), synchronous DRAM (SDRAM), double data rate SDRAM (DDR\nSDRAM), enhanced SDRAM (ESDRAM), Synchlink DRAM (SLDRAM), direct Rambus RAM (DRRAM), direct Rambus dynamic RAM (DRDRAM), and Rambus dynamic RAM.\nComputer 812 can also include removable/non-removable, volatile/nonvolatile computer storage media.  FIG. 8 illustrates, for example, a disk storage 824.  Disk storage 824 can also include, but is not limited to, devices like a magnetic disk\ndrive, floppy disk drive, tape drive, Jaz drive, Zip drive, LS-100 drive, flash memory card, or memory stick.  The disk storage 824 also can include storage media separately or in combination with other storage media including, but not limited to, an\noptical disk drive such as a compact disk ROM device (CD-ROM), CD recordable drive (CD-R Drive), CD rewritable drive (CD-RW Drive) or a digital versatile disk ROM drive (DVD-ROM).  To facilitate connection of the disk storage 824 to the system bus 818, a\nremovable or non-removable interface is typically used, such as interface 826.  FIG. 8 also depicts software that acts as an intermediary between users and the basic computer resources described in the suitable operating environment 801.  Such software\ncan also include, for example, an operating system 828.  Operating system 828, which can be stored on disk storage 824, acts to control and allocate resources of the computer 812.  System applications 830 take advantage of the management of resources by\noperating system 828 through program modules 832 and program data 834, e.g., stored either in system memory 816 or on disk storage 824.  It is to be appreciated that this disclosure can be implemented with various operating systems or combinations of\noperating systems.  A user enters commands or information into the computer 812 through input device(s) 836.  Input devices 836 include, but are not limited to, a pointing device such as a mouse, trackball, stylus, touch pad, keyboard, microphone,\njoystick, game pad, satellite dish, scanner, TV tuner card, digital camera, digital video camera, web camera, and the like.  These and other input devices connect to the processing unit 814 through the system bus 818 via interface port(s) 838.  Interface\nport(s) 838 include, for example, a serial port, a parallel port, a game port, and a universal serial bus (USB).  Output device(s) 840 use some of the same type of ports as input device(s) 836.  Thus, for example, a USB port can be used to provide input\nto computer 812, and to output information from computer 812 to an output device 840.  Output adapter 842 is provided to illustrate that there are some output devices 840 like monitors, speakers, and printers, among other output devices 840, which\nrequire special adapters.  The output adapters 842 include, by way of illustration and not limitation, video and sound cards that provide a means of connection between the output device 840 and the system bus 818.  It should be noted that other devices\nand/or systems of devices provide both input and output capabilities such as remote computer(s) 844.\nComputer 812 can operate in a networked environment using logical connections to one or more remote computers, such as remote computer(s) 844.  The remote computer(s) 844 can be a computer, a server, a router, a network PC, a workstation, a\nmicroprocessor based appliance, a peer device or other common network node and the like, and typically can also include many or all of the elements described relative to computer 812.  For purposes of brevity, only a memory storage device 846 is\nillustrated with remote computer(s) 844.  Remote computer(s) 844 is logically connected to computer 812 through a network interface 848 and then physically connected via communication connection 850.  Network interface 848 encompasses wire and/or\nwireless communication networks such as local-area networks (LAN), wide-area networks (WAN), cellular networks, etc. LAN technologies include Fiber Distributed Data Interface (FDDI), Copper Distributed Data Interface (CDDI), Ethernet, Token Ring and the\nlike.  WAN technologies include, but are not limited to, point-to-point links, circuit switching networks like Integrated Services Digital Networks (ISDN) and variations thereon, packet switching networks, and Digital Subscriber Lines (DSL). \nCommunication connection(s) 850 refers to the hardware/software employed to connect the network interface 848 to the system bus 818.  While communication connection 850 is shown for illustrative clarity inside computer 812, it can also be external to\ncomputer 812.  The hardware/software for connection to the network interface 848 can also include, for exemplary purposes only, internal and external technologies such as, modems including regular telephone grade modems, cable modems and DSL modems, ISDN\nadapters, and Ethernet cards.\nIn an embodiment, for example, computer 812 can perform operations comprising: transmitting a homomorphic encryption public key and homomorphically encrypted input data to a service provider; receiving, from the service provider, a\nhomomorphically encrypted signature generated based on the homomorphic encryption public key, the homomorphically encrypted input data, and a homomorphic encryption equivalent defined function; and in response to a determination, based on a defined\nfunction corresponding to the homomorphic encryption equivalent defined function, that the homomorphically encrypted signature and input data are valid for a computation service, performing the computation service on the input data.\nIt is to be understood that although this disclosure includes a detailed description on cloud computing, implementation of the teachings recited herein are not limited to a cloud computing environment.  Rather, embodiments of the present\ninvention are capable of being implemented in conjunction with any other type of computing environment now known or later developed.\nCloud computing is a model of service delivery for enabling convenient, on-demand network access to a shared pool of configurable computing resources (e.g., networks, network bandwidth, servers, processing, memory, storage, applications, virtual\nmachines, and services) that can be rapidly provisioned and released with minimal management effort or interaction with a provider of the service.  This cloud model may include at least five characteristics, at least three service models, and at least\nfour deployment models.\nCharacteristics are as follows:\nOn-demand self-service: a cloud consumer can unilaterally provision computing capabilities, such as server time and network storage, as needed automatically without requiring human interaction with the service's provider.\nBroad network access: capabilities are available over a network and accessed through standard mechanisms that promote use by heterogeneous thin or thick client platforms (e.g., mobile phones, laptops, and PDAs).\nResource pooling: the provider's computing resources are pooled to serve multiple consumers using a multi-tenant model, with different physical and virtual resources dynamically assigned and reassigned according to demand.  There is a sense of\nlocation independence in that the consumer generally has no control or knowledge over the exact location of the provided resources but may be able to specify location at a higher level of abstraction (e.g., country, state, or datacenter).\nRapid elasticity: capabilities can be rapidly and elastically provisioned, in some cases automatically, to quickly scale out and rapidly released to quickly scale in. To the consumer, the capabilities available for provisioning often appear to\nbe unlimited and can be purchased in any quantity at any time.\nMeasured service: cloud systems automatically control and optimize resource use by leveraging a metering capability at some level of abstraction appropriate to the type of service (e.g., storage, processing, bandwidth, and active user accounts). Resource usage can be monitored, controlled, and reported, providing transparency for both the provider and consumer of the utilized service.\nService Models are as follows:\nSoftware as a Service (SaaS): the capability provided to the consumer is to use the provider's applications running on a cloud infrastructure.  The applications are accessible from various client devices through a thin client interface such as a\nweb browser (e.g., web-based e-mail).  The consumer does not manage or control the underlying cloud infrastructure including network, servers, operating systems, storage, or even individual application capabilities, with the possible exception of limited\nuser-specific application configuration settings.\nPlatform as a Service (PaaS): the capability provided to the consumer is to deploy onto the cloud infrastructure consumer-created or acquired applications created using programming languages and tools supported by the provider.  The consumer\ndoes not manage or control the underlying cloud infrastructure including networks, servers, operating systems, or storage, but has control over the deployed applications and possibly application hosting environment configurations.\nInfrastructure as a Service (IaaS): the capability provided to the consumer is to provision processing, storage, networks, and other fundamental computing resources where the consumer is able to deploy and run arbitrary software, which can\ninclude operating systems and applications.  The consumer does not manage or control the underlying cloud infrastructure but has control over operating systems, storage, deployed applications, and possibly limited control of select networking components\n(e.g., host firewalls).\nDeployment Models are as follows:\nPrivate cloud: the cloud infrastructure is operated solely for an organization.  It may be managed by the organization or a third party and may exist on-premises or off-premises.\nCommunity cloud: the cloud infrastructure is shared by several organizations and supports a specific community that has shared concerns (e.g., mission, security requirements, policy, and compliance considerations).  It may be managed by the\norganizations or a third party and may exist on-premises or off-premises.\nPublic cloud: the cloud infrastructure is made available to the general public or a large industry group and is owned by an organization selling cloud services.\nHybrid cloud: the cloud infrastructure is a composition of two or more clouds (private, community, or public) that remain unique entities but are bound together by standardized or proprietary technology that enables data and application\nportability (e.g., cloud bursting for load-balancing between clouds).\nA cloud computing environment is service oriented with a focus on statelessness, low coupling, modularity, and semantic interoperability.  At the heart of cloud computing is an infrastructure that includes a network of interconnected nodes.\nReferring now to FIG. 9, an illustrative cloud computing environment 904 is depicted.  As shown, cloud computing environment 904 includes one or more cloud computing nodes 902 with which local computing devices used by cloud consumers, such as,\nfor example, personal digital assistant (PDA) or cellular telephone 906A, desktop computer 906B, laptop computer 906C, and/or automobile computer system 906N may communicate.  Nodes 902 may communicate with one another.  They may be grouped (not shown)\nphysically or virtually, in one or more networks, such as Private, Community, Public, or Hybrid clouds as described hereinabove, or a combination thereof.  This allows cloud computing environment 904 to offer infrastructure, platforms and/or software as\nservices for which a cloud consumer does not need to maintain resources on a local computing device.  It is understood that the types of computing devices 906A-N shown in FIG. 9 are intended to be illustrative only and that computing nodes 902 and cloud\ncomputing environment 904 can communicate with any type of computerized device over any type of network and/or network addressable connection (e.g., using a web browser).\nReferring now to FIG. 2, a set of functional abstraction layers provided by cloud computing environment 904 (FIG. 9) is shown.  It should be understood in advance that the components, layers, and functions shown in FIG. 2 are intended to be\nillustrative only and embodiments of the invention are not limited thereto.  As depicted, the following layers and corresponding functions are provided:\nHardware and software layer 1002 includes hardware and software components.  Examples of hardware components include: mainframes 1002a; RISC (Reduced Instruction Set Computer) architecture based servers 1002b; servers 1002c; blade servers 1002d;\nstorage devices 1002e; and networks and networking components 1002f.  In some embodiments, software components include network application server software 1002g and database software 1002h.\nVirtualization layer 1004 provides an abstraction layer from which the following examples of virtual entities may be provided: virtual servers 1004a; virtual storage 1004b; virtual networks 1004c, including virtual private networks; virtual\napplications and operating systems 1004d; and virtual clients 1004e.\nIn one example, management layer 1006 may provide the functions described below.  Resource provisioning 1006a provides dynamic procurement of computing resources and other resources that are utilized to perform tasks within the cloud computing\nenvironment.  Metering and Pricing 1006b provide cost tracking as resources are utilized within the cloud computing environment, and billing or invoicing for consumption of these resources.  In one example, these resources may include application\nsoftware licenses.  Security provides identity verification for cloud consumers and tasks, as well as protection for data and other resources.  User portal 1006c provides access to the cloud computing environment for consumers and system administrators. \nService level management 1006d provides cloud computing resource allocation and management such that required service levels are met.  Service Level Agreement (SLA) planning and fulfillment 1006e provide pre-arrangement for, and procurement of, cloud\ncomputing resources for which a future requirement is anticipated in accordance with an SLA.\nWorkloads layer 1008 provides examples of functionality for which the cloud computing environment may be utilized.  Non-limiting examples of workloads and functions which may be provided from this layer include: mapping and navigation 1008a;\nsoftware development and lifecycle management 1008b; virtual classroom education delivery 1008c; data analytics processing 1008d; transaction processing 1008e; and mobile desktop 1008f.\nEmbodiments of the present invention may be a system, a method, an apparatus and/or a computer program product at any possible technical detail level of integration.  The computer program product can include a computer readable storage medium\n(or media) having computer readable program instructions thereon for causing a processor to carry out aspects of the present invention.  The computer readable storage medium can be a tangible device that can retain and store instructions for use by an\ninstruction execution device.  The computer readable storage medium can be, for example, but is not limited to, an electronic storage device, a magnetic storage device, an optical storage device, an electromagnetic storage device, a semiconductor storage\ndevice, or any suitable combination of the foregoing.  A non-exhaustive list of more specific examples of the computer readable storage medium can also include the following: a portable computer diskette, a hard disk, a random access memory (RAM), a\nread-only memory (ROM), an erasable programmable read-only memory (EPROM or Flash memory), a static random access memory (SRAM), a portable compact disc read-only memory (CD-ROM), a digital versatile disk (DVD), a memory stick, a floppy disk, a\nmechanically encoded device such as punch-cards or raised structures in a groove having instructions recorded thereon, and any suitable combination of the foregoing.  A computer readable storage medium, as used herein, is not to be construed as being\ntransitory signals per se, such as radio waves or other freely propagating electromagnetic waves, electromagnetic waves propagating through a waveguide or other transmission media (e.g., light pulses passing through a fiber-optic cable), or electrical\nsignals transmitted through a wire.\nComputer readable program instructions described herein can be downloaded to respective computing/processing devices from a computer readable storage medium or to an external computer or external storage device via a network, for example, the\nInternet, a local area network, a wide area network and/or a wireless network.  The network can include copper transmission cables, optical transmission fibers, wireless transmission, routers, firewalls, switches, gateway computers and/or edge servers. \nA network adapter card or network interface in each computing/processing device receives computer readable program instructions from the network and forwards the computer readable program instructions for storage in a computer readable storage medium\nwithin the respective computing/processing device.  Computer readable program instructions for carrying out operations of various aspects of the present invention can be assembler instructions, instruction-set-architecture (ISA) instructions, machine\ninstructions, machine dependent instructions, microcode, firmware instructions, state-setting data, configuration data for integrated circuitry, or either source code or object code written in any combination of one or more programming languages,\nincluding an object oriented programming language such as Smalltalk, C++, or the like, and procedural programming languages, such as the \"C\" programming language or similar programming languages.  The computer readable program instructions can execute\nentirely on the user's computer, partly on the user's computer, as a stand-alone software package, partly on the user's computer and partly on a remote computer or entirely on the remote computer or server.  In the latter scenario, the remote computer\ncan be connected to the user's computer through any type of network, including a local area network (LAN) or a wide area network (WAN), or the connection can be made to an external computer (for example, through the Internet using an Internet Service\nProvider).  In some embodiments, electronic circuitry including, for example, programmable logic circuitry, field-programmable gate arrays (FPGA), or programmable logic arrays (PLA) can execute the computer readable program instructions by utilizing\nstate information of the computer readable program instructions to customize the electronic circuitry, in order to perform aspects of the present invention.\nAspects of the present invention are described herein with reference to flowchart illustrations and/or block diagrams of methods, apparatus (systems), and computer program products according to embodiments of the invention.  It will be\nunderstood that each block of the flowchart illustrations and/or block diagrams, and combinations of blocks in the flowchart illustrations and/or block diagrams, can be implemented by computer readable program instructions.  These computer readable\nprogram instructions can be provided to a processor of a general purpose computer, special purpose computer, or other programmable data processing apparatus to produce a machine, such that the instructions, which execute via the processor of the computer\nor other programmable data processing apparatus, create means for implementing the functions/acts specified in the flowchart and/or block diagram block or blocks.  These computer readable program instructions can also be stored in a computer readable\nstorage medium that can direct a computer, a programmable data processing apparatus, and/or other devices to function in a particular manner, such that the computer readable storage medium having instructions stored therein comprises an article of\nmanufacture including instructions which implement aspects of the function/act specified in the flowchart and/or block diagram block or blocks.  The computer readable program instructions can also be loaded onto a computer, other programmable data\nprocessing apparatus, or other device to cause a series of operational acts to be performed on the computer, other programmable apparatus or other device to produce a computer implemented process, such that the instructions which execute on the computer,\nother programmable apparatus, or other device implement the functions/acts specified in the flowchart and/or block diagram block or blocks.\nThe flowchart and block diagrams in the Figures illustrate the architecture, functionality, and operation of possible implementations of systems, methods, and computer program products according to various embodiments of the present invention. \nIn this regard, each block in the flowchart or block diagrams can represent a module, segment, or portion of instructions, which includes one or more executable instructions for implementing the specified logical function(s).  In some alternative\nimplementations, the functions noted in the blocks can occur out of the order noted in the Figures.  For example, two blocks shown in succession can, in fact, be executed substantially concurrently, or the blocks can sometimes be executed in the reverse\norder, depending upon the functionality involved.  It will also be noted that each block of the block diagrams and/or flowchart illustration, and combinations of blocks in the block diagrams and/or flowchart illustration, can be implemented by special\npurpose hardware-based systems that perform the specified functions or acts or carry out combinations of special purpose hardware and computer instructions.\nWhile the subject matter has been described above in the general context of computer-executable instructions of a computer program product that runs on a computer and/or computers, those skilled in the art will recognize that this disclosure\nalso can or can be implemented in combination with other program modules.  Generally, program modules include routines, programs, components, data structures, etc. that perform particular tasks and/or implement particular abstract data types.  Moreover,\nthose skilled in the art will appreciate that the inventive computer-implemented methods can be practiced with other computer system configurations, including single-processor or multiprocessor computer systems, mini-computing devices, mainframe\ncomputers, as well as computers, hand-held computing devices (e.g., PDA, phone), microprocessor-based or programmable consumer or industrial electronics, and the like.  The illustrated aspects can also be practiced in distributed computing environments\nwhere tasks are performed by remote processing devices that are linked through a communications network.  However, some, if not all aspects of this disclosure can be practiced on stand-alone computers.  In a distributed computing environment, program\nmodules can be located in both local and remote memory storage devices.\nAs used in this application, the terms \"component,\" \"system,\" \"platform,\" \"interface,\" and the like, can refer to and/or can include a computer-related entity or an entity related to an operational machine with one or more specific\nfunctionalities.  The entities disclosed herein can be either hardware, a combination of hardware and software, software, or software in execution.  For example, a component can be, but is not limited to being, a process running on a processor, a\nprocessor, an object, an executable, a thread of execution, a program, and/or a computer.  By way of illustration, both an application running on a server and the server can be a component.  One or more components can reside within a process and/or\nthread of execution and a component can be localized on one computer and/or distributed between two or more computers.  In another example, respective components can execute from various computer readable media having various data structures stored\nthereon.  The components can communicate via local and/or remote processes such as in accordance with a signal having one or more data packets (e.g., data from one component interacting with another component in a local system, distributed system, and/or\nacross a network such as the Internet with other systems via the signal).  As another example, a component can be an apparatus with specific functionality provided by mechanical parts operated by electric or electronic circuitry, which is operated by a\nsoftware or firmware application executed by a processor.  In such a case, the processor can be internal or external to the apparatus and can execute at least a part of the software or firmware application.  As yet another example, a component can be an\napparatus that provides specific functionality through electronic components without mechanical parts, wherein the electronic components can include a processor or other means to execute software or firmware that confers at least in part the\nfunctionality of the electronic components.  In an aspect, a component can emulate an electronic component via a virtual machine, e.g., within a server computing system.\nIn addition, the term \"or\" is intended to mean an inclusive \"or\" rather than an exclusive \"or.\" That is, unless specified otherwise, or clear from context, \"X employs A or B\" is intended to mean any of the natural inclusive permutations.  That\nis, if X employs A; X employs B; or X employs both A and B, then \"X employs A or B\" is satisfied under any of the foregoing instances.  Moreover, articles \"a\" and \"an\" as used in the subject specification and annexed drawings should generally be\nconstrued to mean \"one or more\" unless specified otherwise or clear from context to be directed to a singular form.  As used herein, the terms \"example\" and/or \"exemplary\" are utilized to mean serving as an example, instance, or illustration.  For the\navoidance of doubt, the subject matter disclosed herein is not limited by such examples.  In addition, any aspect or design described herein as an \"example\" and/or \"exemplary\" is not necessarily to be construed as preferred or advantageous over other\naspects or designs, nor is it meant to preclude equivalent exemplary structures and techniques known to those of ordinary skill in the art.\nAs it is employed in the subject specification, the term \"processor\" can refer to substantially any computing processing unit or device comprising, but not limited to, single-core processors; single-processors with software multithread execution\ncapability; multi-core processors; multi-core processors with software multithread execution capability; multi-core processors with hardware multithread technology; parallel platforms; and parallel platforms with distributed shared memory.  Additionally,\na processor can refer to an integrated circuit, an application specific integrated circuit (ASIC), a digital signal processor (DSP), a field programmable gate array (FPGA), a programmable logic controller (PLC), a complex programmable logic device\n(CPLD), a discrete gate or transistor logic, discrete hardware components, or any combination thereof designed to perform the functions described herein.  Further, processors can exploit nano-scale architectures such as, but not limited to, molecular and\nquantum-dot based transistors, switches and gates, in order to optimize space usage or enhance performance of user equipment.  A processor can also be implemented as a combination of computing processing units.  In this disclosure, terms such as \"store,\"\n\"storage,\" \"data store,\" data storage,\" \"database,\" and substantially any other information storage component relevant to operation and functionality of a component are utilized to refer to \"memory components,\" entities embodied in a \"memory,\" or\ncomponents comprising a memory.  It is to be appreciated that memory and/or memory components described herein can be either volatile memory or nonvolatile memory, or can include both volatile and nonvolatile memory.  By way of illustration, and not\nlimitation, nonvolatile memory can include read only memory (ROM), programmable ROM (PROM), electrically programmable ROM (EPROM), electrically erasable ROM (EEPROM), flash memory, or nonvolatile random access memory (RAM) (e.g., ferroelectric RAM\n(FeRAM).  Volatile memory can include RAM, which can act as external cache memory, for example.  By way of illustration and not limitation, RAM is available in many forms such as synchronous RAM (SRAM), dynamic RAM (DRAM), synchronous DRAM (SDRAM),\ndouble data rate SDRAM (DDR SDRAM), enhanced SDRAM (ESDRAM), Synchlink DRAM (SLDRAM), direct Rambus RAM (DRRAM), direct Rambus dynamic RAM (DRDRAM), and Rambus dynamic RAM (RDRAM).  Additionally, the disclosed memory components of systems or\ncomputer-implemented methods herein are intended to include, without being limited to including, these and any other suitable types of memory.\nWhat has been described above include mere examples of systems, computer program products, and computer-implemented methods.  It is, of course, not possible to describe every conceivable combination of components, products and/or\ncomputer-implemented methods for purposes of describing this disclosure, but one of ordinary skill in the art can recognize that many further combinations and permutations of this disclosure are possible.  Furthermore, to the extent that the terms\n\"includes,\" \"has,\" \"possesses,\" and the like are used in the detailed description, claims, appendices and drawings such terms are intended to be inclusive in a manner similar to the term \"comprising\" as \"comprising\" is interpreted when employed as a\ntransitional word in a claim.  The descriptions of the various embodiments have been presented for purposes of illustration, but are not intended to be exhaustive or limited to the embodiments disclosed.  Many modifications and variations will be\napparent to those of ordinary skill in the art without departing from the scope and spirit of the described embodiments.  The terminology used herein was chosen to best explain the principles of the embodiments, the practical application or technical\nimprovement over technologies found in the marketplace, or to enable others of ordinary skill in the art to understand the embodiments disclosed herein.", "application_number": "15350324", "abstract": " Techniques are provided for providing a local computation service on\n     client device authorized by a remote service provider while keeping local\n     data private from the remote service provider. In one example, a\n     computer-implemented method comprises transmitting, by a device\n     operatively coupled to a processor, a homomorphic encryption public key\n     and homomorphically encrypted input data to a service provider. The\n     computer-implemented method also comprises receiving, by the device from\n     the service provider, a homomorphically encrypted signature generated\n     based on the homomorphic encryption public key, the homomorphically\n     encrypted input data, and a homomorphic encryption equivalent defined\n     function. The computer-implemented method also comprises in response to a\n     determination, based on a defined function corresponding to the\n     homomorphic encryption equivalent defined function, that the\n     homomorphically encrypted signature and input data corresponding to the\n     homomorphically encrypted input data are valid for a computation service,\n     performing, by the device, the computation service on the input data.\n", "citations": ["8862895", "9031229", "9288039", "9288193", "9436835", "9787647", "20050078825", "20060281442", "20070016528", "20100229217", "20110153393", "20110161658", "20130097417", "20130269020", "20130326224", "20140187266", "20140298420", "20140331272", "20140334622", "20150348335", "20160072623", "20160142418", "20160205114", "20160269174", "20160321456", "20160344557", "20170019248", "20180359097"], "related": []}, {"id": "20180157580", "patent_code": "10303579", "patent_name": "Debug session analysis for related work item discovery", "year": "2019", "inventor_and_country_data": " Inventors: \nCraggs; Daniel P. (Montreal, CA), Swan; Jeremiah S. (Stouffville, CA)  ", "description": "<BR><BR>BACKGROUND\nThe present invention relates generally to the field of computers, and more particularly to automatic debug session analysis of systems.\nOften problems and defects have been discovered by previous developers in code repositories.  Either the problem wasn't fixed properly, or they decided not to fix it.  It might even be user error.  Work management software integrated into source\ncode repositories such as rational team concert (RTC) give a wealth of information on these previous defects or code changes but it's not always possible to immediately find which work item is relevant to the problem a developer is currently debugging. \nA developer can waste a lot of time diagnosing a problem that has already been diagnosed and in some cases solved.  At other times, a developer may spend a long time debugging a problem in a certain part of the code, but the problematic code change may\nexist elsewhere and may indirectly cause the problem.\n<BR><BR>SUMMARY\nAccording to one embodiment, a method for automatic debug session analysis for related work item discovery is provided.  The method includes recording metadata describing a particular debug session associated with a user for a respective work\nitem.  The method further includes associating the metadata recorded in the particular debug session with the respective work item.  The method further includes in response to the user working on a new issue, comparing the metadata saved with other work\nitems.  The method further includes in response to identifying a work item with a predetermined level of similar metadata from debug sessions, notifying the user of a potential work item match.  The method further includes in response to not identifying\na work item with a predetermined level of similar metadata from debug sessions, refraining from suggesting the new issue for future matches.\nAccording to another embodiment, a computer system for automatic debug session analysis for related work item discovery, is provided.  The computer system includes one or more processors, one or more computer-readable memories, one or more\ncomputer-readable tangible storage devices and program instructions which are stored on at least one of the one or more storage devices for execution by at least one of the one or more processors via at least one of the one or more memories.  The\ncomputer system further includes program instructions to record metadata describing a particular debug session associated with a user for a respective work item.  The computer system further includes program instructions to associate the metadata\nrecorded in the particular debug session with the respective work item.  The computer system further includes program instructions to comparing the metadata saved with other work items in response to the user working on a new issue.  The computer system\nfurther includes program instructions to notify the user of a potential work item match in response to identifying a work item with a predetermined level of similar metadata from debug sessions.  The computer system further includes program instructions\nto refrain from suggesting the new issue for future matches in response to not identifying a work item with a predetermined level of similar metadata from debug sessions.\nAccording to another embodiment, a computer program product for automatic debug session analysis for related work item discovery is provided, the computer program product comprising one or more computer-readable tangible storage devices and\nprogram instructions stored on at least one of the one or more computer-readable tangible storage devices.  The program instructions comprise program instructions to record metadata describing a particular debug session associated with a user for a\nrespective work item.  The program instructions further comprise program instructions to associate the metadata recorded in the particular debug session with the respective work item.  The program instructions further comprise program instructions to\ncomparing the metadata saved with other work items in response to the user working on a new issue.  The program instructions further comprise program instructions to notify the user of a potential work item match in response to identifying a work item\nwith a predetermined level of similar metadata from debug sessions.  The program instructions further comprise program instructions to refrain from suggesting the new issue for future matches in response to not identifying a work item with a\npredetermined level of similar metadata from debug sessions. <BR><BR>BRIEF DESCRIPTION OF THE SEVERAL VIEWS OF THE DRAWINGS\nThese and other objects, features and advantages of the present invention will become apparent from the following detailed description of illustrative embodiments thereof, which is to be read in connection with the accompanying drawings.  The\nvarious features of the drawings are not to scale as the illustrations are for clarity in facilitating one skilled in the art in understanding the invention in conjunction with the detailed description.  In the drawings:\nFIG. 1 illustrates a networked computer environment according to one embodiment;\nReferring now to FIG. 2, an exemplary flow diagram illustration in accordance with one embodiment is depicted;\nReferring now to FIG. 3, an alternative exemplary flow diagram illustration in accordance with one embodiment is depicted;\nFIG. 4 is a block diagram of internal and external components of computers and servers depicted in FIG. 1 according to at least one embodiment;\nFIG. 5 is a block diagram of an illustrative cloud computing environment including the computer system depicted in FIG. 1, in accordance with an embodiment of the present disclosure; and\nFIG. 6 is a block diagram of functional layers of the illustrative cloud computing environment of FIG. 5, in accordance with an embodiment of the present disclosure.\n<BR><BR>DETAILED DESCRIPTION\nDetailed embodiments of the claimed structures and methods are disclosed herein; however, it can be understood that the disclosed embodiments are merely illustrative of the claimed structures and methods that may be embodied in various forms. \nThis invention may, however, be embodied in many different forms and should not be construed as limited to the exemplary embodiments set forth herein.  Rather, these exemplary embodiments are provided so that this disclosure will be thorough and complete\nand will fully convey the scope of this invention to those skilled in the art.  In the description, details of well-known features and techniques may be omitted to avoid unnecessarily obscuring the presented embodiments.\nThe present invention relates generally to the field of computers, and more particularly to automatic debug session analysis of systems.  The following described exemplary embodiments provide a system, method and program product to, among other\nthings, automatic debug session analysis of systems.  Therefore, the present embodiment has the capacity to improve the computer systems compliance field.\nDuring system monitoring and compliance, whilst developers develop and debug their code, recording relevant metadata and associating it with their current work item, a computer system may monitor actions by the developers to enhance efficient\nsystems integration.  As previously described, however, developers can waste a lot of time diagnosing a problem that has already been diagnosed and in some cases solved.  At other times, a developer may spend a long time debugging a problem in a certain\npart of the code, but the problematic code change may exist elsewhere and may indirectly cause the problem.  Further, one can use a text search on a code repository to match descriptions of work items.  However, the search requires the correct\nterminology to be matched by the one who created the work item and one who is searching for it, and it can be easy to not be able to find the correct work item.  One can also inspect code change histories to see which work items have affected the code\nyou are currently inspecting.  Looking at a code's change history can be limited help if the defective behavior is fixed elsewhere in a super class for example.  As such, it may be advantageous to store metadata on a developers debug session whilst the\ndebugger is working on work items.\nThe present invention provides a system platform for monitoring and storing metadata on developers debug sessions whilst working on work items.  This includes breakpoints set, stack traces collected, exceptions, variable reference searches, call\ntype hierarchy inquiries as well as variables and monitors set and their values.  By recording this information and associating it with the relevant work item, this invention builds a foundation for future debug sessions to compare themselves to.  For\ninstance, when a user is then working on a new issue, the metadata collected can be compared against other work items.  If there's a work item with sufficiently similar metadata from the developer debug sessions, the user can be prompted or they can ask\nexplicitly that there is a possible matching work item.  The user can then check the work item to see if it covers the same problem or if it somehow related.  By determining it's not a match, the invention can stop suggesting it for future matches if the\nuser wishes.\nEmbodiments of the present invention have advantages as it can suggest matching work items based on a developer's behavior rather than just their code change.  It means that work items that require debugging the code but not necessarily changing\nit can be suggested as related work item, which is something existing code repositories do not have the ability to do today.  For example, aspects of the invention monitor developers whilst they develop and debug their code, recording relevant metadata\nand associating it with their current work item.  As previously described, alternative embodiments could also extract metadata from historical work items comments with stack traces, delivered change sets, saved breakpoint files and log files to provide a\nlimited analysis on work items completed before the implementation of this invention.  In one implementation, the user can specify which work item they are currently working on before debugging, or this could be detected automatically.  This way debug\ndata can be correctly attributed to the correct work item.  In one aspect, one implementation of this invention works on a point based system to determine similarity of work items.  For each similarity, for instance, two work items contain in their\nmetadata, a certain number of points are attributed based on the significance of similarity.  Different categories are described in more detail below:\nThe present invention may be a system, a method, and/or a computer program product.  The computer program product may include a computer readable storage medium (or media) having computer readable program instructions thereon for causing a\nprocessor to carry out aspects of the present invention.\nThe computer readable storage medium can be a tangible device that can retain and store instructions for use by an instruction execution device.  The computer readable storage medium may be, for example, but is not limited to, an electronic\nstorage device, a magnetic storage device, an optical storage device, an electromagnetic storage device, a semiconductor storage device, or any suitable combination of the foregoing.  A non-exhaustive list of more specific examples of the computer\nreadable storage medium includes the following: a portable computer diskette, a hard disk, a random access memory (RAM), a read-only memory (ROM), an erasable programmable read-only memory (EPROM or Flash memory), a static random access memory (SRAM), a\nportable compact disc read-only memory (CD-ROM), a digital versatile disk (DVD), a memory stick, a floppy disk, a mechanically encoded device such as punch-cards or raised structures in a groove having instructions recorded thereon, and any suitable\ncombination of the foregoing.  A computer readable storage medium, as used herein, is not to be construed as being transitory signals per se, such as radio waves or other freely propagating electromagnetic waves, electromagnetic waves propagating through\na waveguide or other transmission media (e.g., light pulses passing through a fiber-optic cable), or electrical signals transmitted through a wire.\nComputer readable program instructions described herein can be downloaded to respective computing/processing devices from a computer readable storage medium or to an external computer or external storage device via a network, for example, the\nInternet, a local area network, a wide area network and/or a wireless network.  The network may comprise copper transmission cables, optical transmission fibers, wireless transmission, routers, firewalls, switches, gateway computers and/or edge servers. \nA network adapter card or network interface in each computing/processing device receives computer readable program instructions from the network and forwards the computer readable program instructions for storage in a computer readable storage medium\nwithin the respective computing/processing device.\nComputer readable program instructions for carrying out operations of the present invention may be assembler instructions, instruction-set-architecture (ISA) instructions, machine instructions, machine dependent instructions, microcode, firmware\ninstructions, state-setting data, or either source code or object code written in any combination of one or more programming languages, including an object oriented programming language such as Smalltalk, C++ or the like, and conventional procedural\nprogramming languages, such as the \"C\" programming language or similar programming languages.  The computer readable program instructions may execute entirely on the user's computer, partly on the user's computer, as a stand-alone software package,\npartly on the user's computer and partly on a remote computer or entirely on the remote computer or server.  In the latter scenario, the remote computer may be connected to the user's computer through any type of network, including a local area network\n(LAN) or a wide area network (WAN), or the connection may be made to an external computer (for example, through the Internet using an Internet Service Provider).  In some embodiments, electronic circuitry including, for example, programmable logic\ncircuitry, field-programmable gate arrays (FPGA), or programmable logic arrays (PLA) may execute the computer readable program instructions by utilizing state information of the computer readable program instructions to personalize the electronic\ncircuitry, in order to perform aspects of the present invention.\nAspects of the present invention are described herein with reference to flowchart illustrations and/or block diagrams of methods, apparatus (systems), and computer program products according to embodiments of the invention.  It will be\nunderstood that each block of the flowchart illustrations and/or block diagrams, and combinations of blocks in the flowchart illustrations and/or block diagrams, can be implemented by computer readable program instructions.\nThese computer readable program instructions may be provided to a processor of a general purpose computer, special purpose computer, or other programmable data processing apparatus to produce a machine, such that the instructions, which execute\nvia the processor of the computer or other programmable data processing apparatus, create means for implementing the functions/acts specified in the flowchart and/or block diagram block or blocks.  These computer readable program instructions may also be\nstored in a computer readable storage medium that can direct a computer, a programmable data processing apparatus, and/or other devices to function in a particular manner, such that the computer readable storage medium having instructions stored therein\ncomprises an article of manufacture including instructions which implement aspects of the function/act specified in the flowchart and/or block diagram block or blocks.\nThe computer readable program instructions may also be loaded onto a computer, other programmable data processing apparatus, or other device to cause a series of operational steps to be performed on the computer, other programmable apparatus or\nother device to produce a computer implemented process, such that the instructions which execute on the computer, other programmable apparatus, or other device implement the functions/acts specified in the flowchart and/or block diagram block or blocks.\nThe flowchart and block diagrams in the Figures illustrate the architecture, functionality, and operation of possible implementations of systems, methods, and computer program products according to various embodiments of the present invention. \nIn this regard, each block in the flowchart or block diagrams may represent a module, segment, or portion of instructions, which comprises one or more executable instructions for implementing the specified logical function(s).  In some alternative\nimplementations, the functions noted in the block may occur out of the order noted in the figures.  For example, two blocks shown in succession may, in fact, be executed substantially concurrently, or the blocks may sometimes be executed in the reverse\norder, depending upon the functionality involved.  It will also be noted that each block of the block diagrams and/or flowchart illustration, and combinations of blocks in the block diagrams and/or flowchart illustration, can be implemented by special\npurpose hardware-based systems that perform the specified functions or acts or carry out combinations of special purpose hardware and computer instructions.\nThe following described exemplary embodiments provide a system, method and program product to provide automatic debug session analysis of systems.\nReferring to FIG. 1, computer system environment 100, for monitoring developers whilst they develop and debug their code, recording relevant metadata, and associating it with their current work item, whereby the work items may include\nbreakpoints set, stack traces collected, exceptions, variable reference searches, call type hierarchy inquiries, as well as, variables and monitors set and their value.\nAccording embodiments to the present invention, by recording the work items and associate the work items with pre-recorded work items, the invention builds a foundation for debug sessions, whereby developers may properly address system\nmalfunction that was addressed in a previous or re-recorded debug session.  The computer system environment 100 may include a client computing device 102 with a processor 104, a data storage device 106, and memory 118, which is enabled to run, or execute\nprogram instructions of a software program 108, according to embodiments of the present invention.  The client computing device 102 may include a client systems application 114A, for configuring client preferences for specifying which work item they are\ncurrently working on before debugging the work item.  The computer system environment 100 may also include a work item server 112, running a work item server application 114B, and interconnected with client computing device 102, over communications\nnetwork 110, for recording relevant metadata, and associating it with their current work item.  The work item server 112 may also enable the delivery and operation of secure, personalized applications for monitoring work items of users to client\ncomputing device 102.  The computer system environment 100 may also include a plurality of client computing device 102 and work item server 112, only one of which is shown, at least in FIG. 1.\nThe memory 118 may comprise, for example, one or more computer-readable storage media, which may include random-access memory (RAM) such as various forms of dynamic RAM (DRAM), e.g., DDR2 SDRAM, or static RAM (SRAM), flash memory, or any other\nform of fixed or removable mobile computing storage medium that may be used to carry or store desired program code and program data in the form of instructions or data structures and that may be accessed by other components of client computing device\n102, for ensuring that monitoring of developers whilst they develop and debug their code, recording relevant metadata, and associating it with their current work items are accurately displayed on client computing device 102, according to embodiments of\nthe present invention.\nThe communications network 110 may include various types of communication networks, such as a wide area network (WAN), local area network (LAN), a telecommunication network, a wireless network, a public switched network and/or a satellite\nnetwork.  It should be appreciated that FIG. 1 provides only an illustration of one implementation and does not imply any limitations with regard to the environments in which different embodiments may be implemented.  Many modifications to the depicted\nenvironments may be made based on design and implementation requirements, according to embodiments.\nThe client computing device 102 may communicate with the work item server application 114B, running on work item server 112, via the communication network 110, for providing a virtualized framework for displaying representations or results of\ndebug work item to a client of client computing device 102.  The communications network 110 may also include connections, such as wire, wireless communication links, or fiber optic cables.  As will be discussed with reference to FIG. 6, work item server\n112 may include internal components 800a and external components 900a, respectively, and client computing device 102 may include internal components 800b and external components 900b, respectively.\nThe client computing device 102 may be any portable device that provides computing, information storage and, computing retrieval capabilities, including, for example, a handheld device, or handheld computer, pocket PC, connected organizer,\nelectronic book (eBook) reader, a personal digital assistant (PDA), a smart phone, or other portable devices, or any type of computing devices capable of accessing a network for providing a virtualized mobile framework for client computing device 102,\nrecording the work items and associate the work items with pre-recorded work items, the invention builds a foundation for debug sessions.  The client computing device 102 may also be laptop, tablet, or notebook personal computer (PC), a desktop computer,\na mainframe or mini computer, or a personal digital assistant (PDA).  The data storage device 106 of the client computing device 102 is any type of storage device, storage server, storage area network, redundant array of independent discs (RAID), cloud\nstorage service, or any type of data storage.  The data storage device 106 may also be a relational model database server for storing program instructions selection work item items with pre-recorded work items, in client computing device 102, according\nto embodiments.\nWork item server 112 may be, for example, a server computer system such as a management server, a web server, or any other electronic device or computing system capable of receiving and sending data, including, for displaying representations of\ncharts of swatches of legends, based on client preferences of the client computing device 102.\nFurther, the work item server 112 may also represent a \"cloud\" of computers interconnected by one or more networks, whereby work item server 112 may be a primary server for a computing system utilizing clustered computers when accessed through\ncommunications network 110.  The work item repository 120 is any type of storage device, storage server, storage area network, redundant array of independent discs (RAID), cloud storage service, or any type of data storage for storing the work items and\nassociate the work items with pre-recorded work items, the invention builds a foundation for debug sessions.\nAccording to embodiments, the work item repository 120 stores metadata on developers' debug sessions whilst working on work items on client computing device 102.  For instance, according to one implementation, this includes breakpoints set,\nstack traces collected, exceptions, variable reference searches, call type hierarchy inquiries as well as variables and monitors set and their values of the work items.  By recording this information and associating it with the relevant work item,\nalready stored in work item repository 120, work item server 112 creates a platform for retrieval of recorded metadata for future debug sessions to compare the recorded work items with already recorded work items, according to embodiments of the present\ninvention.  In the depicted environment, for instance, when a user is then working on a new issue, in client computing device 102, the metadata collected can be compared against other previous work items, previously stored in work item server 112,\naccording to embodiments of the present invention.  If there's a work item with sufficiently similar metadata from the developer debug sessions, the user can be prompted (or they can ask explicitly) that there is a possible matching work item.  The user\ncan then check the work item to see if it covers the same problem or if it somehow related.  By determining it's not a match, work item server 112 stops suggesting it for future matches if the user wishes in client computing device 102.\nWork item server 112 suggests matching work items based on a client or developer's behavior rather than just their code change.  Work items that require debugging the code but not necessarily changing it can be suggested as related work item to\nuser in client computing device 102, for comparing metadata of the work item against the work item that the user is working on, according to embodiments.  As previously described, client computing device 102 monitors users or developers whilst they\ndevelop and debug their code on client computing device 102, recording relevant metadata and associating it with their current work item in work item server 112.  Alternative embodiments could also extract metadata from historical work items of the work\nitem server, such as, comments with stack traces, delivered change sets, saved breakpoint files and log files to provide a limited analysis on work items completed before debugging the new work items can be monitored and compared against previous work\nitems.  Hence, therefore, debug data can be correctly attributed to the correct work item, according to embodiments.\nOne implementation of this invention works on a point based system to determine similarity of work items.  For each similarity 2 work items contain in their metadata, a certain number of points are attributed based on the significance of\nsimilarity.  The categories may include, 1) first, breakpoints set and stack traces: Matching breakpoints on their own may cast too wide a net at times so the points awarded may be low.  To narrow this, each time a breakpoint is set and hit, the stack\ntrace can be collected instead.  This distinguishes breakpoints set from common classes that are accessed from many locations.  Whereas a matching breakpoint may not provide much insight, a matching breakpoint along with a matching stack would be\nsignificant.  Stack traces can be split into each line within the stack trace for analysis.  This can be useful for identifying code paths that are rarely used in other work items.  Low point amounts could be awarded for single matching lines, but\nincreasing exponentially if the stack matches more lines in a row.  For example, each matching line gives a single point and for each additional line that is matching in the stack, the points value could double; this exponential increase can be\ncalibrated accordingly.  This means that 2 stacks that contain 5 lines that are in the same place but are called in a different order would only be awarded 5 points.  But 5 matching lines in the correct sequence would provide 16 points; 2) second,\nmonitors set or variables inspects: Monitors set would give one indication of a similarity.  The contents of the variable that is monitored or inspected could also be recorded and compared.  The comparisons for the contents can be abstracted too.\nFor example, a string's length can be compared to check if 2 strings are of similar size.  By collecting multiple instances of the same variable, a standard deviation could be calculated to figure out if a string length is sufficiently similar\nto another instance to award points.  This same technique could be used on integers, floats and other numerical values.  Similarities in character sequences could be checked as well.\nThis could be significant where defective behavior is caused by an abnormal variable value, e.g too short or too long, numbers too high or low, or strings with an unusual character in them.  Booleans can also be compared; 3) third, searches for\nreferences to a variable and Call Type Hierarchies, for instance, if a user searches for references to a variable, the variable searched and the search results selected by the user can be collected for comparisons.  Additionally, any requests to view\nType Hierarchies can be logged and used for comparisons as well; 4) fourth, undelivered Code Changes, sometimes a developer will make a change that is never intended to be delivered but it is useful for debugging.  A good example is inversing a boolean\nto test a different code path.  These undelivered changes could be collected and analyzed for comparisons; 5) fifth, exceptions, unhandled exceptions can be recorded.  The type of exception and its stack trace can be compared; finding a match, a search\ncan be instigated by the user, or triggered when a certain threshold for metadata collected has been met.  It can compare the metadata to each work item and allocate points accordingly.\nThe results can be listed in rank order.  While only displaying results that are above a threshold.  A standard deviation can be used to compare results to determine what is a statistically significant points value and add the result based on\nthis value.  If the user acknowledges that this is a match, the metadata from the matching work items can be linked and amalgamated so that future searches are even more effective.\nDealing with a moving source repository can be dealt with existing source code repository technology such as git or RTC.  Software such as these can give a consistent idea of what constitutes a line and where its location is in each version of\nthe codebase.  This is prior art that isn't within the scope of this invention.  There will be metadata that is largely common to all work items.  In order to improve efficiency and reduce storage required, the engine can either refuse to collect this\ndata altogether, or allocate an ID to a certain stack trace for example, so that all metadata can simply hold a reference to a complex datastructure rather than store it themselves.  Moreover, identifying data that is common to most or all sessions is\nimportant.  Points for these similarities could be rescinded depending on how the invention wishes to calibrate scores.  Embodiments of the present invention can also identify missing metadata and attribute points accordingly.  For example, if two work\nitems in the code base had stack traces that were missing a class used in all other work items, points could be allocated accordingly.\nReferring now to FIG. 2, an exemplary flow diagram illustration 200 for automatic debug of work items in accordance with one embodiment is depicted.  In the depicted environment, at step 220, work item server application 114B determines whether\ncurrent work item is known.  If the current work item is known, then, at step 230, the work item server application 114B collects debug metadata from development team system platform interactions.  However, if the current work item is not known, then, at\nstep 210, work item server application 114B determines the current work item.\nAt decision 240, work item server application 114B determines whether new data threshold has been met? If a new data threshold has been met, then, at step 250, work item server application 114B searches server work item system using weighted\ncomparison, matching the metadata for current work items to previous work item and code name histories.  However, if new data threshold has not been met, then, at step 230, work item server application 114B collects debug metadata from development team\nsystem platform interactions, according to embodiments of the present invention.  At step 260, work item server application 114B presents relevant matching to work items to user in client computing device 102.\nReferring now to FIG. 3, an alternative exemplary flow diagram illustration 200 for automatic debug of work items in accordance with one embodiment is depicted.\nAt step 310, work item server application 114B records metadata describing a particular debug session associated with a user of client computing device 102, for a respective work item of work item server 112.  At step 320 the work item server\napplication 114B associates the metadata recorded in the particular debug session with the respective work item of work item server 112, according to embodiments.  At step 330, in response to the user working on a new issue, the work item server 112\ncompares the metadata saved with other work items.  At step 340, in response to identifying a work item with a predetermined level of similar metadata from debug sessions, the work item server 112 notifies the user of a potential work item match the\nrespective work item.  At step 350, in response to the user working on a new issue, work item server application 114B refrains from suggesting the new issue for future matches.\nAccording to embodiments of the present invention, the metadata includes breakpoints set, stack traces collected, exceptions, variable reference searches, call type hierarchy inquiries further comprising variables and monitors set and respective\nvalues.  According to embodiments, the metadata recorded and an association with the respective work item are saved by work item server application 114B in work item repository 120.  The potential work item match is identified according to predetermined\ncriteria including a same problem, a particular code change, a debugging session, a work item that requires debugging code without changing the code as a related work item or a predetermined relationship including a behavioral pattern of the user.  The\nmetadata can be extracted metadata rom historical work items to provide a limited analysis on the work items that are completed, according to embodiments.\nFIG. 4 is a block diagram 400 of internal and external components of computers depicted in FIG. 1 in accordance with an illustrative embodiment of the present invention.  It should be appreciated that FIG. 4 provides only an illustration of one\nimplementation and does not imply any limitations with regard to the environments in which different embodiments may be implemented.  Many modifications to the depicted environments may be made based on design and implementation requirements.\nData processing system 800, 900 is representative of any electronic device capable of executing machine-readable program instructions.  Data processing system 800, 900 may be representative of a smart phone, a computer system, PDA, or other\nelectronic devices.  Examples of computing systems, environments, and/or configurations that may represented by data processing system 800, 900 include, but are not limited to, personal computer systems, server computer systems, thin clients, thick\nclients, hand-held or laptop devices, multiprocessor systems, microprocessor-based systems, network PCs, minicomputer systems, and distributed cloud computing environments that include any of the above systems or devices.\nClient computing device (FIG. 1) and work item server application 114B (FIG. 1) may include respective sets of internal components 800 a,b and external components 900 a,b illustrated in FIG. 4.  Each of the sets of internal components 800\ninclude one or more processors 820, one or more computer-readable RAMs 822 and one or more computer-readable ROMs 824 on one or more buses 826, and one or more operating systems 828 and one or more computer-readable tangible storage devices 830.  The one\nor more operating systems 828 and the Software Program 108 (FIG. 1) and client system application 114A in client computing device 102 (FIG. 1) and work item server application 114B (FIG. 1) in work item server application 114B (FIG. 1) are stored on one\nor more of the respective computer-readable tangible storage devices 830 for execution by one or more of the respective processors 820 via one or more of the respective RAMs 822 (which typically include cache memory).  In the embodiment illustrated in\nFIG. 4, each of the computer-readable tangible storage devices 830 is a magnetic disk storage device of an internal hard drive.\nAlternatively, each of the computer-readable tangible storage devices 830 is a semiconductor storage device such as ROM 824, EPROM, flash memory or any other computer-readable tangible storage device that can store a computer program and digital\ninformation.  Each set of internal components 800 a,b also includes a R/W drive or interface 832 to read from and write to one or more portable computer-readable tangible storage devices 936 such as a CD-ROM, DVD, memory stick, magnetic tape, magnetic\ndisk, optical disk or semiconductor storage device.  A software program, such as the Software Program 108 (FIG. 1) and the client systems application 114A (FIG. 1) can be stored on one or more of the respective portable computer-readable tangible storage\ndevices 936, read via the respective R/W drive or interface 832 and loaded into the respective hard drive 830.\nEach set of internal components 800 a,b also includes network adapters or interfaces 836 such as a TCP/IP adapter cards, wireless Wi-Fi interface cards, or 3G or 4G wireless interface cards or other wired or wireless communication links.  The\nSoftware Program 108 (FIG. 1) and client system application 114A (FIG. 1) in client computing system computer 102, and work item server application 114B (FIG. 1) in communications network 110 (FIG. 1) can be downloaded to client computing device 102\n(FIG. 1) and communications network 110 (FIG. 1) from an external computer via a network (for example, the Internet, a local area network or other, wide area network) and respective network adapters or interfaces 836.  From the network adapters or\ninterfaces 836, the Software Program 108 (FIG. 1) and client system application 114A (FIG. 1) in client computing system computer 102, and work item server application 114B (FIG. 1) in communications network 110 (FIG. 1) and communications network 110\n(FIG. 1) are loaded into the respective hard drive 830.  The network may comprise copper wires, optical fibers, wireless transmission, routers, firewalls, switches, gateway computers and/or edge servers.\nEach of the sets of external components 900 a,b can include a computer display monitor 920, a keyboard 930, and a computer mouse 934.  External components 900 a,b can also include touch screens, virtual keyboards, touch pads, pointing devices,\nand other human interface devices.  Each of the sets of internal components 800 a,b also includes device drivers 840 to interface to computer display monitor 920, keyboard 930 and computer mouse 934.  The device drivers 840, R/W drive or interface 832\nand network adapter or interface 836 comprise hardware and software (stored in storage device 830 and/or ROM 824).\nIt is understood in advance that although this disclosure includes a detailed description on cloud computing, implementation of the teachings recited herein are not limited to a cloud computing environment.  Rather, embodiments of the present\ninvention are capable of being implemented in conjunction with any other type of computing environment now known or later developed.\nCloud computing is a model of service delivery for enabling convenient, on-demand network access to a shared pool of configurable computing resources (e.g. networks, network bandwidth, servers, processing, memory, storage, applications, virtual\nmachines, and services) that can be rapidly provisioned and released with minimal management effort or interaction with a provider of the service.  This cloud model may include at least five characteristics, at least three service models, and at least\nfour deployment models.\nCharacteristics are as follows:\nOn-demand self-service: a cloud consumer can unilaterally provision computing capabilities, such as server time and network storage, as needed automatically without requiring human interaction with the service's provider.\nBroad network access: capabilities are available over a network and accessed through standard mechanisms that promote use by heterogeneous thin or thick client platforms (e.g., mobile phones, laptops, and PDAs).\nResource pooling: the provider's computing resources are pooled to serve multiple consumers using a multi-tenant model, with different physical and virtual resources dynamically assigned and reassigned according to demand.  There is a sense of\nlocation independence in that the consumer generally has no control or knowledge over the exact location of the provided resources but may be able to specify location at a higher level of abstraction (e.g., country, state, or datacenter).\nRapid elasticity: capabilities can be rapidly and elastically provisioned, in some cases automatically, to quickly scale out and rapidly released to quickly scale in. To the consumer, the capabilities available for provisioning often appear to\nbe unlimited and can be purchased in any quantity at any time.\nMeasured service: cloud systems automatically control and optimize resource use by leveraging a metering capability at some level of abstraction appropriate to the type of service (e.g., storage, processing, bandwidth, and active user accounts). Resource usage can be monitored, controlled, and reported providing transparency for both the provider and consumer of the utilized service.\nService Models are as follows:\nSoftware as a Service (SaaS): the capability provided to the consumer is to use the provider's applications running on a cloud infrastructure.  The applications are accessible from various client devices through a thin client interface such as a\nweb browser (e.g., web-based e-mail).  The consumer does not manage or control the underlying cloud infrastructure including network, servers, operating systems, storage, or even individual application capabilities, with the possible exception of limited\nuser-specific application configuration settings.\nPlatform as a Service (PaaS): the capability provided to the consumer is to deploy onto the cloud infrastructure consumer-created or acquired applications created using programming languages and tools supported by the provider.  The consumer\ndoes not manage or control the underlying cloud infrastructure including networks, servers, operating systems, or storage, but has control over the deployed applications and possibly application hosting environment configurations.\nInfrastructure as a Service (IaaS): the capability provided to the consumer is to provision processing, storage, networks, and other fundamental computing resources where the consumer is able to deploy and run arbitrary software, which can\ninclude operating systems and applications.  The consumer does not manage or control the underlying cloud infrastructure but has control over operating systems, storage, deployed applications, and possibly limited control of select networking components\n(e.g., host firewalls).\nDeployment Models are as follows:\nPrivate cloud: the cloud infrastructure is operated solely for an organization.  It may be managed by the organization or a third party and may exist on-premises or off-premises.\nCommunity cloud: the cloud infrastructure is shared by several organizations and supports a specific community that has shared concerns (e.g., mission, security requirements, policy, and compliance considerations).  It may be managed by the\norganizations or a third party and may exist on-premises or off-premises.\nPublic cloud: the cloud infrastructure is made available to the general public or a large industry group and is owned by an organization selling cloud services.\nHybrid cloud: the cloud infrastructure is a composition of two or more clouds (private, community, or public) that remain unique entities but are bound together by standardized or proprietary technology that enables data and application\nportability (e.g., cloud bursting for load-balancing between clouds).\nA cloud computing environment is service oriented with a focus on statelessness, low coupling, modularity, and semantic interoperability.  At the heart of cloud computing is an infrastructure comprising a network of interconnected nodes.\nReferring now to FIG. 5, illustrative cloud computing environment 500 is depicted.  As shown, cloud computing environment 600 comprises one or more cloud computing nodes 100 with which local computing devices used by cloud consumers, such as,\nfor example, personal digital assistant (PDA) or cellular telephone 600A, desktop computer 600B, laptop computer 600C, and/or automobile computer system 600N may communicate.  Nodes 100 may communicate with one another.  They may be grouped (not shown)\nphysically or virtually, in one or more networks, such as Private, Community, Public, or Hybrid clouds as described hereinabove, or a combination thereof.  This allows cloud computing environment 600 to offer infrastructure, platforms and/or software as\nservices for which a cloud consumer does not need to maintain resources on a local computing device.  It is understood that the types of computing devices 600A-N shown in FIG. 7 are intended to be illustrative only and that computing nodes 100 and cloud\ncomputing environment 600 can communicate with any type of computerized device over any type of network and/or network addressable connection (e.g., using a web browser).\nReferring now to FIG. 6, a set of functional abstraction layers 6000 provided by cloud computing environment 600 (FIG. 5) is shown.  It should be understood in advance that the components, layers, and functions shown in FIG. 6 are intended to be\nillustrative only and embodiments of the invention are not limited thereto.  As depicted, the following layers and corresponding functions are provided:\nHardware and software layer 6010 includes hardware and software components.  Examples of hardware components include: mainframes; RISC (Reduced Instruction Set Computer) architecture based servers; storage devices; networks and networking\ncomponents.  In some embodiments, software components include network application server software.\nVirtualization layer 6012 provides an abstraction layer from which the following examples of virtual entities may be provided: virtual servers; virtual storage; virtual networks, including virtual private networks; virtual applications and\noperating systems; and virtual clients.\nIn one example, management layer 6014 may provide the functions described below.  Resource provisioning provides dynamic procurement of computing resources and other resources that are utilized to perform tasks within the cloud computing\nenvironment.  Metering and Pricing provide cost tracking as resources are utilized within the cloud computing environment, and billing or invoicing for consumption of these resources.  In one example, these resources may comprise application software\nlicenses.  Security provides identity verification for cloud consumers and tasks, as well as protection for data and other resources.  User portal provides access to the cloud computing environment for consumers and system administrators.  Service level\nmanagement provides cloud computing resource allocation and management such that required service levels are met.  Service Level Agreement (SLA) planning and fulfillment provide pre-arrangement for, and procurement of, cloud computing resources for which\na future requirement is anticipated in accordance with an SLA.  An Indicator for Conversation Nonproductivity may measure the productivity of a conversation between multiple users of a mobile computing device.\nWorkloads layer 6016 provides examples of functionality for which the cloud computing environment may be utilized.  Examples of workloads and functions which may be provided from this layer include: mapping and navigation; software development\nand lifecycle management; virtual classroom education delivery; data analytics processing; and transaction processing.\nThe descriptions of the various embodiments of the present invention have been presented for purposes of illustration, but are not intended to be exhaustive or limited to the embodiments disclosed.  Many modifications and variations will be\napparent to those of ordinary skill in the art without departing from the scope of the described embodiments.  The terminology used herein was chosen to best explain the principles of the embodiments, the practical application or technical improvement\nover technologies found in the marketplace, or to enable others of ordinary skill in the art to understand the embodiments disclosed herein.", "application_number": "15900863", "abstract": " A method for automatic debug session analysis for related work item\n     discovery, is provided. The method includes recording metadata describing\n     a particular debug session associated with a user for a respective work\n     item. The method further includes associating the metadata recorded in\n     the particular debug session with the respective work item. In response\n     to the user working on a new issue, comparing the metadata saved with\n     other work items. In response to identifying a work item with a\n     predetermined level of similar metadata from debug sessions, notifying\n     the user of a potential work item match. In response to not identifying a\n     work item with a predetermined level of similar metadata from debug\n     sessions, refraining from suggesting the new issue for future matches.\n", "citations": ["7096458", "7343588", "8347269", "8504994", "8909990", "8910120", "8935673", "9032374", "20090327809", "20120144256", "20160203072", "20160282408"], "related": ["15276841"]}, {"id": "20180233014", "patent_code": "10373464", "patent_name": "Apparatus and method for updating partiality vectors based on monitoring\n     of person and his or her home", "year": "2019", "inventor_and_country_data": " Inventors: \nWilkinson; Bruce W. (Rogers, AR), Mattingly; Todd D. (Bentonville, AR)  ", "description": "<BR><BR>TECHNICAL FIELD\nThis invention relates generally to monitoring systems and, more particularly, to systems for monitoring deviations in a person's activity.\n<BR><BR>BACKGROUND\nWhile people typically don't perform the same tasks each day, eat the same meals each day, travel to the same locations each day, etc., most people have fairly routine schedules.  For example, although an individual may not eat the exact same\nmeal for dinner every night, he or she may have a meal pattern that is relatively consistent from week-to-week or month-to-month.  As another example, although an individual may not travel to the same locations every day, he or she may typically go to\nthe grocery store on Mondays, to the gym on Tuesdays and Thursdays, and out to one of a select number of restaurants on Fridays.  Oftentimes, a deviation from these routines or patterns may signal that something is wrong or that something has changed in\nthe person's life.  Consequently, a way to better understand a person's routines may be useful in predicting problems, or changes, with that person and/or his or her routines. <BR><BR>BRIEF DESCRIPTION OF THE DRAWINGS\nDisclosed herein are embodiments of systems, apparatuses and methods pertaining detecting a deviation in a person's activity.  This description includes drawings, wherein:\nFIG. 1 is a diagram of a person 104 and a portion of his or her home 100 including multiple sensors, according to some embodiments;\nFIG. 2 is a block diagram of a system 200 for detecting a deviation in a person's activity, according to some embodiments;\nFIG. 3 is a flow chart depicting example operations for detecting a deviation in a person's activity, according to some embodiments;\nFIG. 4 comprises a flow diagram as configured in accordance with various embodiments of these teachings;\nFIG. 5 comprises a flow diagram as configured in accordance with various embodiments of these teachings;\nFIG. 6 comprises a graphic representation as configured in accordance with various embodiments of these teachings;\nFIG. 7 comprises a graph as configured in accordance with various embodiments of these teachings;\nFIG. 8 comprises a flow diagram as configured in accordance with various embodiments of these teachings;\nFIG. 9 comprises a graphic representation as configured in accordance with various embodiments of these teachings;\nFIG. 10 comprises a graphic representation as configured in accordance with various embodiments of these teachings;\nFIG. 11 comprises a graphic representation as configured in accordance with various embodiments of these teachings;\nFIG. 12 comprises a flow diagram as configured in accordance with various embodiments of these teachings;\nFIG. 13 comprises a flow diagram as configured in accordance with various embodiments of these teachings;\nFIG. 14 comprises a graphic representation as configured in accordance with various embodiments of these teachings;\nFIG. 15 comprises a graphic representation as configured in accordance with various embodiments of these teachings;\nFIG. 16 comprises a block diagram as configured in accordance with various embodiments of these teachings;\nFIG. 17 comprises a flow diagram as configured in accordance with various embodiments of these teachings;\nFIG. 18 comprises a graph as configured in accordance with various embodiments of these teachings;\nFIG. 19 comprises a flow diagram as configured in accordance with various embodiments of these teachings;\nFIG. 20 comprises a block diagram as configured in accordance with various embodiments of these teachings; and\nFIG. 21 is a flow chart depicting example operations for monitoring parameters associated with a person and the person's home and updating a partiality vector for the person based on a deviation.\nElements in the figures are illustrated for simplicity and clarity and have not necessarily been drawn to scale.  For example, the dimensions and/or relative positioning of some of the elements in the figures may be exaggerated relative to other\nelements to help to improve understanding of various embodiments of the present invention.  Also, common but well-understood elements that are useful or necessary in a commercially feasible embodiment are often not depicted in order to facilitate a less\nobstructed view of these various embodiments of the present invention.  Certain actions and/or steps may be described or depicted in a particular order of occurrence while those skilled in the art will understand that such specificity with respect to\nsequence is not actually required.  The terms and expressions used herein have the ordinary technical meaning as is accorded to such terms and expressions by persons skilled in the technical field as set forth above except where different specific\nmeanings have otherwise been set forth herein.\n<BR><BR>DETAILED DESCRIPTION\nGenerally speaking, pursuant to various embodiments, systems, apparatuses, and methods are provided herein useful to detecting a deviation in a person's activity.  In some embodiments, an apparatus comprises one or more sensors, the one or more\nsensors configured to monitor parameters associated with a person and the person's home, and a control circuit, the control circuit communicatively coupled to the one or more sensors and configured to generate one or more partiality vectors for the\nperson, wherein the one or more partiality vectors have at least one of a magnitude and an angle that corresponds to a magnitude of the person's belief in an amount of good that comes from an order associated with that partiality, receive, from the one\nor more sensors, values associated with the parameters, create, based on the values associated with the parameters, a spectral profile for the person, determine, based on the spectral profile and a routine experiential base state for the person, that a\ncombination of the values indicates a deviation, and update, based on the deviation, at least one of the one or more partiality vectors for the person.\nAs previously discussed, most people have fairly routine schedules from day-to-day, week-to-week, month-to-month, etc. Further, understanding a person's routines may be useful in detecting problems, or changes, with that person and/or his or her\nroutines.  For example, if a person who normally goes to the gym on Tuesdays and Thursdays stops going to the gym on Tuesdays and Thursdays, it may indicate that he or she isn't feeling well or has decided that going to the gym is not worth the effort. \nIn addition to determining a deviation (e.g., no longer going to the gym), an alert can be sent indicating that he or she is no longer going to the gym.  For example, the person could set an alert to be sent to his or her friend so that his or her friend\nwill know he or she is no longer going to the gym and attempt to motivate him or her to resume going to the gym.  Described herein are systems, methods, and apparatuses that can monitor a person and his or her environment, determine that the person has\ndeviated from his or her normal routine, and cause an alert to be transmitted that indicates that there has been a deviation.  FIG. 1 provides some background information for such a system.\nFIG. 1 is a diagram of a person 104 and a portion of his or her home 100 including multiple sensors, according to some embodiments.  The person's 104 home 100 includes a variety of different sensors.  The sensors can include motion sensors,\nimage sensors, noise sensors, light sensors, weight sensors, usage sensors, door sensors, utility usage sensors, or any other suitable type of sensor.  Additionally, the person 104 can wear, or otherwise host, sensors on or in his or her body.\nThe portion of the person's 104 home 100 depicted in FIG. 1 is the kitchen.  The kitchen includes a motion sensor 108, a noise sensor 110 (e.g., a microphone), a light sensor housed within a light fixture 112, an image sensor 114 (e.g., a video\ncamera or a still camera), cabinet door sensors 118, and cabinet weight sensors 124.  The motion sensor 108 can monitor motion and activity within the kitchen.  The noise sensor 110 can monitor noise within the kitchen.  The cabinet door sensors 118 can\nmonitor opening and closing and/or the state (e.g., open or closed) of the cabinet door(s).  The cabinet weight sensors 124 can monitor items within the cabinet.  For example, the weight sensors 124 may span a portion of the cabinet's footprint that is\nlarge enough to accommodate several items.  In such embodiments, the cabinet weight sensor 124 may generally monitor the weight of items in the cabinet.  In other embodiments, the cabinet weight sensor 124 may include multiple smaller weight sensors.  In\nsuch embodiments the person 104 can arrange items in the cabinet so that the cabinet weight sensors 124 can monitor how much of an item remains, or the presence of an item in the cabinet.  The light sensor can monitor light in the kitchen and/or energy\nusage of the light fixture 112.\nThe appliances within the kitchen can also include a variety of sensors.  For example, a refrigerator 128 includes a freezer door sensor 120 and a refrigerator door sensor 122 and an oven 132 includes an over door sensor 134.  Although not\ndepicted, the oven 132, refrigerator 128, and microwave 126 can also include usage sensors (e.g., energy usage, operational time, operational parameters, etc.) and/or weight sensors similar to the cabinet weight sensors 124 included in the cabinet. \nWhile FIG. 1 depicts only the person's 104 kitchen, the rest of the home 100 can also include sensors similar to those depicted in the kitchen.\nIn FIG. 1, the person 104 is wearing a fitness band 106.  The fitness band 106 can include a plurality of sensors that can monitor the person's 104 vital signs, bodily functions, location, activity, etc. For example, the fitness band 106 can\ninclude a pedometer, an accelerometer, a motion sensor, a heart rate sensor, an image sensor, a noise sensor, an activity sensor, a blood pressure sensor, a location sensor (e.g., a GPS transceiver), etc. Although FIG. 1 only depicts the person 104 as\nwearing the fitness band 106, in some embodiments, the person can wear (or otherwise possess) additional sensor and/or devices having sensors.\nThe sensors, or an appliance associated with a sensor, can also include a transmitter (or transceiver).  For example, the refrigerator 128 includes a refrigerator transmitter 116 and the oven 132 includes an oven transmitter 130.  Likewise, the\nfitness band 106 can include a transmitter.  The sensors, as well as the transmitters, are operable to transmit data to a control circuit 102.  The data can include values associated with parameters monitored by the sensors.  The control circuit 102\nmonitors and processes the data.  The control circuit 102 processes the data to determine deviations from the person's normal routine.  In some embodiments, the control circuit 102 may require a learning phase during set up.  In such embodiments, the\ncontrol circuit 102 processes the data to learn the person's 104 normal routine.  Upon detecting a deviation from the person's 104 normal routine, the control circuit 102 can determine a type of alert that is appropriate based on the deviation as well as\nan appropriate recipient for the alert.  The control circuit 102 can also transmit, or cause transmission of, the alert to the recipient.\nWhile FIG. 1 and the related text provide background information about a system that can detect deviations from a person's normal routine and transmit alerts based on the deviations, FIG. 2 and the related text describe an example system that\ncan detect deviations from a person's normal routine and transmit alerts based on the deviations.\nFIG. 2 is a block diagram of a system 200 for detecting a deviation in a person's activity, according to some embodiments.  The system 200 includes a control circuit 202, sensors 214, and a recipient device 216.  The sensors 214 can be any type,\nand number, of sensors suitable for monitoring parameters associated with a person and indicative of, or associated with, his or her activities.  The sensors 214 are in communication with the control circuit 202 and transmit data to the control circuit\n202 for processing.  The data can include values associated with the parameters.\nThe control circuit 202 can comprise a fixed-purpose hard-wired hardware platform (including but not limited to an application-specific integrated circuit (ASIC) (which is an integrated circuit that is customized by design for a particular use,\nrather than intended for general-purpose use), a field-programmable gate array (FPGA), and the like) or can comprise a partially or wholly-programmable hardware platform (including but not limited to microcontrollers, microprocessors, and the like). \nThese architectural options for such structures are well known and understood in the art and require no further description here.  The control circuit 202 is configured (for example, by using corresponding programming as will be well understood by those\nskilled in the art) to carry out one or more of the steps, actions, and/or functions described herein.\nBy one optional approach the control circuit 202 operably couples to a memory.  The memory may be integral to the control circuit 202 or can be physically discrete (in whole or in part) from the control circuit 202 as desired.  This memory can\nalso be local with respect to the control circuit 202 (where, for example, both share a common circuit board, chassis, power supply, and/or housing) or can be partially or wholly remote with respect to the control circuit 202 (where, for example, the\nmemory is physically located in another facility, metropolitan area, or even country as compared to the control circuit 202).\nThis memory can serve, for example, to non-transitorily store the computer instructions that, when executed by the control circuit 202, cause the control circuit 202 to behave as described herein.  As used herein, this reference to\n\"non-transitorily\" will be understood to refer to a non-ephemeral state for the stored contents (and hence excludes when the stored contents merely constitute signals or waves) rather than volatility of the storage media itself and hence includes both\nnon-volatile memory (such as read-only memory (ROM) as well as volatile memory (such as an erasable programmable read-only memory (EPROM).\nThe control circuit 202 includes a parameter database 204, an alert database 206, a deviation determination unit 208, an alert determination unit 210, a receiver 212, and a transmitter 218.  Although depicted as individual units, in some\nembodiments the receiver 212 and the transmitter 218 can be a single unit, such as a transceiver.  The parameter database 204 includes the parameters that are, or can be, monitored by the sensors 214.  As one example, the parameter database 204 can\ninclude an array of the parameters and the types of sensors 214 with which the parameters are associated.  In some embodiments, the parameter database 204, or another database (e.g., a dedicated user database), can include an array of users and the\nsensors associated with the user's account, as well and information about each user's routines.\nThe deviation determination unit 208 processes the data from the sensors 214 to determine if a deviation has occurred with regard to a user's routine.  The deviation determination unit 208 can make this determination by accessing the parameter\ndatabase 204, as well as other databases that may contain user information.  The alert database 206 includes possible alerts.  For example, the alert database 206 can include a list of all possible alerts and what conditions prompt each of the alerts. \nIn some embodiments, the alert database 206, or another database (e.g., a dedicated user database) can include alerts, and recipients, associated with each user.  The users can configure what types of alerts should be associated with different types of\ndeviations as well as who the recipient should be for each deviation.  Additionally, some or all of the alerts and recipients can be standardized or preconfigured for the users.  After the deviation determination unit 208 determines that the user has\ndeviated from his or her routine, the alert determination unit 210 determines an appropriate alert.  Additionally, the alert determination unit 210 can determine the appropriate recipient for the alert.  The transmitter 218 then transmits the alert to\nthe recipient device 216.\nWhile FIG. 2 and the related text describe an example system that can detect deviations from a person's normal routine and transmit alerts based on the deviations, FIG. 3 and the related text describe example operations for performed by such a\nsystem.\nFIG. 3 is a flow chart depicting example operations for detecting a deviation in a person's activity, according to some embodiments.  The flow begins at block 302.\nAt block 302, parameters are monitored.  For example, a plurality of sensors monitors parameters that are associated with a person and his or her environment and activities.  The plurality of sensors can include sensors that monitor the person\nand his or her activity and location as well as sensors within the person home or car that monitor the person's environment.  The flow continues at block 304.\nAt block 304, values are received.  For example, a control circuit can receive the values from one or more of the plurality of sensors.  The values can be associated with the parameters monitored by the plurality of sensors.  For example, the\nvalues can indicate information about the person such as his or her heartrate, blood pressure, body temperature, current activity, past activity, location, etc. The values can also indicate information about the person's environment such as room\ntemperature, appliance usage, cabinet or refrigerator contents, energy usage, noise level, humidity level, occupants, etc. The flow continues at block 306.\nAt block 306, a deviation is determined.  For example, the control circuit can determine that there has been a deviation from the person's routine.  The control circuit can determine deviations based on a single value, for example, being above a\nthreshold, below a threshold, out of range, etc. Additionally, in some embodiments, the control circuit can determine deviations based on multiple values.  For example, each of the multiple values may be above or below a threshold or out of range.  As\nanother example, each of the multiple values may be within a normal or expected range, but the values in the aggregate may indicate a deviation.  For example, the values may indicate that the person's pulse is 140 BPM and that the person is not currently\nengaged in physical exercise.  While a heartrate of 140 BPM is high, it is not necessarily outside of a normal range and may not be out the person's normal or expected range.  Additionally, that the person is not currently engaged in physical activity is\nnot abnormal.  However, the relatively high heartrate coupled with the lack of physical exercise may be a deviation that indicates a problem.  In some embodiments, the control circuit references only the person's information to determine if there is a\ndeviation.  In other embodiments, the control circuit can aggregate data over time and from any number of users to determine trends in a larger population.  In such embodiments, the control circuit can use this aggregated information to determine if\nthere is a deviation.  The flow continues at block 308.\nAt block 308, an alert is determined.  For example, the control circuit can determine a type of alert.  The type of alert can be based on the deviation and/or the values.  More specifically, the type of alert can be based on the magnitude of the\nvariance in the values from their expected value.  For example, if the person typically gets out of bed at 7 A, at 9 A the control circuit may simply select an alert such as a wakeup call to the person.  However, if the person typically gets out of bed\nat 7 A and it is 9 P, the control circuit may select an alert to notify a local police department to request a wellness check.  The control circuit can also determine a recipient for the alert.  The recipients can include the person, family members,\nfriends, emergency personnel, retailers, etc. The control circuit can determine a recipient based upon user specifications, data from other users, preset configurations, etc. The control circuit can also determine a mode of transmission of the alert. \nFor example, the alert can be a phone (e.g., voice) call, a text message, an email, a page, a social media message, a product shipment, etc. For example, if the control circuit determines that the person typically has pasta with dinner on Tuesdays,\nleaves the office around 6 P, and that there is not sufficient pasta in the person's home to support this meal, the alert can be an order to a retailer for more pasta.  The flow continues at block 310.\nAt block 310, the alert is transmitted.  For example, the control circuit can cause transmission of the alert.  The control circuit can cause transmission of the alert by sending the alert, or providing a signal (e.g., including the alert and\ninstructions) to a transmitter.\nWhile the discussion of FIGS. 1-3 provides detail regarding monitoring a person's activity, detecting a deviation, and transmitting an alert based on the deviation, the discussion of FIGS. 4-20 provides additional detail regarding a person's\nvalues and generating a vector representation of the person's values.\nGenerally speaking, many of these embodiments provide for a memory having information stored therein that includes partiality information for each of a plurality of persons in the form of a plurality of partiality vectors for each of the persons\nwherein each partiality vector has at least one of a magnitude and an angle that corresponds to a magnitude of the person's belief in an amount of good that comes from an order associated with that partiality.  This memory can also contain vectorized\ncharacterizations for each of a plurality of products, wherein each of the vectorized characterizations includes a measure regarding an extent to which a corresponding one of the products accords with a corresponding one of the plurality of partiality\nvectors.\nRules can then be provided that use the aforementioned information in support of a wide variety of activities and results.  Although the described vector-based approaches bear little resemblance (if any) (conceptually or in practice) to prior\napproaches to understanding and/or metricizing a given person's product/service requirements, these approaches yield numerous benefits including, at least in some cases, reduced memory requirements, an ability to accommodate (both initially and\ndynamically over time) an essentially endless number and variety of partialities and/or product attributes, and processing/comparison capabilities that greatly ease computational resource requirements and/or greatly reduced time-to-solution results.\nSo configured, these teachings can constitute, for example, a method for automatically correlating a particular product with a particular person by using a control circuit to obtain a set of rules that define the particular product from amongst\na plurality of candidate products for the particular person as a function of vectorized representations of partialities for the particular person and vectorized characterizations for the candidate products.  This control circuit can also obtain\npartiality information for the particular person in the form of a plurality of partiality vectors that each have at least one of a magnitude and an angle that corresponds to a magnitude of the particular person's belief in an amount of good that comes\nfrom an order associated with that partiality and vectorized characterizations for each of the candidate products, wherein each of the vectorized characterizations indicates a measure regarding an extent to which a corresponding one of the candidate\nproducts accords with a corresponding one of the plurality of partiality vectors.  The control circuit can then generate an output comprising identification of the particular product by evaluating the partiality vectors and the vectorized\ncharacterizations against the set of rules.\nThe aforementioned set of rules can include, for example, comparing at least some of the partiality vectors for the particular person to each of the vectorized characterizations for each of the candidate products using vector dot product\ncalculations.  By another approach, in lieu of the foregoing or in combination therewith, the aforementioned set of rules can include using the partiality vectors and the vectorized characterizations to define a plurality of solutions that collectively\nform a multi-dimensional surface and selecting the particular product from the multi-dimensional surface.  In such a case the set of rules can further include accessing other information (such as objective information) for the particular person\ncomprising information other than partiality vectors and using the other information to constrain a selection area on the multi-dimensional surface from which the particular product can be selected.\nPeople tend to be partial to ordering various aspects of their lives, which is to say, people are partial to having things well arranged per their own personal view of how things should be.  As a result, anything that contributes to the proper\nordering of things regarding which a person has partialities represents value to that person.  Quite literally, improving order reduces entropy for the corresponding person (i.e., a reduction in the measure of disorder present in that particular aspect\nof that person's life) and that improvement in order/reduction in disorder is typically viewed with favor by the affected person.\nGenerally speaking a value proposition must be coherent (logically sound) and have \"force.\" Here, force takes the form of an imperative.  When the parties to the imperative have a reputation of being trustworthy and the value proposition is\nperceived to yield a good outcome, then the imperative becomes anchored in the center of a belief that \"this is something that I must do because the results will be good for me.\" With the imperative so anchored, the corresponding material space can be\nviewed as conforming to the order specified in the proposition that will result in the good outcome.\nPursuant to these teachings a belief in the good that comes from imposing a certain order takes the form of a value proposition.  It is a set of coherent logical propositions by a trusted source that, when taken together, coalesce to form an\nimperative that a person has a personal obligation to order their lives because it will return a good outcome which improves their quality of life.  This imperative is a value force that exerts the physical force (effort) to impose the desired order. \nThe inertial effects come from the strength of the belief.  The strength of the belief comes from the force of the value argument (proposition).  And the force of the value proposition is a function of the perceived good and trust in the source that\nconvinced the person's belief system to order material space accordingly.  A belief remains constant until acted upon by a new force of a trusted value argument.  This is at least a significant reason why the routine in people's lives remains relatively\nconstant.\nNewton's three laws of motion have a very strong bearing on the present teachings.  Stated summarily, Newton's first law holds that an object either remains at rest or continues to move at a constant velocity unless acted upon by a force, the\nsecond law holds that the vector sum of the forces F on an object equal the mass m of that object multiplied by the acceleration a of the object (i.e., F=ma), and the third law holds that when one body exerts a force on a second body, the second body\nsimultaneously exerts a force equal in magnitude and opposite in direction on the first body.\nRelevant to both the present teachings and Newton's first law, beliefs can be viewed as having inertia.  In particular, once a person believes that a particular order is good, they tend to persist in maintaining that belief and resist moving\naway from that belief.  The stronger that belief the more force an argument and/or fact will need to move that person away from that belief to a new belief.\nRelevant to both the present teachings and Newton's second law, the \"force\" of a coherent argument can be viewed as equaling the \"mass\" which is the perceived Newtonian effort to impose the order that achieves the aforementioned belief in the\ngood which an imposed order brings multiplied by the change in the belief of the good which comes from the imposition of that order.  Consider that when a change in the value of a particular order is observed then there must have been a compelling value\nclaim influencing that change.  There is a proportionality in that the greater the change the stronger the value argument.  If a person values a particular activity and is very diligent to do that activity even when facing great opposition, we say they\nare dedicated, passionate, and so forth.  If they stop doing the activity, it begs the question, what made them stop? The answer to that question needs to carry enough force to account for the change.\nAnd relevant to both the present teachings and Newton's third law, for every effort to impose good order there is an equal and opposite good reaction.\nFIG. 4 provides a simple illustrative example in these regards.  At block 401 it is understood that a particular person has a partiality (to a greater or lesser extent) to a particular kind of order.  At block 402 that person willingly exerts\neffort to impose that order to thereby, at block 403, achieve an arrangement to which they are partial.  And at block 404, this person appreciates the \"good\" that comes from successfully imposing the order to which they are partial, in effect\nestablishing a positive feedback loop.\nUnderstanding these partialities to particular kinds of order can be helpful to understanding how receptive a particular person may be to purchasing a given product or service.  FIG. 5 provides a simple illustrative example in these regards.  At\nblock 501 it is understood that a particular person values a particular kind of order.  At block 502 it is understood (or at least presumed) that this person wishes to lower the effort (or is at least receptive to lowering the effort) that they must\npersonally exert to impose that order.  At decision block 503 (and with access to information 504 regarding relevant products and or services) a determination can be made whether a particular product or service lowers the effort required by this person\nto impose the desired order.  When such is not the case, it can be concluded that the person will not likely purchase such a product/service 505 (presuming better choices are available).\nWhen the product or service does lower the effort required to impose the desired order, however, at block 506 a determination can be made as to whether the amount of the reduction of effort justifies the cost of purchasing and/or using the\nproffered product/service.  If the cost does not justify the reduction of effort, it can again be concluded that the person will not likely purchase such a product/service 505.  When the reduction of effort does justify the cost, however, this person may\nbe presumed to want to purchase the product/service and thereby achieve the desired order (or at least an improvement with respect to that order) with less expenditure of their own personal effort (block 507) and thereby achieve, at block 508,\ncorresponding enjoyment or appreciation of that result.\nTo facilitate such an analysis, the applicant has determined that factors pertaining to a person's partialities can be quantified and otherwise represented as corresponding vectors (where \"vector\" will be understood to refer to a geometric\nobject/quantity having both an angle and a length/magnitude).  These teachings will accommodate a variety of differing bases for such partialities including, for example, a person's values, affinities, aspirations, and preferences.\nA value is a person's principle or standard of behavior, their judgment of what is important in life.  A person's values represent their ethics, moral code, or morals and not a mere unprincipled liking or disliking of something.  A person's\nvalue might be a belief in kind treatment of animals, a belief in cleanliness, a belief in the importance of personal care, and so forth.\nAn affinity is an attraction (or even a feeling of kinship) to a particular thing or activity.  Examples including such a feeling towards a participatory sport such as golf or a spectator sport (including perhaps especially a particular team\nsuch as a particular professional or college football team), a hobby (such as quilting, model railroading, and so forth), one or more components of popular culture (such as a particular movie or television series, a genre of music or a particular musical\nperformance group, or a given celebrity, for example), and so forth.\n\"Aspirations\" refer to longer-range goals that require months or even years to reasonably achieve.  As used herein \"aspirations\" does not include mere short-term goals (such as making a particular meal tonight or driving to the store and back\nwithout a vehicular incident).  The aspired-to goals, in turn, are goals pertaining to a marked elevation in one's core competencies (such as an aspiration to master a particular game such as chess, to achieve a particular articulated and recognized\nlevel of martial arts proficiency, or to attain a particular articulated and recognized level of cooking proficiency), professional status (such as an aspiration to receive a particular advanced education degree, to pass a professional examination such\nas a state Bar examination of a Certified Public Accountants examination, or to become Board certified in a particular area of medical practice), or life experience milestone (such as an aspiration to climb Mount Everest, to visit every state capital, or\nto attend a game at every major league baseball park in the United States).  It will further be understood that the goal(s) of an aspiration is not something that can likely merely simply happen of its own accord; achieving an aspiration requires an\nintelligent effort to order one's life in a way that increases the likelihood of actually achieving the corresponding goal or goals to which that person aspires.  One aspires to one day run their own business as versus, for example, merely hoping to one\nday win the state lottery.\nA preference is a greater liking for one alternative over another or others.  A person can prefer, for example, that their steak is cooked \"medium\" rather than other alternatives such as \"rare\" or \"well done\" or a person can prefer to play golf\nin the morning rather than in the afternoon or evening.  Preferences can and do come into play when a given person makes purchasing decisions at a retail shopping facility.  Preferences in these regards can take the form of a preference for a particular\nbrand over other available brands or a preference for economy-sized packaging as versus, say, individual serving-sized packaging.\nValues, affinities, aspirations, and preferences are not necessarily wholly unrelated.  It is possible for a person's values, affinities, or aspirations to influence or even dictate their preferences in specific regards.  For example, a person's\nmoral code that values non-exploitive treatment of animals may lead them to prefer foods that include no animal-based ingredients and hence to prefer fruits and vegetables over beef and chicken offerings.  As another example, a person's affinity for a\nparticular musical group may lead them to prefer clothing that directly or indirectly references or otherwise represents their affinity for that group.  As yet another example, a person's aspirations to become a Certified Public Accountant may lead them\nto prefer business-related media content.\nWhile a value, affinity, or aspiration may give rise to or otherwise influence one or more corresponding preferences, however, is not to say that these things are all one and the same; they are not.  For example, a preference may represent\neither a principled or an unprincipled liking for one thing over another, while a value is the principle itself.  Accordingly, as used herein it will be understood that a partiality can include, in context, any one or more of a value-based,\naffinity-based, aspiration-based, and/or preference-based partiality unless one or more such features is specifically excluded per the needs of a given application setting.\nInformation regarding a given person's partialities can be acquired using any one or more of a variety of information-gathering and/or analytical approaches.  By one simple approach, a person may voluntarily disclose information regarding their\npartialities (for example, in response to an online questionnaire or survey or as part of their social media presence).  By another approach, the purchasing history for a given person can be analyzed to intuit the partialities that led to at least some\nof those purchases.  By yet another approach demographic information regarding a particular person can serve as yet another source that sheds light on their partialities.  Other ways that people reveal how they order their lives include but are not\nlimited to: (1) their social networking profiles and behaviors (such as the things they \"like\" via Facebook, the images they post via Pinterest, informal and formal comments they initiate or otherwise provide in response to third-party postings including\nstatements regarding their own personal long-term goals, the persons/topics they follow via Twitter, the photographs they publish via Picasso, and so forth); (2) their Internet surfing history; (3) their on-line or otherwise-published affinity-based\nmemberships; (4) real-time (or delayed) information (such as steps walked, calories burned, geographic location, activities experienced, and so forth) from any of a variety of personal sensors (such as smart phones, tablet/pad-styled computers, fitness\nwearables, Global Positioning System devices, and so forth) and the so-called Internet of Things (such as smart refrigerators and pantries, entertainment and information platforms, exercise and sporting equipment, and so forth); (5) instructions,\nselections, and other inputs (including inputs that occur within augmented-reality user environments) made by a person via any of a variety of interactive interfaces (such as keyboards and cursor control devices, voice recognition, gesture-based\ncontrols, and eye tracking-based controls), and so forth.\nThe present teachings employ a vector-based approach to facilitate characterizing, representing, understanding, and leveraging such partialities to thereby identify products (and/or services) that will, for a particular corresponding consumer,\nprovide for an improved or at least a favorable corresponding ordering for that consumer.  Vectors are directed quantities that each have both a magnitude and a direction.  Per the applicant's approach these vectors have a real, as versus a metaphorical,\nmeaning in the sense of Newtonian physics.  Generally speaking, each vector represents order imposed upon material space-time by a particular partiality.\nFIG. 6 provides some illustrative examples in these regards.  By one approach the vector 600 has a corresponding magnitude 601 (i.e., length) that represents the magnitude of the strength of the belief in the good that comes from that imposed\norder (which belief, in turn, can be a function, relatively speaking, of the extent to which the order for this particular partiality is enabled and/or achieved).  In this case, the greater the magnitude 601, the greater the strength of that belief and\nvice versa.  Per another example, the vector 600 has a corresponding angle A 602 that instead represents the foregoing magnitude of the strength of the belief (and where, for example, an angle of 0.degree.  represents no such belief and an angle of\n90.degree.  represents a highest magnitude in these regards, with other ranges being possible as desired).\nAccordingly, a vector serving as a partiality vector can have at least one of a magnitude and an angle that corresponds to a magnitude of a particular person's belief in an amount of good that comes from an order associated with a particular\npartiality.\nApplying force to displace an object with mass in the direction of a certain partiality-based order creates worth for a person who has that partiality.  The resultant work (i.e., that force multiplied by the distance the object moves) can be\nviewed as a worth vector having a magnitude equal to the accomplished work and having a direction that represents the corresponding imposed order.  If the resultant displacement results in more order of the kind that the person is partial to then the net\nresult is a notion of \"good.\" This \"good\" is a real quantity that exists in meta-physical space much like work is a real quantity in material space.  The link between the \"good\" in meta-physical space and the work in material space is that it takes work\nto impose order that has value.\nIn the context of a person, this effort can represent, quite literally, the effort that the person is willing to exert to be compliant with (or to otherwise serve) this particular partiality.  For example, a person who values animal rights would\nhave a large magnitude worth vector for this value if they exerted considerable physical effort towards this cause by, for example, volunteering at animal shelters or by attending protests of animal cruelty.\nWhile these teachings will readily employ a direct measurement of effort such as work done or time spent, these teachings will also accommodate using an indirect measurement of effort such as expense; in particular, money.  In many cases people\ntrade their direct labor for payment.  The labor may be manual or intellectual.  While salaries and payments can vary significantly from one person to another, a same sense of effort applies at least in a relative sense.\nAs a very specific example in these regards, there are wristwatches that require a skilled craftsman over a year to make.  The actual aggregated amount of force applied to displace the small components that comprise the wristwatch would be\nrelatively very small.  That said, the skilled craftsman acquired the necessary skill to so assemble the wristwatch over many years of applying force to displace thousands of little parts when assembly previous wristwatches.  That experience, based upon\na much larger aggregation of previously-exerted effort, represents a genuine part of the \"effort\" to make this particular wristwatch and hence is fairly considered as part of the wristwatch's worth.\nThe conventional forces working in each person's mind are typically more-or-less constantly evaluating the value propositions that correspond to a path of least effort to thereby order their lives towards the things they value.  A key reason\nthat happens is because the actual ordering occurs in material space and people must exert real energy in pursuit of their desired ordering.  People therefore naturally try to find the path with the least real energy expended that still moves them to the\nvalued order.  Accordingly, a trusted value proposition that offers a reduction of real energy will be embraced as being \"good\" because people will tend to be partial to anything that lowers the real energy they are required to exert while remaining\nconsistent with their partialities.\nFIG. 7 presents a space graph that illustrates many of the foregoing points.  A first vector 701 represents the time required to make such a wristwatch while a second vector 702 represents the order associated with such a device (in this case,\nthat order essentially represents the skill of the craftsman).  These two vectors 701 and 702 in turn sum to form a third vector 703 that constitutes a value vector for this wristwatch.  This value vector 703, in turn, is offset with respect to energy\n(i.e., the energy associated with manufacturing the wristwatch).\nA person partial to precision and/or to physically presenting an appearance of success and status (and who presumably has the wherewithal) may, in turn, be willing to spend $100,000 for such a wristwatch.  A person able to afford such a price,\nof course, may themselves be skilled at imposing a certain kind of order that other persons are partial to such that the amount of physical work represented by each spent dollar is small relative to an amount of dollars they receive when exercising their\nskill(s).  (Viewed another way, wearing an expensive wristwatch may lower the effort required for such a person to communicate that their own personal success comes from being highly skilled in a certain order of high worth.)\nGenerally speaking, all worth comes from imposing order on the material space-time.  The worth of a particular order generally increases as the skill required to impose the order increases.  Accordingly, unskilled labor may exchange $10 for\nevery hour worked where the work has a high content of unskilled physical labor while a highly-skilled data scientist may exchange $75 for every hour worked with very little accompanying physical effort.\nConsider a simple example where both of these laborers are partial to a well-ordered lawn and both have a corresponding partiality vector in those regards with a same magnitude.  To observe that partiality the unskilled laborer may own an\ninexpensive push power lawn mower that this person utilizes for an hour to mow their lawn.  The data scientist, on the other hand, pays someone else $75 in this example to mow their lawn.  In both cases these two individuals traded one hour of worth\ncreation to gain the same worth (to them) in the form of a well-ordered lawn; the unskilled laborer in the form of direct physical labor and the data scientist in the form of money that required one hour of their specialized effort to earn.\nThis same vector-based approach can also represent various products and services.  This is because products and services have worth (or not) because they can remove effort (or fail to remove effort) out of the customer's life in the direction of\nthe order to which the customer is partial.  In particular, a product has a perceived effort embedded into each dollar of cost in the same way that the customer has an amount of perceived effort embedded into each dollar earned.  A customer has an\nincreased likelihood of responding to an exchange of value if the vectors for the product and the customer's partiality are directionally aligned and where the magnitude of the vector as represented in monetary cost is somewhat greater than the worth\nembedded in the customer's dollar.\nPut simply, the magnitude (and/or angle) of a partiality vector for a person can represent, directly or indirectly, a corresponding effort the person is willing to exert to pursue that partiality.  There are various ways by which that value can\nbe determined.  As but one non-limiting example in these regards, the magnitude/angle V of a particular partiality vector can be expressed as:\n.function..times..times..times.  ##EQU00001## where X refers to any of a variety of inputs (such as those described above) that can impact the characterization of a particular partiality (and where these teachings will accommodate either or both\nsubjective and objective inputs as desired) and W refers to weighting factors that are appropriately applied the foregoing input values (and where, for example, these weighting factors can have values that themselves reflect a particular person's\nconsumer personality or otherwise as desired and can be static or dynamically valued in practice as desired).\nIn the context of a product (or service) the magnitude/angle of the corresponding vector can represent the reduction of effort that must be exerted when making use of this product to pursue that partiality, the effort that was expended in order\nto create the product/service, the effort that the person perceives can be personally saved while nevertheless promoting the desired order, and/or some other corresponding effort.  Taken as a whole the sum of all the vectors must be perceived to increase\nthe overall order to be considered a good product/service.\nIt may be noted that while reducing effort provides a very useful metric in these regards, it does not necessarily follow that a given person will always gravitate to that which most reduces effort in their life.  This is at least because a\ngiven person's values (for example) will establish a baseline against which a person may eschew some goods/services that might in fact lead to a greater overall reduction of effort but which would conflict, perhaps fundamentally, with their values.  As a\nsimple illustrative example, a given person might value physical activity.  Such a person could experience reduced effort (including effort represented via monetary costs) by simply sitting on their couch, but instead will pursue activities that involve\nthat valued physical activity.  That said, however, the goods and services that such a person might acquire in support of their physical activities are still likely to represent increased order in the form of reduced effort where that makes sense.  For\nexample, a person who favors rock climbing might also favor rock climbing clothing and supplies that render that activity safer to thereby reduce the effort required to prevent disorder as a consequence of a fall (and consequently increasing the good\noutcome of the rock climber's quality experience).\nBy forming reliable partiality vectors for various individuals and corresponding product characterization vectors for a variety of products and/or services, these teachings provide a useful and reliable way to identify products/services that\naccord with a given person's own partialities (whether those partialities are based on their values, their affinities, their preferences, or otherwise).\nIt is of course possible that partiality vectors may not be available yet for a given person due to a lack of sufficient specific source information from or regarding that person.  In this case it may nevertheless be possible to use one or more\npartiality vector templates that generally represent certain groups of people that fairly include this particular person.  For example, if the person's gender, age, academic status/achievements, and/or postal code are known it may be useful to utilize a\ntemplate that includes one or more partiality vectors that represent some statistical average or norm of other persons matching those same characterizing parameters.  (Of course, while it may be useful to at least begin to employ these teachings with\ncertain individuals by using one or more such templates, these teachings will also accommodate modifying (perhaps significantly and perhaps quickly) such a starting point over time as part of developing a more personal set of partiality vectors that are\nspecific to the individual.) A variety of templates could be developed based, for example, on professions, academic pursuits and achievements, nationalities and/or ethnicities, characterizing hobbies, and the like.\nFIG. 8 presents a process 800 that illustrates yet another approach in these regards.  For the sake of an illustrative example it will be presumed here that a control circuit of choice (with useful examples in these regards being presented\nfurther below) carries out one or more of the described steps/actions.\nAt block 801 the control circuit monitors a person's behavior over time.  The range of monitored behaviors can vary with the individual and the application setting.  By one approach, only behaviors that the person has specifically approved for\nmonitoring are so monitored.\nAs one example in these regards, this monitoring can be based, in whole or in part, upon interaction records 802 that reflect or otherwise track, for example, the monitored person's purchases.  This can include specific items purchased by the\nperson, from whom the items were purchased, where the items were purchased, how the items were purchased (for example, at a bricks-and-mortar physical retail shopping facility or via an on-line shopping opportunity), the price paid for the items, and/or\nwhich items were returned and when), and so forth.\nAs another example in these regards the interaction records 802 can pertain to the social networking behaviors of the monitored person including such things as their \"likes,\" their posted comments, images, and tweets, affinity group\naffiliations, their on-line profiles, their playlists and other indicated \"favorites,\" and so forth.  Such information can sometimes comprise a direct indication of a particular partiality or, in other cases, can indirectly point towards a particular\npartiality and/or indicate a relative strength of the person's partiality.\nOther interaction records of potential interest include but are not limited to registered political affiliations and activities, credit reports, military-service history, educational and employment history, and so forth.\nAs another example, in lieu of the foregoing or in combination therewith, this monitoring can be based, in whole or in part, upon sensor inputs from the Internet of Things (IoT) 803.  The Internet of Things refers to the Internet-based\ninter-working of a wide variety of physical devices including but not limited to wearable or carriable devices, vehicles, buildings, and other items that are embedded with electronics, software, sensors, network connectivity, and sometimes actuators that\nenable these objects to collect and exchange data via the Internet.  In particular, the Internet of Things allows people and objects pertaining to people to be sensed and corresponding information to be transferred to remote locations via intervening\nnetwork infrastructure.  Some experts estimate that the Internet of Things will consist of almost 50 billion such objects by 2020.  (Further description in these regards appears further herein.)\nDepending upon what sensors a person encounters, information can be available regarding a person's travels, lifestyle, calorie expenditure over time, diet, habits, interests and affinities, choices and assumed risks, and so forth.  This process\n800 will accommodate either or both real-time or non-real time access to such information as well as either or both push and pull-based paradigms.\nBy monitoring a person's behavior over time, a general sense of that person's daily routine can be established (sometimes referred to herein as a routine experiential base state).  As a very simple illustrative example, a routine experiential\nbase state can include a typical daily event timeline for the person that represents typical locations that the person visits and/or typical activities in which the person engages.  The timeline can indicate those activities that tend to be scheduled\n(such as the person's time at their place of employment or their time spent at their child's sports practices) as well as visits/activities that are normal for the person though not necessarily undertaken with strict observance to a corresponding\nschedule (such as visits to local stores, movie theaters, and the homes of nearby friends and relatives).\nAt block 804 this process 800 provides for detecting changes to that established routine.  These teachings are highly flexible in these regards and will accommodate a wide variety of \"changes.\" Some illustrative examples include but are not\nlimited to changes with respect to a person's travel schedule, destinations visited or time spent at a particular destination, the purchase and/or use of new and/or different products or services, a subscription to a new magazine, a new Rich Site Summary\n(RSS) feed or a subscription to a new blog, a new \"friend\" or \"connection\" on a social networking site, a new person, entity, or cause to follow on a Twitter-like social networking service, enrollment in an academic program, and so forth.\nUpon detecting a change, at optional block 805 this process 800 will accommodate assessing whether the detected change constitutes a sufficient amount of data to warrant proceeding further with the process.  This assessment can comprise, for\nexample, assessing whether a sufficient number (i.e., a predetermined number) of instances of this particular detected change have occurred over some predetermined period of time.  As another example, this assessment can comprise assessing whether the\nspecific details of the detected change are sufficient in quantity and/or quality to warrant further processing.  For example, merely detecting that the person has not arrived at their usual 6 PM-Wednesday dance class may not be enough information, in\nand of itself, to warrant further processing, in which case the information regarding the detected change may be discarded or, in the alternative, cached for further consideration and use in conjunction or aggregation with other, later-detected changes.\nAt block 807 this process 800 uses these detected changes to create a spectral profile for the monitored person.  FIG. 9 provides an illustrative example in these regards with the spectral profile denoted by reference numeral 901.  In this\nillustrative example the spectral profile 901 represents changes to the person's behavior over a given period of time (such as an hour, a day, a week, or some other temporal window of choice).  Such a spectral profile can be as multidimensional as may\nsuit the needs of a given application setting.\nAt optional block 807 this process 800 then provides for determining whether there is a statistically significant correlation between the aforementioned spectral profile and any of a plurality of like characterizations 808.  The like\ncharacterizations 808 can comprise, for example, spectral profiles that represent an average of groupings of people who share many of the same (or all of the same) identified partialities.  As a very simple illustrative example in these regards, a first\nsuch characterization 902 might represent a composite view of a first group of people who have three similar partialities but a dissimilar fourth partiality while another of the characterizations 903 might represent a composite view of a different group\nof people who share all four partialities.\nThe aforementioned \"statistically significant\" standard can be selected and/or adjusted to suit the needs of a given application setting.  The scale or units by which this measurement can be assessed can be any known, relevant scale/unit\nincluding, but not limited to, scales such as standard deviations, cumulative percentages, percentile equivalents, Z-scores, T-scores, standard nines, and percentages in standard nines.  Similarly, the threshold by which the level of statistical\nsignificance is measured/assessed can be set and selected as desired.  By one approach the threshold is static such that the same threshold is employed regardless of the circumstances.  By another approach the threshold is dynamic and can vary with such\nthings as the relative size of the population of people upon which each of the characterizations 808 are based and/or the amount of data and/or the duration of time over which data is available for the monitored person.\nReferring now to FIG. 10, by one approach the selected characterization (denoted by reference numeral 1001 in this figure) comprises an activity profile over time of one or more human behaviors.  Examples of behaviors include but are not limited\nto such things as repeated purchases over time of particular commodities, repeated visits over time to particular locales such as certain restaurants, retail outlets, athletic or entertainment facilities, and so forth, and repeated activities over time\nsuch as floor cleaning, dish washing, car cleaning, cooking, volunteering, and so forth.  Those skilled in the art will understand and appreciate, however, that the selected characterization is not, in and of itself, demographic data (as described\nelsewhere herein).\nMore particularly, the characterization 1001 can represent (in this example, for a plurality of different behaviors) each instance over the monitored/sampled period of time when the monitored/represented person engages in a particular\nrepresented behavior (such as visiting a neighborhood gym, purchasing a particular product (such as a consumable perishable or a cleaning product), interacts with a particular affinity group via social networking, and so forth).  The relevant overall\ntime frame can be chosen as desired and can range in a typical application setting from a few hours or one day to many days, weeks, or even months or years.  (It will be understood by those skilled in the art that the particular characterization shown in\nFIG. 10 is intended to serve an illustrative purpose and does not necessarily represent or mimic any particular behavior or set of behaviors).\nGenerally speaking it is anticipated that many behaviors of interest will occur at regular or somewhat regular intervals and hence will have a corresponding frequency or periodicity of occurrence.  For some behaviors that frequency of occurrence\nmay be relatively often (for example, oral hygiene events that occur at least once, and often multiple times each day) while other behaviors (such as the preparation of a holiday meal) may occur much less frequently (such as only once, or only a few\ntimes, each year).  For at least some behaviors of interest that general (or specific) frequency of occurrence can serve as a significant indication of a person's corresponding partialities.\nBy one approach, these teachings will accommodate detecting and timestamping each and every event/activity/behavior or interest as it happens.  Such an approach can be memory intensive and require considerable supporting infrastructure.\nThe present teachings will also accommodate, however, using any of a variety of sampling periods in these regards.  In some cases, for example, the sampling period per se may be one week in duration.  In that case, it may be sufficient to know\nthat the monitored person engaged in a particular activity (such as cleaning their car) a certain number of times during that week without known precisely when, during that week, the activity occurred.  In other cases it may be appropriate or even\ndesirable, to provide greater granularity in these regards.  For example, it may be better to know which days the person engaged in the particular activity or even the particular hour of the day.  Depending upon the selected granularity/resolution,\nselecting an appropriate sampling window can help reduce data storage requirements (and/or corresponding analysis/processing overhead requirements).\nAlthough a given person's behaviors may not, strictly speaking, be continuous waves (as shown in FIG. 10) in the same sense as, for example, a radio or acoustic wave, it will nevertheless be understood that such a behavioral characterization\n1001 can itself be broken down into a plurality of sub-waves 1002 that, when summed together, equal or at least approximate to some satisfactory degree the behavioral characterization 1001 itself.  (The more-discrete and sometimes less-rigidly periodic\nnature of the monitored behaviors may introduce a certain amount of error into the corresponding sub-waves.  There are various mathematically satisfactory ways by which such error can be accommodated including by use of weighting factors and/or expressed\ntolerances that correspond to the resultant sub-waves.)\nIt should also be understood that each such sub-wave can often itself be associated with one or more corresponding discrete partialities.  For example, a partiality reflecting concern for the environment may, in turn, influence many of the\nincluded behavioral events (whether they are similar or dissimilar behaviors or not) and accordingly may, as a sub-wave, comprise a relatively significant contributing factor to the overall set of behaviors as monitored over time.  These sub-waves\n(partialities) can in turn be clearly revealed and presented by employing a transform (such as a Fourier transform) of choice to yield a spectral profile 1003 wherein the X axis represents frequency and the Y axis represents the magnitude of the response\nof the monitored person at each frequency/sub-wave of interest.\nThis spectral response of a given individual--which is generated from a time series of events that reflect/track that person's behavior--yields frequency response characteristics for that person that are analogous to the frequency response\ncharacteristics of physical systems such as, for example, an analog or digital filter or a second order electrical or mechanical system.  Referring to FIG. 11, for many people the spectral profile of the individual person will exhibit a primary frequency\n1101 for which the greatest response (perhaps many orders of magnitude greater than other evident frequencies) to life is exhibited and apparent.  In addition, the spectral profile may also possibly identify one or more secondary frequencies 1102 above\nand/or below that primary frequency 1101.  (It may be useful in many application settings to filter out more distant frequencies 1103 having considerably lower magnitudes because of a reduced likelihood of relevance and/or because of a possibility of\nerror in those regards; in effect, these lower-magnitude signals constitute noise that such filtering can remove from consideration.)\nAs noted above, the present teachings will accommodate using sampling windows of varying size.  By one approach the frequency of events that correspond to a particular partiality can serve as a basis for selecting a particular sampling rate to\nuse when monitoring for such events.  For example, Nyquist-based sampling rules (which dictate sampling at a rate at least twice that of the frequency of the signal of interest) can lead one to choose a particular sampling rate (and the resultant\ncorresponding sampling window size).\nAs a simple illustration, if the activity of interest occurs only once a week, then using a sampling of half-a-week and sampling twice during the course of a given week will adequately capture the monitored event.  If the monitored person's\nbehavior should change, a corresponding change can be automatically made.  For example, if the person in the foregoing example begins to engage in the specified activity three times a week, the sampling rate can be switched to six times per week (in\nconjunction with a sampling window that is resized accordingly).\nBy one approach, the sampling rate can be selected and used on a partiality-by-partiality basis.  This approach can be especially useful when different monitoring modalities are employed to monitor events that correspond to different\npartialities.  If desired, however, a single sampling rate can be employed and used for a plurality (or even all) partialities/behaviors.  In that case, it can be useful to identify the behavior that is exemplified most often (i.e., that behavior which\nhas the highest frequency) and then select a sampling rate that is at least twice that rate of behavioral realization, as that sampling rate will serve well and suffice for both that highest-frequency behavior and all lower-frequency behaviors as well.\nIt can be useful in many application settings to assume that the foregoing spectral profile of a given person is an inherent and inertial characteristic of that person and that this spectral profile, in essence, provides a personality profile of\nthat person that reflects not only how but why this person responds to a variety of life experiences.  More importantly, the partialities expressed by the spectral profile for a given person will tend to persist going forward and will not typically\nchange significantly in the absence of some powerful external influence (including but not limited to significant life events such as, for example, marriage, children, loss of job, promotion, and so forth).\nIn any event, by knowing a priori the particular partialities (and corresponding strengths) that underlie the particular characterization 1001, those partialities can be used as an initial template for a person whose own behaviors permit the\nselection of that particular characterization 1001.  In particular, those particularities can be used, at least initially, for a person for whom an amount of data is not otherwise available to construct a similarly rich set of partiality information.\nAs a very specific and non-limiting example, per these teachings the choice to make a particular product can include consideration of one or more value systems of potential customers.  When considering persons who value animal rights, a product\nconceived to cater to that value proposition may require a corresponding exertion of additional effort to order material space-time such that the product is made in a way that (A) does not harm animals and/or (even better) (B) improves life for animals\n(for example, eggs obtained from free range chickens).  The reason a person exerts effort to order material space-time is because they believe it is good to do and/or not good to not do so.  When a person exerts effort to do good (per their personal\nstandard of \"good\") and if that person believes that a particular order in material space-time (that includes the purchase of a particular product) is good to achieve, then that person will also believe that it is good to buy as much of that particular\nproduct (in order to achieve that good order) as their finances and needs reasonably permit (all other things being equal).\nThe aforementioned additional effort to provide such a product can (typically) convert to a premium that adds to the price of that product.  A customer who puts out extra effort in their life to value animal rights will typically be willing to\npay that extra premium to cover that additional effort exerted by the company.  By one approach a magnitude that corresponds to the additional effort exerted by the company can be added to the person's corresponding value vector because a product or\nservice has worth to the extent that the product/service allows a person to order material space-time in accordance with their own personal value system while allowing that person to exert less of their own effort in direct support of that value (since\nmoney is a scalar form of effort).\nBy one approach there can be hundreds or even thousands of identified partialities.  In this case, if desired, each product/service of interest can be assessed with respect to each and every one of these partialities and a corresponding\npartiality vector formed to thereby build a collection of partiality vectors that collectively characterize the product/service.  As a very simple example in these regards, a given laundry detergent might have a cleanliness partiality vector with a\nrelatively high magnitude (representing the effectiveness of the detergent), a ecology partiality vector that might be relatively low or possibly even having a negative magnitude (representing an ecologically disadvantageous effect of the detergent post\nusage due to increased disorder in the environment), and a simple-life partiality vector with only a modest magnitude (representing the relative ease of use of the detergent but also that the detergent presupposes that the user has a modern washing\nmachine).  Other partiality vectors for this detergent, representing such things as nutrition or mental acuity, might have magnitudes of zero.\nAs mentioned above, these teachings can accommodate partiality vectors having a negative magnitude.  Consider, for example, a partiality vector representing a desire to order things to reduce one's so-called carbon footprint.  A magnitude of\nzero for this vector would indicate a completely neutral effect with respect to carbon emissions while any positive-valued magnitudes would represent a net reduction in the amount of carbon in the atmosphere, hence increasing the ability of the\nenvironment to be ordered.  Negative magnitudes would represent the introduction of carbon emissions that increases disorder of the environment (for example, as a result of manufacturing the product, transporting the product, and/or using the product)\nFIG. 12 presents one non-limiting illustrative example in these regards.  The illustrated process presumes the availability of a library 1201 of correlated relationships between product/service claims and particular imposed orders.  Examples of\nproduct/service claims include such things as claims that a particular product results in cleaner laundry or household surfaces, or that a particular product is made in a particular political region (such as a particular state or country), or that a\nparticular product is better for the environment, and so forth.  The imposed orders to which such claims are correlated can reflect orders as described above that pertain to corresponding partialities.\nAt block 1202 this process provides for decoding one or more partiality propositions from specific product packaging (or service claims).  For example, the particular textual/graphics-based claims presented on the packaging of a given product\ncan be used to access the aforementioned library 1201 to identify one or more corresponding imposed orders from which one or more corresponding partialities can then be identified.\nAt block 1203 this process provides for evaluating the trustworthiness of the aforementioned claims.  This evaluation can be based upon any one or more of a variety of data points as desired.  FIG. 12 illustrates four significant possibilities\nin these regards.  For example, at block 1204 an actual or estimated research and development effort can be quantified for each claim pertaining to a partiality.  At block 1205 an actual or estimated component sourcing effort for the product in question\ncan be quantified for each claim pertaining to a partiality.  At block 1206 an actual or estimated manufacturing effort for the product in question can be quantified for each claim pertaining to a partiality.  And at block 1207 an actual or estimated\nmerchandising effort for the product in question can be quantified for each claim pertaining to a partiality.\nIf desired, a product claim lacking sufficient trustworthiness may simply be excluded from further consideration.  By another approach the product claim can remain in play but a lack of trustworthiness can be reflected, for example, in a\ncorresponding partiality vector direction or magnitude for this particular product.\nAt block 1208 this process provides for assigning an effort magnitude for each evaluated product/service claim.  That effort can constitute a one-dimensional effort (reflecting, for example, only the manufacturing effort) or can constitute a\nmultidimensional effort that reflects, for example, various categories of effort such as the aforementioned research and development effort, component sourcing effort, manufacturing effort, and so forth.\nAt block 1209 this process provides for identifying a cost component of each claim, this cost component representing a monetary value.  At block 1210 this process can use the foregoing information with a product/service partiality propositions\nvector engine to generate a library 1211 of one or more corresponding partiality vectors for the processed products/services.  Such a library can then be used as described herein in conjunction with partiality vector information for various persons to\nidentify, for example, products/services that are well aligned with the partialities of specific individuals.\nFIG. 13 provides another illustrative example in these same regards and may be employed in lieu of the foregoing or in total or partial combination therewith.  Generally speaking, this process 1300 serves to facilitate the formation of product\ncharacterization vectors for each of a plurality of different products where the magnitude of the vector length (and/or the vector angle) has a magnitude that represents a reduction of exerted effort associated with the corresponding product to pursue a\ncorresponding user partiality.\nBy one approach, and as illustrated in FIG. 13, this process 1300 can be carried out by a control circuit of choice.  Specific examples of control circuits are provided elsewhere herein.\nAs described further herein in detail, this process 1300 makes use of information regarding various characterizations of a plurality of different products.  These teachings are highly flexible in practice and will accommodate a wide variety of\npossible information sources and types of information.  By one optional approach, and as shown at optional block 1301, the control circuit can receive (for example, via a corresponding network interface of choice) product characterization information\nfrom a third-party product testing service.  The magazine/web resource Consumers Report provides one useful example in these regards.  Such a resource provides objective content based upon testing, evaluation, and comparisons (and sometimes also provides\nsubjective content regarding such things as aesthetics, ease of use, and so forth) and this content, provided as-is or pre-processed as desired, can readily serve as useful third-party product testing service product characterization information.\nAs another example, any of a variety of product-testing blogs that are published on the Internet can be similarly accessed and the product characterization information available at such resources harvested and received by the control circuit. \n(The expression \"third party\" will be understood to refer to an entity other than the entity that operates/controls the control circuit and other than the entity that provides the corresponding product itself.)\nAs another example, and as illustrated at optional block 1302, the control circuit can receive (again, for example, via a network interface of choice) user-based product characterization information.  Examples in these regards include but are\nnot limited to user reviews provided on-line at various retail sites for products offered for sale at such sites.  The reviews can comprise metricized content (for example, a rating expressed as a certain number of stars out of a total available number\nof stars, such as 3 stars out of 5 possible stars) and/or text where the reviewers can enter their objective and subjective information regarding their observations and experiences with the reviewed products.  In this case, \"user-based\" will be\nunderstood to refer to users who are not necessarily professional reviewers (though it is possible that content from such persons may be included with the information provided at such a resource) but who presumably purchased the product being reviewed\nand who have personal experience with that product that forms the basis of their review.  By one approach the resource that offers such content may constitute a third party as defined above, but these teachings will also accommodate obtaining such\ncontent from a resource operated or sponsored by the enterprise that controls/operates this control circuit.\nIn any event, this process 1300 provides for accessing (see block 1304) information regarding various characterizations of each of a plurality of different products.  This information 1304 can be gleaned as described above and/or can be obtained\nand/or developed using other resources as desired.  As one illustrative example in these regards, the manufacturer and/or distributor of certain products may source useful content in these regards.\nThese teachings will accommodate a wide variety of information sources and types including both objective characterizing and/or subjective characterizing information for the aforementioned products.\nExamples of objective characterizing information include, but are not limited to, ingredients information (i.e., specific components/materials from which the product is made), manufacturing locale information (such as country of origin, state of\norigin, municipality of origin, region of origin, and so forth), efficacy information (such as metrics regarding the relative effectiveness of the product to achieve a particular end-use result), cost information (such as per product, per ounce, per\napplication or use, and so forth), availability information (such as present in-store availability, on-hand inventory availability at a relevant distribution center, likely or estimated shipping date, and so forth), environmental impact information\n(regarding, for example, the materials from which the product is made, one or more manufacturing processes by which the product is made, environmental impact associated with use of the product, and so forth), and so forth.\nExamples of subjective characterizing information include but are not limited to user sensory perception information (regarding, for example, heaviness or lightness, speed of use, effort associated with use, smell, and so forth), aesthetics\ninformation (regarding, for example, how attractive or unattractive the product is in appearance, how well the product matches or accords with a particular design paradigm or theme, and so forth), trustworthiness information (regarding, for example, user\nperceptions regarding how likely the product is perceived to accomplish a particular purpose or to avoid causing a particular collateral harm), trendiness information, and so forth.\nThis information 1304 can be curated (or not), filtered, sorted, weighted (in accordance with a relative degree of trust, for example, accorded to a particular source of particular information), and otherwise categorized and utilized as desired. As one simple example in these regards, for some products it may be desirable to only use relatively fresh information (i.e., information not older than some specific cut-off date) while for other products it may be acceptable (or even desirable) to use,\nin lieu of fresh information or in combination therewith, relatively older information.  As another simple example, it may be useful to use only information from one particular geographic region to characterize a particular product and to therefore not\nuse information from other geographic regions.\nAt block 1303 the control circuit uses the foregoing information 1304 to form product characterization vectors for each of the plurality of different products.  By one approach these product characterization vectors have a magnitude (for the\nlength of the vector and/or the angle of the vector) that represents a reduction of exerted effort associated with the corresponding product to pursue a corresponding user partiality (as is otherwise discussed herein).\nIt is possible that a conflict will become evident as between various ones of the aforementioned items of information 1304.  In particular, the available characterizations for a given product may not all be the same or otherwise in accord with\none another.  In some cases it may be appropriate to literally or effectively calculate and use an average to accommodate such a conflict.  In other cases it may be useful to use one or more other predetermined conflict resolution rules 1305 to\nautomatically resolve such conflicts when forming the aforementioned product characterization vectors.\nThese teachings will accommodate any of a variety of rules in these regards.  By one approach, for example, the rule can be based upon the age of the information (where, for example the older (or newer, if desired) data is preferred or weighted\nmore heavily than the newer (or older, if desired) data.  By another approach, the rule can be based upon a number of user reviews upon which the user-based product characterization information is based (where, for example, the rule specifies that\nwhichever user-based product characterization information is based upon a larger number of user reviews will prevail in the event of a conflict).  By another approach, the rule can be based upon information regarding historical accuracy of information\nfrom a particular information source (where, for example, the rule specifies that information from a source with a better historical record of accuracy shall prevail over information from a source with a poorer historical record of accuracy in the event\nof a conflict).\nBy yet another approach, the rule can be based upon social media.  For example, social media-posted reviews may be used as a tie-breaker in the event of a conflict between other more-favored sources.  By another approach, the rule can be based\nupon a trending analysis.  And by yet another approach the rule can be based upon the relative strength of brand awareness for the product at issue (where, for example, the rule specifies resolving a conflict in favor of a more favorable characterization\nwhen dealing with a product from a strong brand that evidences considerable consumer goodwill and trust).\nIt will be understood that the foregoing examples are intended to serve an illustrative purpose and are not offered as an exhaustive listing in these regards.  It will also be understood that any two or more of the foregoing rules can be used in\ncombination with one another to resolve the aforementioned conflicts.\nBy one approach the aforementioned product characterization vectors are formed to serve as a universal characterization of a given product.  By another approach, however, the aforementioned information 1304 can be used to form product\ncharacterization vectors for a same characterization factor for a same product to thereby correspond to different usage circumstances of that same product.  Those different usage circumstances might comprise, for example, different geographic regions of\nusage, different levels of user expertise (where, for example, a skilled, professional user might have different needs and expectations for the product than a casual, lay user), different levels of expected use, and so forth.  In particular, the\ndifferent vectorized results for a same characterization factor for a same product may have differing magnitudes from one another to correspond to different amounts of reduction of the exerted effort associated with that product under the different usage\ncircumstances.\nAs noted above, the magnitude corresponding to a particular partiality vector for a particular person can be expressed by the angle of that partiality vector.  FIG. 14 provides an illustrative example in these regards.  In this example the\npartiality vector 1401 has an angle M 1402 (and where the range of available positive magnitudes range from a minimal magnitude represented by 0.degree.  (as denoted by reference numeral 1403) to a maximum magnitude represented by 90.degree.  (as denoted\nby reference numeral 1404)).  Accordingly, the person to whom this partiality vector 1401 pertains has a relatively strong (but not absolute) belief in an amount of good that comes from an order associated with that partiality.\nFIG. 15, in turn, presents that partiality vector 1501 in context with the product characterization vectors 1501 and 1503 for a first product and a second product, respectively.  In this example the product characterization vector 1501 for the\nfirst product has an angle Y 1502 that is greater than the angle M 1402 for the aforementioned partiality vector 1401 by a relatively small amount while the product characterization vector 1503 for the second product has an angle X 1504 that is\nconsiderably smaller than the angle M 1402 for the partiality vector 1401.\nSince, in this example, the angles of the various vectors represent the magnitude of the person's specified partiality or the extent to which the product aligns with that partiality, respectively, vector dot product calculations can serve to\nhelp identify which product best aligns with this partiality.  Such an approach can be particularly useful when the lengths of the vectors are allowed to vary as a function of one or more parameters of interest.  As those skilled in the art will\nunderstand, a vector dot product is an algebraic operation that takes two equal-length sequences of numbers (in this case, coordinate vectors) and returns a single number.\nThis operation can be defined either algebraically or geometrically.  Algebraically, it is the sum of the products of the corresponding entries of the two sequences of numbers.  Geometrically, it is the product of the Euclidean magnitudes of the\ntwo vectors and the cosine of the angle between them.  The result is a scalar rather than a vector.  As regards the present illustrative example, the resultant scaler value for the vector dot product of the product 1 vector 1501 with the partiality\nvector 1401 will be larger than the resultant scaler value for the vector dot product of the product 2 vector 1503 with the partiality vector 1401.  Accordingly, when using vector angles to impart this magnitude information, the vector dot product\noperation provides a simple and convenient way to determine proximity between a particular partiality and the performance/properties of a particular product to thereby greatly facilitate identifying a best product amongst a plurality of candidate\nproducts.\nBy way of further illustration, consider an example where a particular consumer has a strong partiality for organic produce and is financially able to afford to pay to observe that partiality.  A dot product result for that person with respect\nto a product characterization vector(s) for organic apples that represent a cost of $10 on a weekly basis (i.e., CvP1v) might equal (1,1), hence yielding a scalar result of .parallel.1.parallel.  (where Cv refers to the corresponding partiality vector\nfor this person and P1v represents the corresponding product characterization vector for these organic apples).  Conversely, a dot product result for this same person with respect to a product characterization vector(s) for non-organic apples that\nrepresent a cost of $5 on a weekly basis (i.e., CvP2v) might instead equal (1,0), hence yielding a scalar result of .parallel.1/2.parallel..  Accordingly, although the organic apples cost more than the non-organic apples, the dot product result for the\norganic apples exceeds the dot product result for the non-organic apples and therefore identifies the more expensive organic apples as being the best choice for this person.\nTo continue with the foregoing example, consider now what happens when this person subsequently experiences some financial misfortune (for example, they lose their job and have not yet found substitute employment).  Such an event can present the\n\"force\" necessary to alter the previously-established \"inertia\" of this person's steady-state partialities; in particular, these negatively-changed financial circumstances (in this example) alter this person's budget sensitivities (though not, of course\ntheir partiality for organic produce as compared to non-organic produce).  The scalar result of the dot product for the $5/week non-organic apples may remain the same (i.e., in this example, .parallel.1/2.parallel.), but the dot product for the $10/week\norganic apples may now drop (for example, to .parallel.1/2.parallel.  as well).  Dropping the quantity of organic apples purchased, however, to reflect the tightened financial circumstances for this person may yield a better dot product result.  For\nexample, purchasing only $5 (per week) of organic apples may produce a dot product result of .parallel.1.parallel..  The best result for this person, then, under these circumstances, is a lesser quantity of organic apples rather than a larger quantity of\nnon-organic apples.\nIn a typical application setting, it is possible that this person's loss of employment is not, in fact, known to the system.  Instead, however, this person's change of behavior (i.e., reducing the quantity of the organic apples that are\npurchased each week) might well be tracked and processed to adjust one or more partialities (either through an addition or deletion of one or more partialities and/or by adjusting the corresponding partiality magnitude) to thereby yield this new result\nas a preferred result.\nThe foregoing simple examples clearly illustrate that vector dot product approaches can be a simple yet powerful way to quickly eliminate some product options while simultaneously quickly highlighting one or more product options as being\nespecially suitable for a given person.\nSuch vector dot product calculations and results, in turn, help illustrate another point as well.  As noted above, sine waves can serve as a potentially useful way to characterize and view partiality information for both people and\nproducts/services.  In those regards, it is worth noting that a vector dot product result can be a positive, zero, or even negative value.  That, in turn, suggests representing a particular solution as a normalization of the dot product value relative to\nthe maximum possible value of the dot product.  Approached this way, the maximum amplitude of a particular sine wave will typically represent a best solution.\nTaking this approach further, by one approach the frequency (or, if desired, phase) of the sine wave solution can provide an indication of the sensitivity of the person to product choices (for example, a higher frequency can indicate a\nrelatively highly reactive sensitivity while a lower frequency can indicate the opposite).  A highly sensitive person is likely to be less receptive to solutions that are less than fully optimum and hence can help to narrow the field of candidate\nproducts while, conversely, a less sensitive person is likely to be more receptive to solutions that are less than fully optimum and can help to expand the field of candidate products.\nFIG. 16 presents an illustrative apparatus 1600 for conducting, containing, and utilizing the foregoing content and capabilities.  In this particular example, the enabling apparatus 1600 includes a control circuit 1601.  Being a \"circuit,\" the\ncontrol circuit 1601 therefore comprises structure that includes at least one (and typically many) electrically-conductive paths (such as paths comprised of a conductive metal such as copper or silver) that convey electricity in an ordered manner, which\npath(s) will also typically include corresponding electrical components (both passive (such as resistors and capacitors) and active (such as any of a variety of semiconductor-based devices) as appropriate) to permit the circuit to effect the control\naspect of these teachings.\nSuch a control circuit 1601 can comprise a fixed-purpose hard-wired hardware platform (including but not limited to an application-specific integrated circuit (ASIC) (which is an integrated circuit that is customized by design for a particular\nuse, rather than intended for general-purpose use), a field-programmable gate array (FPGA), and the like) or can comprise a partially or wholly-programmable hardware platform (including but not limited to microcontrollers, microprocessors, and the like). These architectural options for such structures are well known and understood in the art and require no further description here.  This control circuit 1601 is configured (for example, by using corresponding programming as will be well understood by\nthose skilled in the art) to carry out one or more of the steps, actions, and/or functions described herein.\nBy one optional approach the control circuit 1601 operably couples to a memory 1602.  This memory 1602 may be integral to the control circuit 1601 or can be physically discrete (in whole or in part) from the control circuit 1601 as desired. \nThis memory 1602 can also be local with respect to the control circuit 1601 (where, for example, both share a common circuit board, chassis, power supply, and/or housing) or can be partially or wholly remote with respect to the control circuit 1601\n(where, for example, the memory 1602 is physically located in another facility, metropolitan area, or even country as compared to the control circuit 1601).\nThis memory 1602 can serve, for example, to non-transitorily store the computer instructions that, when executed by the control circuit 1601, cause the control circuit 1601 to behave as described herein.  (As used herein, this reference to\n\"non-transitorily\" will be understood to refer to a non-ephemeral state for the stored contents (and hence excludes when the stored contents merely constitute signals or waves) rather than volatility of the storage media itself and hence includes both\nnon-volatile memory (such as read-only memory (ROM) as well as volatile memory (such as an erasable programmable read-only memory (EPROM).)\nEither stored in this memory 1602 or, as illustrated, in a separate memory 1603 are the vectorized characterizations 1604 for each of a plurality of products 1605 (represented here by a first product through an Nth product where \"N\" is an\ninteger greater than \"1\").  In addition, and again either stored in this memory 1602 or, as illustrated, in a separate memory 1606 are the vectorized characterizations 1607 for each of a plurality of individual persons 1608 (represented here by a first\nperson through a Zth person wherein \"Z\" is also an integer greater than \"1\").\nIn this example the control circuit 1601 also operably couples to a network interface 1609.  So configured the control circuit 1601 can communicate with other elements (both within the apparatus 1600 and external thereto) via the network\ninterface 1609.  Network interfaces, including both wireless and non-wireless platforms, are well understood in the art and require no particular elaboration here.  This network interface 1609 can compatibly communicate via whatever network or networks\n1610 may be appropriate to suit the particular needs of a given application setting.  Both communication networks and network interfaces are well understood areas of prior art endeavor and therefore no further elaboration will be provided here in those\nregards for the sake of brevity.\nBy one approach, and referring now to FIG. 17, the control circuit 1601 is configured to use the aforementioned partiality vectors 1607 and the vectorized product characterizations 1604 to define a plurality of solutions that collectively form a\nmultidimensional surface (per block 1701).  FIG. 18 provides an illustrative example in these regards.  FIG. 18 represents an N-dimensional space 1800 and where the aforementioned information for a particular customer yielded a multi-dimensional surface\ndenoted by reference numeral 1801.  (The relevant value space is an N-dimensional space where the belief in the value of a particular ordering of one's life only acts on value propositions in that space as a function of a least-effort functional\nrelationship.)\nGenerally speaking, this surface 1801 represents all possible solutions based upon the foregoing information.  Accordingly, in a typical application setting this surface 1801 will contain/represent a plurality of discrete solutions.  That said,\nand also in a typical application setting, not all of those solutions will be similarly preferable.  Instead, one or more of those solutions may be particularly useful/appropriate at a given time, in a given place, for a given customer.\nWith continued reference to FIGS. 17 and 18, at optional block 1702 the control circuit 1601 can be configured to use information for the customer 1703 (other than the aforementioned partiality vectors 1607) to constrain a selection area 1802 on\nthe multi-dimensional surface 1801 from which at least one product can be selected for this particular customer.  By one approach, for example, the constraints can be selected such that the resultant selection area 1802 represents the best 95th\npercentile of the solution space.  Other target sizes for the selection area 1802 are of course possible and may be useful in a given application setting.\nThe aforementioned other information 1703 can comprise any of a variety of information types.  By one approach, for example, this other information comprises objective information.  (As used herein, \"objective information\" will be understood to\nconstitute information that is not influenced by personal feelings or opinions and hence constitutes unbiased, neutral facts.)\nOne particularly useful category of objective information comprises objective information regarding the customer.  Examples in these regards include, but are not limited to, location information regarding a past, present, or planned/scheduled\nfuture location of the customer, budget information for the customer or regarding which the customer must strive to adhere (such that, by way of example, a particular product/solution area may align extremely well with the customer's partialities but is\nwell beyond that which the customer can afford and hence can be reasonably excluded from the selection area 1802), age information for the customer, and gender information for the customer.  Another example in these regards is information comprising\nobjective logistical information regarding providing particular products to the customer.  Examples in these regards include but are not limited to current or predicted product availability, shipping limitations (such as restrictions or other conditions\nthat pertain to shipping a particular product to this particular customer at a particular location), and other applicable legal limitations (pertaining, for example, to the legality of a customer possessing or using a particular product at a particular\nlocation).\nAt block 1704 the control circuit 1601 can then identify at least one product to present to the customer by selecting that product from the multi-dimensional surface 1801.  In the example of FIG. 18, where constraints have been used to define a\nreduced selection area 1802, the control circuit 1601 is constrained to select that product from within that selection area 1802.  For example, and in accordance with the description provided herein, the control circuit 1601 can select that product via\nsolution vector 1803 by identifying a particular product that requires a minimal expenditure of customer effort while also remaining compliant with one or more of the applied objective constraints based, for example, upon objective information regarding\nthe customer and/or objective logistical information regarding providing particular products to the customer.\nSo configured, and as a simple example, the control circuit 1601 may respond per these teachings to learning that the customer is planning a party that will include seven other invited individuals.  The control circuit 1601 may therefore be\nlooking to identify one or more particular beverages to present to the customer for consideration in those regards.  The aforementioned partiality vectors 1607 and vectorized product characterizations 1604 can serve to define a corresponding\nmulti-dimensional surface 1801 that identifies various beverages that might be suitable to consider in these regards.\nObjective information regarding the customer and/or the other invited persons, however, might indicate that all or most of the participants are not of legal drinking age.  In that case, that objective information may be utilized to constrain the\navailable selection area 1802 to beverages that contain no alcohol.  As another example in these regards, the control circuit 1601 may have objective information that the party is to be held in a state park that prohibits alcohol and may therefore\nsimilarly constrain the available selection area 1802 to beverages that contain no alcohol.\nAs described above, the aforementioned control circuit 1601 can utilize information including a plurality of partiality vectors for a particular customer along with vectorized product characterizations for each of a plurality of products to\nidentify at least one product to present to a customer.  By one approach 1900, and referring to FIG. 19, the control circuit 1601 can be configured as (or to use) a state engine to identify such a product (as indicated at block 1901).  As used herein,\nthe expression \"state engine\" will be understood to refer to a finite-state machine, also sometimes known as a finite-state automaton or simply as a state machine.\nGenerally speaking, a state engine is a basic approach to designing both computer programs and sequential logic circuits.  A state engine has only a finite number of states and can only be in one state at a time.  A state engine can change from\none state to another when initiated by a triggering event or condition often referred to as a transition.  Accordingly, a particular state engine is defined by a list of its states, its initial state, and the triggering condition for each transition.\nIt will be appreciated that the apparatus 1600 described above can be viewed as a literal physical architecture or, if desired, as a logical construct.  For example, these teachings can be enabled and operated in a highly centralized manner (as\nmight be suggested when viewing that apparatus 1600 as a physical construct) or, conversely, can be enabled and operated in a highly decentralized manner.  FIG. 20 provides an example as regards the latter.\nIn this illustrative example a central cloud server 2001, a supplier control circuit 2002, and the aforementioned Internet of Things 2003 communicate via the aforementioned network 1610.\nThe central cloud server 2001 can receive, store, and/or provide various kinds of global data (including, for example, general demographic information regarding people and places, profile information for individuals, product descriptions and\nreviews, and so forth), various kinds of archival data (including, for example, historical information regarding the aforementioned demographic and profile information and/or product descriptions and reviews), and partiality vector templates as described\nherein that can serve as starting point general characterizations for particular individuals as regards their partialities.  Such information may constitute a public resource and/or a privately-curated and accessed resource as desired.  (It will also be\nunderstood that there may be more than one such central cloud server 2001 that store identical, overlapping, or wholly distinct content.)\nThe supplier control circuit 2002 can comprise a resource that is owned and/or operated on behalf of the suppliers of one or more products (including but not limited to manufacturers, wholesalers, retailers, and even resellers of\npreviously-owned products).  This resource can receive, process and/or analyze, store, and/or provide various kinds of information.  Examples include but are not limited to product data such as marketing and packaging content (including textual\nmaterials, still images, and audio-video content), operators and installers manuals, recall information, professional and non-professional reviews, and so forth.\nAnother example comprises vectorized product characterizations as described herein.  More particularly, the stored and/or available information can include both prior vectorized product characterizations (denoted in FIG. 20 by the expression\n\"vectorized product characterizations V1.0\") for a given product as well as subsequent, updated vectorized product characterizations (denoted in FIG. 20 by the expression \"vectorized product characterizations V2.0\") for the same product.  Such\nmodifications may have been made by the supplier control circuit 2002 itself or may have been made in conjunction with or wholly by an external resource as desired.\nThe Internet of Things 2003 can comprise any of a variety of devices and components that may include local sensors that can provide information regarding a corresponding user's circumstances, behaviors, and reactions back to, for example, the\naforementioned central cloud server 2001 and the supplier control circuit 2002 to facilitate the development of corresponding partiality vectors for that corresponding user.  As previously discussed, these sensors can be used to monitor a person and/or\nthe person's environment (e.g., his or her home, workplace, etc.).  These sensors can include motion sensors, image sensors, noise sensors, light sensors, weight sensors, usage sensors, door sensors, or any other suitable type of sensor.  Additionally,\nthese sensors can be worn, or otherwise hosted, by the person (e.g., a fitness band, heartrate monitor, etc.).  Again, however, these teachings will also support a decentralized approach.  In many cases devices that are fairly considered to be members of\nthe Internet of Things 2003 constitute network edge elements (i.e., network elements deployed at the edge of a network).  In some case the network edge element is configured to be personally carried by the person when operating in a deployed state. \nExamples include but are not limited to so-called smart phones, smart watches, fitness monitors that are worn on the body, and so forth.  In other cases, the network edge element may be configured to not be personally carried by the person when operating\nin a deployed state.  This can occur when, for example, the network edge element is too large and/or too heavy to be reasonably carried by an ordinary average person.  This can also occur when, for example, the network edge element has operating\nrequirements ill-suited to the mobile environment that typifies the average person.\nFor example, a so-called smart phone can itself include a suite of partiality vectors for a corresponding user (i.e., a person that is associated with the smart phone which itself serves as a network edge element) and employ those partiality\nvectors to facilitate vector-based ordering (either automated or to supplement the ordering being undertaken by the user) as is otherwise described herein.  In that case, the smart phone can obtain corresponding vectorized product characterizations from\na remote resource such as, for example, the aforementioned supplier control circuit 2002 and use that information in conjunction with local partiality vector information to facilitate the vector-based ordering.\nAlso, if desired, the smart phone in this example can itself modify and update partiality vectors for the corresponding user.  To illustrate this idea in FIG. 20, this device can utilize, for example, information gained at least in part from\nlocal sensors to update a locally-stored partiality vector (represented in FIG. 20 by the expression \"partiality vector V1.0\") to obtain an updated locally-stored partiality vector (represented in FIG. 20 by the expression \"partiality vector V2.0\"). \nUsing this approach, a user's partiality vectors can be locally stored and utilized.  Such an approach may better comport with a particular user's privacy concerns.\nFIG. 21 is a flow chart depicting example operations for monitoring parameters associated with a person and the person's home and updating a partiality vector for the person based on a deviation.  The flow begins at block 2102.\nAt block 2102, parameters associated with a person and a person's home are monitored.  For example, a plurality of sensors can monitor the person and/or his or her home.  The plurality of sensors can be located about the person's home and/or on\nthe person.  The plurality of sensors can include sensors that monitor the person and his or her activity around his or her home.  For example, the plurality of sensors can include biometric sensors, motion sensors, noise sensors, light sensors, weight\nsensors, and any other suitable type of sensor.  The flow continues at block 2104.\nAt block 2104, one or more partiality vectors for the person are generated.  For example, a control circuit can generate the one or more partiality vectors.  The partiality vectors are representative of partiality information for the person.  In\nsome embodiments, the partiality information for the person can be based, at least in part, on information gleaned from the plurality of sensors.  Additionally, or alternatively, the partiality information can be based on information derived from other\nsources, such as historical purchases or actions of the person, the person's online presence, previous partialities indicated by the person, etc. The partiality vectors have at least one of a magnitude and an angle.  The magnitude and/or the angle of the\npartiality vector corresponds to a magnitude of the person's belief in an amount of good that comes from an order associated with that partiality.  The flow continues at block 2106.\nAt block 2106, values associated with the parameters are received.  For example, the control circuit can receive the values associated with the parameters from the plurality of sensors.  The values associated with the parameters can be numeric,\nstate, and/or qualitative values collected by the plurality of sensors.  For example, the values associated with the parameters can be weights, times, indications of movement, indications of a state of a device (e.g., on or off), quality of service, etc.\nThe flow continues at block 2108.\nAt block 2108, a spectral profile for the person is created.  For example, the control circuit can create the spectral profile for the person.  The spectral profile is based, at least in part, on the values associated with the parameters.  Put\nsimply, the spectral profile is a representation of the person's activities and, in essence, provides a personality of the person that reflects not only how but why the person responses to a variety of life experiences.  In some embodiments, the spectral\nprofile can represent changes to the person's behavior over a given period of time.  The spectral profile can be multidimensional, if need be, based on the requirements of the values making up the spectral profile.  Based on the values associated with\nthe parameters, the spectral profile can have one or more frequencies.  Additionally, one or more of these frequencies may be primary frequencies while others of the frequencies may be secondary frequencies.  The flow continues at block 2110.\nAt block 2110, it is determined that a combination of the values associated with the parameters indicates a deviation.  For example, the control circuit can determine, based on values associated with the parameters, the spectral profile for the\nperson, and a routine experiential base state for the person that a deviation has occurred.  The deviation can be an aberration from the person's normal routine or known partialities, as compared to the person's spectral profile and/or routine\nexperiential base state.  For example, the deviation could be that the person is no longer going to the gym, eating healthy food, partial to products that are environmentally friendly, partial to products that are inexpensive, etc. The flow continues at\nblock 2112.\nAt block 2112, at least one of the partiality vectors for the person is updated.  For example, the control circuit can update at least one partiality vectors for the person.  In some embodiments, the partiality vector is updated based on the\ndeviation.  For example, if the deviation is that the person no longer partial to products that are environmentally friendly, the control circuit can update a partiality vector for the person reflecting a decreased magnitude and/or angle of a partiality\nvector associated with a preference for products that are environmentally friendly.  That is, the partiality vector can be updated to reflect the person's diminished belief in the amount of good that comes from the use of environmentally friendly\nproducts.  As another example, if the deviation is that the person is going to the gym less frequently, the control circuit can update the magnitude and/or angle of the partiality vector indicating a diminished belief in the amount of good that comes\nfrom physical activity.\nIt will be understood that the smart phone employed in the immediate example is intended to serve in an illustrative capacity and is not intended to suggest any particular limitations in these regards.  In fact, any of a wide variety of Internet\nof Things devices/components could be readily configured in the same regards.  As one simple example in these regards, a computationally-capable networked refrigerator could be configured to order appropriate perishable items for a corresponding user as\na function of that user's partialities.\nPresuming a decentralized approach, these teachings will accommodate any of a variety of other remote resources 2004.  These remote resources 2004 can, in turn, provide static or dynamic information and/or interaction opportunities or analytical\ncapabilities that can be called upon by any of the above-described network elements.  Examples include but are not limited to voice recognition, pattern and image recognition, facial recognition, statistical analysis, computational resources, encryption\nand decryption services, fraud and misrepresentation detection and prevention services, digital currency support, and so forth.\nAs already suggested above, these approaches provide powerful ways for identifying products and/or services that a given person, or a given group of persons, may likely wish to buy to the exclusion of other options.  When the magnitude and\ndirection of the relevant/required meta-force vector that comes from the perceived effort to impose order is known, these teachings will facilitate, for example, engineering a product or service containing potential energy in the precise ordering\ndirection to provide a total reduction of effort.  Since people generally take the path of least effort (consistent with their partialities) they will typically accept such a solution.\nAs one simple illustrative example, a person who exhibits a partiality for food products that emphasize health, natural ingredients, and a concern to minimize sugars and fats may be presumed to have a similar partiality for pet foods because\nsuch partialities may be based on a value system that extends beyond themselves to other living creatures within their sphere of concern.  If other data is available to indicate that this person in fact has, for example, two pet dogs, these partialities\ncan be used to identify dog food products having well-aligned vectors in these same regards.  This person could then be solicited to purchase such dog food products using any of a variety of solicitation approaches (including but not limited to general\ninformational advertisements, discount coupons or rebate offers, sales calls, free samples, and so forth).\nAs another simple example, the approaches described herein can be used to filter out products/services that are not likely to accord well with a given person's partiality vectors.  In particular, rather than emphasizing one particular product\nover another, a given person can be presented with a group of products that are available to purchase where all of the vectors for the presented products align to at least some predetermined degree of alignment/accord and where products that do not meet\nthis criterion are simply not presented.\nAnd as yet another simple example, a particular person may have a strong partiality towards both cleanliness and orderliness.  The strength of this partiality might be measured in part, for example, by the physical effort they exert by\nconsistently and promptly cleaning their kitchen following meal preparation activities.  If this person were looking for lawn care services, their partiality vector(s) in these regards could be used to identify lawn care services who make representations\nand/or who have a trustworthy reputation or record for doing a good job of cleaning up the debris that results when mowing a lawn.  This person, in turn, will likely appreciate the reduced effort on their part required to locate such a service that can\nmeaningfully contribute to their desired order.\nThese teachings can be leveraged in any number of other useful ways.  As one example in these regards, various sensors and other inputs can serve to provide automatic updates regarding the events of a given person's day.  By one approach, at\nleast some of this information can serve to help inform the development of the aforementioned partiality vectors for such a person.  At the same time, such information can help to build a view of a normal day for this particular person.  That baseline\ninformation can then help detect when this person's day is going experientially awry (i.e., when their desired \"order\" is off track).  Upon detecting such circumstances these teachings will accommodate employing the partiality and product vectors for\nsuch a person to help make suggestions (for example, for particular products or services) to help correct the day's order and/or to even effect automatically-engaged actions to correct the person's experienced order.\nWhen this person's partiality (or relevant partialities) are based upon a particular aspiration, restoring (or otherwise contributing to) order to their situation could include, for example, identifying the order that would be needed for this\nperson to achieve that aspiration.  Upon detecting, (for example, based upon purchases, social media, or other relevant inputs) that this person is aspirating to be a gourmet chef, these teachings can provide for plotting a solution that would begin\nproviding/offering additional products/services that would help this person move along a path of increasing how they order their lives towards being a gourmet chef.\nBy one approach, these teachings will accommodate presenting the consumer with choices that correspond to solutions that are intended and serve to test the true conviction of the consumer as to a particular aspiration.  The reaction of the\nconsumer to such test solutions can then further inform the system as to the confidence level that this consumer holds a particular aspiration with some genuine conviction.  In particular, and as one example, that confidence can in turn influence the\ndegree and/or direction of the consumer value vector(s) in the direction of that confirmed aspiration.\nAll the above approaches are informed by the constraints the value space places on individuals so that they follow the path of least perceived effort to order their lives to accord with their values which results in partialities.  People\ngenerally order their lives consistently unless and until their belief system is acted upon by the force of a new trusted value proposition.  The present teachings are uniquely able to identify, quantify, and leverage the many aspects that collectively\ninform and define such belief systems.\nA person's preferences can emerge from a perception that a product or service removes effort to order their lives according to their values.  The present teachings acknowledge and even leverage that it is possible to have a preference for a\nproduct or service that a person has never heard of before in that, as soon as the person perceives how it will make their lives easier they will prefer it.  Most predictive analytics that use preferences are trying to predict a decision the customer is\nlikely to make.  The present teachings are directed to calculating a reduced effort solution that can/will inherently and innately be something to which the person is partial.\nThose skilled in the art will recognize that a wide variety of modifications, alterations, and combinations can be made with respect to the above described embodiments without departing from the scope of the invention, and that such\nmodifications, alterations, and combinations are to be viewed as being within the ambit of the inventive concept.\nThis application is related to, and incorporates herein by reference in its entirety, each of the following U.S.  applications listed as follows by application number and filing date: 62/323,026 filed Apr.  15, 2016; 62/341,993 filed May 26,\n2016; 62/348,444 filed Jun.  10, 2016; 62/350,312 filed Jun.  15, 2016; 62/350,315 filed Jun.  15, 2016; 62/351,467 filed Jun.  17, 2016; 62/351,463 filed Jun.  17, 2016; 62/352,858 filed Jun.  21, 2016; 62/356,387 filed Jun.  29, 2016; 62/356,374 filed\nJun.  29, 2016; 62/356,439 filed Jun.  29, 2016; 62/356,375 filed Jun.  29, 2016; 62/358,287 filed Jul.  5, 2016; 62/360,356 filed Jul.  9, 2016; 62/360,629 filed Jul.  11, 2016; 62/365,047 filed Jul.  21, 2016; 62/367,299 filed Jul.  27, 2016;\n62/370,853 filed Aug.  4, 2016; 62/370,848 filed Aug.  4, 2016; 62/377,298 filed Aug.  19, 2016; 62/377,113 filed Aug.  19, 2016; 62/380,036 filed Aug.  26, 2016; 62/381,793 filed Aug.  31, 2016; 62/395,053 filed Sep. 15, 2016; 62/397,455 filed Sep. 21,\n2016; 62/400,302 filed Sep. 27, 2016; 62/402,068 filed Sep. 30, 2016; 62/402,164 filed Sep. 30, 2016; 62/402,195 filed Sep. 30, 2016; 62/402,651 filed Sep. 30, 2016; 62/402,692 filed Sep. 30, 2016; 62/402,711 filed Sep. 30, 2016; 62/406,487 filed Oct. \n11, 2016; 62/408,736 filed Oct.  15, 2016; 62/409,008 filed Oct.  17, 2016; 62/410,155 filed Oct.  19, 2016; 62/413,312 filed Oct.  26, 2016; 62/413,304 filed Oct.  26, 2016; 62/413,487 filed Oct.  27, 2016; 62/422,837 filed Nov.  16, 2016; 62/423,906\nfiled Nov.  18, 2016; 62/424,661 filed Nov.  21, 2016; 62/427,478 filed Nov.  29, 2016; 62/436,842 filed Dec.  20, 2016; 62/436,885 filed Dec.  20, 2016; 62/436,791 filed Dec.  20, 2016; 62/439,526 filed Dec.  28, 2016; 62/442,631 filed Jan.  5, 2017;\n62/445,552 filed Jan.  12, 2017; 62/463,103 filed Feb.  24, 2017; 62/465,932 filed Mar.  2, 2017; 62/467,546 filed Mar.  6, 2017; 62/467,968 filed Mar.  7, 2017; 62/467,999 filed Mar.  7, 2017; 62/471,089 filed Mar.  14, 2017; 62/471,804 filed Mar.  15,\n2017; 62/471,830 filed Mar.  15, 2017; 62/479,106 filed Mar.  30, 2017; 62/479,525 filed Mar.  31, 2017; 62/480,733 filed Apr.  3, 2017; 62/482,863 filed Apr.  7, 2017; 62/482,855 filed Apr.  7, 2017; 62/485,045 filed Apr.  13, 2017; Ser.  No. 15/487,760\nfiled Apr.  14, 2017; Ser.  No. 15/487,538 filed Apr.  14, 2017; Ser.  No. 15/487,775 filed Apr.  14, 2017; Ser.  No. 15/488,107 filed Apr.  14, 2017; Ser.  No. 15/488,015 filed Apr.  14, 2017; Ser.  No. 15/487,728 filed Apr.  14, 2017; Ser.  No.\n15/487,882 filed Apr.  14, 2017; Ser.  No. 15/487,826 filed Apr.  14, 2017; Ser.  No. 15/487,792 filed Apr.  14, 2017; Ser.  No. 15/488,004 filed Apr.  14, 2017; Ser.  No. 15/487,894 filed Apr.  14, 2017; 62/486,801 filed Apr.  18, 2017; 62/491,455 filed\nApr.  28, 2017; 62/502,870 filed May 8, 2017; 62/510,322 filed May 24, 2017; 62/510,317 filed May 24, 2017; Ser.  No. 15/606,602 filed May 26, 2017; 62/511,559 filed May 26, 2017; 62/513,490 filed Jun.  1, 2017; 62/515,675 filed Jun.  6, 2017; Ser.  No.\n15/624,030 filed Jun.  15, 2017; Ser.  No. 15/625,599 filed Jun.  16, 2017; Ser.  No. 15/628,282 filed Jun.  20, 2017; 62/523,148 filed Jun.  21, 2017; 62/525,304 filed Jun.  27, 2017; Ser.  No. 15/634,862 filed Jun.  27, 2017; 62/527,445 filed Jun.  30,\n2017; Ser.  No. 15/655,339 filed Jul.  20, 2017; Ser.  No. 15/669,546 filed Aug.  4, 2017; and 62/542,664 filed Aug.  8, 2017; 62/542,896 filed Aug.  9, 2017; Ser.  No. 15/678,608 filed Aug.  16, 2017; 62/548,503 filed Aug.  22, 2017; 62/549,484 filed\nAug.  24, 2017; Ser.  No. 15/685,981 filed Aug.  24, 2017; 62/558,420 filed Sep. 14, 2017; Ser.  No. 15/704,878 filed Sep. 14, 2017; 62/559,128 filed Sep. 15, 2017; Ser.  No. 15/783,787 filed Oct.  13, 2017; Ser.  No. 15/783,929 filed Oct.  13, 2017;\nSer.  No. 15/783,825 filed Oct.  13, 2017; Ser.  No. 15/783,551 filed Oct.  13, 2017; Ser.  No. 15/783,645 filed Oct.  13, 2017; Ser.  No. 15/782,555 filed Oct.  13, 2017; Ser.  No. 15/782,509 filed Oct.  13, 2017; 62/571,867 filed Oct.  13, 2017; Ser. \nNo. 15/783,668 filed Oct.  13, 2017; Ser.  No. 15/783,960 filed Oct.  13, 2017; and Ser.  No. 15/782,559 filed Oct.  13, 2017.\nThose skilled in the art will recognize that a wide variety of other modifications, alterations, and combinations can also be made with respect to the above described embodiments without departing from the scope of the invention, and that such\nmodifications, alterations, and combinations are to be viewed as being within the ambit of the inventive concept.\nIn some embodiments, an apparatus comprises one or more sensors, the one or more sensors configured to monitor parameters associated with a person and the person's home, and a control circuit, the control circuit communicatively coupled to the\none or more sensors and configured to generate one or more partiality vectors for the person, wherein the one or more partiality vectors have at least one of a magnitude and an angle that corresponds to a magnitude of the person's belief in an amount of\ngood that comes from an order associated with that partiality, receive, from the one or more sensors, values associated with the parameters, create, based on the values associated with the parameters, a spectral profile for the person, determine, based\non the spectral profile and a routine experiential base state for the person, that a combination of the values indicates a deviation, and update, based on the deviation, at least one of the one or more partiality vectors for the person.\nIn some embodiments, a method comprises monitoring, via one or more sensors, parameters associated with a person and the person's home, generating, by a control circuit, one or more partiality vectors for the person, wherein the one or more\npartiality vectors have at least one of a magnitude and an angle that corresponds to a magnitude of the person's belief in an amount of good that comes from an order associated with that partiality, receiving, at the control circuit from the one or more\nsensors, values associated with the parameters, creating, based on the values associated with the parameters, a spectral profile for the person, determining, based on the spectral profile and a routine experiential base state for the person, that a\ncombination of the values indicates a deviation, an updating, based on the deviation, at least one of the one or more partiality vectors for the person.", "application_number": "15947380", "abstract": " In some embodiments, apparatuses, systems, and methods are provided\n     herein useful to detecting a deviation in a person's activity. In some\n     embodiments, an apparatus comprises one or more sensors, the one or more\n     sensors configured to monitor parameters associated with a person and the\n     person's home, and a control circuit, the control circuit communicatively\n     coupled to the one or more sensors and configured to generate one or more\n     partiality vectors for the person, receive, from the one or more sensors,\n     values associated with the parameters, create, based on the values\n     associated with the parameters, a spectral profile for the person,\n     determine, based on the spectral profile and a routine base state for the\n     person, that a combination of the values indicates a deviation, and\n     update at least one of the one or more partiality vectors for the person.\n", "citations": ["4771380", "4931929", "5092343", "5357439", "5410471", "5712830", "5737611", "5974396", "6236974", "6249773", "6260024", "6327574", "6519571", "6583720", "6594642", "6614348", "6615208", "6654725", "6731940", "6826541", "6856249", "6901304", "6937710", "7063263", "7072848", "7130814", "7147154", "7174312", "7225979", "7249708", "7330828", "7346563", "7369680", "7508307", "7584139", "7657457", "7658327", "7680694", "7685024", "7707073", "7720720", "7766829", "7778773", "7814029", "7819315", "7856368", "7860759", "7873543", "7945473", "8013729", "8036951", "8055546", "8073460", "8086546", "8117089", "8140388", "8244830", "8249946", "8261306", "8266017", "8271322", "8285715", "8316020", "8364520", "8370207", "8370216", "8386285", "8401914", "8429026", "8447703", "8457354", "8494915", "8538829", "8558703", "8577753", "8583511", "8595773", "8606636", "8606645", "8630921", "8666844", "8738541", "8744920", "8803366", "8818876", "8849719", "8874485", "8968195", "9015277", "9030295", "9036019", "9087358", "9129250", "9165320", "9174758", "9183510", "9189021", "9218633", "9224157", "9230070", "9251527", "9256693", "9256890", "9286617", "9294298", "9325849", "9424589", "9451576", "9489674", "9750439", "20010014868", "20010034661", "20020003166", "20020010000", "20020052825", "20020095345", "20020128910", "20020152001", "20020161664", "20020174025", "20020178013", "20020194604", "20030028424", "20030065520", "20030083951", "20030088370", "20030107650", "20030126023", "20030130897", "20030130908", "20030149693", "20030177072", "20030212619", "20040030531", "20040064379", "20040100380", "20040103043", "20040117383", "20040153442", "20040158497", "20040165708", "20040176987", "20040198386", "20040225651", "20050034161", "20050049920", "20050159996", "20050187021", "20050189414", "20050273377", "20050283394", "20060010029", "20060036485", "20060055543", "20060136293", "20060183980", "20060230053", "20060237532", "20060256008", "20060259360", "20060288374", "20070016488", "20070050201", "20070073553", "20070179846", "20070219866", "20070244741", "20070265870", "20070290038", "20070294133", "20070299724", "20080004995", "20080043013", "20080052171", "20080059297", "20080065468", "20080071622", "20080089288", "20080114642", "20080208673", "20080248815", "20080288327", "20090012704", "20090018996", "20090063290", "20090083121", "20090094121", "20090128325", "20090132347", "20090164772", "20090166375", "20090171968", "20090197616", "20090234712", "20090271293", "20090303052", "20100030578", "20100042940", "20100064040", "20100084463", "20100133850", "20100185552", "20100198668", "20100216509", "20100293032", "20100293569", "20110004588", "20110022606", "20110035282", "20110131089", "20110213661", "20110218859", "20110225046", "20110246260", "20110246306", "20110251897", "20110267374", "20110282476", "20110302011", "20110316697", "20120019378", "20120036522", "20120054018", "20120150626", "20120166268", "20120259732", "20120271740", "20120310715", "20130030915", "20130031018", "20130066740", "20130073389", "20130080364", "20130091146", "20130106604", "20130138530", "20130232221", "20130140357", "20130175335", "20130176115", "20130214938", "20130226539", "20130268317", "20130268335", "20130268886", "20130275275", "20130311324", "20130326008", "20130339122", "20140002643", "20140040038", "20140052562", "20140058775", "20140058794", "20140074649", "20140074743", "20140089133", "20140108125", "20140122228", "20140129393", "20140156392", "20140164046", "20140164476", "20140180815", "20140180953", "20140195902", "20140207659", "20140214543", "20140214590", "20140214600", "20140249966", "20140266791", "20140278815", "20140279200", "20140279202", "20140279208", "20140279294", "20140297001", "20140297470", "20140304123", "20140310040", "20140310056", "20140316916", "20140330738", "20140344102", "20150006314", "20150032847", "20150058154", "20150058175", "20150081469", "20150106236", "20150120550", "20150120600", "20150139416", "20150149443", "20150161706", "20150186773", "20150186981", "20150190086", "20150193115", "20150206246", "20150221016", "20150227871", "20150227883", "20150242750", "20150254712", "20150254785", "20150256899", "20150269642", "20150310536", "20150324490", "20150324881", "20150356601", "20150370985", "20150379597", "20160005070", "20160027068", "20160027094", "20160034907", "20160063440", "20160071116", "20160086255", "20160092988", "20160094703", "20160098547", "20160110759", "20160140589", "20160171424", "20160171539", "20160171597", "20160171866", "20160239857", "20160253710", "20160283979", "20160292634", "20160292769", "20160300547", "20160345869", "20160350715", "20160371650", "20170109806", "20170180147", "20170300856", "20170300936", "20170300944", "20170300946", "20170300956", "20170300992", "20170300999", "20170301000", "20170301001", "20170301002", "20170301008", "20170308909", "20170345033", "20170364860", "20170364925", "20170364962", "20180005177", "20180025365", "20180040044", "20180047065", "20180053240", "20180060943", "20180082252", "20180083908", "20180107971", "20180108062", "20180113431", "20180137461", "20180144397", "20180174101", "20180174188", "20180174198", "20180174223", "20180174224", "20180254096", "20180268357", "20180285816", "20180300677", "20180300788", "20190005021"], "related": ["15642738", "62359462", "62485045"]}, {"id": "20180239966", "patent_code": "10303954", "patent_name": "Monitoring, detection, and surveillance system using principal component\n     analysis with machine and sensor data", "year": "2019", "inventor_and_country_data": " Inventors: \nXiao; Wei (Seattle, WA), Silva; Jorge Manuel Gomes da (Durham, NC), Emrani; Saba (Santa Clara, CA), Chaudhuri; Arin (Raleigh, NC)  ", "description": "<BR><BR>BACKGROUND\nLow-rank subspace models are powerful tools to analyze high-dimensional data from dynamical systems.  Applications include tracking in radar and sonar, face recognition, recommender systems, cloud removal in satellite images, anomaly detection,\nbackground subtraction for surveillance video, system monitoring, etc. Principal component analysis (PCA) is a widely used tool to obtain a low-rank subspace from high dimensional data.  For a given rank r, PCA finds the r-dimensional linear subspace\nthat minimizes the square error loss between a data vector and its projection onto that subspace.  Although PCA is widely used, it is not robust against outliers.  With just one grossly corrupted entry, the low-rank subspace estimated from classic PCA\ncan be arbitrarily far from the true subspace.  This shortcoming reduces the value of PCA because outliers are often observed in the modern world's massive data.  For example, data collected through sensors, cameras, websites, etc. are often very noisy\nand contain error entries or outliers.\nRobust PCA (RPCA) methods have been investigated to provide good practical performance with strong theoretical performance guarantees, but are typically batch algorithms that require loading of all observations into memory before processing. \nThis makes them inefficient and impractical for use in processing very large datasets commonly referred to as \"big data\" due to the amount of memory required and the slow processing speeds.  The robust PCA methods further fail to address the problem of\nslowly or abruptly changing subspace.\n<BR><BR>SUMMARY\nIn an example embodiment, a non-transitory computer-readable medium is provided having stored thereon computer-readable instructions that, when executed by a computing device, cause the computing device to update an estimate of one or more\nprincipal components for a next observation vector.  An initial observation matrix is defined with a first plurality of observation vectors.  A number of the first plurality of observation vectors is a predefined window length.  Each observation vector\nof the first plurality of observation vectors includes a plurality of values.  Each value of the plurality of values is associated with a variable to define a plurality of variables.  Each variable of the plurality of variables describes a characteristic\nof a physical object.  A principal components decomposition is computed using the defined initial observation matrix.  The principal components decomposition includes a sparse noise vectors, a first singular value decomposition vector U, and a second\nsingular value decomposition vector v for each observation vector of the first plurality of observation vectors.  A rank r is determined based on the computed principal components decomposition.  A next principal components decomposition is computed for\na next observation vector using the determined rank r. The computed next principal components decomposition is output for the next observation vector.  The output next principal components decomposition is monitored to determine a status of the physical\nobject.\nIn another example embodiment, a computing device is provided.  The computing device includes, but is not limited to, a processor and a non-transitory computer-readable medium operably coupled to the processor.  The computer-readable medium has\ninstructions stored thereon that, when executed by the computing device, cause the computing device to update an estimate of one or more principal components for a next observation vector.\nIn yet another example embodiment, a method of updating an estimate of one or more principal components for a next observation vector is provided.\nOther principal features of the disclosed subject matter will become apparent to those skilled in the art upon review of the following drawings, the detailed description, and the appended claims. <BR><BR>BRIEF DESCRIPTION OF THE DRAWINGS\nIllustrative embodiments of the disclosed subject matter will hereafter be described referring to the accompanying drawings, wherein like numerals denote like elements.\nFIG. 1 depicts a block diagram of a monitoring device in accordance with an illustrative embodiment.\nFIG. 2 depicts a flow diagram illustrating example operations performed by the monitoring device of FIG. 1 in accordance with an illustrative embodiment.\nFIG. 3 depicts a flow diagram illustrating additional example operations performed by the monitoring device of FIG. 1 in accordance with an illustrative embodiment.\nFIG. 4 depicts a flow diagram illustrating additional example operations performed by the monitoring device of FIG. 1 in accordance with an illustrative embodiment.\nFIGS. 5A, 5B, and 5C depict a flow diagram illustrating additional example operations performed by the monitoring device of FIG. 1 in accordance with an illustrative embodiment.\nFIG. 6 graphically illustrates a plurality of observation vectors in accordance with an illustrative embodiment.\nFIG. 7 provides a comparison between a relative error computed for a low-rank matrix using a known robust principal component analysis (RPCA) algorithm, using the operations of FIGS. 2-4, and using the operations of FIGS. 3-5 with a slowly\nchanging subspace in accordance with an illustrative embodiment.\nFIG. 8 provides a comparison between a relative error computed for a sparse noise matrix using the known RPCA algorithm, using the operations of FIGS. 2-4, and using the operations of FIGS. 3-5 with the slowly changing subspace in accordance\nwith an illustrative embodiment.\nFIG. 9 provides a comparison between a proportion of correctly identified elements in the sparse noise matrix using the known RPCA algorithm, using the operations of FIGS. 2-4, and using the operations of FIGS. 3-5 with the slowly changing\nsubspace in accordance with an illustrative embodiment.\nFIG. 10 provides a comparison as a function of time between the relative error computed for the low-rank matrix using the known RPCA algorithm, using the operations of FIGS. 2-4, and using the operations of FIGS. 3-5 with a rank of 10, a\nsparsity probability of 0.01, and the slowly changing subspace in accordance with an illustrative embodiment.\nFIG. 11 provides a comparison as a function of time between the relative error computed for the low-rank matrix using the known RPCA algorithm, using the operations of FIGS. 2-4, and using the operations of FIGS. 3-5 with a rank of 50, a\nsparsity probability of 0.01, and the slowly changing subspace in accordance with an illustrative embodiment.\nFIG. 12 provides a comparison between a relative error computed for the low-rank matrix using the known RPCA algorithm, using the operations of FIGS. 2-4, and using the operations of FIGS. 3-5 with two abrupt changes in the subspace in\naccordance with an illustrative embodiment.\nFIG. 13 provides a comparison between a relative error computed for the sparse noise matrix using the known RPCA algorithm, using the operations of FIGS. 2-4, and using the operations of FIGS. 3-5 with the two abrupt changes in the subspace in\naccordance with an illustrative embodiment.\nFIG. 14 provides a comparison between the proportion of correctly identified elements in the sparse noise matrix using the known RPCA algorithm, using the operations of FIGS. 2-4, and using the operations of FIGS. 3-5 with the two abrupt changes\nin the subspace in accordance with an illustrative embodiment.\nFIG. 15 provides a comparison as a function of time between the relative error computed for the low-rank matrix using the known RPCA algorithm, using the operations of FIGS. 2-4, and using the operations of FIGS. 3-5 with a rank of 10, a\nsparsity probability of 0.01, and the two abrupt changes in the subspace in accordance with an illustrative embodiment.\nFIG. 16 provides a comparison as a function of time between the relative error computed for the low-rank matrix using the known RPCA algorithm, using the operations of FIGS. 2-4, and using the operations of FIGS. 3-5 with a rank of 50, a\nsparsity probability of 0.01, and the two abrupt changes in the subspace in accordance with an illustrative embodiment.\nFIG. 17 provides a comparison as a function of rank between a relative difference between a detected change point time and a true change point time using the operations of FIGS. 3-5 with the sparsity probability of 0.01, and the two abrupt\nchanges in the subspace in accordance with an illustrative embodiment.\nFIG. 18A shows an image capture from an airport video at a first time in accordance with an illustrative embodiment.\nFIG. 18B shows the low-rank matrix computed from the image capture of FIG. 18A using the operations of FIGS. 3-5 in accordance with an illustrative embodiment.\nFIG. 18C shows the low-rank matrix computed from the image capture of FIG. 18A using the known RPCA algorithm in accordance with an illustrative embodiment.\nFIG. 18D shows the sparse noise matrix computed from the image capture of FIG. 18A using the operations of FIGS. 3-5 in accordance with an illustrative embodiment.\nFIG. 18E shows the sparse noise matrix computed from the image capture of FIG. 18A using the known RPCA algorithm in accordance with an illustrative embodiment.\nFIG. 19A shows an image capture from the airport video at a second time in accordance with an illustrative embodiment.\nFIG. 19B shows the low-rank matrix computed from the image capture of FIG. 19A using the operations of FIGS. 3-5 in accordance with an illustrative embodiment.\nFIG. 19C shows the low-rank matrix computed from the image capture of FIG. 19A using the known RPCA algorithm in accordance with an illustrative embodiment.\nFIG. 19D shows the sparse noise matrix computed from the image capture of FIG. 19A using the operations of FIGS. 3-5 in accordance with an illustrative embodiment.\nFIG. 19E shows the sparse noise matrix computed from the image capture of FIG. 19A using the known RPCA algorithm in accordance with an illustrative embodiment.\nFIG. 20 shows a comparison of principal components computed using moving windows RPCA in accordance with an illustrative embodiment.\n<BR><BR>DETAILED DESCRIPTION\nReferring to FIG. 1, a block diagram of a monitoring device 100 is shown in accordance with an illustrative embodiment.  Monitoring device 100 may include an input interface 102, an output interface 104, a communication interface 106, a\nnon-transitory computer-readable medium 108, a processor 110, a decomposition application 122, a dataset 124, a dataset decomposition description 126, and a dataset change points description 128.  Fewer, different, and/or additional components may be\nincorporated into monitoring device 100.\nInput interface 102 provides an interface for receiving information from the user or another device for entry into monitoring device 100 as understood by those skilled in the art.  Input interface 102 may interface with various input\ntechnologies including, but not limited to, a keyboard 112, a microphone 113, a mouse 114, a display 116, a track ball, a keypad, one or more buttons, etc. to allow the user to enter information into monitoring device 100 or to make selections presented\nin a user interface displayed on display 116.  The same interface may support both input interface 102 and output interface 104.  For example, display 116 comprising a touch screen provides a mechanism for user input and for presentation of output to the\nuser.  Monitoring device 100 may have one or more input interfaces that use the same or a different input interface technology.  The input interface technology further may be accessible by monitoring device 100 through communication interface 106.\nOutput interface 104 provides an interface for outputting information for review by a user of monitoring device 100 and/or for use by another application or device.  For example, output interface 104 may interface with various output\ntechnologies including, but not limited to, display 116, a speaker 118, a printer 120, etc. Monitoring device 100 may have one or more output interfaces that use the same or a different output interface technology.  The output interface technology\nfurther may be accessible by monitoring device 100 through communication interface 106.\nCommunication interface 106 provides an interface for receiving and transmitting data between devices using various protocols, transmission technologies, and media as understood by those skilled in the art.  Communication interface 106 may\nsupport communication using various transmission media that may be wired and/or wireless.  Monitoring device 100 may have one or more communication interfaces that use the same or a different communication interface technology.  For example, monitoring\ndevice 100 may support communication using an Ethernet port, a Bluetooth antenna, a telephone jack, a USB port, etc. Data and messages may be transferred between monitoring device 100 and another computing device of a distributed computing system 130\nusing communication interface 106.\nComputer-readable medium 108 is a non-transitory electronic holding place or storage for information so the information can be accessed by processor 110 as understood by those skilled in the art.  Computer-readable medium 108 can include, but is\nnot limited to, any type of random access memory (RAM), any type of read only memory (ROM), any type of flash memory, etc. such as magnetic storage devices (e.g., hard disk, floppy disk, magnetic strips, .  . . ), optical disks (e.g., compact disc (CD),\ndigital versatile disc (DVD), .  . . ), smart cards, flash memory devices, etc. Monitoring device 100 may have one or more computer-readable media that use the same or a different memory media technology.  For example, computer-readable medium 108 may\ninclude different types of computer-readable media that may be organized hierarchically to provide efficient access to the data stored therein as understood by a person of skill in the art.  As an example, a cache may be implemented in a smaller, faster\nmemory that stores copies of data from the most frequently/recently accessed main memory locations to reduce an access latency.  Monitoring device 100 also may have one or more drives that support the loading of a memory media such as a CD, DVD, an\nexternal hard drive, etc. One or more external hard drives further may be connected to monitoring device 100 using communication interface 106.\nProcessor 110 executes instructions as understood by those skilled in the art.  The instructions may be carried out by a special purpose computer, logic circuits, or hardware circuits.  Processor 110 may be implemented in hardware and/or\nfirmware.  Processor 110 executes an instruction, meaning it performs/controls the operations called for by that instruction.  The term \"execution\" is the process of running an application or the carrying out of the operation called for by an\ninstruction.  The instructions may be written using one or more programming language, scripting language, assembly language, etc. Processor 110 operably couples with input interface 102, with output interface 104, with communication interface 106, and\nwith computer-readable medium 108 to receive, to send, and to process information.  Processor 110 may retrieve a set of instructions from a permanent memory device and copy the instructions in an executable form to a temporary memory device that is\ngenerally some form of RAM.  Monitoring device 100 may include a plurality of processors that use the same or a different processing technology.\nDecomposition application 122 performs operations associated with defining dataset decomposition 126 and/or dataset change points description 128 from data stored in dataset 124.  Dataset decomposition 126 may be used to monitor changes in data\nin dataset 124 to support various data analysis functions as well as provide alert/messaging related to the monitored data.  Some or all of the operations described herein may be embodied in decomposition application 122.  The operations may be\nimplemented using hardware, firmware, software, or any combination of these methods.\nReferring to the example embodiment of FIG. 1, decomposition application 122 is implemented in software (comprised of computer-readable and/or computer-executable instructions) stored in computer-readable medium 108 and accessible by processor\n110 for execution of the instructions that embody the operations of decomposition application 122.  Decomposition application 122 may be written using one or more programming languages, assembly languages, scripting languages, etc. Decomposition\napplication 122 may be integrated with other analytic tools.  As an example, decomposition application 122 may be part of an integrated data analytics software application and/or software architecture such as that offered by SAS Institute Inc.  of Cary,\nN.C., USA.  For example, decomposition application 122 may be part of SAS.RTM.  Enterprise Miner.TM.  or of SAS.RTM.  Viya.TM.  or of SAS.RTM.  Visual Data Mining and Machine Learning, all of which are developed and provided by SAS Institute Inc.  of\nCary, N.C., USA and may be used to create highly accurate predictive and descriptive models based on analysis of vast amounts of data from across an enterprise.  Merely for further illustration, decomposition application 122 may be implemented using or\nintegrated with one or more SAS software tools such as Base SAS, SAS/STATO, SAS.RTM.  High Performance Analytics Server, SAS.RTM.  LASR.TM., SAS.RTM.  In-Database Products, SAS.RTM.  Scalable Performance Data Engine, SAS/ORO, SAS/ETSO, SAS.RTM.  Event\nStream Processing, SAS.RTM.  Inventory Optimization, SAS.RTM.  Inventory Optimization Workbench, SAS.RTM.  Visual Analytics, SAS In-Memory Statistics for Hadoop.RTM., SAS.RTM.  Forecast Server, all of which are developed and provided by SAS Institute\nInc.  of Cary, N.C., USA.  Data mining is applicable in a wide variety of industries.\nDecomposition application 122 may be integrated with other system processing tools to automatically process data generated as part of operation of an enterprise, device, system, facility, etc., to identify any outliers in the processed data, to\nmonitor changes in the data, to track movement of an object, to process an image, a video, a sound file or other data files such as for background subtraction, cloud removal, face recognition, etc., and to provide a warning or alert associated with the\nmonitored data using input interface 102, output interface 104, and/or communication interface 106 so that appropriate action can be initiated in response to changes in the monitored data.\nDecomposition application 122 may be implemented as a Web application.  For example, decomposition application 122 may be configured to receive hypertext transport protocol (HTTP) responses and to send HTTP requests.  The HTTP responses may\ninclude web pages such as hypertext markup language (HTML) documents and linked objects generated in response to the HTTP requests.  Each web page may be identified by a uniform resource locator (URL) that includes the location or address of the\ncomputing device that contains the resource to be accessed in addition to the location of the resource on that computing device.  The type of file or resource depends on the Internet application protocol such as the file transfer protocol, HTTP, H.323,\netc. The file accessed may be a simple text file, an image file, an audio file, a video file, an executable, a common gateway interface application, a Java applet, an extensible markup language (XML) file, or any other type of file supported by HTTP.\nDataset 124 may include, for example, a plurality of rows and a plurality of columns.  The plurality of rows may be referred to as observation vectors or records (observations), and the columns may be referred to as variables.  Dataset 124 may\nbe transposed.  Dataset 124 may include unsupervised data.  The plurality of variables may define multiple dimensions for each observation vector.  An observation vector m.sub.i may include a value for each of the plurality of variables associated with\nthe observation i. For example, if dataset 124 includes data related to operation of a vehicle, the variables may include an oil pressure, a speed, a gear indicator, a gas tank level, a tire pressure for each tire, an engine temperature, a radiator\nlevel, etc. Dataset 124 may include data captured as a function of time for one or more physical objects.\nThe data stored in dataset 124 may be generated by and/or captured from a variety of sources including one or more sensors of the same or different type, one or more computing devices, etc. The data stored in dataset 124 may be received directly\nor indirectly from the source and may or may not be pre-processed in some manner.  For example, the data may be pre-processed using an event stream processor such as the SAS.RTM.  Event Stream Processing Engine (ESPE), developed and provided by SAS\nInstitute Inc.  of Cary, N.C., USA.  As a result, the data of dataset 124 may be processed as it is streamed through monitoring device 100.\nAs used herein, the data may include any type of content represented in any computer-readable format such as binary, alphanumeric, numeric, string, markup language, etc. The data may be organized using delimited fields, such as comma or space\nseparated fields, fixed width fields, using a SAS.RTM.  dataset, etc. The SAS dataset may be a SAS.RTM.  file stored in a SAS.RTM.  library that a SAS.RTM.  software tool creates and processes.  The SAS dataset contains data values that may be organized\nas a table of observations (rows) and variables (columns) that can be processed by one or more SAS software tools.\nDataset 124 may be stored on computer-readable medium 108 or on one or more computer-readable media of distributed computing system 130 and accessed by monitoring device 100 using communication interface 106, input interface 102, and/or output\ninterface 104.  Data stored in dataset 124 may be sensor measurements or signal values captured by a sensor, may be generated or captured in response to occurrence of an event or a transaction, generated by a device such as in response to an interaction\nby a user with the device, etc. The data stored in dataset 124 may include any type of content represented in any computer-readable format such as binary, alphanumeric, numeric, string, markup language, etc. The content may include textual information,\ngraphical information, image information, audio information, numeric information, etc. that further may be encoded using various encoding techniques as understood by a person of skill in the art.  The data stored in dataset 124 may be captured at\ndifferent time points periodically, intermittently, when an event occurs, etc. One or more columns of dataset 124 may include a time and/or date value.\nDataset 124 may include data captured under normal operating conditions of the physical object.  Dataset 124 may include data captured at a high data rate such as 200 or more observations per second for one or more physical objects.  For\nexample, data stored in dataset 124 may be generated as part of the Internet of Things (IoT), where things (e.g., machines, devices, phones, sensors) can be connected to networks and the data from these things collected and processed within the things\nand/or external to the things before being stored in dataset 124.  For example, the IoT can include sensors in many different devices and types of devices, and high value analytics can be applied to identify hidden relationships, monitor for system\nchanges, etc. to drive increased efficiencies.  This can apply to both big data analytics and real-time analytics.  Some of these devices may be referred to as edge devices, and may involve edge computing circuitry.  These devices may provide a variety\nof stored or generated data, such as network data or data specific to the network devices themselves.  Again, some data may be processed with an ESPE, which may reside in the cloud or in an edge device before being stored in dataset 124.\nDataset 124 may be stored using various structures as known to those skilled in the art including one or more files of a file system, a relational database, one or more tables of a system of tables, a structured query language database, etc. on\nmonitoring device 100 or on distributed computing system 130.  Monitoring device 100 may coordinate access to dataset 124 that is distributed across distributed computing system 130 that may include one or more computing devices.  For example, dataset\n124 may be stored in a cube distributed across a grid of computers as understood by a person of skill in the art.  As another example, dataset 124 may be stored in a multi-node Hadoop.RTM.  cluster.  For instance, Apache.TM.  Hadoop.RTM.  is an\nopen-source software framework for distributed computing supported by the Apache Software Foundation.  As another example, dataset 124 may be stored in a cloud of computers and accessed using cloud computing technologies, as understood by a person of\nskill in the art.  The SAS.RTM.  LASR.TM.  Analytic Server may be used as an analytic platform to enable multiple users to concurrently access data stored in dataset 124.  The SAS.RTM.  Viya.TM.  open, cloud-ready, in-memory architecture also may be used\nas an analytic platform to enable multiple users to concurrently access data stored in dataset 124.  Some systems may use SAS In-Memory Statistics for Hadoop.RTM.  to read big data once and analyze it several times by persisting it in-memory for the\nentire session.  Some systems may be of other types and configurations.\nBold letters are used herein to denote vectors and matrices.  .parallel.a.parallel..sub.1 and .parallel.a.parallel..sub.2 represent the l1-norm and l2-norm of vector a, respectively.  For an arbitrary real matrix A, .parallel.A.parallel..sub.F\ndenotes a Frobenius norm of matrix A, .parallel.A.parallel..sub.+ denotes a nuclear norm of matrix A (sum of all singular values), and .parallel.A.parallel..sub.1 denotes the l1-norm of matrix A, where A is treated as a vector.\nAn objective function for robust principal component analysis (RPCA) may decompose an observed matrix M (such as data in dataset 124) into a low-rank matrix L and a sparse noise matrix S by solving a principal component pursuit (PCP):\n.times..lamda..times..times..times..times.  ##EQU00001##\nAs used herein, T denotes a number of observations in dataset 124, and t is an index to a specific observation vector in dataset 124.  m.sub.t is an observation vector of dimension m as in m.sub.t is represented by m variables of the plurality\nof variables in dataset 124.  Data referenced as dataset 124 may be streaming observations m.sub.t.di-elect cons..sup.m, t=1, .  . . , T, which can be decomposed into two parts as m.sub.t=l.sub.t+s.sub.t.  The first part l.sub.t is a vector from a\nlow-rank subspace U.sub.t, and the second part s.sub.t is a sparse error with support size c.sub.t, where c.sub.t represents a number of nonzero elements of s.sub.t, such that c.sub.t=.SIGMA..sub.i=1.sup.m I.sub.s.sub.t.sub.[i].noteq.0.  The underlying\nsubspace U.sub.t, may or may not change with time t. When U.sub.t does not change over time, the data in dataset 124 are generated from a stable subspace.  Otherwise, the data in dataset 124 are generated from a changing subspace that may be slowly\nchanging, quickly changing, and/or abruptly changing.  s.sub.t may satisfy a sparsity assumption, i.e., c.sub.t&lt;&lt;m for all t=1, .  . . , T. M.sub.t=[m.sub.1, .  . . , m.sub.t] .di-elect cons..sup.m.times.t denotes a matrix of observation vectors\nuntil time t, and M, L, S denote M.sub.t, L.sub.t, S.sub.t, respectively.  For illustration, FIG. 6 shows a plurality of observation vectors such as a first observation vector m.sub.1 600-1, a second observation vector m.sub.2 600-2, a third observation\nvector m.sub.3 600-3, .  . . , and a k.sup.th observation vector m.sub.k 600-k, where each observation vector includes m=[v.sub.1, v.sub.2, v.sub.3, .  . . , v.sub.m], where v.sub.1 is a value for a first variable of the plurality of variables, v.sub.2\nis a value for a second variable of the plurality of variables, v.sub.3 is a value for a third variable of the plurality of variables, .  . . , v.sub.m is a value for an m.sup.th variable of the plurality of variables.\nAs understood by a person of skill in the art, various algorithms have been developed to solve RPCA-PCP, including accelerated proximal gradient (APG) (see e.g., Z. Lin, A. Ganesh, J. Wright, L. Wu, M. Chen, and Y. Ma, \"Fast convex optimization\nalgorithms for exact recovery of a corrupted low-rank matrix,\" Computational Advances in Multi-Sensor Adaptive Processing (CAMSAP), vol. 61, 2009.) and augmented Lagrangian multiplier (ALM) (see e.g., Z. Lin, M. Chen, and Y. Ma, \"The augmented Lagrange\nmultiplier method for exact recovery of corrupted low-rank matrices,\" arXiv preprint arXiv:1009.5055, 2010.).\nMerely for illustration, in implementing RPCA-PCP-ALM, let S.sub..tau.  denote a shrinkage operator S.sub..tau.=sgn(x)max(|x|-.tau., 0), which is extended to matrices by applying it to each matrix element.  Let .sub..tau.(X) denote a singular\nvalue thresholding operator given by .sub..tau.(X)=US.sub..tau.(.SIGMA.)V.sup.+, where X=U.SIGMA.V.sup.+ is any singular value decomposition.  Matrices S.sub.0 and Y.sub.0 may be initialized to zero and a loop of equations (1) to (3) below repeated until\na convergence criteria (e.g., number of iterations tolerance value) specified by a user is satisfied: L.sup.(k+1)=.sub..mu..sub.-1(M-S.sup.(k)+.mu..sup.-1Y.sup.(k)) (1) S.sup.(k+1)=.sub..lamda..mu..sub.-1(M-L.sup.(k+1)+.mu..sup.-1Y.sup.(k)) (2)\nY.sup.(k+1)-Y.sup.(k)+.mu.(M-L.sup.(k+1)+S.sup.(k+1)).  (3)\n.sub..mu..sub.-1 is computed by choosing values for constants .mu.  and .lamda..  A singular value decomposition (SVD) is computed of X to determine U, .SIGMA., and V.sup.+.  S.sub..tau.  is applied to .SIGMA.  with .tau.=.mu..sup.-1 to shrink\nthe computed singular values.  The singular values smaller than .mu..sup.-1 are set to zero while U and V.sup.+ are not modified.  .sub..lamda.82 .sub.-1 is computed using equation (2) by applying S.sub..tau.  with .tau.=.lamda..mu..sup.-1 to shrink a\nresidual of the decomposition.  The process is repeated until convergence, where an upper indice (e.g., (k), (k+1)) denote an iteration number for the same observation m.sub.t.\nAs another illustration, a stochastic optimization RPCA-PCP (STOC-RPCA-PCP) is described by J. Feng, H. Xu, and S. Yan, \"Online robust pca via stochastic optimization,\" in Advances in Neural Information Processing Systems 26 (C. J. C. Burges, L.\nBottou, M. Welling, Z. Ghahramani, and K. Q. Weinberger, eds.), pp.  404-412, Curran Associates, Inc., 2013.  STOC-RPCA-PCP starts by minimizing a loss function below:\n.times..times..lamda..times..lamda..times.  ##EQU00002## where .lamda..sub.1, .mu..sub.2 are tuning parameters defined by a user as understood by a person of skill in the art.  An equivalent form of the nuclear norm can be defined by the\nfollowing, which states that the nuclear norm for a matrix L whose rank is upper bounded by r has an equivalent form:\n.di-elect cons.  .times..di-elect cons.  .times..times..times..times..times..times..times.  ##EQU00003##\nSubstituting L with UV and plugging equation (5) into equation (4) results in\n.di-elect cons.  .times..di-elect cons.  .times..times..times..lamda..times..lamda..times.  ##EQU00004## where U can be seen as a basis for the low-rank subspace and V represents coefficients of the observations with respect to the basis. \nSTOC-RPCA-PCP minimizes an empirical version of the loss function of equation (6) and processes one observation vector each time instance.  Though t is indicated as a time point other types of monotonically increasing values, preferably with a common\ndifference between successive values, may be used.  Given a finite set of observation vectors M.sub.t=[m.sub.1, .  . . , m.sub.t] .di-elect cons..sup.m.times.t, the empirical version of the loss function of equation (6) at time point t can be defined by\n.function..times..times..function..lamda..times..times..times.  ##EQU00005## where the loss function for each observation is defined as\n.function..times..DELTA..times..times..times..lamda..times..lamda..times.  ##EQU00006##\nFixing U as U.sub.t, v.sub.t and s.sub.t can be obtained by solving the optimization problem:\n.times..times..lamda..times..lamda..times.  ##EQU00007##\nAssuming that {v.sub.i,s.sub.i}.sub.i=1.sup.t, are known, the basis U.sub.t can be updated by minimizing the following function:\n.function..times..DELTA..times..times..times..times..lamda..times..lamda.- .times..lamda..times..times..times.  ##EQU00008## which results in the explicit solution\n.times..times..times..function..times..times..times..lamda..times.  ##EQU00009## where v.sub.i.sup.T represents the transpose of v.sub.i and I represents an identity matrix.  Referring to FIG. 2, example operations associated with decomposition\napplication 122 are described.  Decomposition application 122 may implement an algorithm referenced herein as online, moving window, RPCA-PCP (OMWRPCA).  Additional, fewer, or different operations may be performed depending on the embodiment of\ndecomposition application 122.  The order of presentation of the operations of FIG. 2 is not intended to be limiting.  Although some of the operational flows are presented in sequence, the various operations may be performed in various repetitions,\nconcurrently (in parallel, for example, using threads and/or distributed computing system 130), and/or in other orders than those that are illustrated.  A user may execute decomposition application 122, which causes presentation of a first user interface\nwindow, which may include a plurality of menus and selectors such as drop down menus, buttons, text boxes, hyperlinks, etc. associated with decomposition application 122 as understood by a person of skill in the art.  The plurality of menus and selectors\nmay be accessed in various orders.  An indicator may indicate one or more user selections from a user interface, one or more data entries into a data field of the user interface, one or more data items read from computer-readable medium 108 or otherwise\ndefined with one or more default values, etc. that are received as an input by decomposition application 122.\nIn an operation 200, one or more indicators may be received that indicate values for input parameters used to define execution of decomposition application 122.  As an example, the one or more indicators may be received by decomposition\napplication 122 after selection from a user interface window, after entry by a user into a user interface window, read from a command line, read from a memory location of computer-readable medium 108 or of distributed computing system 130, etc. In an\nalternative embodiment, one or more input parameters described herein may not be user selectable.  For example, a value may be used or a function may be implemented automatically or by default.  Illustrative input parameters may include, but are not\nlimited to: an indicator of dataset 124, such as a location and a name of dataset 124; an indicator of a plurality of variables of dataset 124 to define m, such as a list of column names that include numeric values; an indicator of a value of T, a number\nof observations to process that may be an input or determined by reading dataset 124 or may be determined by incrementing a counter for each streaming observation processed; an indicator of one or more rules associated with selection of an observation\nfrom the plurality of observations of dataset 124 where a column may be specified with a regular expression to define the rule; an indicator of a value of n.sub.win, a window size for a number of observations (in general, the value of n.sub.win should be\nlong enough to capture a temporal content of the signal, but short enough that the signal is approximately stationary within the window; thus, the value is related to how fast the underlying subspace is changing such that, for an underlying subspace that\nchanges quickly, a small value is used; for illustration a default value may be 200); an indicator of a value of n.sub.start, a number of observations used to initialize the OMWRPCA algorithm where a default value may be n.sub.start=n.sub.win\n(n.sub.start may not be equal to n.sub.win, for example, when initialization may include more observations for accuracy); an indicator of a value of rank r of the r-dimensional linear subspace that is not used if the n.sub.start observations are used\ninitialize the OMWRPCA algorithm (in general, the value of r may be selected to be large enough to capture \"most\" of the variance of the data, where \"most\" may be defined, for example, as 90%, or a maximum allowed value based on a dimensionality of the\nobservations); an indicator of whether to use the n.sub.start observations to initialize the OMWRPCA algorithm and to define the rank r or to use zero matrices and the indicated rank r (values of rank r and/or n.sub.start may indicate that one or the\nother is used as well.  For example, rank r equal to zero may indicate that the n.sub.start observations are used to initialize the OMWRPCA algorithm without a separate input parameter); an indicator of a value of .lamda., a first tuning parameter\ndefined above (in general, the value of .lamda.  may be set to either of the values of .lamda..sub.1 or .lamda..sub.2 though other values may be used, for example, as described in E. J. Candes, X. Li, Y. Ma, and J. Wright, \"Robust principal component\nanalysis?\", Journal of the ACM (JACM), vol. 58, no. 3, p. 11, 2011); an indicator of a value of .mu., a second tuning parameter defined above (in general, the value of .mu.  may be selected based on a desired level of accuracy.  For illustration,\n.mu..times..times..times..times.  ##EQU00010## an indicator of a value of .lamda..sub.1, a third tuning parameter defined above where a default value may be .lamda..sub.1=1/ {square root over (max(m,n.sub.win))}; an indicator of a value of\n.lamda..sub.2, a fourth tuning parameter defined above where a default value may be .lamda..sub.2=100/ {square root over (max(m,n.sub.win))}; an indicator of an RPCA algorithm to apply such as ALM or APG; an indicator of a maximum number of iterations to\nperform by the indicated RPCA algorithm; an indicator of a convergence tolerance to determine when convergence has occurred perform by the indicated RPCA algorithm; an indicator of a low-rank decomposition algorithm such as singular value decomposition\n(SVD) or principal component analysis (PCA) (in general, PCA requires computing the covariance matrix first such that SVD may be appropriate when computing the covariance matrix is expensive, for example, when m is large; an indicator of parameters to\noutput such as the low-rank data matrix for each observation L.sub.t, the low-rank data matrix L.sub.T, the sparse data matrix for each observation S.sub.t, the sparse data matrix S.sub.T, an error matrix that contains noise in dataset 124, the SVD\ndiagonal vector, the SVD left vector, the SVD right vector, the value of rank r, a matrix of principal component loadings, a matrix of principal component scores, etc.; an indicator of where to store and/or to present the indicated output such as a name\nand a location of dataset decomposition description 126 or an indicator that the output is to a display in a table and/or is to be graphed, etc.;\nThe input parameters may vary based on the type of data of dataset 124 and may rely on the expertise of a domain expert.\nIn an operation 201, an iteration index t=1 is initialized.\nIn an operation 202, a determination is made concerning whether to use the n.sub.start observations to initialize the OMWRPCA algorithm.  When the n.sub.start observations are used to initialize the OMWRPCA algorithm, processing continues in an\noperation 206.  When the n.sub.start observations are not used to initialize the OMWRPCA algorithm, processing continues in an operation 204.\nIn operation 204, the rank r is set to the indicated value, a U.sub.0 matrix is initialized to an (m.times.r) zero matrix, an A.sub.0 matrix is initialized to an (r.times.r) zero matrix, a B.sub.0 matrix is initialized to an (m.times.r) zero\nmatrix, and processing continues in operation 210.\nIn operation 206, an initial observation matrix M.sup.s=[m.sub.-(n.sub.start.sub.-1), .  . . , m.sub.0] is selected from dataset 124, where m is an observation vector having the specified index in dataset 124.  The user may or may not have an\ninitial dataset available to select the initial observation matrix M.sup.s.  The user also may monitor the first few observations to determine an appropriate \"burn-in period\".  The user may specify a first observation that is the burn-in number of\nobservations after the beginning of dataset 124.\nIn an operation 208, the rank r, the U.sub.0 matrix, the A.sub.0 matrix, and the B.sub.0 matrix are computed, for example, using RPCA-PCP-ALM as shown referring to FIG. 3 in accordance with an illustrative embodiment.  Though RPCA-PCP-ALM is\nused for illustration, other PCA algorithms may be used to initialize the parameters described in other manners.\nReferring to FIG. 3, example operations associated with decomposition application 122 performing RPCA-PCP-ALM are described.  Additional, fewer, or different operations may be performed depending on the embodiment of decomposition application\n122.  The order of presentation of the operations of FIG. 3 is not intended to be limiting.  Although some of the operational flows are presented in sequence, the various operations may be performed in various repetitions, concurrently (in parallel, for\nexample, using threads and/or distributed computing system 130), and/or in other orders than those that are illustrated.\nIn an operation 300, the S.sub.0 matrix and the Y.sub.0 matrix are initialized to (m.times.n.sub.start) zero matrices, and index k=0 is initialized.  .sub..mu..sub.-1 is initialized as .sub..tau.(X)=US.sub..tau.(.SIGMA.)V.sup.+, where\nX=U.SIGMA.V.sup.+ is any singular value decomposition of M.sup.s as described above.  .sub..lamda..mu..sub.-1 is initialized by applying S.sub..tau.  with .tau.=.lamda..mu..sup.-1 to shrink a residual of the decomposition.\nIn an operation 301, increment k using k=k+1.\nIn an operation 302, L.sup.k=.sub..mu..sub.-1 (M.sup.s-S.sup.(k-1)+.mu..sup.-1Y.sup.(k-1)) is computed using the value of the second tuning parameter .mu..\nIn an operation 304, S.sup.k=.sub..lamda..mu..sub.-1(M.sup.s-L.sup.k+.mu..sup.-1Y.sup.(k-1)) is computed.\nIn an operation 306, Y.sup.k=Y.sup.(k-1)+.mu.(M.sup.s-L.sup.k+S.sup.k) is computed.\nIn an operation 308, a determination is made concerning whether or not a solution has converged.  When the solution has converged, processing continues in an operation 310.  When the solution has not converged, processing continues in an\noperation 301 to repeat operations 301 to 308.  For example, the maximum number of iterations and/or the convergence tolerance may be used to determine when convergence has occurred.  For illustration, convergence may be determined when a Frobenius norm\nof a residual M.sup.s-L.sup.k+S.sup.k is smaller than a predefined tolerance that may be defined by a user or a default value may be used.\nIn operation 310, the rank r, the U.sub.0 matrix, A.sub.t, B.sub.t, s.sub.0 and v.sub.0 are computed from the converged solution for L.sup.k and S.sup.k, and processing continues in operation 210, where L.sup.k=[l.sub.-(n.sub.start.sub.-1), .  .\n. , l.sub.0]=[U.sub.-(n.sub.start.sub.-1)v.sub.-(n.sub.start.sub.-1), .  . . , U.sub.0v.sub.0] and S.sup.k=[s.sub.-(n.sub.start.sub.-1), .  . . , s.sub.0].  From SVD, L.sup.k={circumflex over (.SIGMA.)}{circumflex over (V)}, where .di-elect\ncons..sup.m.times.r, {circumflex over (.SIGMA.)}.di-elect cons..sup.r.times.r, and {circumflex over (V)}.di-elect cons..sup.r.times.n.sup.start.  U.sub.0={circumflex over (.SIGMA.)}.sup.1/2.di-elect cons..sup.m.times.r,\nA.sub.0=.SIGMA..sub.i=-(n.sub.start.sub.-1).sup.0v.sub.iv.sub.i.sup.T.di-- elect cons..sup.r.times.r, B.sub.0=.SIGMA..sub.i=-(n.sub.start.sub.-1).sup.0(m.sub.i-s.sub.i)v.sub.i- .sup.T.di-elect cons..sup.m.times.r.  The rank r of the r-dimensional linear\nsubspace is a dimension of , {circumflex over (.SIGMA.)}, or {circumflex over (V)}.  The v.sub.i vectors are the columns of {circumflex over (V)} obtained from the SVD of L.sup.k.\nReferring again to FIG. 2, in operation 210, a next observation vector m.sub.t, such as m.sub.1 on a first iteration, m.sub.2 on a second iteration, etc. is loaded from dataset 124.  For example, the next observation vector m.sub.t is loaded by\nreading from dataset 124 or by receiving a next streamed observation vector.\nIn an operation 212, a decomposition is computed using the loaded observation vector m.sub.t to update the U.sub.t matrix, the A.sub.t matrix, the B.sub.t matrix, s.sub.t, and v.sub.t, for example, using STOC-RPCA-PCP as shown referring to FIG.\n4 modified to use the indicated value of n.sub.win in accordance with an illustrative embodiment.\nReferring to FIG. 4, example operations associated with decomposition application 122 performing RPCA-PCP-ALM are described.  Additional, fewer, or different operations may be performed depending on the embodiment of decomposition application\n122.  The order of presentation of the operations of FIG. 4 is not intended to be limiting.\nIn an operation 400, v.sub.t and s.sub.t are computed by solving the optimization problem\n.times..times..times..lamda..times..lamda..times.  ##EQU00011##\nIn an operation 402, A.sub.t is computed using A.sub.t=A.sub.t-1+v.sub.tv.sub.t.sup.T-v.sub.t-n.sub.winv.sub.t-n.sub.win- .sup.T, where the value v.sub.t-n.sub.winv.sub.t-n.sub.win.sup.T is removing the effect of the edge of the window.\nIn an operation 404, B.sub.t is computed using B.sub.t=B.sub.t-1+(m.sub.t-s.sub.t)v.sub.t.sup.T-(m.sub.t-n.sub.win-s.sub- .t-n.sub.win)v.sub.t-n.sub.win.sup.T, where the value (m.sub.t-n.sub.win-s.sub.t-n.sub.win)v.sub.t-n.sub.win.sup.T is\nremoving the effect of the edge of the window.\nIn an operation 406, is computed using =A.sub.t+.lamda..sub.1I, where A.sub.t=[a.sub.1, .  . . , a.sub.r] .di-elect cons..sup.r.times.r, .lamda..sub.1 is the value of the third tuning parameter, I is an identity matrix, U.sub.t-1=[u.sub.1, .  .\n. u.sub.r] .di-elect cons..sup.m.times.r, B.sub.t=[b.sub.1, .  . . , b.sub.r] .di-elect cons..sup.r.times.r, and =[a.sub.1, .  . . , a.sub.r] .di-elect cons..sup.r.times.r.  A rank index j is initialized as j=1.\nIn an operation 408, {tilde over (.mu.)}.sub.1 is computed using\n.function..times..times.  ##EQU00012##\nIn an operation 410, .mu..sub.j is computed using\n.function..times.  ##EQU00013##\nIn an operation 412, a determination is made concerning whether or not each rank has been processed, for example, by comparing the rank index j to the rank r. When each rank has been processed, processing continues in an operation 416.  When\neach rank has not been processed, processing continues in an operation 414.\nIn operation 414, the rank index j is incremented as j=j+1, and processing continues in operation 408 to compute the next values.\nIn operation 416, U.sub.t is updated with the computed values of u.sub.j, j=1, .  . . r, where U.sub.t argmin 1/2 Tr [U.sup.T (A.sub.t+.lamda..sub.1I) U.sup.T-Tr(U.sup.TB.sub.t), and processing continues in an operation 214 with the updated\nvalues of A.sub.t, B.sub.t, U.sub.t, v.sub.t, and S.sub.t.\nReferring again to FIG. 2, in operation 214, the low-rank matrix L.sub.T, where L.sub.T={l.sub.1, l.sub.2, .  . . l.sub.T}, is updated with values of l.sub.t=U.sub.tv.sub.t computed in operation 212, and the sparse noise matrix S.sub.T, where\nS.sub.T={s.sub.1, s.sub.2, .  . . s.sub.T} is updated with the value of s.sub.t computed in operation 212.\nIn an operation 216, window decomposition data is output based on the indicated output selections.  For example, one or more of l.sub.t, s.sub.t, v.sub.t, U.sub.t, A.sub.t, B.sub.t, etc. may be output by storing to dataset decomposition\ndescription 126, by presenting on display 116 in a table or a graph, by printing to printer 120 in a table or a graph, etc. Dataset decomposition description 126 may be stored on computer-readable medium 108 or on one or more computer-readable media of\ndistributed computing system 130 and accessed by monitoring device 100 using communication interface 106, input interface 102, and/or output interface 104.  Window decomposition data further may be output by sending to another display or printer of\ndistributed computing system 130 and/or published to another computing device of distributed computing system 130 for further processing of the data in dataset 124 and/or of the window decomposition data.  For example, monitoring of the window\ndecomposition data may be used to determine whether or not a system is performing as expected.\nIn an operation 218, a determination is made concerning whether or not dataset 124 includes one or more unprocessed observation vector.  When dataset 124 includes one or more unprocessed observation vector, processing continues in an operation\n220.  When dataset 124 does not include one or more unprocessed observation vector, processing continues in an operation 222.  When dataset 124 is streamed to monitoring device 100, processing may wait until a full observation vector is received.  When\ndataset 124 is not being streamed, the last observation vector may have been read from dataset 124.  As another option, the value of T indicated by the user may be less than the number of observations included in dataset 124, in which case, processing\ncontinues to operation 222 when the number of iterations of operation 210 specified by the indicated value of T have been completed.\nIn operation 220, the iteration index t is incremented using t=t+1, and processing continues in operation 210 to load the next observation vector and repeat operations 210 to 218.\nIn operation 222, decomposition data is output based on the indicated output selections.  For example, one or more of L.sub.T, S.sub.T, U.sub.T, etc. may be output by storing to dataset decomposition description 126, by presenting on display 116\nin a table or a graph, by printing to printer 120 in a table or a graph, etc. Dataset decomposition description 126 may be stored on computer-readable medium 108 or on one or more computer-readable media of distributed computing system 130 and accessed\nby monitoring device 100 using communication interface 106, input interface 102, and/or output interface 104.  Decomposition data further may be output by sending to another display or printer of distributed computing system 130 and/or published to\nanother computing device of distributed computing system 130 for further processing of the data in dataset 124 and/or of the decomposition data.  For example, monitoring of the decomposition data may be used to determine whether or not a system is\nperforming as expected.  Decomposition data and/or window decomposition data may be selected for output.\nReferring to FIGS. 5A, 5B, and 5C, example operations associated with decomposition application 122 are described.  Decomposition application 122 may implement an algorithm referenced herein as OMWRPCA with hypothesis testing (OMWRPCAHT). \nAdditional, fewer, or different operations may be performed depending on the embodiment of decomposition application 122.  The order of presentation of the operations of FIGS. 5A, 5B, and 5C is not intended to be limiting.\nSimilar to operation 200, in an operation 500, one or more indicators may be received that indicate values for input parameters used to define execution of decomposition application 122.  As an example, the one or more indicators may be received\nby decomposition application 122 after selection from a user interface window, after entry by a user into a user interface window, read from a command line, read from a memory location of computer-readable medium 108 or of distributed computing system\n130, etc. In an alternative embodiment, one or more input parameters described herein may not be user selectable.  For example, a value may be used or a function may be implemented automatically or by default.  Illustrative input parameters may include,\nbut are not limited to: the indicator of dataset 124; the indicator of a plurality of variables of dataset 124 to define m; the indicator of the value of T, the number of observations to process; the indicator of the one or more rules associated with\nselection of an observation from the plurality of observations of dataset 124; the indicator of the value of n.sub.win, the window size for a number of observations; the indicator of the value of n.sub.start, the number of observations used to initialize\nthe OMWRPCA algorithm; the indicator of the value of rank r of the r-dimensional linear subspace that is not used if the n.sub.start observations are used initialize the OMWRPCA algorithm; the indicator of whether to use the n.sub.start observations to\ninitialize the OMWRPCA algorithm; the indicator of the value of .lamda., the first tuning parameter; the indicator of the value of .mu., the second tuning parameter; the indicator of the value of .lamda..sub.1, the third tuning parameter; the indicator\nof the value of .lamda..sub.2, the fourth tuning parameter; the indicator of the RPCA algorithm to apply such as ALM or APG; the indicator of the maximum number of iterations to perform by the indicated RPCA algorithm; the indicator of the convergence\ntolerance to determine when convergence has occurred perform by the indicated RPCA algorithm; the indicator of the low-rank decomposition algorithm; an indicator of n.sub.stable, a first observation window length to process for a stable operation of\nOMWRPCA where a default value may be n.sub.stable=n.sub.win, an indicator of n.sub.sample, a second observation window length to process after n.sub.stable observations and before a start of hypothesis testing where a default value may be\nn.sub.sample=n.sub.win/2;\nan indicator of .alpha., an abnormal observation threshold to indicate an abnormal observation where a default value may be .alpha.=0.01; an indicator of N.sub.check, a buffer window length for hypothesis testing, that may be less than\nn.sub.win/2 to avoid missing a change point, but not too small to generate an inordinate number of false alarms (for illustration, N.sub.check=n.sub.win/10 may be a default value); an indicator of n.sub.prob, a change point threshold that defines a\nnumber of observations within the buffer window length used to indicate a change point within a current buffer window where a default value may be n.sub.prob=a.sub.probN.sub.check, where .alpha..sub.prob=0.5 is a default value though the value can be\nselected based on typical rates of change and ranges of variation in the operating regime of dataset 124, where noisier signals may use longer windows to average out the noise and fast-changing systems need shorter windows to capture the change points;\nan indicator of n.sub.positive, a number of consecutive abnormal indicators to identify a change point where n.sub.positive=3 is a default value; an indicator of n.sub.tol, a tolerance parameter that may have a default value of zero; the indicator of\nparameters to output such as the low-rank data matrix for each observation L.sub.t, the low-rank data matrix L.sub.T, the sparse data matrix for each observation S.sub.t, the sparse data matrix S.sub.T, an error matrix that contains noise in dataset 124,\nthe SVD diagonal vector, the SVD left vector, the SVD right vector, a matrix of principal component loadings, a matrix of principal component scores, a change point index, a change point value, etc.; the indicator of where to store and/or to present the\nindicated output such as a name and a location of dataset decomposition description 126 or an indicator that the output is to a display in a table and/or is to be graphed, etc.; the indicator of where to store and/or to present the indicated output such\nas a name and a location of dataset change points description 128 or an indicator that the output is to a display in a table and/or is to be graphed, etc.;\nIn an operation 502, iteration indices t=0 and t.sub.start=0 are initialized.  Additionally, a zero counter vector H.sub.c is initialized to a 0.sup.m+1 zero vector, a flag buffer list B.sub.f is initialized as an empty list, and a zero count\nbuffer list B.sub.c is initialized as an empty list.\nSimilar to operation 202, in an operation 504, a determination is made concerning whether to use the n.sub.start observations to initialize the OMWRPCA algorithm.  When the n.sub.start observations are used to initialize the OMWRPCA algorithm,\nprocessing continues in an operation 510.  When the n.sub.start observations are not used to initialize the OMWRPCA algorithm, processing continues in an operation 506.\nSimilar to operation 204, in operation 506, the rank r is set to the indicated value, a U.sub.0 matrix is initialized to an (m.times.r) zero matrix, an A.sub.0 matrix is initialized to an (r.times.r) zero matrix, a B.sub.0 matrix is initialized\nto an (m.times.r) zero matrix, and processing continues in operation 514.\nSimilar to operation 206, in operation 510, an initial observation matrix M.sup.s=[m.sub.-(n.sub.start.sub.-1), .  . . , m.sub.0] is selected from dataset 124, where m is an observation vector having the specified index in dataset 124.\nSimilar to operation 208, in an operation 512, the rank r, the U.sub.0 matrix, the A.sub.0 matrix, and the B.sub.0 matrix are computed, for example, using RPCA-PCP-ALM as shown referring to FIG. 3 in accordance with an illustrative embodiment. \nThough RPCA-PCP-ALM is used for illustration, other PCA algorithms may be used to initialize the parameters described in other manners.\nSimilar to operation 220, in operation 514, the iteration index t is incremented using t=t+1.\nSimilar to operation 210, in an operation 516, a next observation vector m.sub.t, such as m.sub.1 on a first iteration, m.sub.2 on a second iteration, etc. is loaded from dataset 124.  For example, the next observation vector m.sub.t is loaded\nby reading from dataset 124 or by receiving a next streamed observation vector.\nSimilar to operation 212, in an operation 518, a decomposition is computed using the loaded observation vector m.sub.t to update the U.sub.t matrix, A.sub.t, B.sub.t, s.sub.t, and v.sub.t, for example, using STOC-RPCA-PCP as shown referring to\nFIG. 4 modified to use the indicated value of n.sub.win in accordance with an illustrative embodiment.\nSimilar to operation 214, in an operation 520, the low-rank matrix L.sub.T, where L.sub.T={l.sub.1, l.sub.2, .  . . l.sub.T}, is updated with values of l.sub.t=U.sub.tv.sub.t computed in operation 518, and the sparse noise matrix S.sub.T, where\nS.sub.T={s.sub.1, s.sub.2, .  . . s.sub.T} is updated with the value of s.sub.t computed in operation 518.\nSimilar to operation 216, in an operation 522, window decomposition data is output based on the indicated output selections, and processing continues in operation 528 shown referring to FIG. 5B.\nSimilar to operation 218, in an operation 524, a determination is made concerning whether or not dataset 124 includes one or more unprocessed observation vector.  When dataset 124 includes one or more unprocessed observation vector, processing\ncontinues in operation 514 to load the next observation vector and repeat one or more of operations 514 to 570.  When dataset 124 does not include one or more unprocessed observation vector, processing continues in an operation 526.\nSimilar to operation 222, in operation 526, decomposition data is output based on the indicated output selections.\nReferring to FIG. 5B, in operation 528, a zero counter time series value c.sub.t is computed using c.sub.t=.SIGMA..sub.i=1.sup.ms.sub.t[i].\nIn an operation 530, a determination is made concerning whether or not the subspace is stable.  When the subspace is stable, processing continues in operation 532.  When the subspace is not stable, processing continues in operation 524. \nStability may be based on processing a number of additional observation vectors m.sub.t based on the indicated first observation window length n.sub.stable.  For example, when t.gtoreq.n.sub.stable+t.sub.start or when t.gtoreq.n.sub.stable+t.sub.start,\nthe subspace may be determined to be stable.\nIn an operation 532, a determination is made concerning whether or not a sufficient hypothesis sample size has been processed.  When the sufficient hypothesis sample size has been processed, processing continues in operation 536.  When the\nsufficient hypothesis sample size has not been processed, processing continues in operation 534.  The sufficient hypothesis sample size may be based on processing a number of additional observation vectors m.sub.t based on the indicated second\nobservation window length n.sub.sample.  For example, when t&gt;n.sub.stable+n.sub.sample+t.sub.start or when t.gtoreq.n.sub.stable+n.sub.sample+t.sub.start, the sufficient sample size has been processed.  Hypothesis testing is performed on each\nsubsequent observation vector m.sub.t.\nIn operation 534, zero counter vector H.sub.c is updated as H.sub.c[c.sub.t+1]=H.sub.c[c.sub.t+1]+1, and processing continue in operation 524 to process a next observation vector.  Zero counter vector H.sub.c maintains a count of a number of\ntimes each value of c.sub.t occurs in a current stable period after the last change point.\nIn operation 536, a probability value p is computed for c.sub.t using p=.SIGMA..sub.i=c.sub.t.sub.-n.sub.tol.sub.+1.sup.m+1 H.sub.c[i]/.SIGMA..sub.i=0.sup.m+1 H.sub.c[i].  Probability value p is a probability that a sparse noise vector includes\nat least as many nonzero elements as the current observation vector m.sub.t.\nIn an operation 538, the computed probability value p is compared to the abnormal observation threshold .alpha..\nIn an operation 540, a flag value f.sub.t is set to zero or one based on the comparison.  The flag value f.sub.t is an indicator of whether or not the current observation vector m.sub.t is abnormal in comparison to previous observation vectors. \nFor example, f.sub.t=1 when p&lt;.alpha., or when p.ltoreq..alpha.  to indicate that the current observation vector m.sub.t is abnormal, and otherwise, f.sub.t=0.  Of course, other flag settings and comparisons may be used as understood by a person of\nskill in the art.  For example, f.sub.t=1 may indicate an abnormal observation.\nIn an operation 542, a determination is made concerning whether or not flag buffer list B.sub.f and zero count buffer list B.sub.c are full.  When the buffer lists are full, processing continues in an operation 544.  When the buffer lists are\nnot full, processing continues in an operation 548.  For example, flag buffer list B.sub.f and zero count buffer list B.sub.c may be full when their length is N.sub.check.\nIn operation 544, a first value in flag buffer list B.sub.f and in zero count buffer list B.sub.c is popped from each list to make room for another item at an end of each buffer list, where c is the value popped from B.sub.c.\nIn an operation 546, the H.sub.c vector is updated as H.sub.c[c+1]=H.sub.c[c+1]+1.  H.sub.c is a zero counter vector that maintains a count of a number of times each value of c.sub.t equals the total number of nonzero components of the estimated\nsparse vector in the current stable period after the last change point.\nIn operation 548, the flag value f.sub.t is appended to an end of flag buffer list B.sub.f, and c.sub.t is appended to an end of zero count buffer list B.sub.c.\nIn an operation 550, a determination is made concerning whether or not flag buffer list B.sub.f and zero count buffer list B.sub.c are now full.  When the buffer lists are now full, processing continues in an operation 552 shown referring to\nFIG. 5C.  When the buffer lists are not now full, processing continues in operation 524.  For example, flag buffer list B.sub.f and zero count buffer list B.sub.c may be full when their length is N.sub.check.\nReferring to FIG. 5C, hypothesis testing is performed.  In operation 552, a number of abnormal values n.sub.abnormal is computed from flag buffer list B.sub.f using n.sub.abnormal=.SIGMA..sub.i=1.sup.N.sup.check B.sub.f[i].\nIn an operation 554, the computed number of abnormal values n.sub.abnormal is compared to the change point threshold n.sub.prob.\nIn an operation 556, a determination is made concerning whether or not a change point has occurred based on the comparison.  When the change point has occurred, processing continues in an operation 558.  When the change point has not occurred,\nprocessing continues in operation 524.  For example, when n.sub.abnormal&gt;n.sub.prob, or when n.sub.abnormal.gtoreq.n.sub.prob, a change point has occurred in the most recent N.sub.check number of observation vectors.\nIn an operation 558, a buffer starting index t.sub.bufstt is identified by looping through entries in flag buffer list B.sub.f from a start of the list to an end of the list to identify occurrence of a change point, which is detected as a first\ninstance of the number of consecutive abnormal indicators (i.e., f.sub.t=1) n.sub.positive in flag buffer list B.sub.f.  For example, if B.sub.f [n1], B.sub.f [n1+1], B.sub.f [n1+n.sub.positive-1] are the first occurrence of the n.sub.positive\nconsecutive abnormal flag values, n1 is the buffer starting index t.sub.bufstt.\nIn an operation 560, a determination is made concerning whether or not a buffer starting index t.sub.bufstt was identified.  When the buffer starting index t.sub.bufstt was identified, processing continues in an operation 562.  When the buffer\nstarting index t.sub.bufstt was not identified, processing continues in operation 524.\nIn operation 562, an overall index t.sub.ov is determined for the observation vector associated with the change point based on a current value of t as t.sub.ov=t-N.sub.check+t.sub.bufstt.  Typically, only the time of the change point is\nimportant.  However, if the change point vector is needed, it is stored and can be extracted using overall index t.sub.ov.\nIn an operation 564, change point data is output based on the indicated output selections.  For example, m.sub.t.sub.ov, may be output by storing to dataset change point description 128, by presenting on display 116 in a table or a graph, by\nprinting to printer 120 in a table or a graph, etc. Dataset change point description 128 may be stored on computer-readable medium 108 or on one or more computer-readable media of distributed computing system 130 and accessed by monitoring device 100\nusing communication interface 106, input interface 102, and/or output interface 104.  Change point data m.sub.t.sub.ov, further may be output by sending to another display or printer of distributed computing system 130 and/or published to another\ncomputing device of distributed computing system 130 for further processing of the data in dataset 124 and/or of the decomposition data.  For example, monitoring of the change point data may be used to determine whether or not a system is performing as\nexpected.  Change point data further may include output that is associated with m.sub.t.sub.ov, such as of l.sub.t.sub.ov, s.sub.t.sub.ov, v.sub.t.sub.ov, U.sub.t.sub.ov, A.sub.t.sub.ov, B.sub.t.sub.ov, etc. For example, an alert may be sent when a\nchange point is identified.  The alert may include a reference to t.sub.ov or to m.sub.t.sub.ov or to l.sub.t.sub.ov, s.sub.t.sub.ov, v.sub.t.sub.ov, U.sub.t.sub.ov, A.sub.t.sub.ov, B.sub.t.sub.ov, etc.\nIn an operation 566, t.sub.ov may be appended to a change point list.\nIn an operation 568, iteration index t is reset to t=t.sub.ov and t.sub.start=t.sub.ov are initialized\nIn an operation 570, the H.sub.c vector is initialized to the 0.sup.m+1 zero vector, the flag buffer list B.sub.f is initialized as the empty list, and the zero count buffer list B.sub.c is initialized as the empty list, and processing continues\nin operation 504 of FIG. 5A to restart from the identified change point vector.  Processing may continue as windows of data are received or read from dataset 124 until processing is stopped.\nReferring to FIG. 7, a comparison between a relative error computed for the low-rank matrix using three different algorithms is shown in accordance with an illustrative embodiment.  The first algorithm is the known RPCA algorithm described by\nFIG. 4 without use of windows or initialization based on the operations of FIG. 3 also indicated as STOC-RPCA-PCP.  The second algorithm uses the operations of FIGS. 2-4 with windowing and initialization based on the operations of FIG. 3 also indicated\nas OMWRPCA.  The third algorithm uses the operations of FIGS. 3-5 with windowing and initialization based on the operations of FIG. 3 and hypothesis testing also indicated as OMWRPCAHT.\nThe comparison was based on data with a slowly changing subspace.  The observation vectors in the slowly changing subspace were generated through M=L+S, where S is the sparse noise matrix with a fraction of a sparsity probability p of non-zero\nelements.  The non-zero elements of S were randomly chosen and generated from a uniform distribution over the interval of [-1000, 1000].  The low-rank subspace L was generated as a product L=UV, where the sizes of U and V are m.times.r and m.times.T,\nrespectively.  The elements of both U and V are independent and identically distributed (i.i.d.) samples from the (0,1) distribution.  U was the basis of the constant subspace with dimension r. T=5000 and m=400 were used to generate the observation\nvectors M. An n.sub.start number of observation vectors with size 400.times.200 was also generated.  Four combinations of (r, p) were generated: 1) (10, 0.01), (10, 0.1), (50, 0.01), and (50, 0.1).  For each combination, 50 replications were run using\nthe following parameters for each simulation study, .lamda..sub.1=1/ {square root over (400)}, .lamda..sub.2=100/ {square root over (400)}, n.sub.win=200, n.sub.start=200, n.sub.stable=200, n.sub.sample=100, N.sub.check=20, n.sub.prob=0.5 N.sub.check,\n.alpha.=0.01, n.sub.positive=3, and, n.sub.tol=0.  Subspace U was changed linearly after generating U.sub.0 by adding new matrices { .sub.k}.sub.k=1.sup.K that were generated independently with i.i.d.  (0,1) elements added to the first r.sub.0 columns of\nU, where .sub.k .di-elect cons..sup.m.times.r.sup.0, k=1, .  . . , K and\n##EQU00014## T.sub.p=250 and r.sub.0=5 were used.\n.times..times..times..times..times..times..times..times..function..times.- .times..function..times..times..ltoreq..ltoreq..times..times..times..funct- ion..function.  ##EQU00015## was used to generate the slowly changing subspace observation\nvectors.\nThe comparison between the relative error computed for the low-rank matrix using the three different algorithms and the slowly changing subspace is shown for each simulation study using a box plot for each.  For example, a first box plot 700\nshows results for the first algorithm with (10, 0.01), where (r=10, p=0.01), a second box plot 702 shows results for the second algorithm with (10, 0.01), and a third box plot 704 shows results for the third algorithm with (10, 0.01).  A fourth box plot\n710 shows results for the first algorithm with (10, 0.1), a fifth box plot 712 shows results for the second algorithm with (10, 0.1), and a sixth box plot 714 shows results for the third algorithm with (10, 0.1).  A seventh box plot 720 shows results for\nthe first algorithm with (50, 0.01), an eighth box plot 722 shows results for the second algorithm with (50, 0.01), and a ninth box plot 724 shows results for the third algorithm with (50, 0.01).  A tenth box plot 730 shows results for the first\nalgorithm with (50, 0.1), an eleventh box plot 732 shows results for the second algorithm with (50, 0.1), and a twelfth box plot 734 shows results for the third algorithm with (50, 0.1).\nReferring to FIG. 8, a comparison between a relative error computed for the sparse noise matrix using the three different algorithms and the slowly changing subspace is shown for each simulation study using a box plot for each in accordance with\nan illustrative embodiment.  For example, a first box plot 800 shows results for the first algorithm with (10, 0.01), where (r=10, p=0.01), a second box plot 802 shows results for the second algorithm with (10, 0.01), and a third box plot 804 shows\nresults for the third algorithm with (10, 0.01).  A fourth box plot 810 shows results for the first algorithm with (10, 0.1), a fifth box plot 812 shows results for the second algorithm with (10, 0.1), and a sixth box plot 814 shows results for the third\nalgorithm with (10, 0.1).  A seventh box plot 820 shows results for the first algorithm with (50, 0.01), an eighth box plot 822 shows results for the second algorithm with (50, 0.01), and a ninth box plot 824 shows results for the third algorithm with\n(50, 0.01).  A tenth box plot 830 shows results for the first algorithm with (50, 0.1), an eleventh box plot 832 shows results for the second algorithm with (50, 0.1), and a twelfth box plot 834 shows results for the third algorithm with (50, 0.1).\nReferring to FIG. 9, a comparison between a proportion of correctly identified elements in the sparse noise matrix using the three different algorithms and the slowly changing subspace is shown for each simulation study using a box plot for each\nin accordance with an illustrative embodiment.  For example, a first box plot 900 shows results for the first algorithm with (10, 0.01), where (r=10, p=0.01), a second box plot 902 shows results for the second algorithm with (10, 0.01), and a third box\nplot 904 shows results for the third algorithm with (10, 0.01).  A fourth box plot 910 shows results for the first algorithm with (10, 0.1), a fifth box plot 912 shows results for the second algorithm with (10, 0.1), and a sixth box plot 914 shows\nresults for the third algorithm with (10, 0.1).  A seventh box plot 920 shows results for the first algorithm with (50, 0.01), an eighth box plot 922 shows results for the second algorithm with (50, 0.01), and a ninth box plot 924 shows results for the\nthird algorithm with (50, 0.01).  A tenth box plot 930 shows results for the first algorithm with (50, 0.1), an eleventh box plot 932 shows results for the second algorithm with (50, 0.1), and a twelfth box plot 934 shows results for the third algorithm\nwith (50, 0.1).\nReferring to FIG. 10, a comparison as a function of time between the relative error computed for the low-rank matrix using the three different algorithms with a rank of 10, a sparsity probability of 0.01, and the slowly changing subspace is\nshown in accordance with an illustrative embodiment.  A first curve 1000 shows results for the first algorithm, and a second curve 1002 shows results for the second algorithm and the third algorithm.  As expected, in a slowly changing subspace, the\nsecond and third algorithms perform similarly and much better than the first algorithm that is not responsive to the changing subspace.\nReferring to FIG. 11, a comparison as a function of time between the relative error computed for the low-rank matrix using the three different algorithms with a rank of 50, a sparsity probability of 0.01, and the slowly changing subspace is\nshown in accordance with an illustrative embodiment.  A third curve 1100 shows results for the first algorithm, and a fourth curve 1102 shows results for the second algorithm and the third algorithm.\nReferring to FIG. 12, a comparison between a relative error computed for the low-rank matrix using the three different algorithms is shown in accordance with an illustrative embodiment.  The comparison was based on data with two abrupt changes\nin the subspace at t=1000 and t=2000.  T=3000 was used.  The same parameters used to create the slowly changing subspace observation vectors were used to generate the with two abrupt, where the underlying subspaces U were changed and generated completely\nindependently for each time window [0,1000], [1000,2000], and [2000,3000].\nFor example, a first box plot 1200 shows results for the first algorithm with (10, 0.01), a second box plot 1202 shows results for the second algorithm with (10, 0.01), and a third box plot 1204 shows results for the third algorithm with (10,\n0.01).  A fourth box plot 1210 shows results for the first algorithm with (10, 0.1), a fifth box plot 1212 shows results for the second algorithm with (10, 0.1), and a sixth box plot 1214 shows results for the third algorithm with (10, 0.1).  A seventh\nbox plot 1220 shows results for the first algorithm with (50, 0.01), an eighth box plot 1222 shows results for the second algorithm with (50, 0.01), and a ninth box plot 1224 shows results for the third algorithm with (50, 0.01).  A tenth box plot 1230\nshows results for the first algorithm with (50, 0.1), an eleventh box plot 1232 shows results for the second algorithm with (50, 0.1), and a twelfth box plot 1234 shows results for the third algorithm with (50, 0.1).\nReferring to FIG. 13, a comparison between a relative error computed for the sparse noise matrix using the three different algorithms and with two abrupt changes in the subspace is shown in accordance with an illustrative embodiment.  For\nexample, a first box plot 1300 shows results for the first algorithm with (10, 0.01), where (r=10, p=0.01), a second box plot 1302 shows results for the second algorithm with (10, 0.01), and a third box plot 1304 shows results for the third algorithm\nwith (10, 0.01).  A fourth box plot 1310 shows results for the first algorithm with (10, 0.1), a fifth box plot 1312 shows results for the second algorithm with (10, 0.1), and a sixth box plot 1314 shows results for the third algorithm with (10, 0.1).  A\nseventh box plot 1320 shows results for the first algorithm with (50, 0.01), an eighth box plot 1322 shows results for the second algorithm with (50, 0.01), and a ninth box plot 1324 shows results for the third algorithm with (50, 0.01).  A tenth box\nplot 1330 shows results for the first algorithm with (50, 0.1), an eleventh box plot 1332 shows results for the second algorithm with (50, 0.1), and a twelfth box plot 1334 shows results for the third algorithm with (50, 0.1).\nReferring to FIG. 14, a comparison between a proportion of correctly identified elements in the sparse noise matrix using the three different algorithms and with two abrupt changes in the subspace is shown in accordance with an illustrative\nembodiment.  For example, a first box plot 1400 shows results for the first algorithm with (10, 0.01), where (r=10, p=0.01), a second box plot 1402 shows results for the second algorithm with (10, 0.01), and a third box plot 1404 shows results for the\nthird algorithm with (10, 0.01).  A fourth box plot 1410 shows results for the first algorithm with (10, 0.1), a fifth box plot 1412 shows results for the second algorithm with (10, 0.1), and a sixth box plot 1414 shows results for the third algorithm\nwith (10, 0.1).  A seventh box plot 1420 shows results for the first algorithm with (50, 0.01), an eighth box plot 1422 shows results for the second algorithm with (50, 0.01), and a ninth box plot 1424 shows results for the third algorithm with (50,\n0.01).  A tenth box plot 1430 shows results for the first algorithm with (50, 0.1), an eleventh box plot 1432 shows results for the second algorithm with (50, 0.1), and a twelfth box plot 1434 shows results for the third algorithm with (50, 0.1).\nReferring to FIG. 15, a comparison as a function of time between the relative error computed for the low-rank matrix using the three different algorithms with a rank of 10, a sparsity probability of 0.01, and with two abrupt changes in the\nsubspace is shown in accordance with an illustrative embodiment.  A first curve 1500 shows results for the first algorithm, a second curve 1502 shows results for the second algorithm, and a third curve 1504 shows results for the third algorithm.\nReferring to FIG. 16, a comparison as a function of time between the relative error computed for the low-rank matrix using the three different algorithms with a rank of 50, a sparsity probability of 0.01, and with two abrupt changes in the\nsubspace is shown in accordance with an illustrative embodiment.  A first curve 1600 shows results for the first algorithm, a second curve 1602 shows results for the second algorithm, and a third curve 1604 shows results for the third algorithm.\nReferring to FIGS. 12-16, as expected, in an abruptly changing subspace, the second algorithm performed much better than the first algorithm that is not responsive to the changing subspace.  The third algorithm performed much better than the\nsecond algorithm that is not responsive to the abrupt changes.\nReferring to FIG. 17, a comparison as a function of rank between a relative difference between a detected change point time and a true change point time using the third algorithm with the sparsity probability of 0.01, and the two abrupt changes\nin the subspace is shown in accordance with an illustrative embodiment.  The results show that the third algorithm can accurately determine the change point time.\nVideo is a good candidate for low-rank subspace tracking due to a correlation between frames.  In surveillance video, a background is generally stable and may change very slowly due to varying illumination.  To demonstrate that the third\nalgorithm can effectively track slowly changing subspace with change points, a \"virtual camera\" was panned from left to right and right to left through an airport video.  The \"virtual camera\" moved at a speed of 1 pixel per 10 frames.  The original frame\nwas size 176.times.144 for the airport video data.  The virtual camera had the same height and half the width.  Each frame was stacked to a column and fed as dataset 124 to the third algorithm.  To make the background subtraction task even more\ndifficult, one change point was added to the video where the \"virtual camera\" jumped instantly from the most right-hand side to the most left-hand side.\nReferring to FIG. 18A, an image capture from an airport video at a first time is shown in accordance with an illustrative embodiment.  Referring to FIG. 18B, the low-rank matrix computed from the image capture of FIG. 18A using the third\nalgorithm is shown in accordance with an illustrative embodiment.  Referring to FIG. 18C, the low-rank matrix computed from the image capture of FIG. 18A using the first algorithm is shown in accordance with an illustrative embodiment.  Referring to FIG.\n18D, the sparse noise matrix computed from the image capture of FIG. 18A using the third algorithm is shown in accordance with an illustrative embodiment.  Referring to FIG. 18E, the sparse noise matrix computed from the image capture of FIG. 18A using\nthe first algorithm is shown in accordance with an illustrative embodiment.  The results generated using the third algorithm are less blurry with a less populated sparse noise matrix.\nReferring to FIG. 19A, an image capture from the airport video at a second time is shown in accordance with an illustrative embodiment.  Referring to FIG. 19B, the low-rank matrix computed from the image capture of FIG. 19A using the third\nalgorithm is shown in accordance with an illustrative embodiment.  Referring to FIG. 19C, the low-rank matrix computed from the image capture of FIG. 19A using the first algorithm is shown in accordance with an illustrative embodiment.  Referring to FIG.\n19D, the sparse noise matrix computed from the image capture of FIG. 19A using the third algorithm is shown in accordance with an illustrative embodiment.  Referring to FIG. 19E, the sparse noise matrix computed from the image capture of FIG. 19A using\nthe first algorithm is shown in accordance with an illustrative embodiment.  The results generated using the third algorithm are less blurry with a less populated sparse noise matrix.\nReferring to FIG. 20, a comparison of principal components computed using the third algorithm is shown in accordance with an illustrative embodiment that shows detection of a wind turbine that begins to deviate from the other turbines.\nThere are applications for decomposition application 122 in areas such as process control and equipment health monitoring, radar tracking, sonar tracking, face recognition, recommender system, cloud removal in satellite images, anomaly\ndetection, background subtraction for surveillance video, system monitoring, failure detection in mechanical systems, intrusion detection in computer networks, human activity recognition based on sensor data, etc.\nFor tracking in video: in each image, the sparse noise matrix S represents the pixels of moving objects, while the low-rank subspace L represents a static background.  Thus, standard tracking algorithms such as a Kalman filter may be applied to\nthe sparse noise matrix S only while ignoring the low-rank subspace L.\nFor recommender systems: the low-rank subspace L may be used to represent preferences of users according to a rating they assign to movies, songs or other items.  Such preferences can vary with time.  Therefore, it is important to monitor change\npoints.  Additionally, the sparse noise matrix S may correspond to abnormal/undesirable users such as bots.\nDataset 124 may include sensor readings measuring multiple key health or process parameters at a very high frequency.  A change point may indicate when a process being monitored deviates from a normal operating condition such as when a fault, a\ndisturbance, a state change, etc. occurs.  Decomposition application 122 is effective in an online environment in which high-frequency data is generated.\nThe word \"illustrative\" is used herein to mean serving as an example, instance, or illustration.  Any aspect or design described herein as \"illustrative\" is not necessarily to be construed as preferred or advantageous over other aspects or\ndesigns.  Further, for the purposes of this disclosure and unless otherwise specified, \"a\" or \"an\" means \"one or more\".  Still further, using \"and\" or \"or\" in the detailed description is intended to include \"and/or\" unless specifically indicated\notherwise.\nThe foregoing description of illustrative embodiments of the disclosed subject matter has been presented for purposes of illustration and of description.  It is not intended to be exhaustive or to limit the disclosed subject matter to the\nprecise form disclosed, and modifications and variations are possible in light of the above teachings or may be acquired from practice of the disclosed subject matter.  The embodiments were chosen and described in order to explain the principles of the\ndisclosed subject matter and as practical applications of the disclosed subject matter to enable one skilled in the art to utilize the disclosed subject matter in various embodiments and with various modifications as suited to the particular use\ncontemplated.", "application_number": "15893959", "abstract": " A computing device updates an estimate of one or more principal\n     components for a next observation vector. An initial observation matrix\n     is defined with first observation vectors. A number of the first\n     observation vectors is a predefined window length. Each observation\n     vector of the first observation vectors includes a plurality of values. A\n     principal components decomposition is computed using the initial\n     observation matrix. The principal components decomposition includes a\n     sparse noise vector s, a first singular value decomposition vector U, and\n     a second singular value decomposition vector v for each observation\n     vector of the first observation vectors. A rank r is determined based on\n     the principal components decomposition. A next principal components\n     decomposition is computed for a next observation vector using the\n     determined rank r. The next principal components decomposition is output\n     for the next observation vector and monitored to determine a status of a\n     physical object.\n", "citations": ["7590282", "9598947", "9697177", "20080059051", "20090310855", "20110272161", "20120063641", "20150323425"], "related": ["62462291"]}, {"id": "20180338010", "patent_code": "10334065", "patent_name": "Method for detecting applications of mobile user terminals", "year": "2019", "inventor_and_country_data": " Inventors: \nLlanos Alonso; Julia (Madrid, ES), Guzman Sacristan; Antonio (Madrid, ES), Alonso Cebrian; Jose Maria (Madrid, ES)  ", "description": "<BR><BR>RELATED APPLICATION\nThis application claims the benefit of priority of European Patent Application No. 17382279.2 filed May 16, 2017, the contents of which are incorporated herein by reference in their entirety.\n<BR><BR>FIELD AND BACKGROUND OF THE INVENTION\nThe present invention has its application within the telecommunication sector, more specifically, relates to the analysis of mobile user traffic.\nMore particularly, the present invention refers to a method for detecting from mobile traffic applications (apps) of mobile user terminals (smartphones, tablets, etc.).\nSmartphones offer users the possibility to install on them whatever applications (apps) they decide to (apart from preinstalled apps).  These apps belong to categories as entertainment, sports, productivity, travel .  . . . Therefore,\napplications installed in a certain smartphone provide useful information about its user profile, to be understood as the set of habits and preferences of a person.\nThose apps require Internet connection for tasks as content update or access authorization.  The set of queries or requests sent to retrieve data from Internet is here defined as traffic.  Being a protocol a set of predefined rules that defines\nthe way of transferring information, requests information may vary depending on the used protocol.  Examples of information appearing in requests are: source IP, request date and time, domain or user agent.  The latter concepts, domain and user agent,\nare defined as follows: Domain is the unique name that identifies a website on the Internet.  User agent includes information about several aspects like: application source, device operating system or software version.  It has to be emphasized that not\nevery protocol includes the user agent field.\nThe smartphones have recently experimented an exponential growth in terms of number of users and hours spent with them.  In this context, knowing applications used by a customer will allow to precisely define its profile.  A correct user profile\nis the key to success in multiple use-cases like recommender systems, protection against possible security threats (malicious apps) or statistical analysis, as defined as follows: Recommender systems: Those systems are present in several areas such as\ncinema, music or shopping.  They aim to predict user interests, i.e. user profile, on those areas using information of his activity.  Based on these predictions, they provide recommendations to users about elements that match their interests.  As more\nprecise the predictions, the better the recommendations.  Malicious apps: Applications classified as malicious are, for example, those tricking users into unwanted pays or subscriptions.  Statistical analysis: Analysis over user profiles and their\ndistribution, which can guide, for example, further commercial or investment decisions.\nMobile Network Operators (MNOs) can obtain information required to define users profile from mobile traffic.  A request is generated each time a mobile user interacts with an app on its smartphone.  The request passes through the MNO\ninfrastructure, which both stores it in a database as sends it to the Internet.  Data stored in the MNO database is simplified information of HTTP and DNS requests.  Hypertext Transfer Protocol (HTTP) is a protocol for transferring hypermedia files. \nDomain Name System (DNS) is a naming system for clients or services connected to the Internet or to a private network.  DNS associates a domain name with an internet protocol address (IP).  The information stored in the database is the domain and the\ndate and time of the request, i.e. the complete URL is not consulted in any case.  In addition, all stored data are anonymized.\nThere are approaches for analyzing mobile traffic based on domain information.  However, relation between domains and applications is not bijective.  Unique domains, i.e. domains exclusively accessed by an app, are the less frequent.  Instead,\nthere are some domains accessed by many apps.  In the latter case, the knowledge of the domain does not univocally define the application.\nThere are also approaches for analyzing mobile traffic based on user agent.  User agent presents two major drawbacks: not all HTTP petitions have user agent value, and applications developers decide the value of user agent field, so they can use\nanother apps' user agent instead of setting their own.\nFinally, there is a great variability in the requests of a concrete application.  It is due, inter alia, to the different operating systems or mobile user devices (smartphones, tablets).  Even different executions of the same application on the\nsame terminal do not maintain the same request order.  Some issues related to the requests variability are, to name but a few: request may be cached, latencies between requests vary depending on the mobile use, list of domains consulted by an app may\nvary between devices, or dynamic content include noise in executions.\nTherefore, it is highly desirable to develop a method of apps detection from the mobile traffic which allows the MNOs to get a more precise user profile.\n<BR><BR>SUMMARY OF THE INVENTION\nThe present invention solves the aforementioned problems and overcomes previously explained state-of-art work limitations by providing a method for detecting applications (apps) downloaded and/or used by a user in his/her mobile terminal (e.g.,\na smartphone, tablet, etc.).  The apps detection is based on the analysis of domain information collected from the mobile user's traffic.  More particularly, the method of apps detection uses an analysis of domains by words considering their frequency\nand so the method is device and request order independent.\nAn aspect of the present invention refers to a method for detecting applications of mobile users, the applications generating a train of files associated with one or more mobile user terminals and each mobile user terminal engaged in the\ngeneration of mobile user traffic, which comprises the following steps: parsing the train of files to obtain the set of Internet domains to which requests from an application are made and splitting every obtained domain into a list of words which\ngenerates a signature of the application, weighting the words of the generated signature to obtain a frequency of each word, splitting the mobile user traffic of each mobile user terminal into traffic blocks, each traffic block being a set of domains\nrequested in a time interval, and splitting each traffic block into words; generating a traffic vector for each traffic block by including the words of the traffic block and the frequency of each word according to its repetition on the traffic block,\ncomparing the generated traffic vectors with the generated signature of each application by applying the cosine similarity method and obtaining, through this comparison, a number of times that the generated signature of each application is detected in\nthe generated traffic vectors of a mobile user terminal.\nThe present invention has a number of advantages with respect to prior art, which can be summarized as follows: The proposed method profiles a user more precisely and this is useful to propose successfully by a recommender system, e.g., a\nconcrete use-case of the invention could be an apps recommender.  The invention allows the detection of malicious applications so that the user can avoid them or, at least, to understand the risks.  The invention allows users to be profiled by means of\nknowing the categories of the apps on their smartphones and the frequency of its use.  Statistical analysis over these user profiles can lead to further commercial or investment decisions based on the users' apps.  The proposed method runs using only DNS\nand HTTP traffic, specifically the domain of the requests.  Every single module of the proposal (collection of isolated traffic by application, signatures generation, traffic parsing, evaluation .  . . ) can be automatized to be a feedback system.  The\nmethod is robust to temporal incoherence in requests arrival order.  The method is learning-designed, improving the precision of phone apps detection.  The method can work in real-time or in batch-mode (i.e. in non-real-time).\nThese and other advantages will be apparent in the light of the detailed description of the invention. <BR><BR>BRIEF DESCRIPTION OF THE SEVERAL VIEWS OF THE DRAWINGS\nFor the purpose of aiding the understanding of the characteristics of the invention, according to a preferred practical embodiment thereof and in order to complement this description, the following FIGURES are attached as an integral part\nthereof, having an illustrative and non-limiting character:\nFIG. 1 shows a flow chart of a method for detecting applications in mobile traffic, according to a preferred embodiment of the invention.\n<BR><BR>DESCRIPTION OF SPECIFIC EMBODIMENTS OF THE INVENTION\nThe matters defined in this detailed description are provided to assist in a comprehensive understanding of the invention.  Accordingly, those of ordinary skill in the art will recognize that variation changes and modifications of the\nembodiments described herein can be made without departing from the scope and spirit of the invention.  Also, description of well-known functions and elements are omitted for clarity and conciseness.\nOf course, the embodiments of the invention can be implemented in a variety of architectural platforms, operating and server systems, devices, systems, or applications.  Any particular architectural layout or implementation presented herein is\nprovided for purposes of illustration and comprehension only and is not intended to limit aspects of the invention.\nFIG. 1 presents a main chart flow of the method steps, divided in eight main stages: Stage 1, Generate signatures (1): Each app generates a train of files, files generated with isolated traffic, multiple times and with multiple devices.  All the\nsamples are grouped for each app and the method parses these train files.  From each group associated with an app, only the domains to which requests are made by the app are considered.  Every domain is splitted to get a list of words that represent each\napp. The list of words corresponding to each application is defined here as the app signature.  Stage 2, Perform weighting (2) algorithm computations on the generated signatures: words on the signature are weighted, the range of weights being 0-1. \nHigher weights are assigned to most frequent and significant words.  Stage 3, Split real traffic (3) at time intervals per user: user traffic is divided in blocks.  Division is performed attending to temporal criteria, i.e. a block is formed with the\nmobile traffic on a specific time interval.  The blocks are further analyzed in search of the predominant app. Stage 4, Split each traffic block (4) in words: each traffic block is a set of domains queried in a time interval.  Domains are here splitted,\nusing the dot as the splitting criteria.  Hence, the traffic block is now a set of words.  Repetition is allowed.  Stage 5, Generate traffic vectors by performing frequency (5) computations on each interval: the traffic block is here reduced to a vector\nincluding words and their frequency attending to their repetition on the block.  Stage 6, Apply the similarity (6) on each interval and signatures: traffic vectors are here compared against app signatures via the known cosine similarity method\n(described, for example, by Li, B. et al. in \"Distance weighted cosine similarity measure for text classification\", Intelligent Data Engineering and Automated Learning--IDEAL, volume 8206 of Lecture Notes in Computer Science, Springer, pp.  611-618,\n2013).  The maximum value for an app signature results in the definition of a tern user-app-value for that block.  A list of terns is generated for the traffic.  Stage 7, Estimate the probability (7) of a user having each app: the likelihood for a user\nof having an app installed is estimated based on evidences of previous output.  Those evidences are the number of times the app was detected and the likelihood, i.e. the similarity result of each detection.  Stage 8, Apply threshold (8) on the output:\nirrelevant results must be discarded.  To this aim, a threshold (minimum likelihood value required) is fixed avoiding low-likelihood results to be considered.  The threshold is fixed by means of the maximum value of F1, F1 being one of the F-measures\ndescribed by Powers, D. M. in \"Evaluation: from precision, recall and F-measure to ROC, informedness, markedness and correlation\" (Journal of Machine Learning Technologies, Vol. 2, No. 1, pp.  37-63, 2011).  F1 measure is defined in terms of precision\nand recall for the model evaluation.  Precision measures the fraction of tuples user-app successfully detected against those wrongly detected.  Recall measures the fraction of tuples user-app successfully detected against those miss-detected.\nReal time solution pre-calculates the first two stages.  For example, in a real-time use case where a user wants to know which apps can be detected from his smartphone, a possible implementation can be described as follows: Each time set, e.g. 5\nminutes, the method automatically collects the generated traffic since previous check.  Stages 3 to 6 of FIG. 1 are applied to this traffic, resulting in a user-app-value tern list.  Stage 7 is run on the tern list.  The outputs of this stage are the\nestimated probabilities of apps being installed on the target smartphone considering only this 5 minutes of traffic.  They are stored in the database for the final combination.  The outputs of all the stages 7 for the whole traffic are lately combined,\nobtaining a final set of applications and its probabilities associated.  At this point, a decay function comes into play, which is responsible for reducing the resulting value of likelihood by observing absence of evidence.  It includes a temporal factor\nin the likelihood estimation, weighting positively the most recent evidences and vice versa.  Looking for the applications installed on the analyzed smartphone, the probabilities are thresholded.  Threshold has been fixed in the training process, looking\nto maximize the detected apps and avoiding false positives.\nNote that in this text, the term \"comprises\" and its derivations (such as \"comprising\", etc.) should not be understood in an excluding sense, that is, these terms should not be interpreted as excluding the possibility that what is described and\ndefined may include further elements, steps, etc.", "application_number": "15980762", "abstract": " A method for detecting applications of mobile user terminals, comprising:\n       parsing files of an app to obtain domains of requests and splitting\n     every domain into words to generate an app signature, weighting the words\n     to obtain their frequency, splitting the mobile traffic into traffic\n     blocks and each traffic block into words, generating a traffic vector for\n     each block by including the repetition or frequency of each word in the\n     block, comparing the generated traffic vectors with the generated\n     signature by applying a similarity method to obtain the number of times\n     that the signature is detected in the traffic vectors of a mobile\n     terminal, estimating a probability of a user having the app installed in\n     the mobile terminal, applying a threshold on the probability to discard\n     wrongly detected applications.\n", "citations": ["9633081", "20090138446", "20090282027", "20110029657", "20120147769", "20150058488"], "related": []}, {"id": "20190007252", "patent_code": "10333759", "patent_name": "Receiver for receiving data in a broadcast system", "year": "2019", "inventor_and_country_data": " Inventors: \nQi; Junge (Braunschweig, DE), Robert; Joerg (Vreden, DE), Zoellner; Jan (Braunschweig, DE), Stadelmeier; Lothar (Stuttgart, DE), Loghin; Nabil (Freiburg, DE)  ", "description": "<BR><BR>BACKGROUND\n<BR><BR>Field of the Disclosure\nThe present disclosure relates to receiver and a corresponding receiving method for receiving data in a broadcast system.  Further, the present disclosure relates to a broadband server and a corresponding method for providing redundancy data and\nto a broadcast system.\nThe present invention relates, for instance, to the field of Digital Video Broadcasting (DVB) utilizing Orthogonal Frequency Division Multiplexing (OFDM).  Further, the present invention can be applied in other systems, such as a DAB (Digital\nAudio Broadcasting), DRM, MediaFlo, ISDB, ATSC (e.g. 3.0) or LTE broadcast system.\n<BR><BR>Description of Related Art\nThe transmission parameters of known broadcast systems, such as the broadcast systems in accordance with the DVB-T2 standard (second generation digital terrestrial television broadcast systems standard), are generally optimized for fixed\nreception with stationary receivers, e.g. with roof-top antennas.  In future broadcast systems, such as the upcoming DVB-NGH (DVB Next Generation Handheld; in the following also referred to as NGH) standard, a mobile receiver (which is the main focus of\nthis upcoming standard) shall be enabled to receive data correctly also in bad reception situations, e.g. despite suffering from multipath propagation, fading effects and Doppler shifts.  Such broadcast systems are particularly characterized by the fact\nthat there is generally no feedback channel and no signalling from receivers to transmitters.\nA receiver for receiving data in a broadcast system by which the probability of error-free reception/reconstruction of data by a mobile receiver is increased compared to receivers in known broadcast systems, even under bad reception conditions,\nis disclosed in WO 2011/080020 A1.  The disclosed receiver comprises\na broadcast receiver unit for receiving from said broadcast system a receiver input data stream segmented into frames, wherein basic codeword portions of codewords are mapped onto said frames, a codeword comprising said at least a basic codeword\nportion generated from an input data word according to a first code,\na data demapper for demapping the basic codeword portions from said frames of the receiver input data stream,\na decoder for error correction code decoding said codewords into output data words of at least one output data stream in a regular decoding step by use of the basic codeword portion comprised in a codeword,\na check unit for checking if the regular decoding of a codeword is erroneous,\na unicast request unit for requesting, if said regular decoding of a codeword is erroneous, through a unicast system an auxiliary codeword portion of the erroneously decoded codeword for use as incremental redundancy in an additional decoding\nstep,\na unicast receiver unit for receiving from said unicast system an auxiliary codeword portion of the erroneously decoded codeword,\nwherein said decoder is adapted to decode the respective codeword again in an additional decoding step by additionally using the received auxiliary codeword portion, and\na data output for outputting said at least one receiver output data stream segmented into said decoded output data words.\nThe main use of redundancy data is the increase of the coverage area for terrestrial broadcasting.  Subscribers located at the edge of the coverage area of a broadcast system (also called broadcast network) are suffering from low receptions\nlevels, which may hinder error-free decoding.  This is also true for indoor reception or if large objects attenuate the transmitted signal.  To counter this problem the utilization of a (wired or wireless) broadband system (also called broadband network)\nfor providing additional redundancy for enabling error-free reception has been proposed.  In many cases only a few dBs received signal level are missing for the correct demodulation and decoding of the broadcast data, resulting in an additional\nredundancy data stream of few hundred kbit/s. Furthermore other channel impairments like burst noise or narrowband interferer create decoding errors in a sheer broadcast reception scenario which are corrected with the additional redundancy data stream.\nThe \"background\" description provided herein is for the purpose of generally presenting the context of the disclosure.  Work of the presently named inventor(s), to the extent it is described in this background section, as well as aspects of the\ndescription which may not otherwise qualify as prior art at the time of filing, are neither expressly or impliedly admitted as prior art against the present invention.\n<BR><BR>SUMMARY\nIt is an object to provide a receiver for receiving data in a broadcast system and a corresponding broadband server for providing redundancy data that enable to further increase the probability of error-free reception/reconstruction of broadcast\ndata without increasing the costs for transmitting too many redundancy data.  It is a further object to provide corresponding methods, a broadcast system, as well as a corresponding computer program for implementing said methods and a non-transitory\ncomputer-readable recording medium for implementing said methods.\nAccording to an aspect there is provided a receiver for receiving data in a broadcast system comprising:\na broadcast receiver that receives via said broadcast system a receiver input data stream comprising a plurality of channel symbols represented by constellation points in a constellation diagram,\na demodulator that demodulates said channel symbols into codewords,\na decoder that decodes said codewords into output data words,\na redundancy calculator that determines a required amount of redundancy data required for correct demodulation and decoding by use of the originally received channel symbol and additional redundancy data,\na broadband request unit that requests, if demodulation of a channel symbol and/or decoding of a codeword is erroneous or likely to fail, a required amount of redundancy data via a broadband system, and\na broadband receiver that receives redundancy data via said broadband system,\nwherein said demodulator and/or said decoder is configured to use said redundancy data to demodulate the respective channel symbol and to decode the respective codeword, respectively.\nAccording to a further aspect there is provided a corresponding receiving method for receiving data in a broadcast system comprising:\nreceiving via said broadcast system a receiver input data stream comprising a plurality of channel symbols represented by constellation points in a constellation diagram,\ndemodulating said channel symbols into codewords,\ndecoding said codewords into output data words,\ndetermining a required amount of redundancy data required for correct demodulation and decoding by use of the originally received channel symbol and additional redundancy data,\nrequesting, if demodulation of a channel symbol and/or decoding of a codeword is erroneous or likely to fail, a required amount of redundancy data via a broadband system, and\nreceiving redundancy data via said broadband system,\nwherein said redundancy data are used to demodulate the respective channel symbol and to decode the respective codeword, respectively.\nAccording to a further aspect there is provided a broadband server for providing redundancy data to a receiver of a broadcast system via a broadband system, comprising:\na receiving unit that receives requests from receivers of said broadcast system via said broadband system to provide redundancy data to the respective receivers via said broadband system to enable correct demodulation of a channel symbol and/or\ndecoding of a codeword, a request including channel state information,\na redundancy calculator that determines the required amount of redundancy data required for correct demodulation and decoding by use of said channel state information, and\na transmitting unit that provides redundancy data in at least said required amount to the receiver that requested redundancy data.\nAccording to a further aspect there is provided a method for providing redundancy data to a receiver of a broadcast system via a broadband system, comprising:\nreceiving requests from receivers of said broadcast system via said broadband system to provide redundancy data to the respective receivers via said broadband system to enable correct demodulation of a channel symbol and/or decoding of a\ncodeword, a request including channel state information,\ndetermining the required amount of redundancy data required for correct demodulation and decoding by use of said channel state information, and\nproviding redundancy data in at least said required amount to the receiver that requested redundancy data.\nAccording to still further aspects a broadcast system, a computer program comprising program means for causing a computer to carry out the steps of the method disclosed herein, when said computer program is carried out on a computer, as well as\na non-transitory computer-readable recording medium that stores therein a computer program product, which, when executed by a processor, causes the method disclosed herein to be performed are provided.\nPreferred embodiments are defined in the dependent claims.  It shall be understood that the claimed methods, the claimed broadcast system, the claimed computer program and the claimed computer-readable recording medium have similar and/or\nidentical preferred embodiments as the claimed receiver and/or broadband server and as defined in the dependent claims.\nOne of the aspects of the disclosure is to make use of the known concept of using redundancy data (in the known system obtained via a unicast system, but generally obtainable via a broadband system) and to further define in which way the optimal\namount of redundancy data can best be obtained.  This avoids a waste of available resource if only the minimal amount of necessary redundancy data is transmitted.\nIt is to be understood that both the foregoing general description of the invention and the following detailed description are exemplary, but are not restrictive of the invention. <BR><BR>BRIEF DESCRIPTION OF THE DRAWINGS\nA more complete appreciation of the disclosure and many of the attendant advantages thereof will be readily obtained as the same becomes better understood by reference to the following detailed description when considered in connection with the\naccompanying drawings, wherein:\nFIG. 1 shows a schematic diagram of a broadcast system according to the present disclosure,\nFIG. 2 shows a schematic diagram of a first embodiment of a receiver according to the present disclosure,\nFIG. 3 shows a more detailed diagram of a broadcast system according to the present disclosure,\nFIGS. 4A, 4B and 4C show diagrams illustrating the use of least significant bits as redundancy data,\nFIGS. 5A, 5B and 5C show diagrams illustrating the use of puncturing according to an embodiment of the present disclosure,\nFIGS. 6A and 6B show diagrams illustrating the use of a constellation subset identifier as redundancy data,\nFIG. 7 shows a diagram illustrating the identification of subcarriers having a low CNR,\nFIG. 8 shows a schematic diagram of a second embodiment of a receiver according to the present disclosure,\nFIG. 9 shows a schematic diagram of a third embodiment of a receiver according to the present disclosure,\nFIG. 10 shows a diagram of the relationship between overall cost for transmission and transmitter power consumption,\nFIG. 11 shows a schematic diagram of a dynamic broadcast system using the present invention,\nFIG. 12 shows a schematic diagram of a control device for use in a broadcast system according to the present disclosure,\nFIG. 13 shows a schematic diagram of another embodiment of a broadcast system according to the present disclosure,\nFIG. 14 shows a schematic diagram of another embodiment of a broadcast system according to the present disclosure,\nFIG. 15 shows a diagram illustrating the average estimated Mutual Information with and without knowledge of the transmitted bits,\nFIG. 16 shows a schematic diagram of another embodiment of a broadcast server according to the present disclosure,\nFIG. 17 shows a diagram illustrating cooperative decoding with a server controlling the data exchange, and\nFIG. 18 shows a diagram illustrating cooperative decoding without a server controlling the data exchange.\n<BR><BR>DESCRIPTION OF THE EMBODIMENTS\nReferring now to the drawings, wherein like reference numerals designate identical or corresponding parts throughout the several views, FIG. 1 shows a schematic diagram of a broadcast system 1 according to the present disclosure.  It comprises a\nbroadcast transmitter 2 that transmits, via said broadcast system, a receiver input data stream comprising a plurality of channel symbols represented by constellation points in a constellation diagram.  Further, it comprises one or more receivers 3, in\nthis case two receivers indicated as \"user A\" and \"user B\" arranged at different distances from the broadcast transmitter 2, according to the present disclosure for receiving data transmitted by the broadcast transmitter 2.  Still further, the broadcast\nsystem 1 comprises a broadband server 4 (also called broadband provider), in this case a redundancy server that provides redundancy data via a broadband system for reception by said receiver.  Due to the use of transmission of data via broadcast and via\nbroadband the broadcast system 1 may also be called a hybrid broadcast system or a broadcast broadband system.\nFIG. 2 shows a schematic diagram of a receiver 3 according to the present disclosure.  It comprises a broadcast receiver 31 that receives, via said broadcast system 1, a receiver input data stream comprising a plurality of channel symbols\nrepresented by constellation points in a constellation diagram.  A demodulator 32 demodulates said channel symbols into codewords and a decoder 33 decodes said codewords into output data words.  A broadband receiver 34 obtains redundancy data via a\nbroadband system, said redundancy data for a channel symbol including one or more least robust bits of the channel symbol or a constellation subset identifier indicating a subset of constellation points including the constellation point representing the\nchannel symbol.  According to the present disclosure said demodulator 32 and/or said decoder 33 is configured to use said redundancy data to demodulate the respective channel symbol and to decode the respective codeword, respectively.\nIn the proposed scheme the transmission in terrestrial network remains unchanged, but for a poor reception the receiver (also called terminal device) can fetch additional data via the broadband network to improve error correction performance. \nThe receiver evaluates the data received from the terrestrial network, and according to the signal quality it requires certain amount of additional data to assure quasi-error-free (QEF) reception.  Under more severe conditions more additional data is\nneeded.  In this way, for instance, a smooth or seamless transition between pure terrestrial broadcast and complete delivery via the broadband network can be realized.  This creates a new degree of freedom for the broadcast network management and may\nreduce the overall delivery cost and energy consumption.\nThe data received via both networks is combined for decoding in the receiver.  What kind of additional data is transmitted via the broadband network depends on the technology used in the terrestrial broadcast network.  FIG. 3 illustrates the\nproposed broadcast system 1 in more detail, employing the proposed Redundancy on Demand (RoD) concept on the example of DVB-T2.  A RoD capable terminal (i e a receiver according to the present disclosure) 3a is equipped with a RoD client 34', that\nsubstantially corresponds to the broadband receiver 34 (see FIG. 2), that performs a request to the RoD server (i.e. the broadband server) 4 if the reception conditions do not allow for error free decoding based on the data received from the broadcast\ntransmitter 2.  The RoD server 4 is then transmitting the required amount of redundancy, which is generally generated from the initially transmitted data stream, to the receiver 3a.  Different convergence levels for generating the RoD data are possible,\ni.e. the transmitted redundancy can either be generated from the output of the multiplexer (MUX), the channel-coding or the modulation block.  The proposed RoD scheme is backwards compatible, since receivers that are not capable of a broadband connection\nfor improving the reception remain unchanged, such as the receiver 5 shown in FIG. 3.\nA known approach for generating redundancy, which is described in WO 2011/080020 A1, is the retransmission of erroneously received packets with the so cold Automatic Repeat Request (ARQ) scheme.  The generation and reinsertion of redundant\npackets therefore takes place in the multiplexer included in the modulator of the broadcast transmitter 2 (see FIG. 3).  Possible convergence levels are e.g. IP-Packets, FEC Frames or Generic Stream Encapsulation (GSE) Packets for DVB-Systems.  However,\na drawback of this approach is the reduced granularity for generating the redundancy.  If the reception conditions are slightly worse than required for error free reception (e.g. 1 dB below the target SNR), each packet needs to be retransmitted via the\nbroadband system requiring a lot of transmission capacity.\nAnother approach as proposed according to the present disclosure is the usage of the least robust bits (or, generally, the bits having the highest bit error rate, BER), in particular the least significant bits (LSB), of the used constellation\n(e.g. of a QAM constellation) as redundancy data.  The receiver demodulates the QAM constellations, but uses the least robust bits, e.g. the LSBs, from the broadband network instead of the ones from the terrestrial broadcast network, because the least\nrobust bits typically carry the lowest amount of information within the channel symbol (e.g. a QAM symbol).\nAs the bits from the broadband network are very reliable, the demodulator 32 (in particular the demapper included within the demodulator in various embodiments, e.g. used in OFDM receivers) is able to reduce the number of possible constellation\npoints.  Thus, the average Euclidean distance between the remaining constellation points increases, leading to improved performance.  This approach is shown in an example in FIG. 4 according to which the LSBs are considered as least robust bits.  The\nLSBs received via the broadband network in the constellation diagram shown in FIG. 4A is 0.  The crosses 40 denote the possible constellation points and the lines 50 show the decision thresholds.  In the constellation diagrams shown in FIGS. 4B and 4C\ntwo LSBs are known (00 and 01), reducing the remaining constellation points 41, 42 (indicated by crosses) to four and reducing the number of decision thresholds 51, 52.  The same principle also holds for soft-decision demapping.  In this case the\nknowledge of the redundancy data is used to enhance the reliability of the soft-decision output values of the demapper.\nIn another embodiment the demodulator 32 is configured to use said least robust bits of a channel symbol received as redundancy data to replace the least robust bits of the channel symbol received by said broadcast receiver to obtain an improved\nchannel symbol and to demodulate said improved channel symbol.\nIn still another embodiment the receiver can also utilize the least robust bits (e.g. the LSBs) from the broadband network for improving the demapping and/or decoding of the more robust bits (e.g. the MSBs) from the broadcast network.  This\nconcept is similar to \"Genie-aided\" demapping, i.e. an easily implementable soft-decision demapping approach, where the knowledge of the transmitted bits is used to enhance the reliability of the soft-decision output values of the demapper.  Thus, the\ndecoder 33 is configured according to this embodiment to use said least robust bits of a channel symbol received as redundancy data to replace obtained input values of the decoder with their ideal values derived from the known bits contained in the\nredundancy data and, thus, to obtain an improved codeword and to decode said improved codeword.  Typically, the input values of the decoder are soft-decision input values (generally log-likelihood ratios, LLRs) so that obtained uncertain soft-decision\ninput values are set to the ideal values having indefinite likelihood (i.e. perfect knowledge) which are then used in the decoding.\nThe bit rate of the generated redundancy data can be controlled firstly by selecting the number of least robust bits out of each channel symbol, and secondly by puncturing the complete least robust bit stream, as illustrated in FIG. 5.  Here,\nFIG. 5A shows a redundant data stream with bitrate R, FIG. 5B shows a redundant data stream with bitrate R/2, and FIG. 5C shows a redundant data stream with bitrate R/3.  This is important to control the optimum amount of redundancy data.  On the one\nhand the amount of transmitted redundancy data must be sufficient to allow for error-free decoding and/or demodulation, but on the other hand the amount should be as low as possible to avoid transmission of unnecessary redundancy data.\nInstead of retransmitting the initially transmitted bits, it is also possible to define constellation point subsets that are excluded in the receiver.  This allows for increasing the Euclidian distance between the remaining constellation points. If bit sequences with unequal probabilities are transmitted, Huffman coding may be conducted on the selected bits, to enable the receiver to separate them easily and reduce the overhead for the transmission.  This is meaningful if constellation shaping\nis used, altering the probabilities of the subset identifiers, i.e. some subset identifiers occur with higher probability than others.  This is directly related to constellation shaping of (e.g. QAM) constellations, with some constellation points\noccurring with higher probability than others.  In the normal case of equal probabilities, Huffman coding does not provide any gain.\nAn example of a Huffman coding for a 16-QAM constellation is as follows:\nTABLE-US-00001 Original bit sequence Probability Huffman coded bits XXX0 1/2 0 XX10 1/4 01 X0X1 1/4 10 1111 1/16 11\nAfter the identification of the sub-carriers with heavy distortion, redundant bits will be generated from the constellation points of these sub-carriers.  Since the distortion levels of these identified sub-carriers may also vary, the redundant\nbits required for each sub-carrier may also be different.\nAs an example, it shall be supposed that all the N constellation points build a set S. Through the re-labeling S will be divided into sub-sets {S1, S2, .  . . , Sm}, i.e. not bits but (e.g. QAM) subset identifiers are transmitted.  The division\noperation increases the average robustness of the constellation points within each sub-set.  This operation is dependent on the statistical properties of the broadcast signal and the distortion.  The mathematical deviation is omitted here.  A simple\nexample using 16 constellation points of a QAM constellation is shown in FIG. 6.  If the receiver receives a \"0\" (i.e. 16-QAM Gray Mapping with LSB known to be 0), it indicates the original point locates in a first sub-set comprising the constellation\npoints 60 (indicated by crosses) as shown in FIG. 6A.  If the subsets are optimized for maximum average Euclidian distance, the original point is located in a sub-set comprising the constellation points 61 (indicated by crosses) as shown in FIG. 6B.\nThe various division schemes for different distortion levels and forms can be pre-calculated and stored in a look-up table to simplify the on-line operation.  This approach enables a maximal utilization of the capacity of the communication\nchannel\nIn a multi-carrier communication system, the distortion each sub-carrier bears varies much in both time domain and frequency domain.  In case of portable mobile and stable receptions, the broadcast channel has slow-changing and slow-fading\ncharacteristics.  Furthermore, low signal power and narrow band interferences are the main hinders for an error-free reception.  FIG. 7 illustrates such a broadcast channel exemplarily, in particular the variance of signal strength in frequency domain. \nThe first step is to identify the sub-carriers which are bearing severe distortion and have hence an insufficiently low carrier-to-noise-ratio (CNR).  In FIG. 7, they are the ones in the marked area 70.  Redundancy data is then only needed for these\nidentified sub-carriers.  In this way, the required bandwidth in the broadband network is reduced.  Because the channel state may also change temporally, the identification process is carried out periodically or in an event-based manner.\nFor the sub-carriers with low CNR, some or even all of the bits from their constellation points need to be transmitted by the broadband connection, so that a correct decoding can be achieved.  The selection of the bits as redundancy depends on\nthe distortion, the strength of the signal, the deployed mapping scheme.  Moreover, which additional bits should be selected as redundancy data is also dependent on the previously selected bits.  A mathematical derivation is omitted here.\nAn embodiment of a receiver 3b according to the present disclosure making use of this approach in a more general way is shown in FIG. 8.  In addition to the receiver 3 it comprises a quality detector 35 that identifies the quality of received\nchannel symbols and a broadband request unit 36 that requests channel symbols having the lowest quality and/or a quality below a predetermined quality threshold as redundancy data.\nIn a further embodiment, as explained above with reference to FIG. 7, said broadcast receiver 31 is configured to receive said receiver input data stream via a multi-carrier broadcast system, e.g. an OFDM broadcast system (such as a broadcast\nsystem in accordance with a DVB standard).  Said receiver input data stream comprises a plurality of channel symbols carried by multiple frequency sub-carriers.  In this embodiment the quality detector 35 is configured to identify the quality of said\nfrequency sub-carriers, and said broadband request unit 36 is configured to request channel symbols carried by sub-carriers having the lowest quality and/or a quality below a predetermined quality threshold as redundancy data.\nIn an embodiment the broadband receiver 31 is configured to receive redundancy data via a broadband system.  Thus, the broadband server or any other appropriate unit that is able to transmit data through the broadband system thus actively\ntransmits the redundancy data to the receiver.  For instance, it can be estimated, e.g. by the broadband transmitter or the broadcast transmitter, if the decoding and/or demodulation at a receiver will be erroneous due to the channel characteristics, so\nthat actively redundancy data will be sent, even without explicit request by the receiver.  Further, channel information can be used to select the redundancy data requiring the smallest amount of additional redundancy data.\nIn another embodiment, as shown in FIG. 9, the receiver 3c comprises a broadband request unit 37 that requests, if demodulation of a channel symbol and/or decoding of a codeword without redundancy data is erroneous, one or more least robust bits\nor constellation subset identifiers of the corresponding channel symbol via said broadband system as redundancy data.  Thus, the receiver 3c actively requests redundancy data in this embodiment.\nSaid broadband request unit 37 may alternatively, in another embodiment, transmit receiver specific broadcast channel information via said broadband system to a server (e.g. as shown in FIG. 3) that determines the quality of least robust bits\nand/or channel symbols received by the broadcast receiver 31 and transmits least robust bits and/or channel symbols as redundancy data to the receiver via said broadband system.  Further, preferably, said broadband request unit 37 is configured to\ncompress said channel information by precoding before transmitting it to a server.\nIn an embodiment the channel state information (CSI) is estimated in the receivers, but the identification of the sub-carriers and the constellation points re-labelling can be carried out in either receivers or the server.  If the receiver makes\nthe decisions, it needs only transmit back a request for the specific bits.  If the server makes the decisions, the CSI should be transmitted back from the receiver to the server.  This CSI can be pre-coded before transmitting.  For instance, the CSI can\nbe transmitted incrementally, which means only the difference to last estimation is required by the server.  In this case, the CSI can also be seen as two-dimensional spaces with the axis frequency and time.  Furthermore, the CSI has specific\ncharacteristics in both dimensions, e.g. the variation in the time direction may be very slow in case of stationary reception.  Therefore, one could use algorithms similar to MPEG video encoding (e.g. differential encoding) that take benefit of these\ncharacteristics for an efficient transmission of the CSI back to the transmitter.\nIn the following some application scenarios in which embodiments of the present disclosure can be applied will be explained.\nWhen a poor QoS is noticed by the receiver and the availability of the redundancy data is proved, a question may be popped up to the user asking about whether acquiring redundancy data via broadband network is allowed to improve the decoding\nquality.  Once the user accepts this or does choose for permanent allowance, the presentation of the current media content is paused and the broadcast data stream is buffered for a very short interval to equalize the delays in both networks.  Then the\nbroadcast data stream and redundancy data stream are synchronized and decoded jointly.  Afterwards the media content is displayed without any perceptive errors.\nAnother advantage of the use of redundancy data is the possibility to efficiently counteract time varying distortions like man-made-noise.  Man-made-noise is known to be especially severe in the VHF-Band, causing narrowband as well as broadband\ndistortions that can be either constant over time or time varying.  Especially the impact on the QoS of time varying distortions like impulsive noise, which are e.g. caused by switching events of the mains, can be avoided by means of the concept of\nredundancy data.  Heavy noise impulses typically cause a service dropout, since the error correction (e.g. the forward error correction (FeC) as applied in DVB broadcast systems) is not able to correct such strong distortions.  This is especially the\ncase for OFDM-based systems, as a short noise impulse in the time domain distorts a complete OFDM symbol in the frequency domain, due to the so called noise-buck effect of OFDM.  The VHF band is therefore not used anymore in some countries (like Germany)\nfor digital terrestrial transmission, because of problems with man-made-noise.  The use of redundancy data could allow for the reintroduction of terrestrial broadcasting in the VHF-band in such countries.\nIn current broadcast networks, to achieve a \"quasi-error-free\" (QEF) viewing experience, a certain level of signal-to-noise ratio (SNR) is required.  For receivers which have a poor receiving condition, this SNR threshold cannot be reached, thus\na successful decoding of the broadcast signal would be impossible.  The TV services can only be provided completely by other means, e.g. IPTV and the corrupted broadcast signal has to be discarded.  For the proposed concept of using redundancy data,\nhowever, the amount of additional redundancy is dependent on the quality of the broadcast signal: if the distortion is heavier, more redundancy will be needed; if lighter, then less redundancy will be needed.  In a worst case, if the desired amount of\nredundancy data is even larger than that of the original TV content itself, the TV content will be delivered directly to the receiver as a normal IPTV system (100% broadband).  Therefore, the data size that have to be transmitted as redundancy data is\nalways less than without using this approach.\nCompared to traditional systems, with the concept of redundancy data a soft-transition between pure broadcast and complete IPTV can be realized.  This has an influential impact on the network planning, when a high proportion of the receivers are\ncapable of using this concept.  For instance, if a certain area shall be covered with a terrestrial broadcasting network and a certain data rate shall be provided in the broadcast channel.  Previously, after selecting the network setting (code rate,\nmodulation scheme, etc.) the transmitter power had to be increased to ensure a sufficient SNR at each location in this area.  Now, with the concept of redundancy data the transmitter power can be reduced and the receivers located at edge area can be\nserved with some redundancy data via broadband network, so that their demodulation and decoding of the broadcast signal is also \"quasi-error-free\".  Equivalently, the same transmitter power can be maintained, but modulation and error correction rates\nwith higher spectral efficiencies could be applied.  The transmitter power can be reduced to a level, when a further decrease of power consumption or transmission cost is no more possible.  This power level and the achievable power or cost savings are\ngenerally determined by the viewer number, distribution of receivers, cost factors, man-made-noise and so on.  Most of these parameters are changing temporally, therefore online monitoring, optimization and adaption are preferably used.  For instance,\nthe transmitter power is set to lower level during morning, when less people are watching television.  The lower signal strength is compensated by more redundancy data via the broadband network for the relatively small number of receivers.\nThe relation between the overall power consumption/transmission cost and the transmitter power may look as depicted in FIG. 10.  The optimal operation point moves at different time and changes for different network settings, such that a dynamic\nadaption of the network is meaningful.\nThe proposed ideas can also be applied in a dynamic broadcast system as, for instance, described in U.S.  patent application Ser.  No. 13/428,743 filed on Mar.  23, 2012, which description is herein incorporated by reference.  The so-called\ndynamic broadcast concept applied in such a dynamic broadcast system describes a flexible terrestrial broadcast system, utilizing an internet broadband connection and a hard disc in the terminal, to optimize the spectrum usage and the power consumption\nof the transmitter network, by choosing the optimal delivery means depending on the content type (realtime, non-realtime) and the viewer count.  The relationship of the concept of redundancy (on demand) with respect to the dynamic broadcast concept is\ndepicted in FIG. 11 showing a schematic diagram of a dynamic broadcast system 100 according to the present disclosure.\nThe system 100 involves a broadcast (BC) network, a broadband network (BB), hybrid broadcast broadband (HBB) terminals (receivers) and other wireless communication networks.  Their cooperation is managed by the dynamic broadcast network.  The\nfunctions of the blocks shown in FIG. 11 are explained in the following.\nFirst, the packaging of media content unit 112 is described.  The TV content is provided by broadcasters 110 and is segmented into Real-Time (RT) and Non-Real-Time (NRT) events.  For real-time events, (certain elements of) news programs for\ninstance, their content becomes available only at the announced on-air time, so they have to be delivered live; while for non-real-time events, like movies, music, drama etc., their content may be available in advance, so they can be pre-downloaded. \nWith pre-download (broadcast or broadband) network capacity can be used for instance over night, when capacity has been identified to be available, whereas during daytime and in the evening network capacity will be freed for other uses.  The choice of\ncontent that can be pre-downloaded will be based on rules used in a decision logic 114.  These rules will be generated from usage patterns of viewers derived from information available over the broadband network.  In conjunction with other measures the\ndownload of such material will take place as network capacity becomes available--either over the broadcast or the broadband network.  A program schedule therefore should be created that indicates which content comes over the air in real-time and which\ncontent can be played from the storage device in the user terminal.\nNext, a monitoring and signaling unit 116 is described.  To optimize the network operation, knowledge about actual network usage is important.  Two kinds of information should hence be collected from HBB terminals 118 (also called \"terminals\",\n\"user terminals\" or \"receivers\" hereinafter) and transmitted to the decision logic 114 through broadband connection.  The first kind of information is about whether or not programs or pieces of media content are used and by how many people.  This\npopularity can be estimated by monitoring the watching activities of some or all users, as done in today's IPTV networks.  Knowing the accurate popularity and usage pattern of the media content can help the decision logic 114 determining which content\nshould be delivered via the broadband network and/or pre-downloaded as mentioned above.  The second kind of information is about the momentary technical Quality of Service (QoS) of the transmission links.  This can be obtained with integrated measuring\ndevices in HBB terminals 18.  With information about the actual signal quality, the decision logic 14 can manage the network most efficiently.\nThe signaling which delivers data to the HBB terminals 118 will provide information about content items presented for `delivery in advance` (also called `offline delivery, i.e. delivery in advance of the official broadcast time), the time of the\nbroadcast transmission and/or the time of play out over the broadband network.  It will include a program schedule and it will deliver information about the various parameters selected by the dynamic multiplexing and a joint control unit 120.  The\nsignaling information can be transmitted via both networks and in both push and pull modes, so that the HBB terminals 114 can get the current network information even if it is just switched on for the first time.\nThe decision logic 114 is in charge of the management of the whole network and it aims to keep the operation at a minimal cost while assuring required QoS.  Facilitated with the monitoring reports from the HBB terminals 118, and based on\nadditional business rules, cost functions, realistic constraints etc. the decision logic 114 may change the packaging of real-time and non-real-time events, or command a re-multiplexing of the transport streams in broadcast and broadband channels or\nadjust of the transmission parameters and transmitter power.  Before the decision logic 114 has made any changes to the previous program schedule or network settings, it should acknowledge all HBB terminals 18 about the modification through signalling\nNext, a multiplexing and content distribution unit 122 is described.  The flexible distribution of media content through broadcast and broadband network requires content items and complete or partial audio, data and video programs to be\nmultiplexed dynamically.  In consequence, the former fixed mapping between transmission parameters and TV programs has to be eliminated.  Information about such re-multiplexing should be signaled to the HBB terminals 118, so that they are able to follow\nthe changes.  By the reason that the popularity of the different TV programs in one transport stream changes continuously, re-multiplexing may take place online, which means some content being transmitted may be reallocated in other physical channels or\nstill in the current channel but with new transmission parameters.  All these actions should be carried out in a way unnoticeable by the users.\nNext, the joint control unit 120 for control of transmission parameters is described.  In traditional digital broadcast systems the modulation of the transmitted signal and the degree of Forward Error Correction (FEC) used are decided once and\nthey then stay stable.  The transmitter power is selected according to the coverage requirements of the network.  In terrestrial networks, the coverage area is defined by the aforementioned parameters and in addition by the coverage pattern determined by\nthe transmit antenna.  This static network planning leads to inefficient usage of the valuable spectrum, because strong time-variant factors like channel popularity and user terminals receiving conditions have not been taken into consideration.\nDynamic multiplexing can reduce the useful data rate transmitted on a specific channel if the multiplex on that channel is not fully loaded with program items at the moment.  Initiated by the decision logic 114 the joint control unit 120 will\nthen change the FEC settings and/or modify the modulation scheme used on that channel.  This will result in an enhanced robustness of the signal which in consequence will allow the transmitter power to be adapted thus reducing the power density--and the\ncost of transmission.  This creates economical benefits, as well as ecological benefits, since the exposure to radiation and carbon emission will be reduced as a consequence of the lowered transmitter power.  In another case, it shall be supposed that\nsignaling provided from user terminals to the broadcast network including information about technical parameters of the received signal in networks indicate a better-than-required or worse-than-required signal quality as a result of changes in man-made\nnoise (i.e. noise generated by any devices used by anybody in the environment)--which has been found to fluctuate greatly and periodically over time--or due to changes in weather conditions.  Initiated by the decision logic 114 the joint control unit 120\nwill modify the parameters (FEC, modulation, transmitter power) in order to accommodate broadcast QoS at a minimum cost.  In addition, the joint control unit 120--in negotiation with dynamic multiplexing via the decision logic 114--will initiate the\nre-configuration of multiplexes such that the data rate transmitted in heavily disturbed channels will be reduced and the robustness of the signal enhanced as required.\nIn the HBB terminal 118 some content will have to be stored \"off-line\" upon receipt of the appropriate downstream signaling and besides, which content to store should also be decided by the HBB terminal 118.  Therefore it should be capable of\npredicting user's preferences, storing relevant TV content automatically and managing the stored content dynamically.  To accomplish this, a recommender system should be implemented in the HBB terminal 118.  On the other hand some content will be made\navailable via the co-operating broadband network.  The HBB terminal 118 will receive a program schedule, and a delivery network indicator which indicate for which period of time and how often this stored content is to be used instead of content that in\ntraditional broadcasting would be received live.  In addition it will be informed via which of the co-operating networks content will be delivered.  The received content from different networks should be managed properly by the HBB terminal 118.  Content\nitems are often interrelated.  This is obviously true for audio and video but in addition, a plethora of data services like software applications are created by the content owners that will have to be available in the terminal 118 and started, paused or\ncancelled in relation to the audio and video content.  Additional downstream signaling information embedded in the broadcast stream is received by the HBB terminal 18, which indicates the dynamic multiplex configurations and the parameters selected by\njoint control.  Upstream signaling will be generated in HBB terminals 118 for transmission on the broadband network.  The user terminal 118 thus becomes an active component of the dynamic broadcast network instead of being a passive device as in\ntraditional broadcasting.\nSpectrum freed by dynamic broadcast can be offered to secondary wireless networks, like Cellular (LTE), Wi-Fi, etc. for a certain period of time.  To avoid interference, usage of the new \"white space\" created by dynamic broadcast should be\ncoordinated through resource signaling which is an output of the dynamic broadcast system 100 and informs wireless network operators about the dynamically chosen parameters of the broadcast network.  It includes also information about the period of\nvalidity of the multiplex configuration and the spectrum resources which will be freed including an indication of the period of time during which the spectrum will be available.\nMore details about the general concept of dynamic broadcast can be found in the above mentioned US patent application and other publications about dynamic broadcast systems.\nAs the concept of redundancy on demand provides a \"seamless transition\" option between complete broadcast or broadband transmission, it can be efficiently combined with the dynamic broadcast concept, introducing another degree of freedom, so\nthat the dynamic broadcast network can be further optimized in the sense of transmission cost, energy consumption, and spectrum efficiency.  This is indicated in FIG. 11 by the arrow output by the joint control unit 120 that controls the output of RoD\ndata via the broadband network to the HBB terminal 118.\nRedundancy data can also be used in another application as an encryption way to protect the pre-downloaded media content.  The pre-download of the media content can be transmitted with a network configuration of high data rate but week error\ncorrection.  The redundancy data can then be used as a triggering signal to enable the recovery of the original data.\nFurther, conditional access to data can be realized by use of redundancy data.  Conditional access to video services is crucial for pay-TV transmission.  Redundancy data can be used to control the access to pay-TV services by means of the\nbroadband connection.  The corresponding service is transmitted via terrestrial broadcast to achieve low network cost.  However, not the full data rate is transmitted via terrestrial broadcast, but only a specific amount, e.g. like 95% of the data rate. \nThe users that subscribed to the pay-TV service then receive the remaining 5% via the broadband connection as redundancy data.  This allows the network operator for restricting the access to the pay-TV service via the broadband connection only to the\nusers with the corresponding service subscription.  Other users without the additional redundancy data over broadband are not able to decode the service, since the received Mutual Information via terrestrial broadcast is not sufficient for error free\ndecoding.  For this purpose even a slight decrease of the transmitted Mutual Information over the terrestrial broadcast suffices to avoid access of unregistered users to the pay-TV service.\nA schematic diagram of a control device 200 for use in a broadcast system according to the present invention is shown in FIG. 12.  Such a control device 200 may e.g. be used as joint control unit 120 in the broadcast system 100 shown in FIG. 11. The control device 200 comprises a broadcast control unit 201 and a broadband control unit 202.  The broadcast control unit 201 controls a broadcast transmitter of said broadcast system that broadcasts broadcast signals in a coverage area for reception\nby terminals comprising a broadcast receiver and a broadband receiver.  The broadband control unit 202 controls a broadband server of a broadband system that provides redundancy data to terminals within said coverage area.  The broadband control unit 202\nis configured to control the provision of redundancy data by said broadband server for use by one or more terminals which use said redundancy data together with broadcast signals received via said broadcast system for recovering content received within\nsaid broadcast signals and/or provided via said broadband system.  Additional optional elements are shown in dashed boxes and will be explained below.\nIn an embodiment said broadcast control unit 201 is configured to change one or more transmission parameters of said broadcast transmitter depending on one or more parameters of a group of parameters comprising the time of the day, the number,\nlocation, profile and/or parameters of active terminals, cost factors of the transmission of data by said broadcast transmitter and/or said broadband server, channel state information (in particular noise and/or reception level) and/or feedback of\nterminals.  Further, said broadband control unit 202 is configured to provide redundancy data to one or more active terminals which receive broadcast signals with insufficient quality and which use said redundancy data to compensate for the insufficient\nquality of reception of broadcast signals.  Optionally, the control device 200 further comprises a monitoring unit 203 that continuously or repeatedly monitors one or more parameters of said group of parameters.\nIn another embodiment said broadcast control unit 201 is configured to control the transmit power and/or one or more physical layer parameters, in particular modulation and/or code rate, parameters of an interleaver and/or an FFT unit, used by\nsaid broadcast transmitter.\nIn another embodiment said broadcast control unit 201 is configured to adaptively change the transmit power and/or the efficiency of the applied modulation and/or code depending on one or more parameters of a group of parameters comprising the\ntime of the day, the number, location, profile and/or parameters of active terminals, cost factors of the transmission of data by said broadcast transmitter and/or said broadband server, channel state information (in particular noise and/or reception\nlevel) and/or feedback of terminals.\nIn another embodiment said broadband control unit 201 is configured to adaptively change the amount of redundancy data transmitted to one or more active terminals depending on one or more parameters of a group of parameters comprising the time\nof the day, the number, location, profile and/or parameters of active terminals, cost factors of the transmission of data by said broadcast transmitter and/or said broadband server, channel state information, noise and/or feedback of terminals,\npreferably depending on the number of active terminals.  Preferably, in this embodiment the broadcast control unit 201 is configured to reduce the transmit power and/or to apply a modulation and/or code with a higher efficiency and said broadband control\nunit is configured to increase the amount of redundancy data transmitted to one or more active terminals if the number of active terminals is below a lower predetermined threshold and/or to decrease the amount of redundancy data transmitted to one or\nmore active terminals if the number of active terminals is above an upper predetermined threshold.  Even further, the amount of redundancy data may be controlled based on the costs of the transmission, i.e. based on an estimation if it is more cost\nefficient to increase or decrease the amount of redundancy data versus use of broadcast for transmitting data.\nStill further, in an embodiment the control device 200 comprises an optional request receiving unit 204, as also shown in FIG. 12, that receives requests for transmission of redundancy data from terminals.  In this embodiment said broadband\ncontrol unit 202 is configured to control the broadband server to provide redundancy data to requesting terminals.  The requests from terminals may generally differ in the quantity of requested redundancy data, the quality of the requests, the use\nprofiles, etc. For instance, there may be premium users (which may have paid an extra service charge), which may always receive an extra amount of redundancy data in order to ensure a high quality of the transmission in all situations.\nIn another embodiment the control device 200 is particularly designed for use in a dynamic broadcast system as shown in FIG. 11, wherein said broadcast control unit 201 and said broadband control unit 202 are configured to dynamically control\ntransmission parameters, transmission times and transmission paths used for broadcasting and providing content by use of said broadcast transmitter configured to broadcast content via said broadcast system and/or said broadband server configured to\nprovide content via said broadband system.  In this embodiment the control device 200 further comprises an optional decision unit 205 (also shown in FIG. 12) that dynamically decides transmission parameters, transmission times and transmission paths used\nfor broadcasting and providing content by use of said broadcast transmitter and for providing content by said broadband server.\nSaid decision unit 205 is preferably configured to dynamically decide transmission parameters, transmission times and transmission paths used for broadcasting and providing content based on monitoring data carrying information on user specific\ncontent usage and/or transmission quality data carrying information on the quality of a transmission link between said broadband server and a terminal and/or of a reception of content broadcast by said broadcast transmitter.\nFurther, said redundancy data is preferably provided for providing a seamless transition between broadcast and broadband reception and/or recovery of content from signals received via said broadcast system and said broadband system.\nIn another embodiment said broadcast control unit 201 and/or said broadband control unit 202 is configured to control said broadcast transmitter and/or said broadband server to transmit content in a form that does not allow complete recovery in\na terminal without the use of redundancy data, and to control the transmission of redundancy data via said broadband system to terminals that shall be enabled to completely recover received content.\nPreferably, in said embodiment said broadcast control unit 201 and/or said broadband control unit 202 is configured to control said broadcast transmitter and/or said broadband server to transmit content in encrypted form and/or with insufficient\nand/or low quality and wherein said redundancy data is provided for being used for decryption and/or increasing the quality of the received content.  For instance, in an exemplary use scenario, via broadcast a \"normal\" (lower) image quality (e.g. in SD\nformat) is obtained, while by use of the redundancy data (which may then be regarded as \"additional data\" or \"auxiliary data\") received via broadband an \"improved\" (higher) image quality (e.g. in HD format) is obtained.\nFurther, in said embodiment said broadcast control unit 201 is preferably configured to control said broadcast transmitter to adaptively change the mutual information between transmitted and received signals to transmit content in a form that\ndoes not allow complete recovery in a terminal without the use of redundancy data.\nA broadcast system 1a comprising such a control device 200 is schematically depicted in FIG. 13.  The broadcast system 1a comprises a broadcast transmitter 2a that broadcasts broadcast signals in a coverage area for reception by terminals 3\ncomprising a broadcast receiver and a broadband receiver.  The broadcast system 1a further comprises a broadband server 4a that provides redundancy data to terminals within said coverage area.  Finally, the broadcast system 1a comprises a control device\n200 as explained above with reference to FIG. 12 that controls said broadcast transmitter 2a and said broadband server 3a.\nIn the following it will be described in more detail how the required amount of redundancy data can be estimated or determined.  In particular, the estimation of the Mutual Information, the estimation of the number of redundancy data bits and\nthe stream synchronization will be described by use of various embodiments.  The following description will refer to elements shown in FIG. 14 depicting the interaction of a broadband server (called RoD server) 4b and a receiver (called terminal in this\nembodiment) 3d used in a broadcast system 1b according to the present disclosure.\nGenerally, a receiver (see also the embodiment of a receiver shown in FIG. 9) for receiving data in such a broadcast system comprises a broadcast receiver (31 in FIG. 9) that receives via said broadcast system a receiver input data stream\ncomprising a plurality of channel symbols represented by constellation points in a constellation diagram, a demodulator (32 in FIG. 9) that demodulates said channel symbols into codewords and a decoder (33 in FIG. 9) that decodes said codewords into\noutput data words.  A redundancy calculator (not separately shown in FIG. 9; may be a separate element or included in the broadband request unit 37; separately provided as unit 38 in the receiver 3d shown in FIG. 14) determines a required amount of\nredundancy data for correct demodulation and decoding by use of the originally received channel symbol and additional redundancy data.  A broadband request unit (37 in FIG. 9) requests, if demodulation of a channel symbol and/or decoding of a codeword is\nerroneous or likely to fail, a required amount of redundancy data via a broadband system and a broadband receiver (34 in FIG. 9) receives redundancy data via said broadband system.  The demodulator and/or the decoder are configured to use said redundancy\ndata to demodulate the respective channel symbol and to decode the respective codeword, respectively.  These elements are generally also provided in the receiver 3d shown in FIG. 14 even if not explicitly depicted.\nThe broadband server 4b for providing redundancy data to a receiver of such a broadcast system via said broadband system generally comprises a receiving unit 41 that receives requests from receivers of said broadcast system via said broadband\nsystem to provide redundancy data to the respective receivers via said broadband system to enable correct demodulation of a channel symbol and/or decoding of a codeword, a request including channel state information, a redundancy calculator 42 that\ndetermines the required amount of redundancy data required for correct demodulation and decoding by use of said channel state information, and a transmitting unit 43 that provides redundancy data in at least said required amount to the receiver that\nrequested redundancy data.\nAn essential task of a system using redundancy data is to correctly determine the required amount of redundancy data for successful decoding in the terminal (=receiver).  If too few redundancy data is transferred from the redundancy provider\n(i.e. a broadband server) to the terminal, the decoding process will fail and additional redundancy data need to be requested in a second step.  This causes network overhead and increases the system delay until successful decoding is achieved due to the\nmultiple redundancy data requests.  If on the other hand too much redundancy data is transferred to the terminal, the system efficiency is reduced, since data is transmitted via the broadband connection in vain.  The calculation of the correct redundancy\ndata amount is therefore very important, since it influences the performance of the overall system.\nA possible metric for the estimation of the required redundancy data amount in the receiver is the Mutual Information (MI) between transmitted (code) bits and received soft values, belonging to one codeword (e.g. a FEC word).  The Mutual\nInformation is a figure of merit from stochastic and is especially suited for determining the required amount of redundancy data, since it is independent from the channel characteristics and the modulation order of the QAM constellation, but only depends\non the applied code.  If the code rate of the applied code is e.g. 0.5, decoding is successful if the Mutual Information exceeds the value of 0.5.  However, this only holds for an ideal encoder, operating at the maximum channel capacity (Shannon\ncapacity), which is not possible with practical error correction codes.  For instance, the DVB-T2 64K LDPC code with a code rate 0.5 requires a Mutual Information of 0.55 for successful decoding.  There are only very slight deviations in the performance\nof this code depending on the modulation order and the channel characteristics.  The required Mutual Information for the utilized codes can be stored in a table in the broadband server or the terminal, such that the required mutual information that needs\nto be transmitted via redundancy data can be calculated in the terminal or the broadband server.  Hence, in an embodiment the redundancy calculator 38 is configured to estimate said required amount of redundancy data based on channel state information\nand/or Mutual Information between transmitted and received data, in particular between transmitted bits of output data words or codewords and received values representing bits of output data words or codewords.\nThere are two locations in the receiver where the log-likelihood ratios (LLRs) can be extracted to calculate the Mutual Information: Either directly after QAM demapping or after FEC decoding.  If the LLRs after FEC decoding are used, less\nredundancy data needs to be transmitted in principal (because FEC decoding, though not successful, increases the reliability of the LLRs).  Using the estimated Mutual Information it is possible to estimate the meaningfulness to perform FEC decoding. \nWhen the Mutual Information is clearly lower than the required Mutual Information for FEC decoding, FEC decoding should be omitted.  This is the case because on the one hand the Mutual Information increase by the FEC decoder is typically negligible in\nsuch situations, especially for state-of-the-art FEC codes like LDPC or turbo codes, and on the other hand this allows a reduction of the power consumption of the terminal.\nThe Mutual Information is determined based on the Log-Likelihood-Ratios (LLR) at the output of the QAM-demapper and is a good measure if the following FEC is able to successfully decode the FEC codeword.  An LLR is defined here as\n.times..times..times..times..times..times..times..times.  ##EQU00001## The Mutual Information of a single Bit based on its LLR value is defined as If transmitted bit=1: MI=1-log 2(1+e.sup.-inputLLR) If transmitted bit=0: MI=1-log\n2(1+e.sup.+inputLLR).\nThe Mutual Information is typically averaged over one FEC block to decide if successful decoding is possible.  However, the knowledge of the transmitted bit is required for the calculation, which is not available in a receiver.  To avoid the\nneed for the reference data for the calculation of the Mutual Information, the formula is weighted by the linear probability that a 1 or a 0 is transmitted, respectively.  The linear probability (in the range [0,1]) that a 1 is transmitted is calculated\nfrom its LLR value by\n.times..times..times..times..times.  ##EQU00002##\nAfter weighting the initial Mutual Information formulas (assuming bit 1 or bit 0 was transmitted) with the probability p and 1-p, respectively, the following formulas are resulting: MI.sub.1=1-p*log 2(1+e.sup.-inputLLR) MI.sub.0=1-(1-p)*log\n2(1+e.sup.+inputLLR) The estimated Mutual Information without reference is then resulting from their sum M.sub.estimated=MI.sub.1+MI.sub.0=1-p*log 2(1+e.sup.-inputLLR)+1-(1-p)*log 2(1+e.sup.+inputLLR)\nThe comparison of the Mutual Information estimation with its ideal values is shown in FIG. 15 for different channel models and modulation sizes with a large amount of averaged bits and ideal channel knowledge.  It can be observed that estimated\nMutual Information exactly corresponds to the ideal Mutual Information.  In practice, the Mutual Information is estimated for a particular codeword (or a Time Interleaver Frame, consisting of several codewords), which results in a smaller amount of bits\navailable for averaging.  This would result in some degradation of the estimation.  Other metrics to compute the amount of required redundancy can be the estimated signal-to-noise ratio (SNR), the average absolute value of the LLRs or the estimated\nmodulation error rate (given by the deviation of the received QAM symbols to the possible transmit QAM symbols).\nBased on the estimated mutual information the required number of bits for the redundancy data transmission to the receiver needs to be calculated.  This can be done without knowledge of the channel state information (CSI), or taking the CSI into\naccount.  If CSI is available at the broadband server, the bits that experienced strong attenuation from the transmission channel are preferably transmitted first.  If no CSI is available this is not possible.\nTo allow for optimum performance of iterative FEC codes, the transmitted redundancy data bits should be uniformly distributed over the FEC codeword.  This avoids that the transmitted redundancy data is only located e.g. at the beginning of the\nFEC codeword.  This can be achieved by means of a pseudo random address generator that generates the addresses of the bits within the FEC codeword selected for transmission.  Thanks to the random nature of the generated addresses the selected bits are\nuniformly distributed within the FEC codeword.  The random address generator must be known to both the broadband server and the receiver, to allow for unambiguous decoding in the receiver based on the transmitted redundancy data bits.  In case of the\ntransmission of least robust bits (e.g. LSBs) first, as explained in an embodiment above, the random addresses of the least robust bits of all QAM symbols that carry a FEC codeword are used for generating the redundancy data bits first.  Afterwards the\nsecond least robust bits are used, and so on, until the required amount of redundancy data bits is reached.\nThe calculation of the amount of required redundancy data bits is carried out in the receiver, based on the estimated Mutual Information and the required Mutual Information for successful decoding of the utilized FEC code.  The required Mutual\nInformation is known for all code rates (see e.g. FIG. 15 for 64K LDPC of rate 1/2) by simulation and are stored in the server and the receiver.  Depending on the resulting SNR of each received QAM symbol (determined by the CSI), the additional Mutual\nInformation can be calculated that results in the receiver when a particular bit is perfectly known.  This additional Mutual Information is added to the available Mutual Information for each pseudo randomly generated bit location until the threshold of\nthe overall Mutual Information for error free decoding is reached.  By this means, the number of required redundancy data bits can be assessed in the receiver and a request with this number of bits is sent to the broadband server.  The broadband server\nthen uses the same pseudo random address generator to generate the redundancy data bits in the receiver.\nAs random address generator a linear feedback shift register (LFSR) with a polynomial representing a maximum length sequence (MLS) can be used.  For instance for a FEC block size of 64800 the register values generated by a 16-bit LFSR with a\ncycle length of 2.sup.16-1=65535 could be used.  However, only register values smaller or equal to 64800 are used as bit addresses, since the usage of the modulo-operator to truncate larger values could lead to a manifold generation of the same bit\naddress.  Other algorithms like the Mersenne-Twister can be used as well, but are not that simple to implement compared to an LFSR.  Preferably, the requested bits are only information bits in case the FEC code is systematic.  It shall be assumed that\nthe channel completely erased a codeword (of N bits--where K bits are information bits, i.e., the code rate is K/N).  In this case, instead of requesting the complete codeword again (N&gt;K), it would be sufficient to retransmit only the information bits\n(K).\nThe required number of bits in the receiver can then be computed based on the knowledge of the current Mutual Information.  Iteratively new pseudo random bit addresses are generated of bits that are transmitted as redundancy.  After each newly\ngenerated bit the additional Mutual Information is calculated that results from ideally knowing the additional bit at the generated address in the receiver.  The additional Mutual Information is easily accessible from a look up table that can be\npre-computed by means of Monte Carlo Simulation.  Based on the additional Mutual Information the current Mutual Information is updated by adding the additional Mutual Information.  This is iteratively repeated until the current Mutual Information exceeds\nthe required Mutual Information for successful decoding.  In pseudo code the algorithm for the calculation of the number of required bits in the receiver is the following:\nTABLE-US-00002 RoD bits to request = 0 while (current mutual information &lt; required mutual information) { generate bit address within FEC codeword; look up additional mutual information for QAM symbol from LUT current mutual information =\ncurrent mutual information + additional mutual information RoD bits to request = RoD bits to request + 1; }\nIn short: The algorithm describes a method to estimate the number of retransmitted pseudo random information bits (i.e. without utilizing the channel state information) for error free decoding.\nAll Mutual Information here corresponds to bitwise mutual information, such that the values are normalized to 1 to allow for direct comparison with the required mutual information value independent of the modulation order.\nThe table of the additional mutual information per QAM symbol depending on the number of known redundancy data bits within the QAM symbol is stored in the receiver as a look up table (LUT), e.g. in the storage 40.  The additional mutual\ninformation depends on the SNR of the QAM symbol that carries the bit, and the bits that are known within the QAM symbol.  For instance a LUT that stores the additional mutual information for the SNR range of 1 up to 30 dB for 256-QAM requires\n30*256=7680 entries.  If it is assumed that the LSBs are transmitted first, and so on, only 30*8=240 entries are required, since only 8 states are possible for each QAM symbol (1 bit known, .  . . , 8 bits known).  The values of the LUT entries are\ndetermined by Monte-Carlo simulation in advance, based on the formula of the ideal Mutual Information.\nSince the LSBs of QAM symbols carry less Mutual Information and are therefore well suited as redundancy data bits, it is meaningful to optimize the algorithm such that it first generates the bit addresses of the LSBs, then the addresses of the\nbits with the next lower order within the QAM symbols (LSB-1), and so on.  By this means the bits with the highest order, providing the most additional Mutual Information, are transmitted first, reducing the required number of redundancy bits.\nThus, in such an embodiment the redundancy calculator 38 is configured to estimate said required amount of redundancy data based on a comparison between estimated Mutual Information and required Mutual Information for correct demodulation and\ndecoding.  For estimating the Mutual Information a mutual information estimation unit 39 is preferably provided.  Further, in an embodiment a storage 40 is additionally provided that stores the required Mutual Information for a plurality of codes, in\nparticular for a plurality of code rates and/or codeword lengths.\nAccordingly the redundancy calculator 42 of the broadcast server 4b is preferably configured to estimate said required amount of redundancy data based on channel state information and/or Mutual Information between transmitted and received data,\nin particular between transmitted bits of output data words or codewords and received values representing bits of output data words or codewords.  Further, the redundancy calculator 42 is preferably configured to estimate said required amount of\nredundancy data based on a comparison between estimated Mutual Information and required Mutual Information for correct demodulation and decoding.  Still further, preferably a storage 44 is provided that stores the required Mutual Information for a\nplurality of codes, in particular for a plurality of code rates and/or codeword lengths.\nThe algorithm above requires a lot of computations to determine the number of required bits, since the mutual information must be calculated for every additional bit per QAM symbol, to reflect the actual noise of each QAM symbol.  However, the\nalgorithm can be simplified by assuming an average noise level throughout the FEC codeword.  Based on the average noise level the average additional Mutual Information is calculated for the current bit order (LSBs transmitted first).  Based on the\naverage Mutual Information the number of additional bits is calculated to provide the amount of required Mutual Information for error free decoding.  If the number of required bits of this bit order is not sufficient, all bits of this bit order are\nflagged for transmission and this is the same is then iteratively calculated for the next bit order, and so on.  If the current bit order provides enough bits to bridge the remaining gap to the required Mutual Information, the number of redundancy bits\nis calculated by adding the (N/M) bits for each bit order that is completely transmitted, plus the additionally required bits of the current bit order.  This algorithm requires only one calculation for each of the M bit levels, instead of one calculation\nper bit, since the additional Mutual Information for each bit order is assumed to be the same throughout all (N/M) bits of this bit order.  The pseudocode for this simplified calculation of the required number of bits is the following:\nTABLE-US-00003 If (current MI &lt; required MI) { missing MI = required MI - current MI; for (int i = 0; i &lt; M; i++) { get additional MI from LUT (additional MI per QAM symbol if i+1 Bits are known instead of only i Bits, assuming an average\nSNR for all QAM symbols) calculate the number of required QAM symbols to bridge the gap of missing MI if one additional bit is known if (number of required QAM symbols &lt; N/M) { RoD bits to request = i * (N/M) + number of required QAM symbols; break; }\nelse { current MI = current MI + additional MI * (N/M) missing MI = required MI - current MI; } } }\nIn short: The algorithm describes a method to estimate the number of retransmitted pseudo random information bits (i.e. without utilizing the channel state information) for error free decoding, with reduced computational complexity but also\nreduced accuracy compared to algorithm 1.\nThus, in such an embodiment the redundancy calculator 38 of the receiver 3d is configured to determine an average additional Mutual Information for a channel symbol and to add said average additional Mutual Information to available Mutual\nInformation for each bit location of a particular codeword until a threshold of an overall Mutual Information required for correct decoding is reached and to determine the required amount of redundancy data required for correct decoding of said\nparticular codeword based thereon.  Accordingly, the redundancy calculator 42 of the broadband server 4b is configured to determine an average additional Mutual Information for a channel symbol and to add said average additional Mutual Information to\navailable Mutual Information for each bit location of a particular codeword until a threshold of an overall Mutual Information required for correct decoding is reached and to determine the required amount of redundancy data required for correct decoding\nof said particular codeword based thereon.\nAlternatively, the following calculation of the required number of redundancy based on estimated Mutual Information can be used, if it is assumed that the redundancy consists of already transmitted code bits.\nThe estimated Mutual Information shall be denoted as MI.sub.old, the required number of redundancy data as n, the number of bits in the codeword as N (e.g., N=64800 in a 64 k LDPC).  The new Mutual Information MI.sub.new after n (already\ntransmitted) redundant bits have been re-transmitted via a unicast system (generally, the broadband system) is then obtained by:\n.times..times..times..times..times..times..times..times..times..times..ti- mes..times..times..times..times..times..times..times..times.  ##EQU00003##\nThe n redundant bits from the broadband server are received with substantially perfect knowledge, since a unicast system can guarantee error-free transmission.  The formula is due to the mixing property of the EXIT chart, see \"A. Ashikhmin, G.\nKramer, and S. ten Brink, \"Extrinsic information transfer functions: model and erasure channel properties,\" IEEE Trans.  Inform.  Theory, vol. 50, no. 11, pp.  2657-2673, November 2004.\nFrom the previous formula, it is obtained:\n.times..times..times..times..times..times..times..times..times..times..ti- mes.&gt;.times.  ##EQU00004## n will be lower bounded by 0 (if MIold&gt;MInew) and upper bounded by the number of information bits K in the codeword, if MInew is set to\nthe code rate (or slightly above) R=K/N, in case MIold=0.\nIn short: The formula computes the amount n of redundancy that has to be retransmitted.  The new Mutual Information is computed, which is the weighted sum of the old Mutual Information and perfect Mutual Information for those n bits, and\ncompared with the desired Mutual Information that is required for successful decoding.\nIf the CSI of the receiver is available at the broadband server, the calculation of the required redundancy data bits can alternatively be carried out in the server.  The receiver then first transmits the CSI to the server (a possible CSI\ncompression scheme is described below).  Based on the SNR of each QAM symbol (determined from the CSI), the server is able to find the bit in the FEC codeword by means of the LUT that provides the largest additional mutual information.  This way the bits\nthat experienced deep fading are used first as redundancy data bits, since the additional mutual information of these bits is the largest.  The algorithm is very similar to the algorithm without CSI knowledge.  The important difference is that instead of\npseudo random bits, the bits providing the maximum additional information are used as redundancy bits.  This is iteratively repeated until the threshold of the required Mutual Information for error free decoding is reached.  The algorithm for the\ncalculation of the redundancy data bits in the server based on the receivers CSI in pseudo code is the following:\nTABLE-US-00004 RoD bits to request = 0 while (current MI &lt; required MI) { for (all bits in FEC codeword) { find bit with maximum additional MI (by means of LUT) } current MI = current MI + additional MI RoD bits to request = RoD bits to\nrequest + 1; }\nIn short: The algorithm describes a method to estimate the number of retransmitted bits for error free decoding, based on the channel state information, with optimum performance, but high computational complexity.\nThus, in such an embodiment the redundancy calculator 38 is configured to add additional Mutual Information resulting in the receiver, when a particular bit is known, to available Mutual Information for each bit location of a particular codeword\nuntil a threshold of an overall Mutual Information required for correct decoding is reached and to determine the required amount of redundancy data required for correct decoding of said particular codeword based thereon.  Preferably, said redundancy\ncalculator 38 is configured to determine said additional Mutual Information for several or all bits of a channel symbol.  Also in such an embodiment the receiver 3d preferably comprises a storage 40 that stores said additional Mutual Information for a\nplurality of codes, in particular for a plurality of code rates and/or codeword lengths.\nAccordingly, in such an embodiment the redundancy calculator 42 is configured to add additional Mutual Information resulting in the receiver, when a particular bit is known, to available Mutual Information for each bit location of a particular\ncodeword until a threshold of an overall Mutual Information required for correct decoding is reached and to determine the required amount of redundancy data required for correct decoding of said particular codeword based thereon.  Further, preferably the\nredundancy calculator 42 is configured to determine said additional Mutual Information for several or all bits of a channel symbol.  Still further, preferably a storage 44 is provided that stores said additional Mutual Information for a plurality of\ncodes, in particular for a plurality of code rates and/or codeword lengths.  In still another embodiment the redundancy calculator 42 is configured to use bits of a channel symbol providing the maximum additional Mutual Information, resulting in the\nreceiver, when a particular bit is known, as redundancy data.  In a similar way, the receiver could, using channel state information, determine the required number of bits of a channel symbol providing the maximum additional Mutual Information.\nThe broadband server then transmits the redundancy data bits to the receiver via broadband, which is then able to calculate the positions of the redundancy data bit within the FEC codeword with the same algorithm that has been used in the\nredundancy data server to generate the bits.  The receiver is then able to recombine and decode the FEC codeword.\nTo reduce the number of comparisons to find the optimal bit from the LUT, the LSBs only can be transmitted first, then the bits at bit position LSB-1 within the QAM symbol, and so on, since these bits have a high probability to carry the lowest\nMutual Information.  This is neglected in the pseudo code for simplicity.\nIn principle it is also possible to determine the number of required bits based on other parameters like SNR or MER.  However, SNR and MER do not allow for such an accurate estimation taking the CSI into account.  Rough numbers for the required\nRoD amount must be stored in the server and receiver that have been determined by simulation for different delta SNR values (required SNR-actual SNR).  That is, the estimation of the required number of redundancy data bits based on SNR or MER is less\naccurate compared to the Mutual Information and therefore not well suited here.\nIn the following synchronization between receiver and broadband server will be explained.\nThe signaling about how the received data must be combined in the receiver generally takes place in the broadband network.  As a result the frame structure employed in the broadcast network does not necessarily need any extension.  However, at\nthe physical layer an identification of the FEC-encoded data segments is required for the synchronization between the data from both terrestrial and broadband networks.  Besides, at the application layer the redundancy data can be signaled as an\nadditional service, therefore a linkage to the respective original service shall be given.\nCurrent terrestrial broadcasting systems like DVB-T or DVB-T2 contain no suitable mechanism for a unique identification of FEC packets/BBFrames, although the available timestamp of DVB-T2 (ISSY counter) might be applicable to some extent. \nHowever the limited time range of the ISSY counter might prevent a reliable packet identification An unambiguous mechanism is therefore required to inform the broadband server, which BBFrames could not be correctly decoded.  One solution would e.g. be a\ncounter related to each FEC packet, whose value is increased after each FEC packet, allowing for the unique identification of a FEC packet.  If it is intended to introduce the concept of using redundancy (on demand; RoD) in broadcasting systems without\nsuch unique packet identification alternative approaches need to be used.  A specific amount of soft-information (LLR) values of the LDPC or BCH parity block (in case of DVB-T2) of the erroneous packet can be used as a fingerprint that identifies the\npacket.  This is possible, since even a slight difference in the payload between packets leads to different parity blocks.  Based on the sequence of LLR values, the broadband server can perform a correlation to achieve the synchronization.  This allows\nfor the synchronization between broadband server and the receiver even if the required SNR in the receiver is too low to decode any FEC packets correctly.\nThus, in an embodiment of a broadband server 4c depicted in FIG. 16 it comprises, in addition to the elements of the broadband server 4b shown in FIG. 14, an identification unit 45 that identifies a data packet for which redundancy data shall be\ndetermined by use of a correlation using soft information values of data of said data packet, in particular of parity data, contained in a request received from a receiver, wherein said redundancy calculator 42 is configured to use the information about\nthe identity of the data packet to determine redundancy data for said data packet.  In the same way, the receiver could identify the data packet to which received redundancy data belong based on the correlation using soft information of the demodulator\nand/or the decoder.\nIf the receiver was already able to decode some FEC packets, the transmission of soft-information for correlation in the broadband server is not necessary, since a subset of the parity blocks of correctly decoded preceding FEC packets can be\nused for packet identification.  In such cases the known and hard decided fingerprint of the last correctly received packet and the number of erroneous packets is transmitted to the broadband server, which then sends the required amount of redundancy for\nthe requested packets.  For this identification approach even a small amount of bits is sufficient, since no correlation in the receiver is required.  It must only be assured that the fingerprint uniquely identifies the FEC packet.  Assuming that the\nparity blocks are binary sequences with equal distribution, the probability that a fingerprint sequence with length n is not unique for m preceding FEC packets is\n.times..times..times..times..times..times..times..times..times..times..ti- mes..times..times..times.  ##EQU00005##\nBased on this formula the required number of bits can easily be calculated for a given maximum misdetection probability p and the number of FEC packets the identification is carried out with.  The misdetection probability p is given in the\nfollowing table for exemplary values of m and n. It becomes clear that increasing the fingerprint length m, decreases the probability for misdetection.\nTABLE-US-00005 m\\n 8 16 24 32 40 48 56 64 2 3.91E-03 1.53E-05 5.96E-08 2.33E-10 9.09E-13 3.55E-15 1.39E-17 5.42E-20 10 1.63E-01 0.00068644 2.68E-06 1.05E-08 4.09E-11 1.60E-13 6.25E-16 2.44E-- 18 25 0.702147 0.00456774 1.79E-05 6.98E-08 2.73E-10\n1.07E-12 4.16E-15 1.63E-- 17 100 1 0.0727845 0.000295 1.15E-06 4.50E-09 1.76E-11 6.87E-14 2.68E-16 250 1 0.378447 0.00185348 7.25E-06 2.83E-08 1.11E-10 4.32E-13 1.69E-15 1000 1 0.999529 0.0293343 0.000116292 4.54E-07 1.77E-09 6.93E-12 2.71E-14 2500 1 1\n0.169892 0.00072704 2.84E-06 1.11E-08 4.34E-11 1.69E-13 10000 1 1 0.949234 0.0115729 4.55E-05 1.78E-07 6.94E-10 2.71E-12\nHowever, the success rate can be further increased if the frame number and the number of the FEC block within the frame are transmitted.\nThus, in such an embodiment of a broadband server 4c depicted in FIG. 16 the identification unit 45 identifies a data packet for which redundancy data shall be determined by use of a number of bits, in particular parity bits, of the last\ncorrectly decoded codewords contained in a request received from a receiver.  Further, the redundancy calculator 42 is configured to use the information about the identity of the data packet to determine redundancy data for said data packet.  In another\nembodiment a packet counter or a timestamp (ISSY) can be used for packet identification.\nIn the following cooperative decoding with distributed receivers will be explained.\nMost TV devices nowadays are integrated with terrestrial broadcast receiver.  But the TV devices work alone with the locally received signals.  However, as home networks are being installed in more and more household, the receivers can be\nconnected to each other as well, so that a cooperative decoding of the broadcast signal becomes realizable.  A space-diversity will be created when the receivers can carry out the decoding jointly and thus an improvement of the signal quality will also\nbe possible.  This concept is operating without a server that has perfect knowledge of the transmitted signal.  Instead the redundancy data is generated in a cooperative fashion.\nM the embodiment of a broadcast system shown in FIG. 17, n receivers Rx1, Rx2, .  . . , R are connected via a server, which may be located separately or together with one of the receivers.  After receiving the broadcast signal each receiver\nchecks whether and where (temporally or spectrally) redundancy data is required and makes a request to the server.  Having the requests from each receiver, the server requires the necessary data from each receiver, encode it, and distribute it to the\nreceivers that need it.\nAssuming an example with two receivers, Rx1 and Rx2, three cases may happen to each signal part (temporally or spectrally).\n1.  Both receivers can decode it correctly by themselves.  No data exchange is needed in this case.\n2.  Both receivers cannot decode it correctly by themselves.  The LLRs of the signal are quantized and transmitted to the server, who adds them together and multicasts the signal to both receivers.  Afterwards the receivers precede the decoding\nprocess with help of the received LLRs.  3.  One receiver can decode it correctly by itself while the other not.  In best case, another signal part can be found where the situation is reversed and the LLRs of these two signal parts can be added and\nforwarded by the server.  Then each receiver can achieve the desired part by subtracting their own signal (network coding alike).\nFor example\n##STR00001##\nRx1 send S2 and Rx2 send S1' to the server.  The server transmitted then S2+S1 back to each receiver, which can get the desired signal with subtraction.\nSuch a broadcast system thus comprises a broadcast transmitter that broadcasts broadcast signals in a coverage area for reception by terminals comprising a broadcast receiver and a broadband receiver, a broadband server that provides redundancy\ndata to terminals within said coverage area, and one or more terminals comprising a broadcast receiver and a broadband receiver, wherein said broadband server is configured to obtain redundancy data required by a terminal from one or more other\nterminals.\nThe information exchange can take place autonomously when the receivers are somehow connected to each other (e.g. by a home network via Ethernet) such that a distributed network is resulting.  This approach is shown in FIG. 18.  In this case,\nthe server is not necessary and data request, coding and flow control are controlled by receivers themselves.  Such a broadcast system thus comprises a broadcast transmitter that broadcasts broadcast signals in a coverage area for reception by terminals\ncomprising a broadcast receiver and a broadband receiver, and one or more terminals comprising a broadcast receiver, wherein said terminals are configured to obtain redundancy data required by a terminal from one or more other terminals.\nObviously, numerous modifications and variations of the present disclosure are possible in light of the above teachings.  It is therefore to be understood that within the scope of the appended claims, the invention may be practiced otherwise\nthan as specifically described herein.\nIn the claims, the word \"comprising\" does not exclude other elements or steps, and the indefinite article \"a\" or \"an\" does not exclude a plurality.  A single element or other unit may fulfill the functions of several items recited in the claims. The mere fact that certain measures are recited in mutually different dependent claims does not indicate that a combination of these measures cannot be used to advantage.\nIn so far as embodiments of the invention have been described as being implemented, at least in part, by software-controlled data processing apparatus, it will be appreciated that a non-transitory machine-readable medium carrying such software,\nsuch as an optical disk, a magnetic disk, semiconductor memory or the like, is also considered to represent an embodiment of the present invention.  Further, such a software may also be distributed in other forms, such as via the Internet or other wired\nor wireless telecommunication systems.\nThe elements of the claimed devices and apparatus may be implemented by corresponding hardware and/or software elements, for instance appropriated circuits.  A circuit is a structural assemblage of electronic components including conventional\ncircuit elements, integrated circuits including application specific integrated circuits, standard integrated circuits, application specific standard products, and field programmable gate arrays.  Further a circuit includes central processing units,\ngraphics processing units, and microprocessors which are programmed or configured according to software code.  A circuit does not include pure software, although a circuit includes the above-described hardware executing software.\nAny reference signs in the claims should not be construed as limiting the scope.", "application_number": "16126244", "abstract": " A receiver for receiving data in a broadcast system comprises a broadcast\n     receiver that receives via said broadcast system a receiver input data\n     stream comprising a plurality of channel symbols represented by\n     constellation points in a constellation diagram, a demodulator that\n     demodulates said channel symbols into codewords, and a decoder that\n     decodes said codewords into output data words. A redundancy calculator\n     determines a required amount of redundancy data required for correct\n     demodulation and decoding by use of the originally received channel\n     symbol and additional redundancy data. A broadband request unit requests,\n     if demodulation of a channel symbol and/or decoding of a codeword is\n     erroneous or likely to fail, a required amount of redundancy data via a\n     broadband system, that is received by a broadband receiver via said\n     broadband system. Said demodulator and/or said decoder is configured to\n     use said redundancy data for demodulation and decoding, respectively.\n", "citations": ["6023615", "6532562", "6594798", "6996097", "7203227", "7366172", "7519811", "7564878", "7697514", "7733911", "7734946", "7986633", "8433251", "8514721", "8699607", "8775908", "8817626", "8887030", "8923249", "8934445", "8935315", "8938040", "9077459", "9131426", "9215276", "9385752", "9490887", "9538214", "9692630", "9755781", "9838157", "10110352", "20040208255", "20050204242", "20050249211", "20060168264", "20060265603", "20070071121", "20080086662", "20080137718", "20080233966", "20080244676", "20090080351", "20090086657", "20090274109", "20100046651", "20100142612", "20100172423", "20100232488", "20100234071", "20100313096", "20110043614", "20110055320", "20110188597", "20120254684", "20120272117", "20120320994", "20130070821", "20130254828", "20140064233", "20140101508", "20140294105", "20150163085", "20150236818", "20150236828", "20150280861", "20150288553", "20150288990", "20150326290", "20150358106", "20160006593", "20160043830", "20160043890", "20170324510", "20170331598", "20180013516", "20180048423", "20190007252"], "related": ["15610095", "14435556", "2013074733"]}, {"id": "20190018835", "patent_code": "10275451", "patent_name": "Counterintuitive recommendations based upon temporary conditions", "year": "2019", "inventor_and_country_data": " Inventors: \nBhowmick; Arindam (Dublin, CA), Chivardi; Carlos (Glen Ellyn, IL), Hatfield; Jennifer M. (San Francisco, CA), Hurlebaus; Gregory S. (Rochester, MN), Scherpa; Josef (Fort Collins, CO)  ", "description": "<BR><BR>BACKGROUND\nThe present disclosure relates generally to the field of natural language processing, and, more particularly, to using natural language processing in making recommendations to individuals and users.\nAs a field of computer science, natural language processing tends to focus on the relationships between computer systems and human languages.  Many modern natural language processing algorithms are derived based on machine learning and rely\ngreatly on statistical inferences.  By analyzing large sets of real-world examples of natural language usages, a computer system may be able to glean sets of rules that guide the machine through a future analysis of natural language passages.\nRecommendations and recommender systems make recommendations to users based on a comparison of the user's profile with profiles of other users who make use of a marketplace.  However, these recommendations have historically been based off of the\nrelationships between items.  Typically, this has been in the form of \"people who have bought this have also bought these items\".  More advanced systems of recommendations look at the items themselves to determine if the items are related, and the user\nmay be interested in the items based on a similarity between the item being looked at and these items.  However, these recommendation systems are limited in that they are based on the needs of the merchant offering the recommendations and not based on\nother needs, wants or desires of the consumer.  The goal of the recommendation systems is to have the user buy a particular item from the merchant.\n<BR><BR>SUMMARY\nEmbodiments of the present disclosure include a method for providing counter intuitive recommendations to individuals based on the profiles of the individuals/groups and the features of various activities, events, locations, etc., as well as a\ncomputer program product and a system for implementing the method.  As part of the method, a user profile is obtained for the user.  A determination that a trigger condition has occurred for the user.  The duration of the trigger condition is also\ndetermined.  The trigger condition is associated with the user's profile.  A request for a recommendation is received, and a list of recommendations is obtained.  The recommendations are compared against the trigger condition to determine if the\nrecommendation is compatible with the trigger condition.  Those recommendations determined not to be compatible with the trigger condition are removed from the set of recommendations provided to the user.\nThe above summary is not intended to describe each illustrated embodiment or every implementation of the present disclosure. <BR><BR>BRIEF DESCRIPTION OF THE DRAWINGS\nThe drawings included in the present disclosure are incorporated into, and form part of, the specification.  They illustrate embodiments of the present disclosure and, along with the description, serve to explain the principles of the\ndisclosure.  The drawings are only illustrative of typical embodiments and do not limit the disclosure.\nFIG. 1 illustrates a block diagram of an example computing environment in which illustrative embodiments of the present disclosure may be implemented.\nFIG. 2 illustrates a block diagram of an exemplary architecture, including a natural language processing system, configured to identify significant features and context in electronic content, in accordance with embodiments of the present\ndisclosure.\nFIG. 3 is a diagrammatic representation recommender system and application according to illustrative embodiments of the present disclosure.\nFIG. 4 is a flow diagram illustrating a process for making travel recommendations for a group according to illustrative embodiments.\nFIG. 5 is a flow diagram illustrating a process for forming a group of individuals who have similar interests according to illustrative embodiments.\nFIG. 6 is a flow diagram of a process for providing recommendations that go against a currently existing profile for an individual or a group according to illustrative embodiments.\nFIG. 7 is a flow chart illustrating a process of providing proactive recommendations according to illustrative embodiments.\nFIG. 8 is a block diagram illustrating a computing system according to one embodiment.\nFIG. 9 is a diagrammatic representation of an illustrative cloud computing environment.\nFIG. 10 illustrates a set of functional abstraction layers provided by cloud computing environment according to one illustrative embodiment.\nWhile the embodiments described herein are amenable to various modifications and alternative forms, specifics thereof have been shown by way of example in the drawings and will be described in detail.  It should be understood, however, that the\nparticular embodiments described are not to be taken in a limiting sense.  On the contrary, the intention is to cover all modifications, equivalents, and alternatives falling within the spirit and scope of the invention.\n<BR><BR>DETAILED DESCRIPTION\nAspects of the present disclosure relate generally to the field of natural language processing, and in particular to providing recommendations to individuals, groups or combinations thereof based on the analysis of external events and\nconditions.  This information is contained in a variety of data sources which present data or information in natural language, which must be analyzed for a computer system and/or computing application to generate meaning and understand.  While the\npresent disclosure is not necessarily limited to such applications, various aspects of the disclosure may be appreciated through a discussion of various examples using this context.\nCurrently, individuals don't have an easy way to get a quick insight into what is available to them that also matches their taste and interests.  There are some major events that are quick to identify (e.g. major sports games, museums, concerts,\nfestivals, etc.), but there are an infinite number of places and activities that could be of interest to an individual.  Often these activities and places are only familiar to a few (typically local) individuals.  Furthermore, some events or activities,\nare only of interest to certain individuals based on, for example, their hobbies, personality, interests, etc. Only a person familiar with these particular events and/or activities, and who also knows the particular individual very well, for example, at\na personal level, would be able to provide those particular insights to the individual.  As a result, there are an infinite number of missed opportunities that would have resulted in the individual being able to do the activities that they would enjoy\nthe most at a particular place.  Having this information would enhance the quality and enjoyment of their travel or other experience.\nAlso, currently, individuals have a very short time window to try to maximize the use of their time while they're on vacation and away from work or other commitments.  The average person in the US spends only 16 days of their allocated 22 days\nof vacation and holidays.  Overall, in 2016 Americans had over 658 million vacation days that went unused.  A small number of individuals plan their itinerary at a destination in great detail in advance of arriving at a destination.  At most individuals,\ntypically, identify a few key activities that they would like to do at the location, and leave the rest to sort out once they are there.  Many times these activities are the \"popular\" activities at the location.  Many individuals do research online and\non their mobile devices once they are at their destination.  This approach consumes precious vacation time that the individuals could better use, and results in missed opportunities and lost vacation time.  With the vast amount of information currently\navailable online, through various different data sources, it is impossible for an individual to browse through this enormous amount of online information, as well as any online reviews of each potential activity, location, event, etc. Further, this\ninformation is in a constant state of flux, constantly changing as new information and/or reviews are posted for both new and existing activities.  Additionally, there are numerous new sources of information that come online on a regular basis.  Some of\nthese sites are legitimate sites providing relatively unbiased information about activates, locations, events, products, etc. However, it is relatively easy to create online information that provides highly biased viewpoints on the activities, locations,\nevents, products, etc., either to drive traffic to or away from the particular products.  Identifying the legitimate sites from the biased sites can also be a challenge.  The amount of information makes it impossible to have a thorough analysis of the\npotential options without sacrificing a considerable amount of vacation time.  Conversely, sacrificing this time to look at all the potential options, opinions and reviews, makes it increasingly likely that the selected activity won't be enjoyable, have\ngood quality or be a good fit for the individuals.\nIt's also increasingly difficult finding an activity that every person within the same group would enjoy doing.  This group can be a group traveling or can be any type of group that desires to do things together.  This takes additional research\nand discussion to take everyone's ideal activities in consideration.  This results in even more wasted time, and potentially choosing an activity that some people in the group will not enjoy.\nAs discussed above, aspects of the disclosure may relate to natural language processing to provide recommendations.  Accordingly, an understanding of the embodiments of the present disclosure may be aided by describing embodiments of natural\nlanguage processing systems and the environments in which these systems may operate.  Turning now to the figures, FIG. 1 illustrates a block diagram of an example computing environment 100 in which illustrative embodiments of the present disclosure may\nbe implemented.  In some embodiments, the computing environment 100 may include a remote device 102 and a host device 112.\nConsistent with various embodiments, the remote device 102 and the host device 112 may be computer systems.  The remote device 102 and the host device 112 may include one or more processors 106 and 116 and one or more memories 108 and 118,\nrespectively.  The remote device 102 and the host device 112 may be configured to communicate with each other through an internal or external network interface 104 and 114.  The network interfaces 104 and 114 may be, for example, modems or network\ninterface cards.  The remote device 102 and/or the host device 112 may be equipped with a display or monitor.  Additionally, the remote device 102 and/or the host device 112 may include optional input devices (e.g., a keyboard, mouse, or other input\ndevice), and/or any widely available or custom software (e.g., browser software, communications software, search engine and/or web crawling software, natural language processing software, etc.).  In some embodiments, the remote device 102 and/or the host\ndevice 112 may be servers, desktops, laptops, or hand-held devices.\nThe remote device 102 and the host device 112 may be distant from each other and communicate over a network 150.  In some embodiments, the host device 112 may be a central hub from which remote device 102 can establish a communication\nconnection, such as in a client-server networking model.  Alternatively, the host device 112 and remote device 102 may be configured in any other suitable networking relationship (e.g., in a peer-to-peer configuration).\nIn some embodiments, the network 150 can be implemented using any number of any suitable communications media.  For example, the network 150 may be a wide area network (WAN), a local area network (LAN), or the Internet.  In certain embodiments,\nthe remote device 102 and the host device 112 may be local to each other and communicate via any appropriate local communication medium.  For example, the remote device 102 and the host device 112 may communicate using a local area network (LAN), one or\nmore hardwire connections, or a wireless link.  In some embodiments, the remote device 102 and the host device 112 may be communicatively coupled using a combination of one or more networks and/or one or more local connections.  For example, the first\nremote device 102 may be hardwired to the host device 112 (e.g., connected with an Ethernet cable) while a second remote device (not shown) may communicate with the host device using the network 150 (e.g., over the Internet).\nIn some embodiments, the network 150 can be implemented within a cloud computing environment, or using one or more cloud computing services.  Consistent with various embodiments, a cloud computing environment may include a network-based,\ndistributed data processing system that provides one or more cloud computing services.  Further, a cloud computing environment may include many computers (e.g., hundreds or thousands of computers or more) disposed within one or more data centers and\nconfigured to share resources over the network 150.\nIn some embodiments, the remote device 102 may enable users to submit (or may submit automatically with or without user input) electronic documents (e.g., web pages, social media feeds and profiles, etc) containing profile information or\ninformation useful for determining the preferences of the user to the host devices 112 in order to have the profile information ingested and analyzed for sentiment (e.g., by natural language processing system 122).  For example, the remote device 102 may\ninclude submission module 110 and a user interface (UI).  The submission module 110 may be in the form of a web browser, application, or any other suitable software module, and the UI may be any type of interface (e.g., command line prompts, menu\nscreens, graphical user interfaces).  The UI may allow a user to interact with the remote device 102 to submit, using the submission module 110, one or more web pages or social media feeds containing information related to the interests of the submitter\nto the host device 112.  In some embodiments, the submission module 110 may incorporate a web crawler or other software that allows the module to search for and automatically identify profile information for submission to the host device 112.  In some\nembodiments, the submission module may also receive information related to reviews of activities, locations, events, etc.\nIn some embodiments, the information being submitted via the submission module 110 may all belong to (or may have all been created on a website that is owned by) the same entity that is submitting them for analysis.  This may occur, for example,\nwhen an airline submits customer information that was provided directly to the airline by customers who have purchased travel from the airline.  In some other embodiments, the entity submitting the information may be different from the entity that\noriginally received (e.g., collected) the individual profiles or reviews from consumers.  This may occur, for example, when the entity receives reviews from a third party (e.g., a consumer survey company), for free or for a fee, and then submits these\nreviews for analysis.\nIn some embodiments, the remote device 102 may further include a rank notification receiver module 111.  This module may be configured to receive notifications, from the host device 112, of the relative ranks of various features common to a\ngroup of activities, profiles, locations, products, etc. In some embodiments, these relative ranks may then be used by the remote device 102 to aid prospective users in determining which activities or recommendations are more important to consider when\nselecting activities to engage in. For example, these rankings may incorporated (by either the remote device 102 or the host device 112) into web pages that allow consumers to use these received rankings for sorting through products based on matches to\nthe user's profile by the recommendation system.\nIn some embodiments, the host device 112 may include a natural language processing system 122.  The natural language processing system 122 may include a natural language processor 124, a rank notifier 126, and a sentiment ranker 130.  The\nnatural language processor 124 may include numerous subcomponents, such as a tokenizer, a part-of-speech (POS) tagger, a semantic analyzer, and a syntactic analyzer.  An example natural language processor is discussed in more detail in reference to FIG.\n2.\nIn some embodiments, the sentiment ranker 130 may be configured to features based on an analysis of the sentiment associated with ingested and annotated reviews.  In addition, the rank notifier 126 may be connected to the sentiment ranker module\n130 and may serve to notify a user at the remote system 102 (e.g., via the rank notification receiver module 111) of the relative ranks of the suggestions or recommendations.\nIn some embodiments, the natural language processing system 122 may further include a search application (not shown).  The search application may be implemented using a conventional or other search engine, and may be distributed across multiple\ncomputer systems.  The search application may be configured to search one or more databases or other computer systems for profiles or reviews that are related to a target group of individuals or activities.  For example, the search application may be\nconfigured to search a corpus of information related to reviews previously submitted by the submission module 110 in order to identify additional relevant reviews and profiles of those who submitted the reviews.\nWhile FIG. 1 illustrates a computing environment 100 with a single host device 112 and a single remote device 102, suitable computing environments for implementing embodiments of this disclosure may include any number of remote devices and host\ndevices.  The various modules, systems, and components illustrated in FIG. 1 may exist, if at all, across a plurality of host devices and remote devices.  For example, some embodiments may include two host devices.  The two host devices may be\ncommunicatively coupled using any suitable communications connection (e.g., using a WAN, a LAN, a wired connection, an intranet, or the Internet).  The first host device may include a natural language processing system configured to ingest and annotate\nproduct reviews, and the second host device may include a software module configured to compare and rank product features based on the ingested product reviews.\nIt is noted that FIG. 1 is intended to depict the representative major components of an exemplary computing environment 100.  In some embodiments, however, individual components may have greater or lesser complexity than as represented in FIG.\n1, components other than or in addition to those shown in FIG. 1 may be present, and the number, type, and configuration of such components may vary.\nReferring now to FIG. 2, shown is a block diagram of an exemplary architecture 200, including a natural language processing system 212, configured to use product reviews to rank product features, in accordance with embodiments of the present\ndisclosure.  In some embodiments, a remote device (such as remote device 102 of FIG. 1) may submit electronic documents, webpages, social media feeds, etc (containing information to be analyzed to determine if conditions for a trigger event or trigger\ncondition have occurred) to the natural language processing system 212 which may be housed on a host device (such as host device 112 of FIG. 1).  Such a remote device may include a client application 208, which may itself involve one or more entities\noperable to generate or modify information in the webpages that are then dispatched to a natural language processing system 212 via a network 215.\nConsistent with various embodiments, the natural language processing system 212 may respond to electronic document submissions sent by the client application 208.  Specifically, the natural language processing system 212 may analyze a received\nproduct reviews to aid in the analysis of the relative importance of product features for consumer consideration.  In some embodiments, the natural language processing system 212 may include a natural language processor 214, data sources 228, a rank\nnotifier 226, and a sentiment ranker 230.\nThe natural language processor 214 may be a computer modules that analyzes the received webpages, social media feeds, electronic documents, etc. The natural language processor 214 may use various techniques for analyzing electronic documents\n(e.g., syntactic analysis, semantic analysis, etc.).  The natural language processor 214 may be configured to recognize and analyze any number of natural languages.  In some embodiments, the natural language processor 214 may parse passages of the\ndocuments.  Further, the natural language processor 214 may include various modules to perform analyses of the information in the processed items.  These modules may include, but are not limited to, a tokenizer 216, a part-of-speech (POS) tagger 218, a\nsemantic analyzer 220, a syntactic analyzer 222, and sentiment analyzer 224.\nIn some embodiments, the tokenizer 216 may be a computer module that performs lexical analysis.  The tokenizer 216 may convert character strings into ordered sets of tokens.  A token may be a sequence of characters included in an electronic\ndocument and classified as a meaningful representation.  In some embodiments, the tokenizer 216 may identify lexemes in a received characters string and categorize them as tokens.  Further, in some embodiments, the tokenizer 216 may identify text\nboundaries in an electronic document and divide any text passages within the document into their component text elements, such as words, phrases, and punctuation marks.\nConsistent with various embodiments, the POS tagger 218 may be a computer module that annotates words in passages based on their respective parts of speech (e.g., verbs, adverbs, nouns, possessive markers, conjunctions, pronouns, etc.).  The POS\ntagger 218 may read a passage or other text in natural language and annotate each word or token a part of speech.  The POS tagger 218 may determine the part of speech to which a word (or other token) corresponds based on the definitions and context.  The\ncontext of a word may be determined based on its relationships with associated words in a phrase, sentence, or passage.  In some embodiments, the context of a word may be dependent on one or more previously analyzed electronic documents (e.g., the\ncontent of one document may shed light on the meaning of text elements in another document, particularly if they are reviews of the same item).  In some embodiments, the POS tagger 218 may tag or otherwise annotate tokens of a passage with part of speech\ncategories.  These annotated tokens may then be analyzed by other modules of the natural language processing system 212.\nIn some embodiments, the semantic analyzer 220 may be a computer module that is configured to identify semantic relationships between tokens.  In some embodiments, the semantic relationship identifier 220 may discover functional dependencies and\nother semantic relationships between tokens.\nConsistent with various embodiments, the syntactic analyzer 222 may be a computer module that is configured to identify syntactic relationships between tokens.  The syntactic relationship identifier 222 may rely on formal or informal grammar\nrules to identify the grammatical structure of sentences (e.g., which words modify which other words, which noun is the object of a verb, etc.).\nConsistent with various embodiments, the sentiment analyzer 224 may be a computer module that is configured to identify and categorize the sentiments associated with tokens of interest.  In some embodiments, the sentiment analyzer may be\nconfigured to identify, within text passages, and annotate keywords that are preselected as high quality indicators of sentiment polarity (e.g., indicators of positive sentiment could include brilliant, excellent, or fantastic).  Various tools and\nalgorithms may be used the sentiment analyzer 224 as are known to those skilled in the art (e.g., Naive Bayes lexical model).\nIn some embodiments, the natural language processor 214 may be a computer module that may parse a document and generate an associated data structures for one or more portions of the parsed document.  For example, in response to receiving a set\nof reviews from a website that includes a collection of consumer reviews at the natural language processing system 212, the natural language processor 214 may output parsed text elements from the product reviews as data structures.  In some embodiments,\na parsed passage may be represented in a graph structure, such as a parse tree.\nIn some embodiments, the parsed outputs of the natural language processor 214 may be stored as an information corpus 229 in one or more data sources 228.  In some embodiments, data sources 228 may include data warehouses, document repositories,\nand information corpora.  The information corpus 229 may enable data storage and retrieval.  In some embodiments, the information corpus 229 may store standardized and consistent copies of the ingested and parsed reviews.  Data stored in the information\ncorpus 229 may be organized specifically to address the purpose of the system's analysis of that data.  For example, the information corpus 229 may store the ingested reviews based on groups of related items (e.g., products of the same type, similar\nactivities, etc) in order to make ranking features associated with the items easier.  In some embodiments, the information corpus 229 may be a relational database.\nIn some embodiments, the natural language processing system 212 may include a sentiment ranker module 230.  The sentiment ranker module 230 may be a computer module that is configured to generate sentiment scores for specific forms of item\nfeatures based on the analysis of annotated reviews.  The sentiment ranker module 230 may be further configured to rank the item features based on these sentiment scores.\nThe rank notifier 226 may be a computer module that is configured to notify users of item features rankings determined by the sentiment ranker module 230.  In some embodiments, the rank notifier 226 may communicate with a rank notification\nreceiver module (such as module 111 of FIG. 1).\nFIG. 3 schematically shows a recommender system 300 operating to provide recommendations 355 to users such as user 301 that may access the recommender system 300 through an application, such as application 360 using a device 370 according to\nillustrative embodiments.  However, any available recommender system may be used.  As used herein, a user can be an individual or a group of individuals.  Recommender system 300 in some embodiments, comprises an \"explicit-implicit database\" 331\ncomprising explicit and/or implicit data acquired responsive to preferences exhibited by a population of users 301 for items in a catalog of items.  Recommender system 300 may comprise a model maker 340 and a cluster engine 341 that cooperate to cluster\nrelated catalog items in catalog clusters and generate a clustered database 332.  A recommender engine 350 recommends catalog items from catalog clusters in clustered database 332.  The content of the items in clustered database can vary based on the\nparticular implementation of the application 360.  In some embodiments, the catalog items adjust or are augmented based on information received or determined by the natural language processing system of FIGS. 1 and 2 discussed above.\nDevice 370 may be any device in which a user 301 interacts with the application 360 through a network 335 to receive recommendations 355 for content and or activities.  (e.g. mobile phone, tablet computer, desktop computer, music player, etc). \nIn some embodiments, the application is installed on the user's device and accesses content through network 335.  The application 360 is in one embodiment a consumer application 360 accessed by consumers or users 301 to purchase or obtain content and\nhave that content delivered to them via network 335.  In some embodiments, the application 360 is a travel or lifestyle application that allows the user to locate, find or otherwise review activities that they would desire to participate or engage in.\nThe application 360 permits the user to search for content and activities, and also provides recommendations to the user about activities or content they may be interested in by communicating with a recommender system 300.\nIn some embodiments, the application 360 is configured to generate profiles 365 for the users of the recommendation system 300.  Again, a profile 365 can be an individual profile or a group profile.  The profile can be generated by profile\nbuilder 362.  Examples of approaches to generating profiles for the users is discussed in greater detail below with respect to FIGS. 2-4.  The profiles that are generated for use by the recommender system 300 can be customized based on the particular end\nuse of the application.  That is, for example, if the application is configured to provide travel recommendations then the profiles can be customized or tilted towards travel interests.  In some embodiments, the application 360 does not generate the\nprofiles itself, but acquires them from external sources that provide profiles for users or groups.  In some embodiments, the profiles can be generated by the profile builder 362 and also obtained from outside sources.  The profiles 365 can be stored in\na profile store 366.  Profile store 366 may be any type of storage system that can store profile information of individuals and groups.  Each profile 365 is stored as a separate profile from other profiles 365 in the profile store.\nExplicit data optionally comprised in explicit-implicit database 331 includes information acquired by recommender system 300 responsive to explicit requests for information submitted to users 301 in the population.  These requests can be\nobtained in one embodiment from the user 301 when the user generates their personal profile with the application or first interacts with the device 370.  Explicit requests for information may comprise, for example, questions in a questionnaire, requests\nto rank a book or movie for its entertainment value, requests to express an opinion on quality of a product, or requests to provide information related to likes and dislikes.  Implicit data in the explicit-implicit database 331 can includes data acquired\nby the recommender system 300 responsive to observations of behavior of users 301 in the population that is not consciously generated by an explicit request for information.  For example, implicit data may comprise data responsive to determining how the\nuser uses content displayed by the device 370.\nModel maker 340 processes explicit and/or implicit data comprised in explicit-implicit database 331 to implement a model for representing catalog items that represents each of the catalog items by a representation usable to cluster the catalog\nitems.  Cluster engine 341 processes the representations of the catalog items provided by model maker 340 to generate \"clustered database\" 332 in which the plurality of catalog items is clustered into catalog clusters, each of which groups a different\nset of related catalog items.  While FIG. 3 schematically shows explicit-implicit database 331 as separate from clustered database 332, clustered database 332 may be comprised in explicit-implicit database 331.  To generate clustered database 332,\ncluster engine 341 may, for example, simply mark records in explicit-implicit database 331 to indicate clusters with which the records are associated.\nAny of various models for providing representations of catalog items and methods of processing the representations to cluster the catalog items and generate clustered database 332 may be used in practice of an embodiment of the invention.  Model\nmaker 340 may for example generate representations of catalog items that are based on feature vectors.  Optionally, model maker 340 represents catalog items by vectors in a space spanned by eigenvectors, which are determined from a singular value\ndecomposition (SVD) of a \"ranking matrix\" representing preferences of users 301 for the catalog items.  Model maker 340 may represent catalog items by trait vectors in a latent space determined by matrix factorization of a ranking matrix.  However, other\nmethods may be employed.\nCluster engine 341 optionally clusters catalog items in a same catalog cluster if same users exhibit similar preferences for the catalog items.  Optionally, cluster engine 341 uses a classifier, such as a support vector machine, trained on a\nsubset of the catalog items to distinguish catalog items and cluster catalog items into catalog clusters.  In some embodiments, the cluster engine 341 uses an iterative k-means clustering algorithm to cluster vectors representing catalog items and\ngenerate clustered database 332.\nFIG. 4 is a flow diagram illustrating a process for making travel recommendations for a group according to illustrative embodiments.  The process discussed herein can be implemented using the natural language processing system discussed above\nwith respect to FIGS. 1 and 2, and the recommender system discussed above with respect to FIG. 3.  While FIG. 4 discusses travel recommendations, it should be noted that the process could be used for other situations where a group recommendation to\nengage in a certain activity can be envisioned.\nThe process begins by defining the group.  This is illustrated at step 410.  Typically, a group includes two or more individuals.  However, in some embodiments, a group may only have a single member.  One of the members of the group may access\nan application 360, and define the members of the group.  In this approach the user may select the members of the group from a set of their contacts.  These contacts may be contacts, for example, in a phone, electronic address book, social media site,\netc. The selection of the members of the group can be done through an interface.  In some embodiments, the group may be created automatically, by the application 360.  In this approach the application 360 can analyze the contacts of the user to identify\nthose contacts that logically should form a group.  This analysis can consider the profiles 365 and profile data of each contact and based on information in the profiles 365 create the various groups.\nIn some embodiments, the group can be formed in an ad hoc manner.  In forming the group via an ad hoc approach the application 360 can consider events occurring in the real world and convert those events into interests.  For example, the\napplication 360 may determine that there is a forest fire that is threatening a horse farm.  The application 360 may have learned of this through its analysis of new websites.  The application 360 then converts the knowledge about the forest fire and the\nhorse farm into profile data that relates to interests in horses, owning a horse trailer, and the location of the fire.  The application 360 then uses this profile data and the location data to form a group of individuals who may have no previous\nknowledge of each other.\nOnce the group has been formed the user who formed the group can provide information to the application 360 related to an activity or activities that the group desires to do.  This is illustrated at step 420.  This results in the creation of a\ngroup profile for the members of the group.  This is illustrated at step 425.  Steps 420 and 425 will be discussed together.  For example, the user could indicate that the group desires to on a ski trip.  However, the user also indicates that they also\ndesire to go on the ski trip only when there is going to be powder at the resort, and the cost of the airfare is less than $400.00.  The user can further provide more granularity to the application 360 by, for example, indicating further requirements on\nthe trip, such as locations to avoid, cost of lift tickets, time restrictions, etc. This can be referred to as a set of conditions for the activity.  In some embodiments, the application 360 can add additional limitations or restrictions to the request. \nFor example, the application 360 can scan the profiles 365 of the members of the group and identify additional interests of the members of the group.  These profiles 365 for the members can come from other applications such as social media applications,\nor information gleaned from contact information.  During the scan the application 360 can identify, for example, musical interests of the members of the group as well as food preferences for the members of the group.  The information contained in the\nprofiles 365 of the members of the group can include interests that the members had not considered as being relevant to the desired trip they are looking at doing.  In some embodiments, multiple group profiles 365 can be created for the members of the\ngroup to account for various differences in interests between the members of the group.  In this approach, there may be three or more group profiles 365 for the group.  Each of these group profiles 365 are additional group profiles 365 that are\nassociated with the main group profile.  These sub group profiles 365 can be created by the application 360 or by the user who created the group.  As an example of these sub group profiles 365, while all members desire to go skiing, some members of the\ngroup have an interest in snowmobiling, while some members have an interest in snowshoeing.  Separate sub group profiles 365 may be made for the members of the group who have these interests.  Further, it should be noted that membership in one of the sub\ngroup profiles 365 may be, but does not have to be mutually exclusive.  In some embodiments, the profile for the group already exists and the group profile is simply accessed from the source that currently holds the corresponding group profile.\nOnce the group and the profile for the group have been formed the application 360 works in the background to identify a set of trigger events that match the preferences and/or set of conditions defined for the group activity in the group\nprofile.  This is illustrated at step 430.  The application 360 processes the information from the group profile into the set of trigger events.  Trigger events are events that correspond to the determined preferences of the group.  To form the trigger\nevents the application 360 uses the information in the profile to identify locations and/or conditions that match the desired activity or purpose of the group.  In the example of a ski trip, the application 360 identifies a number of ski resorts and\ndetermines the location of each these ski resorts.  To identify the location of the ski resorts the application 360 may implement natural language processing of internet sites related to skiing.  In some embodiments, the application 360 access a\ncatalogue that includes information related to ski resorts.  From this information related to location of the ski resorts, the application 360 generates the trigger events for the locations.  In this example, the trigger events can include monitoring the\nweather at each location that was identified, and to trigger an alert if the weather indicates that there will be a snowfall of more than 12 inches expected.  The application 360 can generate a second trigger event that monitors airfare between the\nlocation of the members of the group and each location determined for the ski resorts.  As many ski resorts are in locations that are not served by regular air service, the application 360 can determine the airport or airports that are closest to the\nparticular ski resort.  In some embodiments, the user may have indicated in the group profile that they want a ski resort that is within a particular distance of an airport.  In this instance the application 360 will generate the trigger for airfares to\nonly those airports that are within the particular distance indicated by the user.  Additional trigger events based on the information entered by the user can be generated by the application 360.  The number of trigger events generated by the application\n360 can be controlled by the user, or in some embodiments, controlled by the application 360.  Further, depending on the type of activity desired, the number of triggers can vary.  For example, a beach vacation may require more trigger events than a\nshopping trip to New York as the general conditions needed to make activity a success are more for the beach than shopping.  (e.g. Beach could have airfare, weather, lodging, timing as the trigger events, whereas shopping may only have airfare and sales\nas trigger events.)\nIn some embodiments, the application 360 uses the profiles 365 for the members of the group to generate additional activities, sets of conditions for the activities, and trigger events for the activities.  For example, the profile for the\nmembers of the group indicate that the members have an interest in a particular type of music, or a particular musical group.  The application 360 can, based on this information, generate one or more trigger events for this particular interest.  These\ntrigger events are generated by the application 360 outside of the specific information provided by the user when defining/setting up the group profile.  These trigger events are provided to alert the user to experiences that may be of interest to the\nmembers of the group outside of the primary reason for the creation of the group.  When the group is an ad hoc group the application 360 can generate trigger events for the ad hoc group for events that relate to the reason the ad hoc group was formed. \nUsing the example of the forest fire and the horse farm, the application 360 may create a trigger event for when the fire's edge is within a certain distance from the farm.\nOnce the trigger events have been defined for the group, the application 360 monitors a variety of electronic information sources in order to identify when a condition for a particular trigger event is met.  This is illustrated at step 440. \nThese information sources can include internet sites, blog posts, RSS feeds, social media platforms and posts, etc. Additional sources of information that can be monitored, can be based upon the particular trigger events that were generated.  For\nexample, if there is a trigger event related to weather then weather related information sources may be monitored.  The application 360 may prioritize particular trigger events over other trigger events, such that only a portion or subset of the set of\ntrigger events is initially monitored and compared.  This may be done to preserve processing power or to enhance the overall efficiency of the application 360.  The prioritization can be provided by the user, group, or the application.  For example, the\napplication 360 may prioritize the weather trigger event over the trigger event related to the cost of airfare.  In this instance, the application 360 does not monitor or consider the airfare condition and trigger event until such time as the weather\ntrigger event has occurred or the associated condition has been met.  The application 360 can prioritize any number of trigger events.  (e.g. the application can consider the three highest trigger events before considering the remaining trigger events,\nor can process each trigger event in their corresponding priority level).  The application 360 may implement web crawlers, bots, interactive web crawlers, interactive bots or other approaches to extract the information from the sites that contain or\npublish the associated information.  The extracted information is processed through a natural language processor to gain contextual knowledge about the information from the source.  Returning to the weather based trigger event, the application 360 can\nunderstand based on the contextual knowledge that a large snowfall is expected at a particular location.\nFollowing the extraction of the information from the information sources, the application 360 proceeds to compare the extracted information against the conditions related to the trigger event or events.  This is illustrated at step 450.  The\napplication 360, for example, uses the tokens generated by the natural language processing system to determine if the generated tokens and analysis of the particular tokens meets the conditions for the trigger event.  At this stage the application 360\ncan use logic rules or other analytical approaches to determine if the condition is met.  It should be noted that any method for determining if a condition has been met can be used.  For example, using the ski trip example, the application 360 could take\na token or string of tokens representing a predicted snowfall of one foot and compare that to a trigger event for predicted snowfall of 12 inches or more and determine that the trigger event has been met, as 12 inches is equal to one foot.\nIf the conditions of the trigger events are met, (e.g. a particular amount of snow expected exceeds the threshold value, and the airfare is below a threshold value, and the resort is within the defined distance from the airport) the application\n360 proceeds to send an alert to the user or members of the group.  This is illustrated at step 460.  The alerts can be sent to the user via email, text message, application 360 method or any other means for alerting the user.  However, in some\nembodiments, the alert can be sent when a threshold number of the trigger events have been met.  For example, an alert can be sent if the snow total expected exceeds the threshold, and the airfare is below the threshold cost, but the distance doesn't\nmeet the required distance.  The alert, in some embodiments, includes information associated with why the alert was generated.  This information can include, for example, details about the event that alert is about as well as information as how to get to\nthe event or book the event.\nThe user receives the alert from the application 360 and is then able to act on the alert.  This is illustrated at step 460.  In some embodiments, the alert includes information to book the event that caused the alert.  For example, the alert\ncould include a link or links to a website(s) to purchase tickets for the event, book travel to the event, etc. The user can then follow the provided links to complete the transaction.  In some embodiments, the application 360 has prepopulated the data\nrequired to book the event.  In this approach all the user has to do is complete the transaction by providing any missing information required.  In some embodiments, the application 360 is capable of completing the entire booking process without the user\nproviding any further information.  In this embodiment, the user simply indicates that the wish to participate in the event, and the application 360 completes the entire booking process in the background.\nFIG. 5 is a flow diagram illustrating a process for forming a group of individuals who have similar interests based upon a trigger event occurring, according to illustrative embodiments.  The process discussed herein can be implemented using the\nnatural language processing system discussed above with respect to FIGS. 1 and 2, and the recommender systems discussed above with respect to FIG. 3.\nThe process begins by creating a profile for the individuals who can form members of the groups.  This is illustrated at step 510.  At this step the user provides basic information to the application 360 that allows for the formation of a basic\nprofile for the user.  This information may include age, gender, name, location, contact information, their interests, hobbies etc. With this basic information the profile builder 362 builds the base profile for the user.  In some embodiments, the\nprofile builder 362 searches for profiles 365 that already exist for other users in the application 360 that are similar to the information that the user has entered.  If a similar profile is found the profile builder 362 may use that similar profile as\na base to generate the user's profile.  However, in other embodiments the user's base profile is generated without concern for other users of application 360.  The individuals interact with the application 360 through the user interface to provide the\napplication 360 with basic information about the individual.  In some embodiments, the application 360 may probe the user to provide more information based on the profile information entered.  For example, the application 360 may identify that a\nparticular interest or hobby can be further refined.  The application 360 can then provide an interface for the user to provide further information that better refines the interest in the profile.\nOnce the user has entered in their basic profile information the application 360 proceeds to enhance the user's profile.  This is illustrated at step 520.  The application 360 enhances the user profile by accessing social networks related to the\nindividual.  The application 360 can query the users for information from the profiles 365 maintained by any number of social networks.  In order to obtain this profile information from the social networks the user may be presented with an interface\nwhere they can enter in information related to the various social networks that they belong to.  This interface can present to the user a list of known social networks, and ask the user to provide their credentials to each of the social networks that\nthey wish to share information with the application 360.  In other approaches the user merely provides the information necessary for the profile builder 362 to locate and access their profile on the social networks.  The profile builder 362 access the\nuser's profile and gathers their profile information from the corresponding social network.  The profile builder 362 can use any means that is permitted by the social network to gather the profile information.  This can, for example, include using\napplication 360 programming interfaces exposed by the social network, or viewing the profile on the social network and scraping the data contained in the account.\nThe profile builder 362 may further gather information about the user from other sources outside of the social networks.  For example, the profile builder 362 may search the computer or devices of the user for additional information related to\nthe user that may be helpful in generating the profile for the user.  The profile builder 362 may access a browser history for the user, the user's calendar, photos, documents, etc, and obtain information from these sources.  This information may include\nthe actual data from the sources, or may include metadata from the sources, such as location data or tags in a photograph.  Further, the user can choose to provide the application 360, and hence the profile builder 362 information from non-social network\nsources.  This can include information that is held by other companies, such as travel agencies, airlines, hotels, banks, etc. The profile builder 362 can access these sites of information to gather additional information that may be relevant to the\ngeneration of the enhanced profile for the user, such as travel plans, or bank balances.\nOnce the various information from the various sources of information have been gathered, the profile builder 362 proceeds to build a profile for the user with the application 360.  This is illustrated at step 530.  The profile builder 362 can\nuse any method for building the profile from the information gathered from the various sources by the profile builder 362, and the information that was provided by the user in the creation of the initial profile.  Once the profile is completed it is\nstored.\nFollowing the completion of the generation of the profiles 365 for the users of the system, the application 360 monitors various sources of information to identify trigger events.  This is illustrated at step 540.  These trigger events can be\nevents that the provider of the application 360 has determined to be conditions that they desire to cause an alert to be generated.  For example, an airline may desire to have a trigger event when they have 10 empty seats on a particular flight to a\nspecific definition.  For example, the airline may determine that if there are 10 seats from Minneapolis to Cancun Mexico in February for sale less than 10 days prior to departure that there may be demand for this trip, but that individuals may not be\naware of the excess capacity and may be interested in this trip.  In another example, a bus company may have an unreserved bus that could be rented by a group if they were made aware of it.  In yet another example a concert venue may have extra tickets\nfor a show that they would like to sell.  The application 360 can monitor for any number of trigger events that have been designated by the provider of the application 360.  Further, in some embodiments, the application 360 can identify the trigger\nevents on its own.  In some embodiments, the users of the application 360 can create trigger events.  For example, a group of people have rented a bus to go on a ski trip.  However, they have a few empty seats left that they desire to fill.  One of the\nmembers of this group can create a trigger event for the open seats on the bus for the ski trip.\nWhen a trigger event is detected the application 360 proceeds to generate a group or groups that may be interested in the trigger event.  This is illustrated at step 550.  Each trigger event has a set of profile characteristics associated with\nit that can be matched to profiles 365 maintained by the application 360.  The application 360 searches the profiles 365 to find individual members who have profiles 365 that indicate that they may be interested in the trigger event.  For each individual\nidentified the group association component looks for other individuals who match the profile of the trigger event, and also match profile of the particular individual.  For example, the group association component may look at the individual's friend list\nand the profiles 365 associated with those friends to determine if any of those friends have profiles 365 that match the trigger event as well.  Individuals that are determined to match the profiles 365 are then aggregated into a new group.  Depending on\nthe parameters of the trigger event, the size of the group may be capped.  If the size of the group is capped the group association component of the application 360 may rank the individuals of the group based on performing a ranking of the matching of\nthe profiles 365 of the members.  This ranking may consider how close the profiles 365 of the individuals are to each other, such that profiles 365 that are more similar to the individuals are ranked higher.  In this way individuals with closer profiles\n365 are considered for the group.  In some embodiments, the group association module can go beyond the profiles 365 of the friend list of the individual, and into the \"friends of friends\" and further to find profiles 365 of individuals that the\nindividual does not know, but may have similar interests and profiles 365.  Once a number of individual profiles 365 are found the group is formed.  A number of groups may be formed at this step by the group association module.  These multiple groups may\nbe related to each other, may have some cross over in members between them, or may be completely separate memberships.  In some embodiments, in identifying the individuals, the calendars of the individuals are considered.  That is they are only selected\nif their calendar indicates that they are free during the time period of the associated activity.\nOnce the group has been formed an offer to the group can be created by the application 360.  This is illustrated at step 560.  In some embodiments, the application 360 may be pre-programmed with the offer to provide to the group.  For example,\nan airline may have determined that if there are 10 seats to Cancun that the airline would offer the group a 30% discount on the going airfare to a group of 5 people.  In some embodiments, the application 360 can alert an administrator (or other\nindividual) associated with the application 360 that a particular trigger event has occurred, and that one or more groups have been identified that meet the conditions of the trigger event.  The administrator can then create an offer at that time for the\ngroups.  The administrator can also, in some embodiments, view the profiles 365 of the groups in determining what offer to make to the groups.  In some embodiments, the application 360 can create an offer package for the group of multiple items.  In\nthese embodiments, the application 360 can create, for example, a travel package of airfare, hotel, lift tickets, etc, for the group that creates an entire trip.  The application 360 can use the profiles 365 of the members of the group to select the\nvarious items to offer from the catalogue.  To identify the items that can be grouped together for the offer the application 360 may pass the group profile through the recommender system.\nOnce the offer is prepared it is provided to the members of the group.  This is illustrated at step 570.  The members of the group can then act upon the offer.  This is illustrated at step 580.  In some embodiments, the offer requires the group\nto act on the offer as a group and not as individuals.  The application 360 can further update the profiles 365 of the members to indicate whether the offer was accepted by the group or rejected (e.g. not acted upon) by the group.  This information\nallows for the application 360 to refine its models as to which groups are provided with the offers.  Further, when the offer is accepted by one group, the offer can be rescinded from the other groups that were offered the offer.\nFIG. 6 is a flow diagram of a process for providing recommendations that go against a currently existing profile for an individual or a group, according to illustrative embodiments.  A contrary recommendation is provided to the user when there\nis other information available to the application 360 that indicates that the normal profile is inappropriate.  Conditions where the current profile is not appropriate could arise from, for example, an injury to the person, a change in dietary\npreferences, a change in weather, a religious holiday, a change in the location, etc. Typically, these conditions are only temporary in nature, and as such, do not require the regeneration or wholesale updating of the user's profile, as the temporary\nnature of the condition means that the original profile will again be relevant.  The process discussed herein can be implemented using the natural language processing system discussed above with respect to FIGS. 1 and 2, and the recommender systems\ndiscussed above with respect to FIG. 3.\nThe process begins by accessing or obtaining the user's profile.  This is illustrated at step 610.  The user's profile is in some embodiments, obtained from the profile store.  The profile can either be an individual profile or a group profile. \nThis profile can be generated by any method of generating a user profile.  In some embodiments, the profiles 365 are the profiles that were generated for use by the application 360 in FIG. 4 or 5.  In some embodiments, the profiles 365 are generated\naccording to the processes discussed above.  If the user does not have a profile in profile store the profile can be generated at this step.\nOnce the profile has been accessed the application 360 examines the data behind the profile to determine if a condition has occurred that could indicate that the current profile is not appropriate for making recommendations.  This is illustrated\nat step 620.  At this step the application 360 processes the data from the various data sources to determine if there is an indication that a trigger condition has occurred to the user.  These trigger conditions can be predefined by the application 360,\nor they may be learned using machine learning techniques.  For example, during a scrape of the user's social media feed, the application 360 finds a post that indicates that the individual was recently at the hospital for a sprained ankle, and will be\nunable to run for 2 weeks.  This application 360 determines that this post is a trigger condition that has occurred.  In another example, the application 360 during a scrape finds a post from a member of a group that indicates that the group has spent\nthe past five days eating pub food.  This post would be considered a trigger condition.  Again, the application 360 using the natural language processing system can identify any number of trigger conditions.  The trigger conditions are annotated or\ntagged with information that indicates what activities are incompatible with the trigger condition.  In the example of the sprained ankle, activities that involve running or extensive walking would be noted as incompatible, while stationary or minimal\nwalking activities would be considered compatible.  In the example of eating pub food for 5 days straight, recommendations for high fat high caloric restaurants can be considered incompatible with this condition, while healthy eating establishments would\nbe considered compatible.\nFollowing the determination of a trigger condition the application 360 determines the duration of the trigger condition.  This is illustrated at step 625.  The application 360 can use the natural language processing system determine the duration\nof the trigger condition.  For example, in the case of the sprained ankle, the application 360 would determine that the trigger condition will last 2 weeks based off of the information in the post.  In some instances, the application 360 accesses other\nsources of information to determine the duration of the trigger condition.  For example, if the post about the sprain did not include how long they would be out, the application 360 can access the internet or other sources, and determine how long it\nusually takes to recover from a sprained ankle.  With this information, the application 360 would assign the trigger condition the determined duration for the condition.\nThese determined trigger conditions are stored in the profile store along with the associated profile.  This is illustrated at step 630.  This association allows the recommender engine to acquire the trigger conditions as well as the associated\nprofile.  In some embodiments, the trigger conditions are added into the user profile.  In some embodiments, a pointer to the trigger conditions is inserted in the profile, and the trigger conditions exist as a separate part of the profile store.  Also\nstored with the trigger conditions is an indication of a duration of the trigger condition.  Again, it should be noted that the trigger conditions does not modify the underlying profile.\nThe application 360 proceeds to operate as normal, and at some point after the formation of the trigger condition a recommendation is requested.  This is illustrated at step 640.  This recommendation request could come from the application 360\nresponding to a trigger event, such as the trigger events discussed above.  In some embodiments, the user may ask for a recommendation from the application 360.  In other embodiments, the user may request or receive a recommendation from other\napplications.\nThe recommendation is generated by recommender system in response to the recommendation request.  This is illustrated at step 650.  The recommender system generates the recommendation based on the information contained in the profile.  This\nrecommendation or list of recommendations can be passed to the application 360.  In some embodiments, the recommendation system uses the trigger conditions to filter recommendations that are provided to the application 360.  For example, if the profile\nindicates that the individual likes to run, the recommender system may generate as a top recommendation a location that has fantastic running conditions and locations.  However, because the individual has recently sprained their ankle this recommendation\nis less likely to be valuable to them.  The recommender engine can access the trigger conditions associated with the profile to augment the profile.  Using the trigger conditions the recommender engine can filter out recommendations that are incompatible\nwith trigger conditions.\nThe recommendations are provided to the application 360.  This is illustrated at step 660.  The application 360 can review the recommendations that are provided by the recommender system to determine if the recommendations are appropriate for\nthe user.  The application 360 can access the trigger conditions associated with the profile and compare the recommendations to the trigger conditions.  If recommendations are found that are not compatible with the trigger conditions, the application 360\ncan filter these recommendations from the output that is generated and presented to the user.  This application 360 can perform this filtering regardless if the recommendation system employed the filters as well.  The user is then presented with\nrecommendations that take into account the restraints that are caused by the trigger condition.  The display of the recommendations to the user is illustrated at step 670.\nFIG. 7 is a flow chart illustrating a process, according to embodiments, of providing proactive recommendations of recreational activities.  The recommendations can be based on matching of stored detailed information and publicly available data,\nhistorical data about an individual or groups of individuals, with available public and licensed information about activities within a particular distance range from a given location, taking several external factors in consideration, such as the\nlocation, the date, the current weather, travel warnings, and special events/offers taking place within a predetermined range of a particular location.\nThe system will also review the feedback from licensed or publicly available data feedback from each activity to learn about the quality of the recommended activity, its popularity, and the compatibility of the activity based on the insights\nprovided by the review data.  The system leverages the wisdom of the crowds, found as unstructured data across the Internet (i.e., to find ideal activities, and provides context on the activity itself (i.e. an activity might be popular but has bad\nreviews), and context related to the user (i.e. individuals similar to you prefer activity x).\nThe system extracts insight into the individual and his companion's information, and separately, it extracts insight into available activities, based on the available data.  The system then acts as a broker, linking each individual or group of\nindividuals, with the ideal available set of activities.  Both parties (individual and activity provider) benefit from enabling them to find each other.  The individual is able to do the activities that they would enjoy the most during a limited window\nof time at a location (either familiar or unfamiliar, local or remote, etc.), and the activity provider benefits by increasing business based on customer affinity and positive feedback from previous customers.\nThe system is in some embodiments adaptable, self-learning and self-tuning, to increase the accuracy of its recommendations over time.  The system receives feedback from its users, after a recommendation is suggested, or the recommendation is\ntaken by the user (e.g. through \"I recommend\" feedback button).  This information is then provided back to the recommender engine for tuning of the recommendations that are provided.\nThe system enables the users (individuals using the application) to provide their profile information.  This is illustrated at step 710.  This can be done with, for example, a simple questionnaire, or with getting their data feed from their\nsocial network of their choice (e.g. Facebook, Twitter, etc.).  The processes discussed above with respect to FIGS. 4-6 for generating a profile can be used at this step.\nThe system stores key information that can be used to match individuals as against available activities.  This is illustrated at step 720.  Some of the data obtained can include things, places or events that the individuals indicated or were\ndetermined by the profile builder that they like, personality insights from their write ups, aggregation of data obtained via background images from their pictures (beach photos, nature photos, sport activities, etc.).  This information can is stored\nwith the profiles in the profile store.\nThe system will store the same information above, for other users of the system, and can indicate that they're part of the same travel group as other users.  This is illustrated at step 730.  This will generate an additional \"travel group\nprofile\", which as its own entity, will have its own weighted set of aggregated interests, personality, dislikes, etc. Additional members of a travel party can be added by providing a profile with public data (e.g. Twitter, Facebook, blogs, social media,\netc.), so the system can automatically determine their personality and other insights, and add them as part of the \"travel group profile\".  Groups can also be either pre-designated by the user or cognitively defined through the user's regular social\nmedia contacts/friends).  The size of the group can be limited to a threshold number of members.  For example, the group may be limited to 5 people.  However, a travel group can have any number of members.  Again the group may be formed manually by one\nof the users or automatically by the system based a threshold number of common interests between users.\nThe system identifies the key metadata about activities at different locations and stores this information.  This is illustrated at step 740.  The identification of locations and activities can be done using the processes discussed above with\nrespect to FIGS. 4-6.  Each activity will have its own logical profile that will determine its popularity, rating, and affinity with potential individuals.  Each activity can have a corresponding profile in the profiles store 365.  Each activity can have\na \"quality rating\" to prevent the recommendation engine 350 from suggesting activities with a high consensus of low quality, and also adjusting a highly popular activity that may not be as good quality (i.e. tourist traps).  The system can determine the\nsentiment of written text, sound or video about a particular activity, and aggregate this information in the \"quality ranking\" method.\nThe system can also create profiles for the authors of the reviews.  This is illustrated at step 745.  The system can, for example, store metadata information about authors of articles, reviews, or blogs about a particular activity, and provide\npersonality insights and other methods to determine a profile for those authors and/or reviewers, and their rating/opinion of that particular activity, to be used as a factor to determine affinity of the activity with individuals with similar interests. \nIt will also determine this rank information for other activities talked about by this author.  These are stored as author profiles within the profile store.\nThe system identifies matches of the user profile and/or the \"travel group profile\" with other similar user profiles, \"activity profiles\" and \"author profiles\".  This is illustrated at step 750.  The system can then assign a rank of similarity\nbetween these users.  This ranking system will allow the system to uncover activities that may be of interest to users based on people similar and with similar interests that may not have been suggested otherwise.\nThe system determines and provides a list of suggested activities (or recommendations) for any user of the application 360, based on their current location.  This is illustrated at step 760.  The system matches the travel profile, or travel\ngroup profile, with activities that are in close proximity to their current (or specified) location.  The activities will be determined based on the type of activity (food, sport, nightlife, etc.).  For the specified type of activity, the system searches\nfor available options within a distance range of the user's location.  The distance range can be input by the user when creating their corresponding profile, or can be determined by the application/system.  For each activity determines if this is a\nfeasible activity based on the date/time, season and weather.  For example: Is the activity only open during summer? Is a concert that is during the weekend? Is there a storm coming that may affect the suggested activity? In some embodiments, the system\ncan determine a weighed recommendation, by matching the available pool of high \"quality ranking\" activities that matches the user's interests, likes, and historical information (similar activities in other places).  In some embodiments, the system adds\nas a factor for consideration of the recommendation, affinity with other users and \"authors\" that have recommended the activity.\nThe system returns to the application 360 a result list of recommendations.  This is illustrated at step 770.  The recommendations can include the probability that the individual/travel group will like the specific activity (e.g. Activity A 90%\nchance; Activity B--85% chance).  The individual/individual group will have the chance to provide immediate feedback (e.g. \"do not recommend again\"), and/or experienced feedback (e.g. \"I recommend\", \"did not like\", \"more recommendations like this\",\netc.).  Individual groups will also have the chance to provide feedback as individual and vote to determine what is the consensus of the group.  The individual can also provide their feedback in real time to provide better insights into the time and\nlocation of when the individual had positive or negative experience during their trip, and allow the system to replicate the highlights of their trip in future travel occasions.  This information can be fed back to the recommendation system 300 and/or\ninto the associated profiles for the corresponding activities, users, authors, etc. in order to update the corresponding information.\nReferring now to FIG. 8, shown is a high-level block diagram of an example computer system 801 that may be used in implementing one or more of the methods, tools, and modules, and any related functions, described herein (e.g., using one or more\nprocessor circuits or computer processors of the computer), in accordance with embodiments of the present disclosure.  In some embodiments, the major components of the computer system 801 may comprise one or more CPUs 802, a memory subsystem 804, a\nterminal interface 812, a storage interface 816, an I/O (Input/Output) device interface 814, and a network interface 818, all of which may be communicatively coupled, directly or indirectly, for inter-component communication via a memory bus 803, an I/O\nbus 808, and an I/O bus interface unit 810.\nThe computer system 801 may contain one or more general-purpose programmable central processing units (CPUs) 802A, 802B, 802C, and 802D, herein generically referred to as the CPU 802.  In some embodiments, the computer system 801 may contain\nmultiple processors typical of a relatively large system; however, in other embodiments the computer system 801 may alternatively be a single CPU system.  Each CPU 802 may execute instructions stored in the memory subsystem 804 and may include one or\nmore levels of on-board cache.\nSystem memory 804 may include computer system readable media in the form of volatile memory, such as random access memory (RAM) 822 or cache memory 824.  Computer system 801 may further include other removable/non-removable,\nvolatile/non-volatile computer system storage media.  By way of example only, storage system 826 can be provided for reading from and writing to a non-removable, non-volatile magnetic media, such as a \"hard drive.\" Although not shown, a magnetic disk\ndrive for reading from and writing to a removable, non-volatile magnetic disk (e.g., a \"floppy disk\"), or an optical disk drive for reading from or writing to a removable, non-volatile optical disc such as a CD-ROM, DVD-ROM or other optical media can be\nprovided.  In addition, memory 804 can include flash memory, e.g., a flash memory stick drive or a flash drive.  Memory devices can be connected to memory bus 803 by one or more data media interfaces.  The memory 804 may include at least one program\nproduct having a set (e.g., at least one) of program modules that are configured to carry out the functions of various embodiments.\nAlthough the memory bus 803 is shown in FIG. 8 as a single bus structure providing a direct communication path among the CPUs 802, the memory subsystem 804, and the I/O bus interface 810, the memory bus 803 may, in some embodiments, include\nmultiple different buses or communication paths, which may be arranged in any of various forms, such as point-to-point links in hierarchical, star or web configurations, multiple hierarchical buses, parallel and redundant paths, or any other appropriate\ntype of configuration.  Furthermore, while the I/O bus interface 810 and the I/O bus 808 are shown as single respective units, the computer system 801 may, in some embodiments, contain multiple I/O bus interface units 810, multiple I/O buses 808, or\nboth.  Further, while multiple I/O interface units are shown, which separate the I/O bus 808 from various communications paths running to the various I/O devices, in other embodiments some or all of the I/O devices may be connected directly to one or\nmore system I/O buses.\nIn some embodiments, the computer system 801 may be a multi-user mainframe computer system, a single-user system, or a server computer or similar device that has little or no direct user interface, but receives requests from other computer\nsystems (clients).  Further, in some embodiments, the computer system 801 may be implemented as a desktop computer, portable computer, laptop or notebook computer, tablet computer, pocket computer, telephone, smart phone, network switches or routers, or\nany other appropriate type of electronic device.\nIt is noted that FIG. 8 is intended to depict the representative major components of an exemplary computer system 801.  In some embodiments, however, individual components may have greater or lesser complexity than as represented in FIG. 5,\ncomponents other than or in addition to those shown in FIG. 8 may be present, and the number, type, and configuration of such components may vary.\nOne or more programs/utilities 828, each having at least one set of program modules 830 may be stored in memory 804.  The programs/utilities 828 may include a hypervisor (also referred to as a virtual machine monitor), one or more operating\nsystems, one or more application programs, other program modules, and program data.  Each of the operating systems, one or more application programs, other program modules, and program data or some combination thereof, may include an implementation of a\nnetworking environment.  Programs 828 and/or program modules 830 generally perform the functions or methodologies of various embodiments.\nIt is to be understood that although this disclosure includes a detailed description on cloud computing, implementation of the teachings recited herein are not limited to a cloud computing environment.  Rather, embodiments of the present\ninvention are capable of being implemented in conjunction with any other type of computing environment now known or later developed.\nCloud computing is a model of service delivery for enabling convenient, on-demand network access to a shared pool of configurable computing resources (e.g., networks, network bandwidth, servers, processing, memory, storage, applications, virtual\nmachines, and services) that can be rapidly provisioned and released with minimal management effort or interaction with a provider of the service.  This cloud model may include at least five characteristics, at least three service models, and at least\nfour deployment models.\nCharacteristics are as follows:\nOn-demand self-service: a cloud consumer can unilaterally provision computing capabilities, such as server time and network storage, as needed automatically without requiring human interaction with the service's provider.\nBroad network access: capabilities are available over a network and accessed through standard mechanisms that promote use by heterogeneous thin or thick client platforms (e.g., mobile phones, laptops, and PDAs).\nResource pooling: the provider's computing resources are pooled to serve multiple consumers using a multi-tenant model, with different physical and virtual resources dynamically assigned and reassigned according to demand.  There is a sense of\nlocation independence in that the consumer generally has no control or knowledge over the exact location of the provided resources but may be able to specify location at a higher level of abstraction (e.g., country, state, or datacenter).\nRapid elasticity: capabilities can be rapidly and elastically provisioned, in some cases automatically, to quickly scale out and rapidly released to quickly scale in. To the consumer, the capabilities available for provisioning often appear to\nbe unlimited and can be purchased in any quantity at any time.\nMeasured service: cloud systems automatically control and optimize resource use by leveraging a metering capability at some level of abstraction appropriate to the type of service (e.g., storage, processing, bandwidth, and active user accounts). Resource usage can be monitored, controlled, and reported, providing transparency for both the provider and consumer of the utilized service.\nService Models are as follows:\nSoftware as a Service (SaaS): the capability provided to the consumer is to use the provider's applications running on a cloud infrastructure.  The applications are accessible from various client devices through a thin client interface such as a\nweb browser (e.g., web-based e-mail).  The consumer does not manage or control the underlying cloud infrastructure including network, servers, operating systems, storage, or even individual application capabilities, with the possible exception of limited\nuser-specific application configuration settings.\nPlatform as a Service (PaaS): the capability provided to the consumer is to deploy onto the cloud infrastructure consumer-created or acquired applications created using programming languages and tools supported by the provider.  The consumer\ndoes not manage or control the underlying cloud infrastructure including networks, servers, operating systems, or storage, but has control over the deployed applications and possibly application hosting environment configurations.\nInfrastructure as a Service (IaaS): the capability provided to the consumer is to provision processing, storage, networks, and other fundamental computing resources where the consumer is able to deploy and run arbitrary software, which can\ninclude operating systems and applications.  The consumer does not manage or control the underlying cloud infrastructure but has control over operating systems, storage, deployed applications, and possibly limited control of select networking components\n(e.g., host firewalls).\nDeployment Models are as follows:\nPrivate cloud: the cloud infrastructure is operated solely for an organization.  It may be managed by the organization or a third party and may exist on-premises or off-premises.\nCommunity cloud: the cloud infrastructure is shared by several organizations and supports a specific community that has shared concerns (e.g., mission, security requirements, policy, and compliance considerations).  It may be managed by the\norganizations or a third party and may exist on-premises or off-premises.\nPublic cloud: the cloud infrastructure is made available to the general public or a large industry group and is owned by an organization selling cloud services.\nHybrid cloud: the cloud infrastructure is a composition of two or more clouds (private, community, or public) that remain unique entities but are bound together by standardized or proprietary technology that enables data and application\nportability (e.g., cloud bursting for load-balancing between clouds).\nA cloud computing environment is service oriented with a focus on statelessness, low coupling, modularity, and semantic interoperability.  At the heart of cloud computing is an infrastructure that includes a network of interconnected nodes.\nThe systems 100, 200, 300 may be employed in a cloud computing environment.  FIG. 9, is a diagrammatic representation of an illustrative cloud computing environment 950 according to one embodiment.  As shown, cloud computing environment 950\ncomprises one or more cloud computing nodes 910 with which local computing devices used by cloud consumers, such as, for example, personal digital assistant (PDA) or cellular telephone 954A, desktop computer 954B, laptop computer 954C, and/or automobile\ncomputer system 954N may communicate.  Nodes 910 may communicate with one another.  They may be grouped (not shown) physically or virtually, in one or more networks, such as Private, Community, Public, or Hybrid clouds as described hereinabove, or a\ncombination thereof.  This allows cloud computing environment 950 to offer infrastructure, platforms and/or software as services for which a cloud consumer does not need to maintain resources on a local computing device.  It is understood that the types\nof computing devices 954A-N shown in FIG. 9 are intended to be illustrative only and that computing nodes 10 and cloud computing environment 950 may communicate with any type of computerized device over any type of network and/or network addressable\nconnection (e.g., using a web browser).\nReferring now to FIG. 10, a set of functional abstraction layers provided by cloud computing environment 950 (FIG. 9) is shown.  It should be understood in advance that the components, layers, and functions shown in FIG. 10 are intended to be\nillustrative only and embodiments of the disclosure are not limited thereto.  As depicted, the following layers and corresponding functions are provided:\nHardware and software layer 1060 includes hardware and software components.  Examples of hardware components include: mainframes 1061; RISC (Reduced Instruction Set Computer) architecture based servers 1062; servers 1063; blade servers 1064;\nstorage devices 1065; and networks and networking components 1066.  In some embodiments, software components include network application server software 1067 and database software 1068.\nVirtualization layer 1070 provides an abstraction layer from which the following examples of virtual entities may be provided: virtual servers 1071; virtual storage 1072; virtual networks 1073, including virtual private networks; virtual\napplications and operating systems 1074; and virtual clients 1075.\nIn one example, management layer 1080 may provide the functions described below.  Resource provisioning 1081 provides dynamic procurement of computing resources and other resources that are utilized to perform tasks within the cloud computing\nenvironment.  Metering and Pricing 1082 provide cost tracking as resources are utilized within the cloud computing environment, and billing or invoicing for consumption of these resources.  In one example, these resources may comprise application\nsoftware licenses.  Security provides identity verification for cloud consumers and tasks, as well as protection for data and other resources.  User portal 1083 provides access to the cloud computing environment for consumers and system administrators. \nService level management 1084 provides cloud computing resource allocation and management such that required service levels are met.  Service Level Agreement (SLA) planning and fulfillment 1085 provide pre-arrangement for, and procurement of, cloud\ncomputing resources for which a future requirement is anticipated in accordance with an SLA.\nWorkloads layer 1090 provides examples of functionality for which the cloud computing environment may be utilized.  Examples of workloads and functions which may be provided from this layer include: mapping and navigation 1091; software\ndevelopment and lifecycle management 1092; virtual classroom education delivery 1093; data analytics processing 1094; transaction processing 1095; and database 1096.\nThe present invention may be a system, a method, and/or a computer program product at any possible technical detail level of integration.  The computer program product may include a computer readable storage medium (or media) having computer\nreadable program instructions thereon for causing a processor to carry out aspects of the present invention.\nThe computer readable storage medium can be a tangible device that can retain and store instructions for use by an instruction execution device.  The computer readable storage medium may be, for example, but is not limited to, an electronic\nstorage device, a magnetic storage device, an optical storage device, an electromagnetic storage device, a semiconductor storage device, or any suitable combination of the foregoing.  A non-exhaustive list of more specific examples of the computer\nreadable storage medium includes the following: a portable computer diskette, a hard disk, a random access memory (RAM), a read-only memory (ROM), an erasable programmable read-only memory (EPROM or Flash memory), a static random access memory (SRAM), a\nportable compact disc read-only memory (CD-ROM), a digital versatile disk (DVD), a memory stick, a floppy disk, a mechanically encoded device such as punch-cards or raised structures in a groove having instructions recorded thereon, and any suitable\ncombination of the foregoing.  A computer readable storage medium, as used herein, is not to be construed as being transitory signals per se, such as radio waves or other freely propagating electromagnetic waves, electromagnetic waves propagating through\na waveguide or other transmission media (e.g., light pulses passing through a fiber-optic cable), or electrical signals transmitted through a wire.\nComputer readable program instructions described herein can be downloaded to respective computing/processing devices from a computer readable storage medium or to an external computer or external storage device via a network, for example, the\nInternet, a local area network, a wide area network and/or a wireless network.  The network may comprise copper transmission cables, optical transmission fibers, wireless transmission, routers, firewalls, switches, gateway computers and/or edge servers. \nA network adapter card or network interface in each computing/processing device receives computer readable program instructions from the network and forwards the computer readable program instructions for storage in a computer readable storage medium\nwithin the respective computing/processing device.\nComputer readable program instructions for carrying out operations of the present invention may be assembler instructions, instruction-set-architecture (ISA) instructions, machine instructions, machine dependent instructions, microcode, firmware\ninstructions, state-setting data, configuration data for integrated circuitry, or either source code or object code written in any combination of one or more programming languages, including an object oriented programming language such as Smalltalk, C++,\nor the like, and procedural programming languages, such as the \"C\" programming language or similar programming languages.  The computer readable program instructions may execute entirely on the user's computer, partly on the user's computer, as a\nstand-alone software package, partly on the user's computer and partly on a remote computer or entirely on the remote computer or server.  In the latter scenario, the remote computer may be connected to the user's computer through any type of network,\nincluding a local area network (LAN) or a wide area network (WAN), or the connection may be made to an external computer (for example, through the Internet using an Internet Service Provider).  In some embodiments, electronic circuitry including, for\nexample, programmable logic circuitry, field-programmable gate arrays (FPGA), or programmable logic arrays (PLA) may execute the computer readable program instructions by utilizing state information of the computer readable program instructions to\npersonalize the electronic circuitry, in order to perform aspects of the present invention.\nAspects of the present invention are described herein with reference to flowchart illustrations and/or block diagrams of methods, apparatus (systems), and computer program products according to embodiments of the invention.  It will be\nunderstood that each block of the flowchart illustrations and/or block diagrams, and combinations of blocks in the flowchart illustrations and/or block diagrams, can be implemented by computer readable program instructions.\nThese computer readable program instructions may be provided to a processor of a general purpose computer, special purpose computer, or other programmable data processing apparatus to produce a machine, such that the instructions, which execute\nvia the processor of the computer or other programmable data processing apparatus, create means for implementing the functions/acts specified in the flowchart and/or block diagram block or blocks.  These computer readable program instructions may also be\nstored in a computer readable storage medium that can direct a computer, a programmable data processing apparatus, and/or other devices to function in a particular manner, such that the computer readable storage medium having instructions stored therein\ncomprises an article of manufacture including instructions which implement aspects of the function/act specified in the flowchart and/or block diagram block or blocks.\nThe computer readable program instructions may also be loaded onto a computer, other programmable data processing apparatus, or other device to cause a series of operational steps to be performed on the computer, other programmable apparatus or\nother device to produce a computer implemented process, such that the instructions which execute on the computer, other programmable apparatus, or other device implement the functions/acts specified in the flowchart and/or block diagram block or blocks.\nThe flowchart and block diagrams in the Figures illustrate the architecture, functionality, and operation of possible implementations of systems, methods, and computer program products according to various embodiments of the present invention. \nIn this regard, each block in the flowchart or block diagrams may represent a module, segment, or portion of instructions, which comprises one or more executable instructions for implementing the specified logical function(s).  In some alternative\nimplementations, the functions noted in the blocks may occur out of the order noted in the Figures.  For example, two blocks shown in succession may, in fact, be executed substantially concurrently, or the blocks may sometimes be executed in the reverse\norder, depending upon the functionality involved.  It will also be noted that each block of the block diagrams and/or flowchart illustration, and combinations of blocks in the block diagrams and/or flowchart illustration, can be implemented by special\npurpose hardware-based systems that perform the specified functions or acts or carry out combinations of special purpose hardware and computer instructions.\nThe descriptions of the various embodiments of the present disclosure have been presented for purposes of illustration, but are not intended to be exhaustive or limited to the embodiments disclosed.  Many modifications and variations will be\napparent to those of ordinary skill in the art without departing from the scope and spirit of the described embodiments.  The terminology used herein was chosen to explain the principles of the embodiments, the practical application or technical\nimprovement over technologies found in the marketplace, or to enable others of ordinary skill in the art to understand the embodiments disclosed herein.", "application_number": "15646304", "abstract": " A system and method for providing counter intuitive recommendations to a\n     user. A user profile is obtained for the user. A determination that a\n     trigger condition has occurred for the user. The duration of the trigger\n     condition is also determined. The trigger condition is associated with\n     the user's profile. A request for a recommendation is received, and a\n     list of recommendations is obtained. The recommendations are compared\n     against the trigger condition to determine if the recommendation is\n     compatible with the trigger condition. Those recommendations determined\n     not to be compatible with the trigger condition are removed from the set\n     of recommendations provided to the user.\n", "citations": ["6370513", "7092936", "8103540", "8606801", "8620764", "9307378", "9355361", "9384661", "9390706", "9448693", "9501764", "9509642", "9563404", "9584583", "9600571", "9760609", "9818088", "20070210938", "20100094878", "20100169131", "20130268302", "20130339341", "20130346124", "20140095599", "20140278071", "20140278601", "20140297672", "20150019342", "20150019710", "20150276419", "20150278225", "20150356201", "20150356417", "20150356441", "20160069705", "20160165402", "20160178376", "20160180723"], "related": []}]